{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de classification finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = pd.read_csv('corpus_en_notes.csv',index_col=0)\n",
    "anglais = anglais.reset_index(drop=True)\n",
    "anglais2 = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "anglais2 = anglais.reset_index(drop=True)\n",
    "# attention, il faut les memes colonnes\n",
    "anglais2 = anglais[anglais.columns]\n",
    "anglais = pd.concat([anglais,anglais2],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention certains textes ne sont pas fournies et donc mis en \"Error\" : A supprimer donc\n",
    "# On pourrait éventuellement tester en ne prenant plus les meth similarités ds les predicteurs\n",
    "anglais = anglais[anglais.meth1_similarites!='Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>...</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>Haiti’s leader marks independence day amid sec...</td>\n",
       "      <td>MARTINSBURG, W.Va. — A suspected drunken drive...</td>\n",
       "      <td>PORT-AU-PRINCE, Haiti — Haitian President Jove...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.79</td>\n",
       "      <td>51.00</td>\n",
       "      <td>10.42</td>\n",
       "      <td>8.33</td>\n",
       "      <td>32.09</td>\n",
       "      <td>13.47</td>\n",
       "      <td>99.20</td>\n",
       "      <td>818.0</td>\n",
       "      <td>231.9</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Fire kills more than 30 animals at zoo in west...</td>\n",
       "      <td>Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2.91</td>\n",
       "      <td>10.57</td>\n",
       "      <td>8.34</td>\n",
       "      <td>28.15</td>\n",
       "      <td>92.87</td>\n",
       "      <td>99.04</td>\n",
       "      <td>129.5</td>\n",
       "      <td>174.9</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>Trump says he does not expect war with Iran, ‘...</td>\n",
       "      <td>(Breitbart) – President Donald Trump welcomed ...</td>\n",
       "      <td>PALM BEACH, United States — US President Donal...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>27.45</td>\n",
       "      <td>9.68</td>\n",
       "      <td>13.14</td>\n",
       "      <td>8.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>96.75</td>\n",
       "      <td>827.2</td>\n",
       "      <td>504.8</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Indian Online Food Delivery Market to Hit $8 B...</td>\n",
       "      <td>Uber has sold its online food-ordering busines...</td>\n",
       "      <td>Rapid digitisation and growth in both online b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.90</td>\n",
       "      <td>10.34</td>\n",
       "      <td>18.21</td>\n",
       "      <td>8.35</td>\n",
       "      <td>23.79</td>\n",
       "      <td>93.55</td>\n",
       "      <td>94.72</td>\n",
       "      <td>620.0</td>\n",
       "      <td>735.1</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>India targets new moon mission in 2020</td>\n",
       "      <td>BENGALURU (Reuters) - India has approved its t...</td>\n",
       "      <td>BANGALORE: India plans to make a fresh attempt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.40</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>15.76</td>\n",
       "      <td>8.35</td>\n",
       "      <td>26.28</td>\n",
       "      <td>74.48</td>\n",
       "      <td>93.05</td>\n",
       "      <td>473.0</td>\n",
       "      <td>559.4</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>3444</td>\n",
       "      <td>Migrate or Clone VMs to new vCenter at other site</td>\n",
       "      <td>vCenter Email Alerts not working anymore?</td>\n",
       "      <td>Hello,\\n\\nWe are preparing to move our environ...</td>\n",
       "      <td>I'm running vCenter 6.7 w/ three host also run...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>3445</td>\n",
       "      <td>You can now consult with your doctors through ...</td>\n",
       "      <td>Never waste a crisis</td>\n",
       "      <td>You can now consult with your doctors through ...</td>\n",
       "      <td>India is doing a commendable job in fighting t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>3446</td>\n",
       "      <td>Thai soldier who killed 20 is shot dead</td>\n",
       "      <td>Thai soldier shot dead after killing 26 in cou...</td>\n",
       "      <td>Jakraphanth Thomma on Saturday killed his comm...</td>\n",
       "      <td>Medics carry a stretcher towards a Thai shoppi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>3447</td>\n",
       "      <td>More than 80 people taken in for questioning a...</td>\n",
       "      <td>Gauteng police take in 87 people for questioni...</td>\n",
       "      <td>The bodies of the victims were found lying in ...</td>\n",
       "      <td>Johannesburg - Gauteng police on Saturday said...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>3448</td>\n",
       "      <td>Migrant caravan crosses into Mexico, walks alo...</td>\n",
       "      <td>Migrant caravan crosses into Mexico, walks alo...</td>\n",
       "      <td>CIUDAD HIDALGO, Mexico — Hundreds of Central A...</td>\n",
       "      <td>Hundreds of Central American migrants crossed ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3402 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ligne                                            title_1  \\\n",
       "0         0  Virginia man arrested in fatal DUI crash in We...   \n",
       "1         1  Guyana: Three injured after car crashes into u...   \n",
       "2         2  Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3         3  Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4         4  India approves third moon mission, months afte...   \n",
       "...     ...                                                ...   \n",
       "3591   3444  Migrate or Clone VMs to new vCenter at other site   \n",
       "3592   3445  You can now consult with your doctors through ...   \n",
       "3593   3446            Thai soldier who killed 20 is shot dead   \n",
       "3594   3447  More than 80 people taken in for questioning a...   \n",
       "3595   3448  Migrant caravan crosses into Mexico, walks alo...   \n",
       "\n",
       "                                                title_2  \\\n",
       "0     Haiti’s leader marks independence day amid sec...   \n",
       "1     Fire kills more than 30 animals at zoo in west...   \n",
       "2     Trump says he does not expect war with Iran, ‘...   \n",
       "3     Indian Online Food Delivery Market to Hit $8 B...   \n",
       "4                India targets new moon mission in 2020   \n",
       "...                                                 ...   \n",
       "3591          vCenter Email Alerts not working anymore?   \n",
       "3592                               Never waste a crisis   \n",
       "3593  Thai soldier shot dead after killing 26 in cou...   \n",
       "3594  Gauteng police take in 87 people for questioni...   \n",
       "3595  Migrant caravan crosses into Mexico, walks alo...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     MARTINSBURG, W.Va. — A suspected drunken drive...   \n",
       "1     Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...   \n",
       "2     (Breitbart) – President Donald Trump welcomed ...   \n",
       "3     Uber has sold its online food-ordering busines...   \n",
       "4     BENGALURU (Reuters) - India has approved its t...   \n",
       "...                                                 ...   \n",
       "3591  Hello,\\n\\nWe are preparing to move our environ...   \n",
       "3592  You can now consult with your doctors through ...   \n",
       "3593  Jakraphanth Thomma on Saturday killed his comm...   \n",
       "3594  The bodies of the victims were found lying in ...   \n",
       "3595  CIUDAD HIDALGO, Mexico — Hundreds of Central A...   \n",
       "\n",
       "                                                 text_2  Geography  Entities  \\\n",
       "0     PORT-AU-PRINCE, Haiti — Haitian President Jove...        4.0  4.000000   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...        4.0  4.000000   \n",
       "2     PALM BEACH, United States — US President Donal...        1.0  2.000000   \n",
       "3     Rapid digitisation and growth in both online b...        1.0  2.333333   \n",
       "4     BANGALORE: India plans to make a fresh attempt...        1.0  1.250000   \n",
       "...                                                 ...        ...       ...   \n",
       "3591  I'm running vCenter 6.7 w/ three host also run...        4.0  3.000000   \n",
       "3592  India is doing a commendable job in fighting t...        1.0  4.000000   \n",
       "3593  Medics carry a stretcher towards a Thai shoppi...        1.0  2.000000   \n",
       "3594  Johannesburg - Gauteng police on Saturday said...        1.0  1.000000   \n",
       "3595  Hundreds of Central American migrants crossed ...        1.0  1.000000   \n",
       "\n",
       "          Time  Narrative   Overall  ...  score_similarite_resume1  \\\n",
       "0     1.000000   4.000000  4.000000  ...                      3.79   \n",
       "1     1.000000   4.000000  3.666667  ...                      9.10   \n",
       "2     1.000000   2.333333  2.333333  ...                     27.45   \n",
       "3     2.666667   1.666667  2.000000  ...                     27.90   \n",
       "4     1.000000   1.250000  1.250000  ...                     32.40   \n",
       "...        ...        ...       ...  ...                       ...   \n",
       "3591  1.000000   2.000000  3.000000  ...                      0.96   \n",
       "3592  3.000000   4.000000  4.000000  ...                     14.06   \n",
       "3593  1.000000   2.000000  1.000000  ...                     40.11   \n",
       "3594  1.000000   1.000000  1.000000  ...                     29.80   \n",
       "3595  1.000000   1.000000  1.000000  ...                     44.02   \n",
       "\n",
       "      score_similarite_resume2 score_classif1 score_classif2 score_sentiment1  \\\n",
       "0                        51.00          10.42           8.33            32.09   \n",
       "1                         2.91          10.57           8.34            28.15   \n",
       "2                         9.68          13.14           8.33            25.00   \n",
       "3                        10.34          18.21           8.35            23.79   \n",
       "4                        -1.95          15.76           8.35            26.28   \n",
       "...                        ...            ...            ...              ...   \n",
       "3591                     -0.44          52.18           9.54            28.40   \n",
       "3592                      1.64          27.53           8.29            31.73   \n",
       "3593                     24.78          10.46           8.36            46.47   \n",
       "3594                     -0.50          10.97           8.42            19.91   \n",
       "3595                     16.45          16.61           8.50            18.34   \n",
       "\n",
       "     score_sentiment2  score_sentiment3  meth1_similarites  meth2_similarites  \\\n",
       "0               13.47             99.20              818.0              231.9   \n",
       "1               92.87             99.04              129.5              174.9   \n",
       "2                2.56             96.75              827.2              504.8   \n",
       "3               93.55             94.72              620.0              735.1   \n",
       "4               74.48             93.05              473.0              559.4   \n",
       "...               ...               ...                ...                ...   \n",
       "3591            97.16             99.92              289.7              418.5   \n",
       "3592             1.55             13.10               40.4              150.6   \n",
       "3593            84.41             97.96              547.7              717.2   \n",
       "3594             1.06             93.64             1364.2              440.1   \n",
       "3595            27.16             99.71             1445.6             1377.2   \n",
       "\n",
       "      Overall2  \n",
       "0     4.000000  \n",
       "1     3.666667  \n",
       "2     2.333333  \n",
       "3     2.000000  \n",
       "4     1.250000  \n",
       "...        ...  \n",
       "3591  3.000000  \n",
       "3592  4.000000  \n",
       "3593  1.000000  \n",
       "3594  1.000000  \n",
       "3595  1.000000  \n",
       "\n",
       "[3402 rows x 33 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anglais['Overall2'] = anglais.Overall\n",
    "anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = anglais.round({'Geography':0, 'Entities':0,'Time':0, 'Narrative':0, 'Overall':0, 'Style':0, 'Tone':0, 'Overall2':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "partiel = anglais[['Geography', 'Entities','Time', 'Narrative', 'Overall', 'Style', 'Tone']].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = pd.concat([anglais[['ligne', 'title_1', 'title_2', 'text_1', 'text_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2']],\n",
    "        partiel,anglais[['Overall2','nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "       'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "       'score_sentiment2', 'score_sentiment3', 'meth1_similarites', 'meth2_similarites']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>summary1_text1</th>\n",
       "      <th>summary2_text1</th>\n",
       "      <th>summary1_text2</th>\n",
       "      <th>summary2_text2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>...</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>Haiti’s leader marks independence day amid sec...</td>\n",
       "      <td>MARTINSBURG, W.Va. — A suspected drunken drive...</td>\n",
       "      <td>PORT-AU-PRINCE, Haiti — Haitian President Jove...</td>\n",
       "      <td>Cody Wade Braithwaite, 32, of Winchester, Vir...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>New Year's Day marked by protests over lack o...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.79</td>\n",
       "      <td>51.00</td>\n",
       "      <td>10.42</td>\n",
       "      <td>8.33</td>\n",
       "      <td>32.09</td>\n",
       "      <td>13.47</td>\n",
       "      <td>99.20</td>\n",
       "      <td>818.0</td>\n",
       "      <td>231.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Fire kills more than 30 animals at zoo in west...</td>\n",
       "      <td>Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>Motorcar PNN 7976 driven by 22-year-old Seera...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>Fire at a zoo in western Germany in the first...</td>\n",
       "      <td>A fire at a zoo in western Germany in the firs...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.44</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2.91</td>\n",
       "      <td>10.57</td>\n",
       "      <td>8.34</td>\n",
       "      <td>28.15</td>\n",
       "      <td>92.87</td>\n",
       "      <td>99.04</td>\n",
       "      <td>129.5</td>\n",
       "      <td>174.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>Trump says he does not expect war with Iran, ‘...</td>\n",
       "      <td>(Breitbart) – President Donald Trump welcomed ...</td>\n",
       "      <td>PALM BEACH, United States — US President Donal...</td>\n",
       "      <td>President Trump welcomed guests to Mar-a-Lago...</td>\n",
       "      <td>It’s a new year, but it’s also a new president.</td>\n",
       "      <td>U.S. President Donald Trump says he does not ...</td>\n",
       "      <td>US President Donald Trump says he does not for...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.70</td>\n",
       "      <td>27.45</td>\n",
       "      <td>9.68</td>\n",
       "      <td>13.14</td>\n",
       "      <td>8.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>96.75</td>\n",
       "      <td>827.2</td>\n",
       "      <td>504.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Indian Online Food Delivery Market to Hit $8 B...</td>\n",
       "      <td>Uber has sold its online food-ordering busines...</td>\n",
       "      <td>Rapid digitisation and growth in both online b...</td>\n",
       "      <td>Uber has sold its online food-ordering busine...</td>\n",
       "      <td>It's food for thought for Uber.</td>\n",
       "      <td>India's online food industry to become an $8 ...</td>\n",
       "      <td>\"Ordering food online is now a habit.\"</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>24.97</td>\n",
       "      <td>27.90</td>\n",
       "      <td>10.34</td>\n",
       "      <td>18.21</td>\n",
       "      <td>8.35</td>\n",
       "      <td>23.79</td>\n",
       "      <td>93.55</td>\n",
       "      <td>94.72</td>\n",
       "      <td>620.0</td>\n",
       "      <td>735.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>India targets new moon mission in 2020</td>\n",
       "      <td>BENGALURU (Reuters) - India has approved its t...</td>\n",
       "      <td>BANGALORE: India plans to make a fresh attempt...</td>\n",
       "      <td>India has approved its third lunar mission mo...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>Work is going \"smoothly\" on the Chandrayaan-3...</td>\n",
       "      <td>\"We are targeting the launch for this year but...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.21</td>\n",
       "      <td>32.40</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>15.76</td>\n",
       "      <td>8.35</td>\n",
       "      <td>26.28</td>\n",
       "      <td>74.48</td>\n",
       "      <td>93.05</td>\n",
       "      <td>473.0</td>\n",
       "      <td>559.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>3444</td>\n",
       "      <td>Migrate or Clone VMs to new vCenter at other site</td>\n",
       "      <td>vCenter Email Alerts not working anymore?</td>\n",
       "      <td>Hello,\\n\\nWe are preparing to move our environ...</td>\n",
       "      <td>I'm running vCenter 6.7 w/ three host also run...</td>\n",
       "      <td>We are preparing to move our environment to a...</td>\n",
       "      <td>Is there a way to clone VMs to a new site whil...</td>\n",
       "      <td>I'm not sure if some updates has stopped this...</td>\n",
       "      <td>I'm trying to get Office 365 to send me email ...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>3445</td>\n",
       "      <td>You can now consult with your doctors through ...</td>\n",
       "      <td>Never waste a crisis</td>\n",
       "      <td>You can now consult with your doctors through ...</td>\n",
       "      <td>India is doing a commendable job in fighting t...</td>\n",
       "      <td>The government has released the much-awaited ...</td>\n",
       "      <td>Can’t make it to the hospital? The guidelines ...</td>\n",
       "      <td>India is doing a commendable job in fighting ...</td>\n",
       "      <td>As the World Health Organization (WHO) reports...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>3446</td>\n",
       "      <td>Thai soldier who killed 20 is shot dead</td>\n",
       "      <td>Thai soldier shot dead after killing 26 in cou...</td>\n",
       "      <td>Jakraphanth Thomma on Saturday killed his comm...</td>\n",
       "      <td>Medics carry a stretcher towards a Thai shoppi...</td>\n",
       "      <td>Jakraphanth Thomma on Saturday killed his com...</td>\n",
       "      <td>Thailand's health minister has praised the sec...</td>\n",
       "      <td>Sergeant Major Jakrapanth Thomma killed 26 pe...</td>\n",
       "      <td>Thai police have shot dead a soldier who kille...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>3447</td>\n",
       "      <td>More than 80 people taken in for questioning a...</td>\n",
       "      <td>Gauteng police take in 87 people for questioni...</td>\n",
       "      <td>The bodies of the victims were found lying in ...</td>\n",
       "      <td>Johannesburg - Gauteng police on Saturday said...</td>\n",
       "      <td>The bodies of the victims were found lying in...</td>\n",
       "      <td>South African police have launched a manhunt a...</td>\n",
       "      <td>Nine Lesotho nationals stoned to death in Mat...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>3448</td>\n",
       "      <td>Migrant caravan crosses into Mexico, walks alo...</td>\n",
       "      <td>Migrant caravan crosses into Mexico, walks alo...</td>\n",
       "      <td>CIUDAD HIDALGO, Mexico — Hundreds of Central A...</td>\n",
       "      <td>Hundreds of Central American migrants crossed ...</td>\n",
       "      <td>Hundreds of Central American migrants crossed...</td>\n",
       "      <td>Members of a migrant caravan making its way fr...</td>\n",
       "      <td>Hundreds of migrants crossed the border into ...</td>\n",
       "      <td>Mexico's National Guard has been deployed alon...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3402 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ligne                                            title_1  \\\n",
       "0         0  Virginia man arrested in fatal DUI crash in We...   \n",
       "1         1  Guyana: Three injured after car crashes into u...   \n",
       "2         2  Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3         3  Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4         4  India approves third moon mission, months afte...   \n",
       "...     ...                                                ...   \n",
       "3397   3444  Migrate or Clone VMs to new vCenter at other site   \n",
       "3398   3445  You can now consult with your doctors through ...   \n",
       "3399   3446            Thai soldier who killed 20 is shot dead   \n",
       "3400   3447  More than 80 people taken in for questioning a...   \n",
       "3401   3448  Migrant caravan crosses into Mexico, walks alo...   \n",
       "\n",
       "                                                title_2  \\\n",
       "0     Haiti’s leader marks independence day amid sec...   \n",
       "1     Fire kills more than 30 animals at zoo in west...   \n",
       "2     Trump says he does not expect war with Iran, ‘...   \n",
       "3     Indian Online Food Delivery Market to Hit $8 B...   \n",
       "4                India targets new moon mission in 2020   \n",
       "...                                                 ...   \n",
       "3397          vCenter Email Alerts not working anymore?   \n",
       "3398                               Never waste a crisis   \n",
       "3399  Thai soldier shot dead after killing 26 in cou...   \n",
       "3400  Gauteng police take in 87 people for questioni...   \n",
       "3401  Migrant caravan crosses into Mexico, walks alo...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     MARTINSBURG, W.Va. — A suspected drunken drive...   \n",
       "1     Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...   \n",
       "2     (Breitbart) – President Donald Trump welcomed ...   \n",
       "3     Uber has sold its online food-ordering busines...   \n",
       "4     BENGALURU (Reuters) - India has approved its t...   \n",
       "...                                                 ...   \n",
       "3397  Hello,\\n\\nWe are preparing to move our environ...   \n",
       "3398  You can now consult with your doctors through ...   \n",
       "3399  Jakraphanth Thomma on Saturday killed his comm...   \n",
       "3400  The bodies of the victims were found lying in ...   \n",
       "3401  CIUDAD HIDALGO, Mexico — Hundreds of Central A...   \n",
       "\n",
       "                                                 text_2  \\\n",
       "0     PORT-AU-PRINCE, Haiti — Haitian President Jove...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     PALM BEACH, United States — US President Donal...   \n",
       "3     Rapid digitisation and growth in both online b...   \n",
       "4     BANGALORE: India plans to make a fresh attempt...   \n",
       "...                                                 ...   \n",
       "3397  I'm running vCenter 6.7 w/ three host also run...   \n",
       "3398  India is doing a commendable job in fighting t...   \n",
       "3399  Medics carry a stretcher towards a Thai shoppi...   \n",
       "3400  Johannesburg - Gauteng police on Saturday said...   \n",
       "3401  Hundreds of Central American migrants crossed ...   \n",
       "\n",
       "                                         summary1_text1  \\\n",
       "0      Cody Wade Braithwaite, 32, of Winchester, Vir...   \n",
       "1      Motorcar PNN 7976 driven by 22-year-old Seera...   \n",
       "2      President Trump welcomed guests to Mar-a-Lago...   \n",
       "3      Uber has sold its online food-ordering busine...   \n",
       "4      India has approved its third lunar mission mo...   \n",
       "...                                                 ...   \n",
       "3397   We are preparing to move our environment to a...   \n",
       "3398   The government has released the much-awaited ...   \n",
       "3399   Jakraphanth Thomma on Saturday killed his com...   \n",
       "3400   The bodies of the victims were found lying in...   \n",
       "3401   Hundreds of Central American migrants crossed...   \n",
       "\n",
       "                                         summary2_text1  \\\n",
       "0                           All images are copyrighted.   \n",
       "1                           All images are copyrighted.   \n",
       "2       It’s a new year, but it’s also a new president.   \n",
       "3                       It's food for thought for Uber.   \n",
       "4                           All images are copyrighted.   \n",
       "...                                                 ...   \n",
       "3397  Is there a way to clone VMs to a new site whil...   \n",
       "3398  Can’t make it to the hospital? The guidelines ...   \n",
       "3399  Thailand's health minister has praised the sec...   \n",
       "3400  South African police have launched a manhunt a...   \n",
       "3401  Members of a migrant caravan making its way fr...   \n",
       "\n",
       "                                         summary1_text2  \\\n",
       "0      New Year's Day marked by protests over lack o...   \n",
       "1      Fire at a zoo in western Germany in the first...   \n",
       "2      U.S. President Donald Trump says he does not ...   \n",
       "3      India's online food industry to become an $8 ...   \n",
       "4      Work is going \"smoothly\" on the Chandrayaan-3...   \n",
       "...                                                 ...   \n",
       "3397   I'm not sure if some updates has stopped this...   \n",
       "3398   India is doing a commendable job in fighting ...   \n",
       "3399   Sergeant Major Jakrapanth Thomma killed 26 pe...   \n",
       "3400   Nine Lesotho nationals stoned to death in Mat...   \n",
       "3401   Hundreds of migrants crossed the border into ...   \n",
       "\n",
       "                                         summary2_text2  Geography  ...  \\\n",
       "0                           All images are copyrighted.          4  ...   \n",
       "1     A fire at a zoo in western Germany in the firs...          4  ...   \n",
       "2     US President Donald Trump says he does not for...          1  ...   \n",
       "3                \"Ordering food online is now a habit.\"          1  ...   \n",
       "4     \"We are targeting the launch for this year but...          1  ...   \n",
       "...                                                 ...        ...  ...   \n",
       "3397  I'm trying to get Office 365 to send me email ...          4  ...   \n",
       "3398  As the World Health Organization (WHO) reports...          1  ...   \n",
       "3399  Thai police have shot dead a soldier who kille...          1  ...   \n",
       "3400                        All images are copyrighted.          1  ...   \n",
       "3401  Mexico's National Guard has been deployed alon...          1  ...   \n",
       "\n",
       "      score_similarite_titres  score_similarite_resume1  \\\n",
       "0                        0.80                      3.79   \n",
       "1                        6.44                      9.10   \n",
       "2                       20.70                     27.45   \n",
       "3                       24.97                     27.90   \n",
       "4                       29.21                     32.40   \n",
       "...                       ...                       ...   \n",
       "3397                    15.18                      0.96   \n",
       "3398                     4.29                     14.06   \n",
       "3399                    40.45                     40.11   \n",
       "3400                    22.58                     29.80   \n",
       "3401                    51.00                     44.02   \n",
       "\n",
       "      score_similarite_resume2  score_classif1  score_classif2  \\\n",
       "0                        51.00           10.42            8.33   \n",
       "1                         2.91           10.57            8.34   \n",
       "2                         9.68           13.14            8.33   \n",
       "3                        10.34           18.21            8.35   \n",
       "4                        -1.95           15.76            8.35   \n",
       "...                        ...             ...             ...   \n",
       "3397                     -0.44           52.18            9.54   \n",
       "3398                      1.64           27.53            8.29   \n",
       "3399                     24.78           10.46            8.36   \n",
       "3400                     -0.50           10.97            8.42   \n",
       "3401                     16.45           16.61            8.50   \n",
       "\n",
       "      score_sentiment1  score_sentiment2  score_sentiment3  meth1_similarites  \\\n",
       "0                32.09             13.47             99.20              818.0   \n",
       "1                28.15             92.87             99.04              129.5   \n",
       "2                25.00              2.56             96.75              827.2   \n",
       "3                23.79             93.55             94.72              620.0   \n",
       "4                26.28             74.48             93.05              473.0   \n",
       "...                ...               ...               ...                ...   \n",
       "3397             28.40             97.16             99.92              289.7   \n",
       "3398             31.73              1.55             13.10               40.4   \n",
       "3399             46.47             84.41             97.96              547.7   \n",
       "3400             19.91              1.06             93.64             1364.2   \n",
       "3401             18.34             27.16             99.71             1445.6   \n",
       "\n",
       "      meth2_similarites  \n",
       "0                 231.9  \n",
       "1                 174.9  \n",
       "2                 504.8  \n",
       "3                 735.1  \n",
       "4                 559.4  \n",
       "...                 ...  \n",
       "3397              418.5  \n",
       "3398              150.6  \n",
       "3399              717.2  \n",
       "3400              440.1  \n",
       "3401             1377.2  \n",
       "\n",
       "[3402 rows x 32 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anglais = anglais.reset_index(drop=True)\n",
    "anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en fait 2 lignes avec un score nan : 469 et 2170, le reste est OK\n",
    "anglais = anglais.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_train = 500\n",
    "dernier_test = 3402    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteurs = ['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1',\n",
    "    'score_similarite_resume2', 'score_classif1', 'score_classif2','score_sentiment1', \n",
    "    'score_sentiment2', 'score_sentiment3', 'meth1_similarites','meth2_similarites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycaret.classification import *\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# english_classif = setup(data = anglais[predicteurs + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = create_model('lr')\n",
    "# rf = create_model('rf')\n",
    "# xgb = create_model('xgboost')\n",
    "# ada = create_model('ada')\n",
    "# lda = create_model('lda')  # linear discriminant\n",
    "# knn = create_model('knn')\n",
    "# mlp = create_model('mlp')\n",
    "# svm = create_model('svm')\n",
    "# rbfsvm = create_model('rbfsvm')\n",
    "# nb = create_model('nb')\n",
    "# gpc = create_model('gpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai_classif = anglais[['Overall', 'Overall2', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'score_sentiment3','meth1_similarites','meth2_similarites']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overall                       int32\n",
       "Overall2                    float64\n",
       "Tone                          int32\n",
       "nb_entites_idem               int64\n",
       "nb_lieux_idem                 int64\n",
       "nb_dates_idem                 int64\n",
       "score_similarite_titres     float64\n",
       "score_similarite_resume1    float64\n",
       "score_similarite_resume2    float64\n",
       "score_classif1              float64\n",
       "score_classif2              float64\n",
       "score_sentiment1            float64\n",
       "score_sentiment2            float64\n",
       "score_sentiment3            float64\n",
       "meth1_similarites           float64\n",
       "meth2_similarites           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si on veut utiliser faire un classemen,t supprimer ligne error puis changer les types pour meth1 meth2\n",
    "essai_classif = essai_classif[essai_classif.meth1_similarites != 'Error']\n",
    "essai_classif['meth1_similarites'] = essai_classif['meth1_similarites'].astype('float')\n",
    "essai_classif['meth2_similarites'] = essai_classif['meth2_similarites'].astype('float')\n",
    "essai_classif.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random Forest simple sur scikit learn\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xtrain[:taille_train],ytrain[:taille_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.53</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>95.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.38</td>\n",
       "      <td>40.52</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>11.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>28.23</td>\n",
       "      <td>84.30</td>\n",
       "      <td>99.21</td>\n",
       "      <td>836.8</td>\n",
       "      <td>955.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.84</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>6.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>21.31</td>\n",
       "      <td>39.07</td>\n",
       "      <td>64.69</td>\n",
       "      <td>406.8</td>\n",
       "      <td>505.5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.27</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.04</td>\n",
       "      <td>20.11</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.28</td>\n",
       "      <td>14.97</td>\n",
       "      <td>5.67</td>\n",
       "      <td>10.96</td>\n",
       "      <td>8.33</td>\n",
       "      <td>21.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>95.43</td>\n",
       "      <td>722.7</td>\n",
       "      <td>314.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "500                 0              0              0                     5.90   \n",
       "501                12              0              6                    50.38   \n",
       "502                 0              0              5                     4.40   \n",
       "503                 0              0              0                     1.54   \n",
       "504                10              0              0                    12.28   \n",
       "...               ...            ...            ...                      ...   \n",
       "3397                0              0              0                    15.18   \n",
       "3398                2              0              0                     4.29   \n",
       "3399                7              0              6                    40.45   \n",
       "3400                9              0              1                    22.58   \n",
       "3401               18              1             12                    51.00   \n",
       "\n",
       "      score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "500                       1.28                      1.53            8.58   \n",
       "501                      40.52                     -1.43           11.16   \n",
       "502                       4.84                     -3.35            6.38   \n",
       "503                       1.41                     15.27            8.01   \n",
       "504                      14.97                      5.67           10.96   \n",
       "...                        ...                       ...             ...   \n",
       "3397                      0.96                     -0.44           52.18   \n",
       "3398                     14.06                      1.64           27.53   \n",
       "3399                     40.11                     24.78           10.46   \n",
       "3400                     29.80                     -0.50           10.97   \n",
       "3401                     44.02                     16.45           16.61   \n",
       "\n",
       "      score_classif2  score_sentiment1  score_sentiment2  score_sentiment3  \\\n",
       "500             8.44              8.96              1.82             95.37   \n",
       "501             8.37             28.23             84.30             99.21   \n",
       "502             8.40             21.31             39.07             64.69   \n",
       "503             8.33              9.04             20.11              3.27   \n",
       "504             8.33             21.39              8.42             95.43   \n",
       "...              ...               ...               ...               ...   \n",
       "3397            9.54             28.40             97.16             99.92   \n",
       "3398            8.29             31.73              1.55             13.10   \n",
       "3399            8.36             46.47             84.41             97.96   \n",
       "3400            8.42             19.91              1.06             93.64   \n",
       "3401            8.50             18.34             27.16             99.71   \n",
       "\n",
       "      meth1_similarites  meth2_similarites  Overall  RF  \n",
       "500                 0.0              432.2        3   4  \n",
       "501               836.8              955.1        1   1  \n",
       "502               406.8              505.5        4   4  \n",
       "503                 0.0                0.0        4   4  \n",
       "504               722.7              314.2        4   3  \n",
       "...                 ...                ...      ...  ..  \n",
       "3397              289.7              418.5        3   3  \n",
       "3398               40.4              150.6        4   4  \n",
       "3399              547.7              717.2        1   1  \n",
       "3400             1364.2              440.1        1   2  \n",
       "3401             1445.6             1377.2        1   1  \n",
       "\n",
       "[2902 rows x 15 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf = rf.predict(Xtrain[taille_train:])\n",
    "res_rf = pd.concat([Xtrain[taille_train:],ytrain[taille_train:],pd.DataFrame(res_rf,columns = ['RF'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 380,   78,    8,   16],\n",
       "       [ 106,  307,   64,   30],\n",
       "       [  16,   94,  238,  212],\n",
       "       [   4,   48,   86, 1215]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résultats corrects : 2116/2900 - 658/2900 : 1 d'écart 110/2900 : 2 d'écart et 16/2900 : 3 écart \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(res_rf.Overall,res_rf.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rf = pd.concat([res_rf,anglais.Overall2[500:]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr, _ = pearsonr(res_rf.Overall, res_rf.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8431947809257406"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(res_rf.Overall2, res_rf.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8460866744263411"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1,  7,  8,  9, 11,  5, 10,  0,  6, 12,  4,  3], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(rf, Xtrain, ytrain, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "tree_feature_importances = rf.feature_importances_\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(predicteurs))\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.array(predicteurs)[sorted_idx])\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  RF  LDA\n",
       "500         3   4    4\n",
       "501         1   1    1\n",
       "502         4   4    4\n",
       "503         4   4    4\n",
       "504         4   3    4\n",
       "...       ...  ..  ...\n",
       "3397        3   3    3\n",
       "3398        4   4    4\n",
       "3399        1   1    1\n",
       "3400        1   2    2\n",
       "3401        1   1    1\n",
       "\n",
       "[2902 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_lda = lda.predict(Xtrain[taille_train:])\n",
    "res_final = pd.concat([res_rf[['Overall','RF']],pd.DataFrame(res_lda,columns = ['LDA'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.22,  7.42, 92.36],\n",
       "       [98.95,  1.05,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.29,  9.76, 89.95],\n",
       "       ...,\n",
       "       [94.47,  5.49,  0.03,  0.  ],\n",
       "       [24.11, 57.55, 15.16,  3.18],\n",
       "       [98.59,  1.41,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import around\n",
    "import numpy\n",
    "np.set_printoptions(suppress=True)  # supprime notation exp\n",
    "res_lda2 = around(lda.predict_proba(Xtrain[taille_train:])*100, decimals=2)\n",
    "res_lda2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  4., 95.],\n",
       "       [78., 18.,  2.,  2.],\n",
       "       [ 0.,  1.,  4., 95.],\n",
       "       ...,\n",
       "       [76., 21.,  3.,  0.],\n",
       "       [29., 38., 25.,  8.],\n",
       "       [83., 13.,  3.,  1.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf2 = around(rf.predict_proba(Xtrain[taille_train:])*100, decimals=2)\n",
    "res_rf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Remarquer que la classification ne tient pas compte du fait que c'est ordonné en classement 1-2-3-4 : ce qui est TRES important (ex : ligne 55% de 1 - 43% de 4) !! : il faudrait donc faire ressortir un score avec les probas plutot !!!_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau programme basé sur les scores probas : si plus de 50% mettre catégorie obtenue sinon, faire la somme 1-2 et 3/4 \n",
    "# et prendre le plus gros score puis regarder si ce sore > 65% alors à ce moment là prendre le plus gros de la catégorie \n",
    "# sinon prendre 2 ou 3\n",
    "def choix_classes(score_prob):\n",
    "    classe_finale = []\n",
    "    for i in range(len(score_prob)):\n",
    "        res = list(score_prob[i,:])\n",
    "        max_res = max(res)\n",
    "        if max_res > 50:\n",
    "            classe_finale.append(res.index(max_res)+1)\n",
    "        else:\n",
    "            som1 = res[0]+res[1]\n",
    "            som2 = res[2]+res[3]\n",
    "            if som1 > som2:\n",
    "                if som1 >= 65:\n",
    "                    choix = 1 if res[0]>res[1] else 2\n",
    "                else:\n",
    "                    choix = 2\n",
    "            else:\n",
    "                if som2 >= 65:\n",
    "                    choix = 4 if res[3]>res[2] else 3\n",
    "                else:\n",
    "                    choix = 3\n",
    "            classe_finale.append(choix)\n",
    "    return classe_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_rf = choix_classes(res_rf2)\n",
    "liste_lda = choix_classes(res_lda2)\n",
    "res_final = pd.concat([res_final,pd.DataFrame(liste_lda,columns = ['LDA_Prob'],index = range(taille_train,dernier_test)),\n",
    "                       pd.DataFrame(liste_rf,columns = ['RF_Prob'],index = range(taille_train,dernier_test))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier()\n",
    "# knn.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "# res_knn = knn.predict(Xtrain[taille_train:])\n",
    "# liste_knn = choix_classes(around(knn.predict_proba(Xtrain[taille_train:])*100, decimals=2))\n",
    "# res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['KNN'],index = range(taille_train,dernier_test)),\n",
    "#                       pd.DataFrame(liste_knn,columns = ['KNN_Prob'],index = range(taille_train,dernier_test))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_logreg = logreg.predict(Xtrain[taille_train:])\n",
    "liste_logreg = choix_classes(around(logreg.predict_proba(Xtrain[taille_train:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_logreg,columns = ['LOGR'],index = range(taille_train,dernier_test)),\n",
    "                      pd.DataFrame(liste_logreg,columns = ['LOGR_Prob'],index = range(taille_train,dernier_test))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# ada = AdaBoostClassifier()\n",
    "# ada.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "# res_ada = ada.predict(Xtrain[taille_train:])\n",
    "# liste_ada = choix_classes(around(ada.predict_proba(Xtrain[taille_train:])*100, decimals=2))\n",
    "# res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['ADA'],index = range(taille_train,dernier_test)),\n",
    "#                       pd.DataFrame(liste_knn,columns = ['ADA_Prob'],index = range(taille_train,dernier_test))],axis=1)\n",
    "# res_final = res_final [['Overall','RF','LDA','KNN','LOGR','ADA','RF_Prob','LDA_Prob','KNN_Prob','LOGR_Prob','ADA_Prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,essai_classif.Overall2[500:]],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 380,   78,    8,   16],\n",
       "       [ 106,  307,   64,   30],\n",
       "       [  16,   94,  238,  212],\n",
       "       [   4,   48,   86, 1215]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8431947809257406\n",
      "0.8460866744263411\n"
     ]
    }
   ],
   "source": [
    "corr1, _ = pearsonr(res_final.Overall, res_final.RF)\n",
    "corr2, _ = pearsonr(res_final.Overall2, res_final.RF)\n",
    "print(corr1)\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 376,   88,    6,   12],\n",
       "       [  96,  301,   82,   28],\n",
       "       [  12,   74,  262,  212],\n",
       "       [   4,   38,  100, 1211]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.RF_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8535814300631663\n",
      "0.8569481579542404\n"
     ]
    }
   ],
   "source": [
    "corr1, _ = pearsonr(res_final.Overall, res_final.RF_Prob)\n",
    "corr2, _ = pearsonr(res_final.Overall2, res_final.RF_Prob)\n",
    "print(corr1)\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 372,   79,   20,   11],\n",
       "       [ 138,  227,   96,   46],\n",
       "       [  16,  100,  160,  284],\n",
       "       [  16,   35,   81, 1221]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814799806521559\n",
      "0.8246711900890981\n"
     ]
    }
   ],
   "source": [
    "corr1, _ = pearsonr(res_final.Overall, res_final.LDA)\n",
    "corr2, _ = pearsonr(res_final.Overall2, res_final.LDA)\n",
    "print(corr1)\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 372,   78,   21,   11],\n",
       "       [ 138,  213,  112,   44],\n",
       "       [  16,   85,  175,  284],\n",
       "       [  16,   33,   83, 1221]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.LDA_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8155224792680713\n",
      "0.8254658289342726\n"
     ]
    }
   ],
   "source": [
    "corr1, _ = pearsonr(res_final.Overall, res_final.LDA_Prob)\n",
    "corr2, _ = pearsonr(res_final.Overall2, res_final.LDA_Prob)\n",
    "print(corr1)\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 352,   88,   19,   23],\n",
       "       [ 156,  179,  105,   67],\n",
       "       [  32,  101,  137,  290],\n",
       "       [  30,   44,   83, 1196]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.LOGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7602841166078951\n",
      "0.772122205382762\n"
     ]
    }
   ],
   "source": [
    "corr1, _ = pearsonr(res_final.Overall, res_final.LOGR)\n",
    "corr2, _ = pearsonr(res_final.Overall2, res_final.LOGR)\n",
    "print(corr1)\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 352,   88,   21,   21],\n",
       "       [ 156,  189,  107,   55],\n",
       "       [  31,  108,  148,  273],\n",
       "       [  30,   49,   99, 1175]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention, ce n'est plus bon du tout ....\n",
    "confusion_matrix(res_final.Overall,res_final.LOGR_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7626529034507271\n",
      "0.776347778534296\n"
     ]
    }
   ],
   "source": [
    "corr1, _ = pearsonr(res_final.Overall, res_final.LOGR_Prob)\n",
    "corr2, _ = pearsonr(res_final.Overall2, res_final.LOGR_Prob)\n",
    "print(corr1)\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>Overall2</th>\n",
       "      <th>stacking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.667</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  RF  LDA  LDA_Prob  RF_Prob  LOGR  LOGR_Prob  Overall2  stacking\n",
       "500         3   4    4         4        4     4          4     2.667      4.00\n",
       "501         1   1    1         1        1     1          1     1.000      1.00\n",
       "502         4   4    4         4        4     4          4     4.000      4.00\n",
       "503         4   4    4         4        4     4          4     4.000      4.00\n",
       "504         4   3    4         4        3     3          3     4.000      3.33\n",
       "...       ...  ..  ...       ...      ...   ...        ...       ...       ...\n",
       "3397        3   3    3         3        3     4          4     3.000      3.33\n",
       "3398        4   4    4         4        4     4          4     4.000      4.00\n",
       "3399        1   1    1         1        1     1          1     1.000      1.00\n",
       "3400        1   2    2         2        2     2          2     1.000      2.00\n",
       "3401        1   1    1         1        1     1          1     1.000      1.00\n",
       "\n",
       "[2902 rows x 9 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final['stacking'] = round((res_final['RF'] + res_final['RF_Prob'] + res_final['LDA'] + res_final['LDA_Prob'] +\n",
    "            + res_final['LOGR'] + res_final['LOGR_Prob'])/6,2)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8438682240594624\n",
      "0.8529143954410722\n"
     ]
    }
   ],
   "source": [
    "corr1, _ = pearsonr(res_final.Overall, res_final.stacking)\n",
    "corr2, _ = pearsonr(res_final.Overall2, res_final.stacking)\n",
    "print(corr1)\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>Overall2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  RF  LDA  LDA_Prob  RF_Prob  LOGR  LOGR_Prob  Overall2\n",
       "516         3   2    4         4        3     3          3       3.0\n",
       "554         2   3    1         1        2     3          2       2.0\n",
       "571         1   1    3         3        2     4          4       1.0\n",
       "672         3   2    4         4        3     4          4       3.0\n",
       "691         1   4    1         1        2     1          1       1.0\n",
       "...       ...  ..  ...       ...      ...   ...        ...       ...\n",
       "3226        4   4    2         2        3     1          1       3.5\n",
       "3232        3   2    3         3        3     3          3       3.0\n",
       "3244        2   1    2         2        2     3          3       2.0\n",
       "3290        4   2    3         3        3     4          4       4.0\n",
       "3362        4   2    4         4        3     2          2       4.0\n",
       "\n",
       "[88 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final[res_final.RF != res_final.RF_Prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 500,  501,  502, ..., 3399, 3400, 3401], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte(df):\n",
    "    res = pd.DataFrame(columns=['index','val1','val2','val3','val4','valfinale'])\n",
    "    for i in df.index.values:\n",
    "        my_dic = {}\n",
    "        my_dic['index'] = i\n",
    "        my_dic['valfinale'] = 0\n",
    "        try:\n",
    "            df.loc[i,df.columns[1:7]].value_counts()[1.0]\n",
    "        except:\n",
    "            my_dic['val1'] = 0\n",
    "        else:\n",
    "            my_dic['val1'] = df.loc[i,df.columns[1:7]].value_counts()[1.0]\n",
    "            if my_dic['val1'] >=4:\n",
    "                my_dic['valfinale']=1\n",
    "        try:\n",
    "            df.loc[i,df.columns[1:7]].value_counts()[2.0]\n",
    "        except:\n",
    "            my_dic['val2'] = 0\n",
    "        else:\n",
    "            my_dic['val2'] = df.loc[i,df.columns[1:7]].value_counts()[2.0]\n",
    "            if my_dic['val2'] >=4:\n",
    "                my_dic['valfinale']=2\n",
    "        try:\n",
    "            df.loc[i,df.columns[1:7]].value_counts()[3.0]\n",
    "        except:\n",
    "            my_dic['val3'] = 0\n",
    "        else:\n",
    "            my_dic['val3'] = df.loc[i,df.columns[1:7]].value_counts()[3.0]\n",
    "            if my_dic['val3'] >=4:\n",
    "                my_dic['valfinale']=3\n",
    "        try:\n",
    "            df.loc[i,df.columns[1:7]].value_counts()[4.0]\n",
    "        except:\n",
    "            my_dic['val4'] = 0\n",
    "        else:\n",
    "            my_dic['val4'] = df.loc[i,df.columns[1:7]].value_counts()[4.0]\n",
    "            if my_dic['val4'] >=4:\n",
    "                my_dic['valfinale']=4\n",
    "                \n",
    "        if my_dic['valfinale'] == 0:\n",
    "            val1 = my_dic['val1'] + my_dic['val2']\n",
    "            val2 = my_dic['val3'] + my_dic['val2']\n",
    "            val3 = my_dic['val4'] + my_dic['val3'] \n",
    "            if val1 > val2 and val1 > val3:\n",
    "                my_dic['valfinale'] = 1* my_dic['val1']/val1 + 2* my_dic['val2']/val1\n",
    "            elif val2 > val1 and val2 > val3:\n",
    "                my_dic['valfinale'] = 3*my_dic['val3']/val2 + 2*my_dic['val2']/val2\n",
    "            elif val3 > val1 and val3 > val2:\n",
    "                my_dic['valfinale'] = 3*my_dic['val3']/val3 + 4*my_dic['val4']/val3\n",
    "            elif val1 == val2 and val1 > val3:\n",
    "                my_dic['valfinale'] = 2\n",
    "            elif val2 == val3 and val2 > val1:\n",
    "                my_dic['valfinale'] = 3\n",
    "            elif val1==val2 and val2==val3:\n",
    "                my_dic['valfinale'] = 2.5           \n",
    "        res.loc[len(res)] = my_dic\n",
    "        \n",
    "    return res       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final2 = decompte(res_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "      <th>valfinale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>511</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>517</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>519</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>525</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index val1 val2 val3 val4 valfinale\n",
       "0    500    0    0    0    6         4\n",
       "1    501    6    0    0    0         1\n",
       "2    502    0    0    0    6         4\n",
       "3    503    0    0    0    6         4\n",
       "4    504    0    0    4    2         3\n",
       "5    505    0    0    0    6         4\n",
       "6    506    0    0    0    6         4\n",
       "7    507    0    0    0    6         4\n",
       "8    508    0    0    2    4         4\n",
       "9    509    0    2    2    2         3\n",
       "10   510    0    0    0    6         4\n",
       "11   511    4    2    0    0         1\n",
       "12   512    0    0    0    6         4\n",
       "13   513    0    0    2    4         4\n",
       "14   514    0    0    0    6         4\n",
       "15   515    0    0    0    6         4\n",
       "16   516    0    1    3    2       3.4\n",
       "17   517    2    4    0    0         2\n",
       "18   518    0    0    0    6         4\n",
       "19   519    6    0    0    0         1\n",
       "20   520    0    0    2    4         4\n",
       "21   521    0    0    0    6         4\n",
       "22   522    0    0    0    6         4\n",
       "23   523    0    5    1    0         2\n",
       "24   524    0    0    0    6         4\n",
       "25   525    2    4    0    0         2\n",
       "26   526    0    0    0    6         4\n",
       "27   527    0    0    0    6         4\n",
       "28   528    0    0    0    6         4\n",
       "29   529    2    4    0    0         2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final2.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "      <th>valfinale</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400.0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val1 val2 val3 val4 valfinale\n",
       "index                               \n",
       "500.0     0    0    0    6         4\n",
       "501.0     6    0    0    0         1\n",
       "502.0     0    0    0    6         4\n",
       "503.0     0    0    0    6         4\n",
       "504.0     0    0    4    2         3\n",
       "...     ...  ...  ...  ...       ...\n",
       "3397.0    0    0    4    2         3\n",
       "3398.0    0    0    0    6         4\n",
       "3399.0    6    0    0    0         1\n",
       "3400.0    0    6    0    0         2\n",
       "3401.0    6    0    0    0         1\n",
       "\n",
       "[2902 rows x 5 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final2 = res_final2.set_index('index')\n",
    "res_final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,res_final2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final=res_final.iloc[500:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>Overall2</th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "      <th>val3</th>\n",
       "      <th>val4</th>\n",
       "      <th>valfinale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Overall   RF  LDA  LDA_Prob  RF_Prob  LOGR  LOGR_Prob  Overall2 val1  \\\n",
       "500.0       3.0  4.0  4.0       4.0      4.0   4.0        4.0     2.667    0   \n",
       "501.0       1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.000    6   \n",
       "502.0       4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000    0   \n",
       "503.0       4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000    0   \n",
       "504.0       4.0  3.0  4.0       4.0      3.0   3.0        3.0     4.000    0   \n",
       "...         ...  ...  ...       ...      ...   ...        ...       ...  ...   \n",
       "3397.0      3.0  3.0  3.0       3.0      3.0   4.0        4.0     3.000    0   \n",
       "3398.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000    0   \n",
       "3399.0      1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.000    6   \n",
       "3400.0      1.0  2.0  2.0       2.0      2.0   2.0        2.0     1.000    0   \n",
       "3401.0      1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.000    6   \n",
       "\n",
       "       val2 val3 val4 valfinale  \n",
       "500.0     0    0    6         4  \n",
       "501.0     0    0    0         1  \n",
       "502.0     0    0    6         4  \n",
       "503.0     0    0    6         4  \n",
       "504.0     0    4    2         3  \n",
       "...     ...  ...  ...       ...  \n",
       "3397.0    0    4    2         3  \n",
       "3398.0    0    0    6         4  \n",
       "3399.0    0    0    0         1  \n",
       "3400.0    6    0    0         2  \n",
       "3401.0    0    0    0         1  \n",
       "\n",
       "[2902 rows x 13 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8254390106991587\n",
      "0.8347949771661561\n"
     ]
    }
   ],
   "source": [
    "corr1, _ = pearsonr(res_final.Overall, res_final.valfinale)\n",
    "corr2, _ = pearsonr(res_final.Overall2, res_final.valfinale)\n",
    "print(corr1)\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pycaret.regression import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "lr = LinearRegression()\n",
    "pls = PLSRegression()\n",
    "etr = ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Overall2</th>\n",
       "      <th>Tone</th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.79</td>\n",
       "      <td>51.00</td>\n",
       "      <td>10.42</td>\n",
       "      <td>8.33</td>\n",
       "      <td>32.09</td>\n",
       "      <td>13.47</td>\n",
       "      <td>99.20</td>\n",
       "      <td>818.0</td>\n",
       "      <td>231.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3.667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.44</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2.91</td>\n",
       "      <td>10.57</td>\n",
       "      <td>8.34</td>\n",
       "      <td>28.15</td>\n",
       "      <td>92.87</td>\n",
       "      <td>99.04</td>\n",
       "      <td>129.5</td>\n",
       "      <td>174.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.333</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20.70</td>\n",
       "      <td>27.45</td>\n",
       "      <td>9.68</td>\n",
       "      <td>13.14</td>\n",
       "      <td>8.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>96.75</td>\n",
       "      <td>827.2</td>\n",
       "      <td>504.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24.97</td>\n",
       "      <td>27.90</td>\n",
       "      <td>10.34</td>\n",
       "      <td>18.21</td>\n",
       "      <td>8.35</td>\n",
       "      <td>23.79</td>\n",
       "      <td>93.55</td>\n",
       "      <td>94.72</td>\n",
       "      <td>620.0</td>\n",
       "      <td>735.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>29.21</td>\n",
       "      <td>32.40</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>15.76</td>\n",
       "      <td>8.35</td>\n",
       "      <td>26.28</td>\n",
       "      <td>74.48</td>\n",
       "      <td>93.05</td>\n",
       "      <td>473.0</td>\n",
       "      <td>559.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>3</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>4</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3402 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  Overall2  Tone  nb_entites_idem  nb_lieux_idem  nb_dates_idem  \\\n",
       "0           4     4.000     2                2              0              2   \n",
       "1           4     3.667     1                0              0              2   \n",
       "2           2     2.333     1               10              0              3   \n",
       "3           2     2.000     2               10              0              4   \n",
       "4           1     1.250     1               18              0              9   \n",
       "...       ...       ...   ...              ...            ...            ...   \n",
       "3397        3     3.000     1                0              0              0   \n",
       "3398        4     4.000     1                2              0              0   \n",
       "3399        1     1.000     1                7              0              6   \n",
       "3400        1     1.000     1                9              0              1   \n",
       "3401        1     1.000     1               18              1             12   \n",
       "\n",
       "      score_similarite_titres  score_similarite_resume1  \\\n",
       "0                        0.80                      3.79   \n",
       "1                        6.44                      9.10   \n",
       "2                       20.70                     27.45   \n",
       "3                       24.97                     27.90   \n",
       "4                       29.21                     32.40   \n",
       "...                       ...                       ...   \n",
       "3397                    15.18                      0.96   \n",
       "3398                     4.29                     14.06   \n",
       "3399                    40.45                     40.11   \n",
       "3400                    22.58                     29.80   \n",
       "3401                    51.00                     44.02   \n",
       "\n",
       "      score_similarite_resume2  score_classif1  score_classif2  \\\n",
       "0                        51.00           10.42            8.33   \n",
       "1                         2.91           10.57            8.34   \n",
       "2                         9.68           13.14            8.33   \n",
       "3                        10.34           18.21            8.35   \n",
       "4                        -1.95           15.76            8.35   \n",
       "...                        ...             ...             ...   \n",
       "3397                     -0.44           52.18            9.54   \n",
       "3398                      1.64           27.53            8.29   \n",
       "3399                     24.78           10.46            8.36   \n",
       "3400                     -0.50           10.97            8.42   \n",
       "3401                     16.45           16.61            8.50   \n",
       "\n",
       "      score_sentiment1  score_sentiment2  score_sentiment3  meth1_similarites  \\\n",
       "0                32.09             13.47             99.20              818.0   \n",
       "1                28.15             92.87             99.04              129.5   \n",
       "2                25.00              2.56             96.75              827.2   \n",
       "3                23.79             93.55             94.72              620.0   \n",
       "4                26.28             74.48             93.05              473.0   \n",
       "...                ...               ...               ...                ...   \n",
       "3397             28.40             97.16             99.92              289.7   \n",
       "3398             31.73              1.55             13.10               40.4   \n",
       "3399             46.47             84.41             97.96              547.7   \n",
       "3400             19.91              1.06             93.64             1364.2   \n",
       "3401             18.34             27.16             99.71             1445.6   \n",
       "\n",
       "      meth2_similarites  \n",
       "0                 231.9  \n",
       "1                 174.9  \n",
       "2                 504.8  \n",
       "3                 735.1  \n",
       "4                 559.4  \n",
       "...                 ...  \n",
       "3397              418.5  \n",
       "3398              150.6  \n",
       "3399              717.2  \n",
       "3400              440.1  \n",
       "3401             1377.2  \n",
       "\n",
       "[3402 rows x 16 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essai_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression simple sur scikit learn\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall2'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall2</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.53</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>95.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.2</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.732548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.38</td>\n",
       "      <td>40.52</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>11.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>28.23</td>\n",
       "      <td>84.30</td>\n",
       "      <td>99.21</td>\n",
       "      <td>836.8</td>\n",
       "      <td>955.1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.605195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.84</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>6.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>21.31</td>\n",
       "      <td>39.07</td>\n",
       "      <td>64.69</td>\n",
       "      <td>406.8</td>\n",
       "      <td>505.5</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.716682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.27</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.04</td>\n",
       "      <td>20.11</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.145009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.28</td>\n",
       "      <td>14.97</td>\n",
       "      <td>5.67</td>\n",
       "      <td>10.96</td>\n",
       "      <td>8.33</td>\n",
       "      <td>21.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>95.43</td>\n",
       "      <td>722.7</td>\n",
       "      <td>314.2</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.142491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.102456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.398949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.082029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.265592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.368371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "500                 0              0              0                     5.90   \n",
       "501                12              0              6                    50.38   \n",
       "502                 0              0              5                     4.40   \n",
       "503                 0              0              0                     1.54   \n",
       "504                10              0              0                    12.28   \n",
       "...               ...            ...            ...                      ...   \n",
       "3397                0              0              0                    15.18   \n",
       "3398                2              0              0                     4.29   \n",
       "3399                7              0              6                    40.45   \n",
       "3400                9              0              1                    22.58   \n",
       "3401               18              1             12                    51.00   \n",
       "\n",
       "      score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "500                       1.28                      1.53            8.58   \n",
       "501                      40.52                     -1.43           11.16   \n",
       "502                       4.84                     -3.35            6.38   \n",
       "503                       1.41                     15.27            8.01   \n",
       "504                      14.97                      5.67           10.96   \n",
       "...                        ...                       ...             ...   \n",
       "3397                      0.96                     -0.44           52.18   \n",
       "3398                     14.06                      1.64           27.53   \n",
       "3399                     40.11                     24.78           10.46   \n",
       "3400                     29.80                     -0.50           10.97   \n",
       "3401                     44.02                     16.45           16.61   \n",
       "\n",
       "      score_classif2  score_sentiment1  score_sentiment2  score_sentiment3  \\\n",
       "500             8.44              8.96              1.82             95.37   \n",
       "501             8.37             28.23             84.30             99.21   \n",
       "502             8.40             21.31             39.07             64.69   \n",
       "503             8.33              9.04             20.11              3.27   \n",
       "504             8.33             21.39              8.42             95.43   \n",
       "...              ...               ...               ...               ...   \n",
       "3397            9.54             28.40             97.16             99.92   \n",
       "3398            8.29             31.73              1.55             13.10   \n",
       "3399            8.36             46.47             84.41             97.96   \n",
       "3400            8.42             19.91              1.06             93.64   \n",
       "3401            8.50             18.34             27.16             99.71   \n",
       "\n",
       "      meth1_similarites  meth2_similarites  Overall2        LR  \n",
       "500                 0.0              432.2     2.667  3.732548  \n",
       "501               836.8              955.1     1.000  0.605195  \n",
       "502               406.8              505.5     4.000  3.716682  \n",
       "503                 0.0                0.0     4.000  4.145009  \n",
       "504               722.7              314.2     4.000  3.142491  \n",
       "...                 ...                ...       ...       ...  \n",
       "3397              289.7              418.5     3.000  3.102456  \n",
       "3398               40.4              150.6     4.000  3.398949  \n",
       "3399              547.7              717.2     1.000  1.082029  \n",
       "3400             1364.2              440.1     1.000  2.265592  \n",
       "3401             1445.6             1377.2     1.000  0.368371  \n",
       "\n",
       "[2902 rows x 15 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_lr = lr.predict(Xtrain[taille_train:])\n",
    "res_lr = pd.concat([Xtrain[taille_train:],ytrain[taille_train:],pd.DataFrame(res_lr,columns = ['LR'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,res_lr['LR']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall2</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.53</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>95.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.2</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.732548</td>\n",
       "      <td>3.813379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.38</td>\n",
       "      <td>40.52</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>11.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>28.23</td>\n",
       "      <td>84.30</td>\n",
       "      <td>99.21</td>\n",
       "      <td>836.8</td>\n",
       "      <td>955.1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.605195</td>\n",
       "      <td>0.924357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.84</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>6.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>21.31</td>\n",
       "      <td>39.07</td>\n",
       "      <td>64.69</td>\n",
       "      <td>406.8</td>\n",
       "      <td>505.5</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.716682</td>\n",
       "      <td>3.733192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.27</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.04</td>\n",
       "      <td>20.11</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.145009</td>\n",
       "      <td>4.156081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.28</td>\n",
       "      <td>14.97</td>\n",
       "      <td>5.67</td>\n",
       "      <td>10.96</td>\n",
       "      <td>8.33</td>\n",
       "      <td>21.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>95.43</td>\n",
       "      <td>722.7</td>\n",
       "      <td>314.2</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.142491</td>\n",
       "      <td>3.222035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.102456</td>\n",
       "      <td>2.583575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.398949</td>\n",
       "      <td>3.376203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.082029</td>\n",
       "      <td>1.157288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.265592</td>\n",
       "      <td>2.448646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.368371</td>\n",
       "      <td>0.429933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "500                 0              0              0                     5.90   \n",
       "501                12              0              6                    50.38   \n",
       "502                 0              0              5                     4.40   \n",
       "503                 0              0              0                     1.54   \n",
       "504                10              0              0                    12.28   \n",
       "...               ...            ...            ...                      ...   \n",
       "3397                0              0              0                    15.18   \n",
       "3398                2              0              0                     4.29   \n",
       "3399                7              0              6                    40.45   \n",
       "3400                9              0              1                    22.58   \n",
       "3401               18              1             12                    51.00   \n",
       "\n",
       "      score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "500                       1.28                      1.53            8.58   \n",
       "501                      40.52                     -1.43           11.16   \n",
       "502                       4.84                     -3.35            6.38   \n",
       "503                       1.41                     15.27            8.01   \n",
       "504                      14.97                      5.67           10.96   \n",
       "...                        ...                       ...             ...   \n",
       "3397                      0.96                     -0.44           52.18   \n",
       "3398                     14.06                      1.64           27.53   \n",
       "3399                     40.11                     24.78           10.46   \n",
       "3400                     29.80                     -0.50           10.97   \n",
       "3401                     44.02                     16.45           16.61   \n",
       "\n",
       "      score_classif2  score_sentiment1  score_sentiment2  score_sentiment3  \\\n",
       "500             8.44              8.96              1.82             95.37   \n",
       "501             8.37             28.23             84.30             99.21   \n",
       "502             8.40             21.31             39.07             64.69   \n",
       "503             8.33              9.04             20.11              3.27   \n",
       "504             8.33             21.39              8.42             95.43   \n",
       "...              ...               ...               ...               ...   \n",
       "3397            9.54             28.40             97.16             99.92   \n",
       "3398            8.29             31.73              1.55             13.10   \n",
       "3399            8.36             46.47             84.41             97.96   \n",
       "3400            8.42             19.91              1.06             93.64   \n",
       "3401            8.50             18.34             27.16             99.71   \n",
       "\n",
       "      meth1_similarites  meth2_similarites  Overall2        LR       PLS  \n",
       "500                 0.0              432.2     2.667  3.732548  3.813379  \n",
       "501               836.8              955.1     1.000  0.605195  0.924357  \n",
       "502               406.8              505.5     4.000  3.716682  3.733192  \n",
       "503                 0.0                0.0     4.000  4.145009  4.156081  \n",
       "504               722.7              314.2     4.000  3.142491  3.222035  \n",
       "...                 ...                ...       ...       ...       ...  \n",
       "3397              289.7              418.5     3.000  3.102456  2.583575  \n",
       "3398               40.4              150.6     4.000  3.398949  3.376203  \n",
       "3399              547.7              717.2     1.000  1.082029  1.157288  \n",
       "3400             1364.2              440.1     1.000  2.265592  2.448646  \n",
       "3401             1445.6             1377.2     1.000  0.368371  0.429933  \n",
       "\n",
       "[2902 rows x 16 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_pls = list(pls.predict(Xtrain[taille_train:]).flatten())\n",
    "res_pls = pd.concat([res_lr,pd.DataFrame(res_pls,columns = ['PLS'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall2</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "      <th>ETR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.53</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>95.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.2</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.732548</td>\n",
       "      <td>3.813379</td>\n",
       "      <td>3.89107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.38</td>\n",
       "      <td>40.52</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>11.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>28.23</td>\n",
       "      <td>84.30</td>\n",
       "      <td>99.21</td>\n",
       "      <td>836.8</td>\n",
       "      <td>955.1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.605195</td>\n",
       "      <td>0.924357</td>\n",
       "      <td>1.14532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.84</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>6.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>21.31</td>\n",
       "      <td>39.07</td>\n",
       "      <td>64.69</td>\n",
       "      <td>406.8</td>\n",
       "      <td>505.5</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.716682</td>\n",
       "      <td>3.733192</td>\n",
       "      <td>3.83505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.27</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.04</td>\n",
       "      <td>20.11</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.145009</td>\n",
       "      <td>4.156081</td>\n",
       "      <td>3.87175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.28</td>\n",
       "      <td>14.97</td>\n",
       "      <td>5.67</td>\n",
       "      <td>10.96</td>\n",
       "      <td>8.33</td>\n",
       "      <td>21.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>95.43</td>\n",
       "      <td>722.7</td>\n",
       "      <td>314.2</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.142491</td>\n",
       "      <td>3.222035</td>\n",
       "      <td>3.17527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.102456</td>\n",
       "      <td>2.583575</td>\n",
       "      <td>3.30918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.398949</td>\n",
       "      <td>3.376203</td>\n",
       "      <td>3.64913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.082029</td>\n",
       "      <td>1.157288</td>\n",
       "      <td>1.31467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.265592</td>\n",
       "      <td>2.448646</td>\n",
       "      <td>2.39192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.368371</td>\n",
       "      <td>0.429933</td>\n",
       "      <td>1.20715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "500                 0              0              0                     5.90   \n",
       "501                12              0              6                    50.38   \n",
       "502                 0              0              5                     4.40   \n",
       "503                 0              0              0                     1.54   \n",
       "504                10              0              0                    12.28   \n",
       "...               ...            ...            ...                      ...   \n",
       "3397                0              0              0                    15.18   \n",
       "3398                2              0              0                     4.29   \n",
       "3399                7              0              6                    40.45   \n",
       "3400                9              0              1                    22.58   \n",
       "3401               18              1             12                    51.00   \n",
       "\n",
       "      score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "500                       1.28                      1.53            8.58   \n",
       "501                      40.52                     -1.43           11.16   \n",
       "502                       4.84                     -3.35            6.38   \n",
       "503                       1.41                     15.27            8.01   \n",
       "504                      14.97                      5.67           10.96   \n",
       "...                        ...                       ...             ...   \n",
       "3397                      0.96                     -0.44           52.18   \n",
       "3398                     14.06                      1.64           27.53   \n",
       "3399                     40.11                     24.78           10.46   \n",
       "3400                     29.80                     -0.50           10.97   \n",
       "3401                     44.02                     16.45           16.61   \n",
       "\n",
       "      score_classif2  score_sentiment1  score_sentiment2  score_sentiment3  \\\n",
       "500             8.44              8.96              1.82             95.37   \n",
       "501             8.37             28.23             84.30             99.21   \n",
       "502             8.40             21.31             39.07             64.69   \n",
       "503             8.33              9.04             20.11              3.27   \n",
       "504             8.33             21.39              8.42             95.43   \n",
       "...              ...               ...               ...               ...   \n",
       "3397            9.54             28.40             97.16             99.92   \n",
       "3398            8.29             31.73              1.55             13.10   \n",
       "3399            8.36             46.47             84.41             97.96   \n",
       "3400            8.42             19.91              1.06             93.64   \n",
       "3401            8.50             18.34             27.16             99.71   \n",
       "\n",
       "      meth1_similarites  meth2_similarites  Overall2        LR       PLS  \\\n",
       "500                 0.0              432.2     2.667  3.732548  3.813379   \n",
       "501               836.8              955.1     1.000  0.605195  0.924357   \n",
       "502               406.8              505.5     4.000  3.716682  3.733192   \n",
       "503                 0.0                0.0     4.000  4.145009  4.156081   \n",
       "504               722.7              314.2     4.000  3.142491  3.222035   \n",
       "...                 ...                ...       ...       ...       ...   \n",
       "3397              289.7              418.5     3.000  3.102456  2.583575   \n",
       "3398               40.4              150.6     4.000  3.398949  3.376203   \n",
       "3399              547.7              717.2     1.000  1.082029  1.157288   \n",
       "3400             1364.2              440.1     1.000  2.265592  2.448646   \n",
       "3401             1445.6             1377.2     1.000  0.368371  0.429933   \n",
       "\n",
       "          ETR  \n",
       "500   3.89107  \n",
       "501   1.14532  \n",
       "502   3.83505  \n",
       "503   3.87175  \n",
       "504   3.17527  \n",
       "...       ...  \n",
       "3397  3.30918  \n",
       "3398  3.64913  \n",
       "3399  1.31467  \n",
       "3400  2.39192  \n",
       "3401  1.20715  \n",
       "\n",
       "[2902 rows x 17 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_etr = list(etr.predict(Xtrain[taille_train:]).flatten())\n",
    "res_etr = pd.concat([res_pls,pd.DataFrame(res_etr,columns = ['ETR'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_etr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall2</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "      <th>ETR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.53</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>95.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.2</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.732548</td>\n",
       "      <td>3.813379</td>\n",
       "      <td>3.89107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.38</td>\n",
       "      <td>40.52</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>11.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>28.23</td>\n",
       "      <td>84.30</td>\n",
       "      <td>99.21</td>\n",
       "      <td>836.8</td>\n",
       "      <td>955.1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.14532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.84</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>6.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>21.31</td>\n",
       "      <td>39.07</td>\n",
       "      <td>64.69</td>\n",
       "      <td>406.8</td>\n",
       "      <td>505.5</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.716682</td>\n",
       "      <td>3.733192</td>\n",
       "      <td>3.83505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.27</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.04</td>\n",
       "      <td>20.11</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.87175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.28</td>\n",
       "      <td>14.97</td>\n",
       "      <td>5.67</td>\n",
       "      <td>10.96</td>\n",
       "      <td>8.33</td>\n",
       "      <td>21.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>95.43</td>\n",
       "      <td>722.7</td>\n",
       "      <td>314.2</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.142491</td>\n",
       "      <td>3.222035</td>\n",
       "      <td>3.17527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.102456</td>\n",
       "      <td>2.583575</td>\n",
       "      <td>3.30918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.398949</td>\n",
       "      <td>3.376203</td>\n",
       "      <td>3.64913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.082029</td>\n",
       "      <td>1.157288</td>\n",
       "      <td>1.31467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.265592</td>\n",
       "      <td>2.448646</td>\n",
       "      <td>2.39192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.20715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "500                 0              0              0                     5.90   \n",
       "501                12              0              6                    50.38   \n",
       "502                 0              0              5                     4.40   \n",
       "503                 0              0              0                     1.54   \n",
       "504                10              0              0                    12.28   \n",
       "...               ...            ...            ...                      ...   \n",
       "3397                0              0              0                    15.18   \n",
       "3398                2              0              0                     4.29   \n",
       "3399                7              0              6                    40.45   \n",
       "3400                9              0              1                    22.58   \n",
       "3401               18              1             12                    51.00   \n",
       "\n",
       "      score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "500                       1.28                      1.53            8.58   \n",
       "501                      40.52                     -1.43           11.16   \n",
       "502                       4.84                     -3.35            6.38   \n",
       "503                       1.41                     15.27            8.01   \n",
       "504                      14.97                      5.67           10.96   \n",
       "...                        ...                       ...             ...   \n",
       "3397                      0.96                     -0.44           52.18   \n",
       "3398                     14.06                      1.64           27.53   \n",
       "3399                     40.11                     24.78           10.46   \n",
       "3400                     29.80                     -0.50           10.97   \n",
       "3401                     44.02                     16.45           16.61   \n",
       "\n",
       "      score_classif2  score_sentiment1  score_sentiment2  score_sentiment3  \\\n",
       "500             8.44              8.96              1.82             95.37   \n",
       "501             8.37             28.23             84.30             99.21   \n",
       "502             8.40             21.31             39.07             64.69   \n",
       "503             8.33              9.04             20.11              3.27   \n",
       "504             8.33             21.39              8.42             95.43   \n",
       "...              ...               ...               ...               ...   \n",
       "3397            9.54             28.40             97.16             99.92   \n",
       "3398            8.29             31.73              1.55             13.10   \n",
       "3399            8.36             46.47             84.41             97.96   \n",
       "3400            8.42             19.91              1.06             93.64   \n",
       "3401            8.50             18.34             27.16             99.71   \n",
       "\n",
       "      meth1_similarites  meth2_similarites  Overall2        LR       PLS  \\\n",
       "500                 0.0              432.2     2.667  3.732548  3.813379   \n",
       "501               836.8              955.1     1.000  1.000000  1.000000   \n",
       "502               406.8              505.5     4.000  3.716682  3.733192   \n",
       "503                 0.0                0.0     4.000  4.000000  4.000000   \n",
       "504               722.7              314.2     4.000  3.142491  3.222035   \n",
       "...                 ...                ...       ...       ...       ...   \n",
       "3397              289.7              418.5     3.000  3.102456  2.583575   \n",
       "3398               40.4              150.6     4.000  3.398949  3.376203   \n",
       "3399              547.7              717.2     1.000  1.082029  1.157288   \n",
       "3400             1364.2              440.1     1.000  2.265592  2.448646   \n",
       "3401             1445.6             1377.2     1.000  1.000000  1.000000   \n",
       "\n",
       "          ETR  \n",
       "500   3.89107  \n",
       "501   1.14532  \n",
       "502   3.83505  \n",
       "503   3.87175  \n",
       "504   3.17527  \n",
       "...       ...  \n",
       "3397  3.30918  \n",
       "3398  3.64913  \n",
       "3399  1.31467  \n",
       "3400  2.39192  \n",
       "3401  1.20715  \n",
       "\n",
       "[2902 rows x 17 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_etr.loc[res_etr.LR<1,['LR']]=1\n",
    "res_etr.loc[res_etr.ETR<1,['ETR']]=1\n",
    "res_etr.loc[res_etr.PLS<1,['PLS']]=1\n",
    "res_etr.loc[res_etr.LR>4,['LR']]=4\n",
    "res_etr.loc[res_etr.ETR>4,['ETR']]=4\n",
    "res_etr.loc[res_etr.PLS>4,['PLS']]=4\n",
    "res_etr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8494505026849813\n",
      "0.8378735502414827\n",
      "0.8786086048900082\n"
     ]
    }
   ],
   "source": [
    "corr1, _ = pearsonr(res_final.Overall2, res_etr.LR)\n",
    "corr2, _ = pearsonr(res_final.Overall2, res_etr.PLS)\n",
    "corr3, _ = pearsonr(res_final.Overall2, res_etr.ETR)\n",
    "print(corr1)\n",
    "print(corr2)\n",
    "print(corr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = res_final.iloc[:,list(range(8))+[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final.columns = ['Overall', 'RF', 'LDA', 'LDA_Prob', 'RF_Prob', 'LOGR', 'LOGR_Prob',\n",
    "       'Overall2', 'classif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>Overall2</th>\n",
       "      <th>classif</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "      <th>ETR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>4</td>\n",
       "      <td>3.732548</td>\n",
       "      <td>3.813379</td>\n",
       "      <td>3.89107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.14532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.716682</td>\n",
       "      <td>3.733192</td>\n",
       "      <td>3.83505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.87175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.142491</td>\n",
       "      <td>3.222035</td>\n",
       "      <td>3.17527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.102456</td>\n",
       "      <td>2.583575</td>\n",
       "      <td>3.30918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.398949</td>\n",
       "      <td>3.376203</td>\n",
       "      <td>3.64913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.082029</td>\n",
       "      <td>1.157288</td>\n",
       "      <td>1.31467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.265592</td>\n",
       "      <td>2.448646</td>\n",
       "      <td>2.39192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.20715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Overall   RF  LDA  LDA_Prob  RF_Prob  LOGR  LOGR_Prob  Overall2  \\\n",
       "500.0       3.0  4.0  4.0       4.0      4.0   4.0        4.0     2.667   \n",
       "501.0       1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.000   \n",
       "502.0       4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "503.0       4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "504.0       4.0  3.0  4.0       4.0      3.0   3.0        3.0     4.000   \n",
       "...         ...  ...  ...       ...      ...   ...        ...       ...   \n",
       "3397.0      3.0  3.0  3.0       3.0      3.0   4.0        4.0     3.000   \n",
       "3398.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "3399.0      1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.000   \n",
       "3400.0      1.0  2.0  2.0       2.0      2.0   2.0        2.0     1.000   \n",
       "3401.0      1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.000   \n",
       "\n",
       "       classif        LR       PLS      ETR  \n",
       "500.0        4  3.732548  3.813379  3.89107  \n",
       "501.0        1  1.000000  1.000000  1.14532  \n",
       "502.0        4  3.716682  3.733192  3.83505  \n",
       "503.0        4  4.000000  4.000000  3.87175  \n",
       "504.0        3  3.142491  3.222035  3.17527  \n",
       "...        ...       ...       ...      ...  \n",
       "3397.0       3  3.102456  2.583575  3.30918  \n",
       "3398.0       4  3.398949  3.376203  3.64913  \n",
       "3399.0       1  1.082029  1.157288  1.31467  \n",
       "3400.0       2  2.265592  2.448646  2.39192  \n",
       "3401.0       1  1.000000  1.000000  1.20715  \n",
       "\n",
       "[2902 rows x 12 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final = pd.concat([res_final,res_etr['LR'],res_etr['PLS'],res_etr['ETR']],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>Overall2</th>\n",
       "      <th>classif</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "      <th>ETR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>4</td>\n",
       "      <td>3.732548</td>\n",
       "      <td>3.813379</td>\n",
       "      <td>3.89107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.14532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.716682</td>\n",
       "      <td>3.733192</td>\n",
       "      <td>3.83505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.87175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.142491</td>\n",
       "      <td>3.222035</td>\n",
       "      <td>3.17527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.518409</td>\n",
       "      <td>3.616495</td>\n",
       "      <td>3.53753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4</td>\n",
       "      <td>3.899352</td>\n",
       "      <td>3.951287</td>\n",
       "      <td>3.92337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.428526</td>\n",
       "      <td>3.141606</td>\n",
       "      <td>3.47505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.333</td>\n",
       "      <td>4</td>\n",
       "      <td>3.178622</td>\n",
       "      <td>3.212011</td>\n",
       "      <td>3.28165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>3</td>\n",
       "      <td>2.705537</td>\n",
       "      <td>2.348118</td>\n",
       "      <td>2.01029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.95420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.511563</td>\n",
       "      <td>1.358691</td>\n",
       "      <td>1.50836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4</td>\n",
       "      <td>3.370517</td>\n",
       "      <td>3.316768</td>\n",
       "      <td>3.59081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4</td>\n",
       "      <td>3.247406</td>\n",
       "      <td>3.404839</td>\n",
       "      <td>3.49673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.967280</td>\n",
       "      <td>3.940790</td>\n",
       "      <td>3.76852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4</td>\n",
       "      <td>3.845134</td>\n",
       "      <td>3.933115</td>\n",
       "      <td>3.96919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.929464</td>\n",
       "      <td>3.056532</td>\n",
       "      <td>3.21313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.136597</td>\n",
       "      <td>2.282964</td>\n",
       "      <td>1.93329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.465392</td>\n",
       "      <td>3.274720</td>\n",
       "      <td>3.61613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.202347</td>\n",
       "      <td>1.150919</td>\n",
       "      <td>1.41995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.402049</td>\n",
       "      <td>3.396908</td>\n",
       "      <td>3.67986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.89882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.97085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2</td>\n",
       "      <td>2.645659</td>\n",
       "      <td>2.698306</td>\n",
       "      <td>2.29080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.333</td>\n",
       "      <td>4</td>\n",
       "      <td>3.273561</td>\n",
       "      <td>2.933858</td>\n",
       "      <td>3.42581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.393392</td>\n",
       "      <td>2.424477</td>\n",
       "      <td>1.88830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.95252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.333</td>\n",
       "      <td>4</td>\n",
       "      <td>3.477233</td>\n",
       "      <td>3.436121</td>\n",
       "      <td>3.43075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389564</td>\n",
       "      <td>3.318034</td>\n",
       "      <td>3.46304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.227802</td>\n",
       "      <td>2.289484</td>\n",
       "      <td>2.28494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.944060</td>\n",
       "      <td>2.006925</td>\n",
       "      <td>1.66257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.535593</td>\n",
       "      <td>3.560612</td>\n",
       "      <td>3.85912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.418551</td>\n",
       "      <td>1.310563</td>\n",
       "      <td>1.35660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.74744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4</td>\n",
       "      <td>3.345885</td>\n",
       "      <td>3.355430</td>\n",
       "      <td>3.61661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.099552</td>\n",
       "      <td>2.879856</td>\n",
       "      <td>3.15315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>4</td>\n",
       "      <td>3.294991</td>\n",
       "      <td>3.366604</td>\n",
       "      <td>3.62153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.92669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.97209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.121714</td>\n",
       "      <td>2.019558</td>\n",
       "      <td>2.28499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.90505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.827853</td>\n",
       "      <td>3.850897</td>\n",
       "      <td>3.82607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.400</td>\n",
       "      <td>3</td>\n",
       "      <td>2.611021</td>\n",
       "      <td>2.756383</td>\n",
       "      <td>2.76490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.926111</td>\n",
       "      <td>3.80093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.605946</td>\n",
       "      <td>3.664050</td>\n",
       "      <td>3.88016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500</td>\n",
       "      <td>4</td>\n",
       "      <td>3.608926</td>\n",
       "      <td>3.659240</td>\n",
       "      <td>3.62210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.660021</td>\n",
       "      <td>3.577455</td>\n",
       "      <td>3.65651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.779587</td>\n",
       "      <td>1.977564</td>\n",
       "      <td>1.45993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4</td>\n",
       "      <td>3.406729</td>\n",
       "      <td>3.527651</td>\n",
       "      <td>3.57400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Overall   RF  LDA  LDA_Prob  RF_Prob  LOGR  LOGR_Prob  Overall2  \\\n",
       "500.0      3.0  4.0  4.0       4.0      4.0   4.0        4.0     2.667   \n",
       "501.0      1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.000   \n",
       "502.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "503.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "504.0      4.0  3.0  4.0       4.0      3.0   3.0        3.0     4.000   \n",
       "505.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "506.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     3.667   \n",
       "507.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "508.0      3.0  4.0  4.0       4.0      4.0   3.0        3.0     3.333   \n",
       "509.0      1.0  2.0  3.0       3.0      2.0   4.0        4.0     1.333   \n",
       "510.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "511.0      1.0  2.0  1.0       1.0      2.0   1.0        1.0     1.000   \n",
       "512.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     3.667   \n",
       "513.0      4.0  4.0  4.0       4.0      4.0   3.0        3.0     3.667   \n",
       "514.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "515.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     3.667   \n",
       "516.0      3.0  2.0  4.0       4.0      3.0   3.0        3.0     3.000   \n",
       "517.0      2.0  2.0  2.0       2.0      2.0   1.0        1.0     2.000   \n",
       "518.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "519.0      1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.000   \n",
       "520.0      4.0  4.0  4.0       4.0      4.0   3.0        3.0     4.000   \n",
       "521.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     3.667   \n",
       "522.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "523.0      2.0  2.0  2.0       3.0      2.0   2.0        2.0     1.667   \n",
       "524.0      3.0  4.0  4.0       4.0      4.0   4.0        4.0     3.333   \n",
       "525.0      1.0  2.0  2.0       2.0      2.0   1.0        1.0     1.000   \n",
       "526.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     3.667   \n",
       "527.0      3.0  4.0  4.0       4.0      4.0   4.0        4.0     3.333   \n",
       "528.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "529.0      4.0  2.0  2.0       2.0      2.0   1.0        1.0     4.000   \n",
       "530.0      2.0  2.0  1.0       1.0      2.0   2.0        2.0     2.000   \n",
       "531.0      3.0  4.0  4.0       4.0      4.0   4.0        4.0     3.000   \n",
       "532.0      1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.000   \n",
       "533.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "534.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     3.667   \n",
       "535.0      4.0  4.0  3.0       3.0      4.0   4.0        4.0     4.000   \n",
       "536.0      3.0  4.0  4.0       4.0      4.0   3.0        3.0     2.667   \n",
       "537.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "538.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "539.0      3.0  2.0  2.0       2.0      2.0   2.0        2.0     3.000   \n",
       "540.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "541.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "542.0      3.0  3.0  3.0       3.0      3.0   3.0        2.0     3.400   \n",
       "543.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     3.667   \n",
       "544.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     4.000   \n",
       "545.0      4.0  4.0  4.0       4.0      4.0   4.0        4.0     3.500   \n",
       "546.0      3.0  4.0  4.0       4.0      4.0   4.0        4.0     3.000   \n",
       "547.0      4.0  3.0  4.0       4.0      3.0   4.0        4.0     4.000   \n",
       "548.0      1.0  1.0  1.0       1.0      1.0   1.0        1.0     1.333   \n",
       "549.0      4.0  4.0  4.0       4.0      4.0   3.0        3.0     3.667   \n",
       "\n",
       "      classif        LR       PLS      ETR  \n",
       "500.0       4  3.732548  3.813379  3.89107  \n",
       "501.0       1  1.000000  1.000000  1.14532  \n",
       "502.0       4  3.716682  3.733192  3.83505  \n",
       "503.0       4  4.000000  4.000000  3.87175  \n",
       "504.0       3  3.142491  3.222035  3.17527  \n",
       "505.0       4  3.518409  3.616495  3.53753  \n",
       "506.0       4  3.899352  3.951287  3.92337  \n",
       "507.0       4  3.428526  3.141606  3.47505  \n",
       "508.0       4  3.178622  3.212011  3.28165  \n",
       "509.0       3  2.705537  2.348118  2.01029  \n",
       "510.0       4  4.000000  4.000000  3.95420  \n",
       "511.0       1  1.511563  1.358691  1.50836  \n",
       "512.0       4  3.370517  3.316768  3.59081  \n",
       "513.0       4  3.247406  3.404839  3.49673  \n",
       "514.0       4  3.967280  3.940790  3.76852  \n",
       "515.0       4  3.845134  3.933115  3.96919  \n",
       "516.0     3.4  2.929464  3.056532  3.21313  \n",
       "517.0       2  2.136597  2.282964  1.93329  \n",
       "518.0       4  3.465392  3.274720  3.61613  \n",
       "519.0       1  1.202347  1.150919  1.41995  \n",
       "520.0       4  3.402049  3.396908  3.67986  \n",
       "521.0       4  4.000000  4.000000  3.89882  \n",
       "522.0       4  4.000000  4.000000  3.97085  \n",
       "523.0       2  2.645659  2.698306  2.29080  \n",
       "524.0       4  3.273561  2.933858  3.42581  \n",
       "525.0       2  2.393392  2.424477  1.88830  \n",
       "526.0       4  4.000000  4.000000  3.95252  \n",
       "527.0       4  3.477233  3.436121  3.43075  \n",
       "528.0       4  3.389564  3.318034  3.46304  \n",
       "529.0       2  2.227802  2.289484  2.28494  \n",
       "530.0       2  1.944060  2.006925  1.66257  \n",
       "531.0       4  3.535593  3.560612  3.85912  \n",
       "532.0       1  1.418551  1.310563  1.35660  \n",
       "533.0       4  4.000000  4.000000  3.74744  \n",
       "534.0       4  3.345885  3.355430  3.61661  \n",
       "535.0       4  3.099552  2.879856  3.15315  \n",
       "536.0       4  3.294991  3.366604  3.62153  \n",
       "537.0       4  4.000000  4.000000  3.92669  \n",
       "538.0       4  4.000000  4.000000  3.97209  \n",
       "539.0       2  2.121714  2.019558  2.28499  \n",
       "540.0       4  4.000000  4.000000  3.90505  \n",
       "541.0       4  3.827853  3.850897  3.82607  \n",
       "542.0       3  2.611021  2.756383  2.76490  \n",
       "543.0       4  4.000000  3.926111  3.80093  \n",
       "544.0       4  3.605946  3.664050  3.88016  \n",
       "545.0       4  3.608926  3.659240  3.62210  \n",
       "546.0       4  3.660021  3.577455  3.65651  \n",
       "547.0       4  4.000000  4.000000  3.00000  \n",
       "548.0       1  1.779587  1.977564  1.45993  \n",
       "549.0       4  3.406729  3.527651  3.57400  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour le classement final utiliser aussi la stade de base des notations : si plus de 4 ....** <br/>\n",
    "**Pour le seuils : Le mieux est d'utiliser un algo qui regrade les erreurs des autres ... NB / LR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on ne garde finalement que LDA - RF et LR en classif et sans les probas qui changent peu finalement\n",
    "def choix_final(df):\n",
    "    res = pd.DataFrame(columns = ['Overall','Classif_value','Regression_value','Classif','Regression','Final','Final_aide'])\n",
    "    for i in range(df.index[0],df.index[len(df)-1]):\n",
    "        my_dic = {}\n",
    "        my_dic['Overall'] = df.Overall[i]                   \n",
    "        my_dic['Classif_value'] = round((df.RF[i] + df.LDA[i] + df.LOGR[i])/3,2)\n",
    "        my_dic['Regression_value'] = round((df.LR[i] + df.PLS[i])/2,2)\n",
    "        if my_dic['Classif_value'] < 1.7:\n",
    "            my_dic['Classif'] = 1\n",
    "        elif my_dic['Classif_value'] < 2.5:\n",
    "            my_dic['Classif'] = 2\n",
    "        elif my_dic['Classif_value'] < 3.25:\n",
    "            my_dic['Classif'] = 3\n",
    "        else:\n",
    "            my_dic['Classif'] = 4\n",
    "        if my_dic['Regression_value'] <= 1.6:\n",
    "            my_dic['Regression'] = 1\n",
    "        elif my_dic['Regression_value'] < 2.5:\n",
    "            my_dic['Regression'] = 2\n",
    "        elif my_dic['Regression_value'] < 3.5:\n",
    "            my_dic['Regression'] = 3\n",
    "        else:\n",
    "            my_dic['Regression'] = 4\n",
    "        diff = 0.01 if my_dic['Classif'] != my_dic['Regression'] else 0\n",
    "        diff += 0.005 if abs(my_dic['Classif']-my_dic['Regression'])>=2 else 0\n",
    "        my_dic['Final'] = round((my_dic['Classif']+my_dic['Regression'])/2,0)\n",
    "        my_dic['Final_aide'] = round((my_dic['Classif']+my_dic['Regression'])/2,0)+diff\n",
    "        res.loc[len(res)] = my_dic\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Classif_value</th>\n",
       "      <th>Regression_value</th>\n",
       "      <th>Classif</th>\n",
       "      <th>Regression</th>\n",
       "      <th>Final</th>\n",
       "      <th>Final_aide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.72</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.86</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2899 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  Classif_value  Regression_value  Classif  Regression  Final  \\\n",
       "0         1.0           1.00              0.78      1.0         1.0    1.0   \n",
       "1         4.0           4.00              3.72      4.0         4.0    4.0   \n",
       "2         4.0           4.00              4.15      4.0         4.0    4.0   \n",
       "3         4.0           3.33              3.17      4.0         3.0    4.0   \n",
       "4         4.0           4.00              3.56      4.0         4.0    4.0   \n",
       "...       ...            ...               ...      ...         ...    ...   \n",
       "2894      1.0           1.00              1.77      1.0         2.0    2.0   \n",
       "2895      3.0           3.67              2.86      4.0         3.0    4.0   \n",
       "2896      4.0           4.00              3.39      4.0         3.0    4.0   \n",
       "2897      1.0           1.00              1.14      1.0         1.0    1.0   \n",
       "2898      1.0           2.00              2.36      2.0         2.0    2.0   \n",
       "\n",
       "      Final_aide  \n",
       "0           1.00  \n",
       "1           4.00  \n",
       "2           4.00  \n",
       "3           4.01  \n",
       "4           4.00  \n",
       "...          ...  \n",
       "2894        2.01  \n",
       "2895        4.01  \n",
       "2896        4.01  \n",
       "2897        1.00  \n",
       "2898        2.00  \n",
       "\n",
       "[2899 rows x 7 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote = choix_final(res_final)\n",
    "vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[280, 165,  25,  10],\n",
       "       [ 71, 247, 178,  11],\n",
       "       [  4,  77, 354, 124],\n",
       "       [  4,  32, 350, 967]], dtype=int64)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plutôt moins bon que la classif : peut etre question de seuil ...\n",
    "confusion_matrix(vote.Overall,vote.Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 278,  177,   15,   10],\n",
       "       [  64,  301,   91,   51],\n",
       "       [   4,  113,  110,  332],\n",
       "       [   4,   46,   46, 1257]], dtype=int64)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ne sert à rien pratiquement, mais seuils à voir\n",
    "confusion_matrix(vote.Overall,vote.Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8183695680938456"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr, _ = pearsonr(vote.Overall, vote.Final)\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMARQUE GENERALE : IL Y A BCP DE 4 ce qui aide beaucoup pour la performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

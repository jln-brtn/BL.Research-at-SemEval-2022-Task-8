{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de classification en Anglais \n",
    "\n",
    "    - Transformers : Summarization : 2 modèles --> 2 Résumés / Puis score de similarités de ces 2 résumés\n",
    "    Noter que l'on peut faire aussi la similarité des textes (autre note ?) et non du résumé\n",
    "    - Text classification sur une base de catégories \"Presse\" : sport - actaulités - économie - etc\n",
    "    - Sentiment analysis : voir si le ton du texte est de même type \n",
    "    - Les 2 derniers classifier seronts utilisés en produit scalaire : Par Catégorie : texte1: note1 - texte2 : note2\n",
    "    et donc sum(notes_par_catégorie) = sum(note1*note2) * 100 au bout (note sur 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pke\n",
    "import spacy\n",
    "import torch\n",
    "import stanza\n",
    "import spacy_stanza\n",
    "import warnings\n",
    "import string\n",
    "from gensim.models import KeyedVectors\n",
    "import enchant    # Pour correction orthographique de synonymes\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection des modèles NLP : ici FRANCAIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement pour l'utilisation de Spacy  - Français\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_spacy = {'en':nlp_en}   # 'en':nlp_en,'de':nlp_de,'es':nlp_es,'pl':nlp_pl  - POUR MEMOIRE\n",
    "langues = ['en','fr','es','de','pl','ar','tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle Word2Vec pour utilisation de synonymes\n",
    "import gensim.downloader\n",
    "model_gensim = gensim.downloader.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords Français NLTK + Spacy \n",
    "stopWords = list(nlp_en.Defaults.stop_words)\n",
    "stopwords_en = list(stopwords.words('english'))  \n",
    "stopwords_en = list(set(stopwords_en + stopWords))\n",
    "stopwds_lg = {'en':stopwords_en}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcteur orthographique pour validation des synonymes OPTIONNEL CAR NON NECESSAIRE\n",
    "d = enchant.Dict(\"en\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection des modèles Transformers : Summary - Text Classification - Sentiment Analysis - Similarity**<br/>\n",
    "    Pour le modèle anglais, on prend 3 summarizer !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèles Transformers de Résumé (NB : Ne pas oublier d'ajouter la truncation pour tous les modèles, peut être source d'erreur)\n",
    "# Visiblement le modèle google/bigbird-pegasus-large-arxiv est trop gros et le pegasus multi news : les 2 très longs ! et résumé long\n",
    "# summarizer1 = pipeline(\"summarization\", model=\"google/bigbird-pegasus-large-arxiv\", truncation = \"only_first\")  # base trop large et longue\n",
    "# summarizer1 = pipeline(\"summarization\", model=\"google/pegasus-multi_news\", truncation = \"only_first\")\n",
    "summarizer1 = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", truncation = \"only_first\")   # ou sshleifer/distilbart-xsum-12-3\n",
    "summarizer2 = pipeline(\"summarization\", model=\"google/pegasus-xsum\", truncation = \"only_first\")  # voir cnn 12-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textes classification ou Zero shot classification (permet de chosir nos propres thèmes)\n",
    "text_clf1 = pipeline(\"zero-shot-classification\", model = \"joeddav/bart-large-mnli-yahoo-answers\", truncation = \"only_first\")   # 10 actégories, voir hugging face\n",
    "text_clf2 = pipeline('zero-shot-classification', model='cross-encoder/nli-MiniLM2-L6-H768',truncation = \"only_first\")\n",
    "# ces modèles sont zero shot classification : catégories possibles choisies par mes soins (dans la presse)\n",
    "candidate_labels = ['Science', 'Politics', 'Education', 'News', 'Health', 'Technology', 'Society', 'Sport', 'Economy', 'Culture', 'International', 'Environment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis : base de 1 à 5 stars\n",
    "sentiment1 = pipeline(\"text-classification\", model = 'nlptown/bert-base-multilingual-uncased-sentiment',truncation = \"only_first\")\n",
    "\n",
    "# Sur la base des sentiments classiques : joy, anger, suprise, sadness, love, fear\n",
    "sentiment2 = pipeline(\"text-classification\", model = 'bhadresh-savani/distilbert-base-uncased-emotion',truncation = \"only_first\")\n",
    "\n",
    "# Sur la base des sentiments classiques : NEGATIVE / POSITIVE\n",
    "sentiment3 = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english',truncation = \"only_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODAGE AVEC SENTENCE TRANSFORMER 2 modfèles et moyenne\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "encoder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "encoder2 = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "def score_similarite(sentence1,sentence2):\n",
    "    # attention, pour que torch fonctionne en dimension sentence1 (et 2) est une liste simple\n",
    "    embed1 = encoder.encode(sentence1, convert_to_tensor=True)\n",
    "    embed2 = encoder.encode(sentence2, convert_to_tensor=True)\n",
    "    embed3 = encoder2.encode(sentence1, convert_to_tensor=True)\n",
    "    embed4 = encoder2.encode(sentence2, convert_to_tensor=True)\n",
    "    return round(float(util.pytorch_cos_sim(embed1,embed2))+float(util.pytorch_cos_sim(embed3,embed4))*100/2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection Data par langues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data_prep_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>pair_lang</th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>title_1</th>\n",
       "      <th>text_1</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>...</th>\n",
       "      <th>text_2</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Style</th>\n",
       "      <th>Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1484084337_1484110209</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>MARTINSBURG, W.Va. — A suspected drunken drive...</td>\n",
       "      <td>Police in West Virginia say a suspected drunke...</td>\n",
       "      <td>['Highway Fatal-DUI-West Virginia', 'Martinsbu...</td>\n",
       "      <td>...</td>\n",
       "      <td>PORT-AU-PRINCE, Haiti — Haitian President Jove...</td>\n",
       "      <td>Haitian President Jovenel Moïse has broken wit...</td>\n",
       "      <td>['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1484396422_1483924666</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.stlucianewsonline.com</td>\n",
       "      <td>Wed Jan  1 21:17:15 2020</td>\n",
       "      <td>https://www.thestar.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...</td>\n",
       "      <td>-</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>['smg2_world', 'smg_europe', 'smg2_news']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1484698254_1483758694</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.teaparty.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.timesofisrael.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>(Breitbart) – President Donald Trump welcomed ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>PALM BEACH, United States — US President Donal...</td>\n",
       "      <td>US president says response to rioting by pro-I...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1576314516_1576455088</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Uber has sold its online food-ordering busines...</td>\n",
       "      <td>Zomato on Tuesday announced it has acquired Ub...</td>\n",
       "      <td>['zomato uber eats business acquisition india ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rapid digitisation and growth in both online b...</td>\n",
       "      <td>The report by Google and Boston Consulting Gro...</td>\n",
       "      <td>['indian online food delivery market to hit us...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484036253_1483894099</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://news.yahoo.com</td>\n",
       "      <td>Wed Jan  1 08:57:59 2020</td>\n",
       "      <td>https://www.channelnewsasia.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>BENGALURU (Reuters) - India has approved its t...</td>\n",
       "      <td>India has approved its third lunar mission mon...</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>BANGALORE: India plans to make a fresh attempt...</td>\n",
       "      <td>India plans to make a fresh attempt to land an...</td>\n",
       "      <td>['India', 'space']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>1586195445_1598778991</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...</td>\n",
       "      <td>...</td>\n",
       "      <td>BM'den Yemen'de kadınların doğumda ölüm riski ...</td>\n",
       "      <td>BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>1590915424_1590940388</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.aksam.com.tr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['İspanya 1. Futbol Ligi', 'la liga', 'koronav...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>1526157103_1492737005</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.samanyoluhaber.com</td>\n",
       "      <td>Thu Feb 20 10:47:10 2020</td>\n",
       "      <td>https://www.fotomac.com.tr</td>\n",
       "      <td>Sun Jan 12 00:00:00 2020</td>\n",
       "      <td>Saray da çare olmadı: 'Borca boğulan dev kulüp...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...</td>\n",
       "      <td>SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...</td>\n",
       "      <td>['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...</td>\n",
       "      <td>...</td>\n",
       "      <td>TFF, resmi internet sitesinden Beşiktaş'ın fai...</td>\n",
       "      <td>Federasyon, Başkan Çebi’nin yaptığı açıklamala...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>1603274500_1618292937</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...</td>\n",
       "      <td>['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...</td>\n",
       "      <td>...</td>\n",
       "      <td>Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...</td>\n",
       "      <td>Covid-19 salgınından vatandaşların korunması i...</td>\n",
       "      <td>['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>1597247537_1604202164</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.takvim.com.tr</td>\n",
       "      <td>Tue May  5 00:00:00 2020</td>\n",
       "      <td>https://www.yeniasir.com.tr</td>\n",
       "      <td>Tue May 12 00:00:00 2020</td>\n",
       "      <td>Grup Yorum üyeleri zorla başlatmıştı... İbrahi...</td>\n",
       "      <td>DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4964 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pair_id pair_lang                       source_url_1  \\\n",
       "0     1484084337_1484110209     en_en     https://www.washingtonpost.com   \n",
       "1     1484396422_1483924666     en_en  https://www.stlucianewsonline.com   \n",
       "2     1484698254_1483758694     en_en           https://www.teaparty.org   \n",
       "3     1576314516_1576455088     en_en           https://gadgets.ndtv.com   \n",
       "4     1484036253_1483894099     en_en             https://news.yahoo.com   \n",
       "...                     ...       ...                                ...   \n",
       "4959  1586195445_1598778991     tr_tr            http://www.haberler.com   \n",
       "4960  1590915424_1590940388     tr_tr           https://www.haberler.com   \n",
       "4961  1526157103_1492737005     tr_tr      http://www.samanyoluhaber.com   \n",
       "4962  1603274500_1618292937     tr_tr           https://www.haberler.com   \n",
       "4963  1597247537_1604202164     tr_tr          https://www.takvim.com.tr   \n",
       "\n",
       "                publish_date_1                     source_url_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020   https://www.washingtonpost.com   \n",
       "1     Wed Jan  1 21:17:15 2020          https://www.thestar.com   \n",
       "2                          NaN    https://www.timesofisrael.com   \n",
       "3                          NaN         https://gadgets.ndtv.com   \n",
       "4     Wed Jan  1 08:57:59 2020  https://www.channelnewsasia.com   \n",
       "...                        ...                              ...   \n",
       "4959                       NaN         https://www.haberler.com   \n",
       "4960                       NaN         https://www.aksam.com.tr   \n",
       "4961  Thu Feb 20 10:47:10 2020       https://www.fotomac.com.tr   \n",
       "4962                       NaN         https://www.haberler.com   \n",
       "4963  Tue May  5 00:00:00 2020      https://www.yeniasir.com.tr   \n",
       "\n",
       "                publish_date_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020   \n",
       "1     Wed Jan  1 00:00:00 2020   \n",
       "2                          NaN   \n",
       "3                          NaN   \n",
       "4                          NaN   \n",
       "...                        ...   \n",
       "4959                       NaN   \n",
       "4960                       NaN   \n",
       "4961  Sun Jan 12 00:00:00 2020   \n",
       "4962                       NaN   \n",
       "4963  Tue May 12 00:00:00 2020   \n",
       "\n",
       "                                                title_1  \\\n",
       "0     Virginia man arrested in fatal DUI crash in We...   \n",
       "1     Guyana: Three injured after car crashes into u...   \n",
       "2     Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3     Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4     India approves third moon mission, months afte...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  Saray da çare olmadı: 'Borca boğulan dev kulüp...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  Grup Yorum üyeleri zorla başlatmıştı... İbrahi...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     MARTINSBURG, W.Va. — A suspected drunken drive...   \n",
       "1     Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...   \n",
       "2     (Breitbart) – President Donald Trump welcomed ...   \n",
       "3     Uber has sold its online food-ordering busines...   \n",
       "4     BENGALURU (Reuters) - India has approved its t...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  \\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...   \n",
       "\n",
       "                                     meta_description_1  \\\n",
       "0     Police in West Virginia say a suspected drunke...   \n",
       "1                                                     -   \n",
       "2                                                   NaN   \n",
       "3     Zomato on Tuesday announced it has acquired Ub...   \n",
       "4     India has approved its third lunar mission mon...   \n",
       "...                                                 ...   \n",
       "4959  Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...   \n",
       "4962  Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_1  ...  \\\n",
       "0     ['Highway Fatal-DUI-West Virginia', 'Martinsbu...  ...   \n",
       "1                                                  ['']  ...   \n",
       "2                                                  ['']  ...   \n",
       "3     ['zomato uber eats business acquisition india ...  ...   \n",
       "4                                                  ['']  ...   \n",
       "...                                                 ...  ...   \n",
       "4959  ['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...  ...   \n",
       "4960  ['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...  ...   \n",
       "4961  ['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...  ...   \n",
       "4962  ['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...  ...   \n",
       "4963                                               ['']  ...   \n",
       "\n",
       "                                                 text_2  \\\n",
       "0     PORT-AU-PRINCE, Haiti — Haitian President Jove...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     PALM BEACH, United States — US President Donal...   \n",
       "3     Rapid digitisation and growth in both online b...   \n",
       "4     BANGALORE: India plans to make a fresh attempt...   \n",
       "...                                                 ...   \n",
       "4959  BM'den Yemen'de kadınların doğumda ölüm riski ...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  TFF, resmi internet sitesinden Beşiktaş'ın fai...   \n",
       "4962  Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...   \n",
       "4963  Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...   \n",
       "\n",
       "                                     meta_description_2  \\\n",
       "0     Haitian President Jovenel Moïse has broken wit...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     US president says response to rioting by pro-I...   \n",
       "3     The report by Google and Boston Consulting Gro...   \n",
       "4     India plans to make a fresh attempt to land an...   \n",
       "...                                                 ...   \n",
       "4959  BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  Federasyon, Başkan Çebi’nin yaptığı açıklamala...   \n",
       "4962  Covid-19 salgınından vatandaşların korunması i...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_2 Geography  Entities  \\\n",
       "0     ['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...       4.0  4.000000   \n",
       "1             ['smg2_world', 'smg_europe', 'smg2_news']       4.0  4.000000   \n",
       "2                                                  ['']       1.0  2.000000   \n",
       "3     ['indian online food delivery market to hit us...       1.0  2.333333   \n",
       "4                                    ['India', 'space']       1.0  1.250000   \n",
       "...                                                 ...       ...       ...   \n",
       "4959  ['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...       1.0  2.000000   \n",
       "4960  ['İspanya 1. Futbol Ligi', 'la liga', 'koronav...       1.0  1.000000   \n",
       "4961                                               ['']       1.0  2.000000   \n",
       "4962     ['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']       1.0  2.000000   \n",
       "4963                                               ['']       2.0  2.000000   \n",
       "\n",
       "          Time  Narrative   Overall     Style      Tone  \n",
       "0     1.000000   4.000000  4.000000  1.666667  2.000000  \n",
       "1     1.000000   4.000000  3.666667  1.666667  1.333333  \n",
       "2     1.000000   2.333333  2.333333  1.000000  1.333333  \n",
       "3     2.666667   1.666667  2.000000  1.666667  1.666667  \n",
       "4     1.000000   1.250000  1.250000  1.000000  1.000000  \n",
       "...        ...        ...       ...       ...       ...  \n",
       "4959  2.000000   4.000000  3.000000  1.000000  1.000000  \n",
       "4960  1.000000   1.000000  1.000000  1.000000  1.000000  \n",
       "4961  3.000000   4.000000  3.000000  1.000000  2.000000  \n",
       "4962  3.000000   3.000000  3.000000  1.000000  1.000000  \n",
       "4963  1.000000   2.000000  2.000000  3.000000  1.000000  \n",
       "\n",
       "[4964 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remémorer numéro de ligne - compléter les Nan\n",
    "data['ligne'] = data.index\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation des datasets, le dernier étant à traduire en plus\n",
    "anglais = data.loc[data.pair_lang == 'en_en',['ligne','title_1','title_2','text_1','text_2','Geography', 'Entities',\n",
    "       'Time', 'Narrative', 'Overall', 'Style', 'Tone']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter aussi le modèle anglais_all_traduit \n",
    "anglais_all_traduit = pd.read_csv('allemand_anglais_traduit.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests divers et Fonctions nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Uber has sold its online food-ordering business in India to local rival Zomato in exchange for a 9.99 percent stake in the startup backed by China's Ant Financial . Uber Eats in India accounted for 3 percent of the business' gross bookings globally, but more than a quarter of its adjusted EBITDA loss in first three quarters of 2019 .\n",
      " India's online food industry to become an $8 billion (roughly Rs. 56,000) market by 2022 -- growing at a CAGR of 25-30 percent . Zomato and Swiggy currently dominate the online food delivery market in India . Peer or network advocacy played a critical role in drawing people to try online food ordering for the first time .\n"
     ]
    }
   ],
   "source": [
    "# Résumés\n",
    "print(summarizer1(anglais.text_1[3])[0]['summary_text'])\n",
    "print(summarizer1(anglais.text_2[3])[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's food for thought for Uber.\n",
      "\"Ordering food online is now a habit.\"\n"
     ]
    }
   ],
   "source": [
    "print(summarizer2(anglais.text_1[3])[0]['summary_text'])\n",
    "print(summarizer2(anglais.text_2[3])[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de calcul du score (produit scalaire) pour résultats de classifaction\n",
    "def fonction_produit_dotcom(liste_categor, dico_scores1,dico_scores2):\n",
    "    \"\"\"\"dico scores sont les résultats obtenus pour chaque catégorie des textes 1 et 2\"\"\"\n",
    "    result = 0.0\n",
    "    for cat in liste_categor:\n",
    "        result += round(dico_scores1[cat] * dico_scores2[cat],4)\n",
    "    return result * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type1\n",
    "def transform_text_clf1(liste_dico):\n",
    "    res = {}\n",
    "    for dic in liste_dico:\n",
    "        res[dic['label']] = dic['score']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type2\n",
    "def transform_text_clf2(liste_cat,liste_sc):\n",
    "    res = {}\n",
    "    for i in range(len(liste_cat)):\n",
    "        res[liste_cat[i]] = liste_sc[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.609999999999996\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "classes = text_clf1(anglais.text_1[3], candidate_labels)\n",
    "scores1 = transform_text_clf2(classes['labels'],classes['scores'])\n",
    "classes2 = text_clf1(anglais.text_2[3], candidate_labels)\n",
    "scores2 = transform_text_clf2(classes2['labels'],classes2['scores'])\n",
    "print(fonction_produit_dotcom(candidate_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.33\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "classes = text_clf2(anglais.text_1[3], candidate_labels)\n",
    "scores1 = transform_text_clf2(classes['labels'],classes['scores'])\n",
    "classes2 = text_clf2(anglais.text_2[3], candidate_labels)\n",
    "scores2 = transform_text_clf2(classes2['labels'],classes2['scores'])\n",
    "print(fonction_produit_dotcom(candidate_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests sentiment analysis\n",
    "liste_labels = ['1 star','2 stars','3 stars','4 stars','5 stars']\n",
    "# scores1 = transform_text_clf1(sentiment1(anglais.text_1[3],return_all_scores=True)[0])\n",
    "# scores2 = transform_text_clf1(sentiment1(anglais.text_2[3],return_all_scores=True)[0])\n",
    "# print(scores1)\n",
    "# print(scores2)\n",
    "# print(fonction_produit_dotcom(liste_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION CE MODELE SE DEFINIT SUR 4 CLASSES : mixed, positif, negatif, objectif\n",
    "liste_sentiments = ['joy','anger','sadness','love','surprise','fear']\n",
    "# scores1 = transform_text_clf1(sentiment2(anglais.title_1[3],return_all_scores=True)[0])\n",
    "# scores2 = transform_text_clf1(sentiment2(anglais.title_2[3],return_all_scores=True)[0])\n",
    "# scores3 = transform_text_clf1(sentiment2(anglais.text_1[3],return_all_scores=True)[0])\n",
    "# scores4 = transform_text_clf1(sentiment2(anglais.text_2[3],return_all_scores=True)[0])\n",
    "# print(fonction_produit_dotcom(liste_sentiments, scores1,scores2))\n",
    "# print(fonction_produit_dotcom(liste_sentiments, scores3,scores4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_sentiments2 = ['NEGATIVE','POSITIVE']\n",
    "# scores1 = transform_text_clf1(sentiment3(anglais.text_1[3],return_all_scores=True)[0])\n",
    "# scores2 = transform_text_clf1(sentiment3(anglais.text_2[3],return_all_scores=True)[0])\n",
    "# print(scores1)\n",
    "# print(scores2)\n",
    "# print(fonction_produit_dotcom(liste_sentiments2, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.97\n",
      "39.28\n",
      "3.79\n",
      "51.0\n"
     ]
    }
   ],
   "source": [
    "# TESTS SCORES DE SIMILARITES : Titres, Textes complets (attention Truncation ...)\n",
    "print(score_similarite(anglais.title_1[3],anglais.title_2[3]))\n",
    "print(score_similarite(anglais.text_1[3],anglais.text_2[3]))\n",
    "print(score_similarite(summarizer1(anglais.text_1[0])[0]['summary_text'],summarizer1(anglais.text_2[0])[0]['summary_text']))\n",
    "print(score_similarite(summarizer2(anglais.text_1[0])[0]['summary_text'],summarizer2(anglais.text_2[0])[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('child', 0.8979307413101196),\n",
       " ('murder', 0.8967654705047607),\n",
       " ('killing', 0.8901609182357788),\n",
       " ('kills', 0.8862658143043518),\n",
       " ('attack', 0.8817499876022339),\n",
       " ('victim', 0.8787229657173157),\n",
       " ('killed', 0.8760652542114258),\n",
       " ('suicide', 0.875905454158783),\n",
       " ('dies', 0.8747766613960266),\n",
       " ('died', 0.8738439083099365)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essais de synonymies à utiliser pour sorties PKE, termes prinicpaux\n",
    "syns = model_gensim.most_similar(\"death\", topn=10)\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de summarization \n",
    "def summarization(texte):\n",
    "    return summarizer1(texte)[0]['summary_text'], summarizer2(texte)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_classifiers = {'text_clf1': 'score_classif1','text_clf2':'score_classif2','sentiment1':'score_sentiment1',\n",
    "                    'sentiment2': 'score_sentiment2','sentiment3': 'score_sentiment3'}\n",
    "dico_categories = {'text_clf1': candidate_labels,'text_clf2':candidate_labels,'sentiment1':liste_labels,\n",
    "                    'sentiment2': liste_sentiments,'sentiment3': liste_sentiments2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de classification et sentiment analysis\n",
    "def classification(texte,clf):\n",
    "    # assume nms des claasifiers et methode de transformation\n",
    "    if clf == \"text_clf1\":\n",
    "        try:\n",
    "            classes = text_clf1(texte,dico_categories['text_clf1'])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return transform_text_clf2(classes['labels'],classes['scores'])    \n",
    "    elif clf == \"text_clf2\":                                 \n",
    "        try:\n",
    "            classes = text_clf2(texte,dico_categories['text_clf2'])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return transform_text_clf2(classes['labels'],classes['scores'])                          \n",
    "    elif clf == \"sentiment1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"sentiment2\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment2(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"sentiment3\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment3(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    else:\n",
    "        return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des mots de moins de 2 lettres non numériques\n",
    "def supp_moins_2_lettres_stopwords(phrase,stopwd):\n",
    "    temp = phrase.split(' ')\n",
    "    res = ''\n",
    "    for mot in temp:\n",
    "        if mot not in stopwd and (len(mot)>2 or (len(mot)>0 and mot[0] in ['0','1','2','3','4','5','6','7','8','9'])):\n",
    "            res += mot + ' '\n",
    "    return res[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des traits d'union(regroupe)/ des apostrophes / ponctuations\n",
    "def modif(texte,stopmots):\n",
    "    # modifications simples des textes : ponctuations, petits mots, stopwords (à faire pour entités et pke textes)\n",
    "    texte=re.sub('\\'',' ',texte)   # suppression apostrophe\n",
    "    texte=re.sub('-','',texte)    # suppression trait union\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation)) # suppression de toutes les ponctuations\n",
    "    texte=regex.sub(' ',texte)\n",
    "    texte = supp_moins_2_lettres_stopwords(texte,stopmots)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des synonymes (existants en orthographe) à la suite de l'analyse pke\n",
    "def ajout_synonymes(mot, correct_ortho = True):\n",
    "    # on ajoute les 10 premiers synonymes existants, on vérifie orthographe (optionnel)\n",
    "    syns = model_gensim.most_similar(mot,topn = 20)\n",
    "    if correct_ortho == True:\n",
    "        res = []\n",
    "        for m in syns:\n",
    "            if d.check(m[0]):   #  il y a le mot et son pourcentage d'importance\n",
    "                res.append(m)\n",
    "        syns = res\n",
    "    return syns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la bonne méthodologie à appliquer PKE ??? : Noms Ok - Verbes ? - Adjectifs ? - Noms propres ?\n",
    "Quelle quantité de mots prendre ?\n",
    "Ne pas noter les titres seuls ? : trop peu de mots !  Et du coup note peut être forte avec un seul mot !\n",
    "Supprimer en en-tête les stopwords, ponctuation, les apostrophes - AUTRES ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres de la méthode : A revoir ?\n",
    "methode1 = {\"NOUN\", \"PROPN\", \"ADJ\",\"VERB\"}\n",
    "methode2 = {\"NOUN\", \"PROPN\", \"ADJ\"}\n",
    "nb_mots = {'meth1': 30, 'meth2':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKE : Analyse des termes principaux dans les textes et titres \n",
    "# Problème \n",
    "def transformation_pke_results(res1,res2, correct_ortho = True):\n",
    "    \"\"\"\n",
    "    Transformation des resultats de PKE : Pb bigramme peuvent ne pas être ds les 2 textes mais 1 mot seulement\n",
    "    liste de clés et dictionnaires de valeurs, bigrammes jouera ainsi de maniere coefficientée \n",
    "    Exemple : fuite eau:0.05 --> 3 mots au final : fuite, eau, fuite eau : 0.05\n",
    "    De plus on ajoute les synonymes issus de gensim en les coefficiant et vérifiant que cela \"\"\"\n",
    "    \n",
    "    liste1 = []; liste2 = [] ; dico1 = {}; dico2 = {}\n",
    "    for elt in res1:\n",
    "        liste1.append(elt[0])\n",
    "        dico1[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:    # bigramme dans ce cas, ajout des 2 mots\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste1.append(mot)\n",
    "                dico1[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste1.append(syn[0])   # Ajout du mot \n",
    "                        dico1[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "                    \n",
    "    for elt in res2:\n",
    "        liste2.append(elt[0])\n",
    "        dico2[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste2.append(mot)\n",
    "                dico2[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste2.append(syn[0])   # Ajout du mot \n",
    "                        dico2[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "    \n",
    "    # similarites entre les 2 listes issus de pke avec poids\n",
    "    sim = 0\n",
    "    for elt in liste1:\n",
    "        if elt in liste2:\n",
    "            sim += (dico1[elt] + dico2[elt])/2\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entites_communes(nlp,text1,text2):\n",
    "    \"\"\"\"\n",
    "    Cette première fonction ne regarde que les entités communes : personnes, dates, groupe, localisations\n",
    "    Elle sera appliquée aux textes et aux titres et cumulé : si cumul en titre et texte : compte double !\"\"\"\n",
    "    \n",
    "    try:\n",
    "        doc1 = nlp(text1)\n",
    "        doc2 = nlp(text2)\n",
    "    except:\n",
    "        return (0,[],0,[],0,[])\n",
    "    else:\n",
    "        nb_commun_ent = 0; liste_commun_ent = []\n",
    "        nb_commun_geo = 0; liste_commun_geo = []\n",
    "        nb_commun_dat = 0; liste_commun_dat = []\n",
    "\n",
    "        if len(doc1.ents)>0 and len(doc2.ents)>0:\n",
    "            liste1 = []; dico1 = {}\n",
    "            for elt in doc1.ents:\n",
    "                if elt.label_ in ['PERSON','PER'] and ' ' in elt.text:\n",
    "                    mots = elt.text.split(' ')\n",
    "                    for mot in mots:\n",
    "                        if mot not in liste1:\n",
    "                            liste1.append(mot)\n",
    "                            dico1[mot] = elt.label_\n",
    "                elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                    if elt.text not in liste1:\n",
    "                        liste1.append(elt.text)\n",
    "                        dico1[elt.text] = elt.label_\n",
    "            liste2 = []\n",
    "            for elt in doc2.ents:\n",
    "                if elt.label_ in ['PERSON','PER'] and ' ' in elt.text:\n",
    "                    mots = elt.text.split(' ')\n",
    "                    for mot in mots:\n",
    "                        if mot not in liste2:\n",
    "                            liste2.append(mot)\n",
    "                elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                    if elt.text not in liste2:\n",
    "                        liste2.append(elt.text)\n",
    "\n",
    "            # points communs des listes        \n",
    "            for elt in liste1:\n",
    "                if elt in liste2:\n",
    "                    if dico1[elt] == 'LOC':\n",
    "                        nb_commun_geo += 1\n",
    "                        liste_commun_geo.append(elt)\n",
    "                    elif dico1[elt] in ['DATE','TIME']:\n",
    "                        nb_commun_dat += 1\n",
    "                        liste_commun_dat.append(elt)\n",
    "                    else:\n",
    "                        nb_commun_ent += 1\n",
    "                        liste_commun_ent.append(elt)\n",
    "\n",
    "        return nb_commun_ent, liste_commun_ent,nb_commun_geo, liste_commun_geo,nb_commun_dat, liste_commun_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Creation_features_comparaison(df,langue, test_position = [methode1,methode2]):\n",
    "    \"\"\"Création des notes pour classification ensuite\"\"\"\n",
    "    \n",
    "    resultats = pd.DataFrame(columns = ['summary1_text1','summary2_text1','summary1_text2','summary2_text2',\n",
    "            'nb_entites_idem','nb_lieux_idem', 'nb_dates_idem','entites_idem','lieux_idem','dates_idem',\n",
    "            'score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "            'score_sentiment1','score_sentiment2','score_sentiment3','meth1_similarites','meth2_similarites'])\n",
    "    \n",
    "    # initialisation de la langue stanza\n",
    "    stanza.download(langue)\n",
    "    nlp_stanza = spacy_stanza.load_pipeline(langue)\n",
    "    stopmts = stopwds_lg[langue]\n",
    "    if langue in dico_spacy.keys():\n",
    "        nlp_spacy = dico_spacy[langue]\n",
    "    else:\n",
    "        nlp_spacy = None\n",
    "        \n",
    "    for i in tqdm(range(len(df))):\n",
    "        dico_res = {}\n",
    "        \n",
    "        # Summary et comparatifs \n",
    "        try:\n",
    "            dico_res['summary1_text1'],dico_res['summary2_text1'] = summarization(df.text_1[i])\n",
    "        except:\n",
    "            dico_res['summary1_text1'] = '';dico_res['summary2_text1'] = ''\n",
    "        try:\n",
    "            dico_res['summary1_text2'],dico_res['summary2_text2'] = summarization(df.text_2[i])\n",
    "        except:\n",
    "            dico_res['summary1_text2'] = '';dico_res['summary2_text2'] = ''\n",
    "        try:\n",
    "            dico_res['score_similarite_titres'] = score_similarite(df.title_1[i],df.title_2[i])\n",
    "        except:\n",
    "            dico_res['score_similarite_titres'] = 'Error'\n",
    "        if len(dico_res['summary1_text1'])>0 and len(dico_res['summary1_text2'])>0:\n",
    "            dico_res['score_similarite_resume1'] = score_similarite(dico_res['summary1_text1'],dico_res['summary1_text2'])\n",
    "        else:\n",
    "            dico_res['score_similarite_resume1'] = 0\n",
    "        if len(dico_res['summary2_text1'])>0 and len(dico_res['summary2_text2'])>0:\n",
    "            dico_res['score_similarite_resume2'] = score_similarite(dico_res['summary2_text1'],dico_res['summary2_text2'])\n",
    "        else:\n",
    "            dico_res['score_similarite_resume2'] = 0\n",
    "        \n",
    "        # analyse de textes classification et de sentiments\n",
    "        if type(df.title_1[i]) == str and type(df.text_1[i]) == str:\n",
    "            texte1 = df.title_1[i] + ' ' + df.text_1[i]\n",
    "        elif type(df.title_1[i]) == str:\n",
    "            texte1 = df.title_1[i]\n",
    "        elif type(df.text_1[i]) == str:\n",
    "            texte1 = df.text_1[i]   \n",
    "        else:\n",
    "            texte1=''\n",
    "        if type(df.title_2[i]) == str and type(df.text_2[i]) == str:\n",
    "            texte2 = df.title_2[i] + ' ' + df.text_2[i]\n",
    "        elif type(df.title_2[i]) == str:\n",
    "            texte2 = df.title_2[i]\n",
    "        elif type(df.text_2[i]) == str:\n",
    "            texte2 = df.text_2[i]   \n",
    "        else:\n",
    "            texte2=''\n",
    "        if len(texte1)>0 and len(texte2)>0:\n",
    "            for classifier in dico_classifiers.keys():\n",
    "                scores1 = classification(texte1,classifier)\n",
    "                scores2 = classification(texte2,classifier)\n",
    "                if scores1 != 'error' and scores2 != 'error':\n",
    "                    dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                else:\n",
    "                    scores1 = classification(df.title_1[i],classifier)\n",
    "                    scores2 = classification(df.title_2[i],classifier)\n",
    "                    if scores1 != 'error' and scores2 != 'error':\n",
    "                        dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                    else:\n",
    "                        dico_res[dico_classifiers[classifier]] = None\n",
    "        else:\n",
    "            for classifier in dico_classifiers.keys():\n",
    "                dico_res[dico_classifiers[classifier]] = 0\n",
    "                \n",
    "        # pré traitement des textes pour entités et PKE\n",
    "        texte1 = modif(texte1, stopmts)\n",
    "        texte2 = modif(texte2, stopmts)\n",
    "        \n",
    "        # ENTITES COMMUNES : on tient compte des bigrammes Noms qui posent erreurs ex: Joe Biden et Biden \n",
    "        # Ici, on considère mieux le CUMUl titres et Textes avec une pondération double pour le titre \n",
    "        # Il faut aussi enlever les petits mots donc pré-traitement en texte\n",
    "        \n",
    "        try:\n",
    "            nb_ent1,list_ent1,nb_geo1,list_geo1,nb_dat1,list_dat1 = entites_communes(nlp_stanza,df.title_1[i],df.title_2[i])\n",
    "        except:\n",
    "            nb_ent1,list_ent1,nb_geo1,list_geo1,nb_dat1,list_dat1 = (0,[],0,[],0,[])\n",
    "        try:\n",
    "            nb_ent2,list_ent2,nb_geo2,list_geo2,nb_dat2,list_dat2 = entites_communes(nlp_stanza,df.text_1[i],df.text_2[i])\n",
    "        except:\n",
    "            nb_ent2,list_ent2,nb_geo2,list_geo2,nb_dat2,list_dat2 = (0,[],0,[],0,[])                                                                       \n",
    "        if nlp_spacy != None:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = entites_communes(nlp_spacy,df.title_1[i],df.title_2[i])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = entites_communes(nlp_spacy,df.text_1[i],df.text_2[i])\n",
    "        else:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = (0,[],0,[],0,[])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = (0,[],0,[],0,[])\n",
    "        dico_res['nb_entites_idem'] = nb_ent1 * 2 + nb_ent2 + nb_ent3 * 2 + nb_ent4\n",
    "        dico_res['nb_lieux_idem'] = nb_geo1  * 2 + nb_geo2 + nb_geo3  * 2 + nb_geo4\n",
    "        dico_res['nb_dates_idem'] = nb_dat1 * 2 + nb_dat2 + nb_dat3 * 2 + nb_dat4\n",
    "        # fusion des listes en supprimant les doublons\n",
    "        dico_res['entites_idem'] = list(set(list_ent1+list_ent2+ list_ent3+list_ent4))\n",
    "        dico_res['lieux_idem'] = list(set(list_geo1+list_geo2+list_geo3+list_geo4))\n",
    "        dico_res['dates_idem'] = list(set(list_dat1+list_dat2+list_dat3+list_dat4))\n",
    "        \n",
    "        for j,meth in enumerate(test_position):\n",
    "            nom ='meth'+str(j+1)\n",
    "            nb_mots_meth = nb_mots[nom]\n",
    "            if len(texte1)>0 and len(texte2)>0:\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte1,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases3 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte2,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases4 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                dico_res[nom+'_similarites'] = round(100*transformation_pke_results(keyphrases3,keyphrases4),1)\n",
    "            else:\n",
    "                dico_res[nom+'_similarites'] = 'Error'\n",
    "        \n",
    "        resultats.loc[len(resultats)] = dico_res\n",
    "        \n",
    "    newdf = pd.concat([df,resultats],axis=1)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention, problème de mémoire : faire par steps de 200, voir pb (peut arriver sur certains textes pourris)\n",
    "# le n°50 n'a pas de sens en texte 2 - nbreux pbs tags : 'GW'\n",
    "# similarites = Creation_features_comparaison(anglais[350:400].reset_index(drop=True),'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # similarites.to_csv('corpus_en_notes.csv')   # A Utiliser pour le premier\n",
    "# precedent = pd.read_csv('corpus_en_notes.csv',index_col=0)\n",
    "# similarites2 = pd.concat([precedent,similarites], axis=0)\n",
    "# #similarites2 = similarites2.sort_values(by='ligne').reset_index(drop=True)\n",
    "# similarites2 = similarites2.reset_index(drop=True)\n",
    "# similarites2.to_csv('corpus_en_notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for j in range(10):\n",
    "#     similarites = Creation_features_comparaison(anglais[1301+100*j:1301+100*(j+1)].reset_index(drop=True),'en')\n",
    "#     precedent = pd.read_csv('corpus_en_notes.csv',index_col=0)\n",
    "#     similarites2 = pd.concat([precedent,similarites], axis=0)\n",
    "#     similarites2 = similarites2.reset_index(drop=True)\n",
    "#     similarites2.to_csv('corpus_en_notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Style</th>\n",
       "      <th>Tone</th>\n",
       "      <th>title_1_de</th>\n",
       "      <th>text_1_de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4280</td>\n",
       "      <td>Germany weather: expert makes \"shock forecast\"...</td>\n",
       "      <td>Black Jack Brigade Convoys to Hohenfels, Germa...</td>\n",
       "      <td>Weather experts present a first forecast for t...</td>\n",
       "      <td>Elements of 2nd Armored Brigade Combat Team, 1...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deutschland-Wetter: Experte macht „Schockprogn...</td>\n",
       "      <td>Wetter-Experten stellen eine erste Prognose fü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4281</td>\n",
       "      <td>Currency: Euro sinks to monthly low</td>\n",
       "      <td>“The Wuhan Shake”- Will It Catch On In Spain?</td>\n",
       "      <td>FRANKFURT (dpa-AFX) - The euro exchange rate f...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nPeople in Italy have been advised ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Devisen: Euro sinkt auf Monatstief</td>\n",
       "      <td>FRANKFURT (dpa-AFX) - Der Eurokurs ist am Donn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4282</td>\n",
       "      <td>Chris Trousdale, singer of the boy band Dream ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singer of the former Boyband Dream Street Chri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Chris Trousdale, Sänger der Boyband Dream Stre...</td>\n",
       "      <td>Sänger der ehemaligen Boyband Dream Street Chr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4283</td>\n",
       "      <td>Berlinale tips for March 1st</td>\n",
       "      <td>Coverage of COVID-19 puts journalists at risk ...</td>\n",
       "      <td>Berlinale Tips for the Short-Decided: At this ...</td>\n",
       "      <td>Journalists in Africa are at risk of being det...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Berlinale-Tipps für den 1. März</td>\n",
       "      <td>Berlinale-Tipps für Kurzentschlossene: Unsere ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4284</td>\n",
       "      <td>Black paramedic shot shot: Beyoncé demands pro...</td>\n",
       "      <td>Beyoncé Makes Surprise Appearance on Disney Si...</td>\n",
       "      <td>Advertisement Advertisement Louisville.US sing...</td>\n",
       "      <td>Image zoom ABC\\n\\nBeyoncé surprised Disney fan...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Schwarze Sanitäterin erschossen: Beyoncé verla...</td>\n",
       "      <td>Anzeige\\n\\nAnzeige\\n\\nLouisville. Die US-Sänge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4356</td>\n",
       "      <td>Child abuse: \"My foster mother sold me for sex</td>\n",
       "      <td>Germany's Merkel backs WHO as calls for more c...</td>\n",
       "      <td>Getty Images/iStockphoto More than 50.In 2018,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Kindesmisshandlung: „Meine Pflege-Mutter verka...</td>\n",
       "      <td>Getty Images/iStockphoto\\n\\nMehr als 50.000 Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4357</td>\n",
       "      <td>Conte: Italy loosens the Corona restrictions</td>\n",
       "      <td>Covid-19 outbreak will strengthen Italy - Conte</td>\n",
       "      <td>OK We use cookies and other technologies on ou...</td>\n",
       "      <td>Italy's dramatic coronavirus epidemic is an ed...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Conte: Italien lockert die Corona-Beschränkungen</td>\n",
       "      <td>OK\\n\\nWir setzen auf unserer Website Cookies u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4358</td>\n",
       "      <td>CDU Secretary of State Krings against clear na...</td>\n",
       "      <td>German coalition parties wrestle over cash inc...</td>\n",
       "      <td>Düsseldorf (ots) - In the debate about hate an...</td>\n",
       "      <td>Article content\\n\\nBERLIN — Germany’s Social D...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CDU-Staatssekretär Krings gegen Klarnamen-Pfli...</td>\n",
       "      <td>Düsseldorf (ots) - In der Debatte um Hass und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4359</td>\n",
       "      <td>Ahrensburg: Casa-Rossa-Wirt gives up and looks...</td>\n",
       "      <td>How to grow chicory | Alys Fowler</td>\n",
       "      <td>Ahrensburg.Only one and a half years after his...</td>\n",
       "      <td>Italians put these bitter greens at the heart ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ahrensburg: Casa-Rossa-Wirt gibt auf und sucht...</td>\n",
       "      <td>Ahrensburg. Nur anderthalb Jahre nach seinem C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4360</td>\n",
       "      <td>Donald Trump gives journalists hygiene tips ab...</td>\n",
       "      <td>Trump Worried Too Much Coronavirus Testing Wou...</td>\n",
       "      <td>Washington - US President Donald Trump feels c...</td>\n",
       "      <td>4.3k SHARES Facebook Twitter Whatsapp Pinteres...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Donald Trump gibt Journalisten Hygiene-Tipps w...</td>\n",
       "      <td>Washington -\\n\\nUS-Präsident Donald Trump fühl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ligne                                            title_1  \\\n",
       "19   4280  Germany weather: expert makes \"shock forecast\"...   \n",
       "20   4281                Currency: Euro sinks to monthly low   \n",
       "21   4282  Chris Trousdale, singer of the boy band Dream ...   \n",
       "22   4283                       Berlinale tips for March 1st   \n",
       "23   4284  Black paramedic shot shot: Beyoncé demands pro...   \n",
       "..    ...                                                ...   \n",
       "95   4356     Child abuse: \"My foster mother sold me for sex   \n",
       "96   4357       Conte: Italy loosens the Corona restrictions   \n",
       "97   4358  CDU Secretary of State Krings against clear na...   \n",
       "98   4359  Ahrensburg: Casa-Rossa-Wirt gives up and looks...   \n",
       "99   4360  Donald Trump gives journalists hygiene tips ab...   \n",
       "\n",
       "                                              title_2  \\\n",
       "19  Black Jack Brigade Convoys to Hohenfels, Germa...   \n",
       "20      “The Wuhan Shake”- Will It Catch On In Spain?   \n",
       "21                                                NaN   \n",
       "22  Coverage of COVID-19 puts journalists at risk ...   \n",
       "23  Beyoncé Makes Surprise Appearance on Disney Si...   \n",
       "..                                                ...   \n",
       "95  Germany's Merkel backs WHO as calls for more c...   \n",
       "96    Covid-19 outbreak will strengthen Italy - Conte   \n",
       "97  German coalition parties wrestle over cash inc...   \n",
       "98                  How to grow chicory | Alys Fowler   \n",
       "99  Trump Worried Too Much Coronavirus Testing Wou...   \n",
       "\n",
       "                                               text_1  \\\n",
       "19  Weather experts present a first forecast for t...   \n",
       "20  FRANKFURT (dpa-AFX) - The euro exchange rate f...   \n",
       "21  Singer of the former Boyband Dream Street Chri...   \n",
       "22  Berlinale Tips for the Short-Decided: At this ...   \n",
       "23  Advertisement Advertisement Louisville.US sing...   \n",
       "..                                                ...   \n",
       "95  Getty Images/iStockphoto More than 50.In 2018,...   \n",
       "96  OK We use cookies and other technologies on ou...   \n",
       "97  Düsseldorf (ots) - In the debate about hate an...   \n",
       "98  Ahrensburg.Only one and a half years after his...   \n",
       "99  Washington - US President Donald Trump feels c...   \n",
       "\n",
       "                                               text_2  Geography  Entities  \\\n",
       "19  Elements of 2nd Armored Brigade Combat Team, 1...        3.0       4.0   \n",
       "20  \\n\\n\\n\\n\\n\\nPeople in Italy have been advised ...        2.0       3.0   \n",
       "21                                                NaN        1.0       1.0   \n",
       "22  Journalists in Africa are at risk of being det...        4.0       4.0   \n",
       "23  Image zoom ABC\\n\\nBeyoncé surprised Disney fan...        2.0       3.0   \n",
       "..                                                ...        ...       ...   \n",
       "95                                                NaN        4.0       4.0   \n",
       "96  Italy's dramatic coronavirus epidemic is an ed...        1.0       1.0   \n",
       "97  Article content\\n\\nBERLIN — Germany’s Social D...        1.0       3.0   \n",
       "98  Italians put these bitter greens at the heart ...        3.0       4.0   \n",
       "99  4.3k SHARES Facebook Twitter Whatsapp Pinteres...        1.0       1.0   \n",
       "\n",
       "    Time  Narrative  Overall  Style  Tone  \\\n",
       "19   4.0        4.0      4.0    2.0   3.0   \n",
       "20   3.0        4.0      4.0    3.0   2.0   \n",
       "21   1.0        2.0      2.0    1.0   1.0   \n",
       "22   3.0        4.0      4.0    3.0   3.0   \n",
       "23   3.0        4.0      4.0    2.0   3.0   \n",
       "..   ...        ...      ...    ...   ...   \n",
       "95   4.0        4.0      4.0    2.0   3.0   \n",
       "96   3.0        3.0      2.0    2.0   2.0   \n",
       "97   4.0        4.0      4.0    1.0   1.0   \n",
       "98   4.0        4.0      4.0    2.0   2.0   \n",
       "99   4.0        4.0      4.0    2.0   4.0   \n",
       "\n",
       "                                           title_1_de  \\\n",
       "19  Deutschland-Wetter: Experte macht „Schockprogn...   \n",
       "20                 Devisen: Euro sinkt auf Monatstief   \n",
       "21  Chris Trousdale, Sänger der Boyband Dream Stre...   \n",
       "22                    Berlinale-Tipps für den 1. März   \n",
       "23  Schwarze Sanitäterin erschossen: Beyoncé verla...   \n",
       "..                                                ...   \n",
       "95  Kindesmisshandlung: „Meine Pflege-Mutter verka...   \n",
       "96   Conte: Italien lockert die Corona-Beschränkungen   \n",
       "97  CDU-Staatssekretär Krings gegen Klarnamen-Pfli...   \n",
       "98  Ahrensburg: Casa-Rossa-Wirt gibt auf und sucht...   \n",
       "99  Donald Trump gibt Journalisten Hygiene-Tipps w...   \n",
       "\n",
       "                                            text_1_de  \n",
       "19  Wetter-Experten stellen eine erste Prognose fü...  \n",
       "20  FRANKFURT (dpa-AFX) - Der Eurokurs ist am Donn...  \n",
       "21  Sänger der ehemaligen Boyband Dream Street Chr...  \n",
       "22  Berlinale-Tipps für Kurzentschlossene: Unsere ...  \n",
       "23  Anzeige\\n\\nAnzeige\\n\\nLouisville. Die US-Sänge...  \n",
       "..                                                ...  \n",
       "95  Getty Images/iStockphoto\\n\\nMehr als 50.000 Ma...  \n",
       "96  OK\\n\\nWir setzen auf unserer Website Cookies u...  \n",
       "97  Düsseldorf (ots) - In der Debatte um Hass und ...  \n",
       "98  Ahrensburg. Nur anderthalb Jahre nach seinem C...  \n",
       "99  Washington -\\n\\nUS-Präsident Donald Trump fühl...  \n",
       "\n",
       "[81 rows x 14 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anglais_all_traduit[19:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b222bde4b0497ab22277ed483f333f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 19:42:24 INFO: Downloading default packages for language: en (English)...\n",
      "2021-12-29 19:42:25 INFO: File exists: C:\\Users\\stg-sdu\\stanza_resources\\en\\default.zip.\n",
      "2021-12-29 19:42:28 INFO: Finished downloading models and saved to C:\\Users\\stg-sdu\\stanza_resources.\n",
      "2021-12-29 19:42:28 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2021-12-29 19:42:28 INFO: Use device: cpu\n",
      "2021-12-29 19:42:28 INFO: Loading: tokenize\n",
      "2021-12-29 19:42:28 INFO: Loading: pos\n",
      "2021-12-29 19:42:28 INFO: Loading: lemma\n",
      "2021-12-29 19:42:28 INFO: Loading: depparse\n",
      "2021-12-29 19:42:28 INFO: Loading: sentiment\n",
      "2021-12-29 19:42:28 INFO: Loading: constituency\n",
      "2021-12-29 19:42:29 INFO: Loading: ner\n",
      "2021-12-29 19:42:29 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ebf0d6e3ed4f15b01c6dd7f707a972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 37. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 35. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 134. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 36. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 34. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 90. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 87. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 40. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 40. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 136. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 73. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 93. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 49. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 48. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 141. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 83. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 78. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 82. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 9. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 9. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 8. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 52. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 50. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 130. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 103. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 67. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 87. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "# Attention, problème de mémoire : faire par steps de 200, voir pb (peut arriver sur certains textes pourris)\n",
    "# bloque à 4, à 17\n",
    "similarites = Creation_features_comparaison(anglais_all_traduit[:100].reset_index(drop=True),'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarites.to_csv('corpus_en_de_notes.csv')   # A Utiliser pour le premier\n",
    "# precedent = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "# similarites2 = pd.concat([precedent,similarites], axis=0)\n",
    "# similarites2 = similarites2.reset_index(drop=True)\n",
    "# similarites2.to_csv('corpus_en_de_notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérification concat\n",
    "# precedent = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "# precedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240ee2b901114d9d9994da8f2614f202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 21:44:10 INFO: Downloading default packages for language: en (English)...\n",
      "2021-12-29 21:44:11 INFO: File exists: C:\\Users\\stg-sdu\\stanza_resources\\en\\default.zip.\n",
      "2021-12-29 21:44:14 INFO: Finished downloading models and saved to C:\\Users\\stg-sdu\\stanza_resources.\n",
      "2021-12-29 21:44:14 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2021-12-29 21:44:14 INFO: Use device: cpu\n",
      "2021-12-29 21:44:14 INFO: Loading: tokenize\n",
      "2021-12-29 21:44:14 INFO: Loading: pos\n",
      "2021-12-29 21:44:14 INFO: Loading: lemma\n",
      "2021-12-29 21:44:14 INFO: Loading: depparse\n",
      "2021-12-29 21:44:14 INFO: Loading: sentiment\n",
      "2021-12-29 21:44:15 INFO: Loading: constituency\n",
      "2021-12-29 21:44:15 INFO: Loading: ner\n",
      "2021-12-29 21:44:15 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6c64dd2c5c492c9061b0cf09b69c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 41. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 36. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 12. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 7. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 116. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 48. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 127. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 22. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 22. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 20. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 44. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 38. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 19. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 118. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 19. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 47. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 44. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c03fa2eb6b464fb7a5c447e91de7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 00:23:36 INFO: Downloading default packages for language: en (English)...\n",
      "2021-12-30 00:23:37 INFO: File exists: C:\\Users\\stg-sdu\\stanza_resources\\en\\default.zip.\n",
      "2021-12-30 00:23:40 INFO: Finished downloading models and saved to C:\\Users\\stg-sdu\\stanza_resources.\n",
      "2021-12-30 00:23:40 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2021-12-30 00:23:40 INFO: Use device: cpu\n",
      "2021-12-30 00:23:40 INFO: Loading: tokenize\n",
      "2021-12-30 00:23:40 INFO: Loading: pos\n",
      "2021-12-30 00:23:40 INFO: Loading: lemma\n",
      "2021-12-30 00:23:40 INFO: Loading: depparse\n",
      "2021-12-30 00:23:41 INFO: Loading: sentiment\n",
      "2021-12-30 00:23:41 INFO: Loading: constituency\n",
      "2021-12-30 00:23:41 INFO: Loading: ner\n",
      "2021-12-30 00:23:42 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1262b1f276a4763b9bc27f86d823c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 118. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 48. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 126. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 84. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 48. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 38. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 30. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 22. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 22. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 20. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 134. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 95. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 134. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 127. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 41. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 38. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 126. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 34. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 31. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 22. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 22. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 20. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9214416e36f4cec8bda0ca4c15914fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 02:57:53 INFO: Downloading default packages for language: en (English)...\n",
      "2021-12-30 02:57:53 INFO: File exists: C:\\Users\\stg-sdu\\stanza_resources\\en\\default.zip.\n",
      "2021-12-30 02:57:57 INFO: Finished downloading models and saved to C:\\Users\\stg-sdu\\stanza_resources.\n",
      "2021-12-30 02:57:57 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2021-12-30 02:57:57 INFO: Use device: cpu\n",
      "2021-12-30 02:57:57 INFO: Loading: tokenize\n",
      "2021-12-30 02:57:57 INFO: Loading: pos\n",
      "2021-12-30 02:57:57 INFO: Loading: lemma\n",
      "2021-12-30 02:57:57 INFO: Loading: depparse\n",
      "2021-12-30 02:57:57 INFO: Loading: sentiment\n",
      "2021-12-30 02:57:57 INFO: Loading: constituency\n",
      "2021-12-30 02:57:58 INFO: Loading: ner\n",
      "2021-12-30 02:57:58 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14381bdf3158469bbfacd2766e13b437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 16. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 125. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 100. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 96. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 137. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 101. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 39. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 35. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 39. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 35. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 116. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 25. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 25. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 24. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 138. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 141. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 91. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 116. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc4eebe059c4ff18c546b095c9dfba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 05:43:27 INFO: Downloading default packages for language: en (English)...\n",
      "2021-12-30 05:43:28 INFO: File exists: C:\\Users\\stg-sdu\\stanza_resources\\en\\default.zip.\n",
      "2021-12-30 05:43:31 INFO: Finished downloading models and saved to C:\\Users\\stg-sdu\\stanza_resources.\n",
      "2021-12-30 05:43:31 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2021-12-30 05:43:31 INFO: Use device: cpu\n",
      "2021-12-30 05:43:31 INFO: Loading: tokenize\n",
      "2021-12-30 05:43:31 INFO: Loading: pos\n",
      "2021-12-30 05:43:31 INFO: Loading: lemma\n",
      "2021-12-30 05:43:31 INFO: Loading: depparse\n",
      "2021-12-30 05:43:31 INFO: Loading: sentiment\n",
      "2021-12-30 05:43:31 INFO: Loading: constituency\n",
      "2021-12-30 05:43:32 INFO: Loading: ner\n",
      "2021-12-30 05:43:32 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf02b8c87afc462984401e99edd8e301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 78. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 141. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 128. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 87. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 125. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 23. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 23. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 22. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 127. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 39. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 35. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 128. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 61. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 50. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 101. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 97. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 79. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 39. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 35. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 64. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 138. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 101. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d918e2b520684f7cba68a9d3720fe506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 08:40:49 INFO: Downloading default packages for language: en (English)...\n",
      "2021-12-30 08:40:50 INFO: File exists: C:\\Users\\stg-sdu\\stanza_resources\\en\\default.zip.\n",
      "2021-12-30 08:40:54 INFO: Finished downloading models and saved to C:\\Users\\stg-sdu\\stanza_resources.\n",
      "2021-12-30 08:40:54 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2021-12-30 08:40:54 INFO: Use device: cpu\n",
      "2021-12-30 08:40:54 INFO: Loading: tokenize\n",
      "2021-12-30 08:40:54 INFO: Loading: pos\n",
      "2021-12-30 08:40:54 INFO: Loading: lemma\n",
      "2021-12-30 08:40:54 INFO: Loading: depparse\n",
      "2021-12-30 08:40:54 INFO: Loading: sentiment\n",
      "2021-12-30 08:40:54 INFO: Loading: constituency\n",
      "2021-12-30 08:40:55 INFO: Loading: ner\n",
      "2021-12-30 08:40:55 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9391d844661a4bceaed2030beed79ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 91. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 118. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 46. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 41. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 75. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 63. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 102. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 79. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 135. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 78. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 106. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 138. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 3. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 106. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 32. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 29. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 48. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 30. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 27. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 56, but you input_length is only 25. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 142, but you input_length is only 25. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 22. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 95. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but you input_length is only 41. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 64, but you input_length is only 36. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    similarites = Creation_features_comparaison(anglais[100+100*j:100+100*(j+1)].reset_index(drop=True),'en')\n",
    "    precedent = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "    similarites2 = pd.concat([precedent,similarites], axis=0)\n",
    "    similarites2 = similarites2.reset_index(drop=True)\n",
    "    similarites2.to_csv('corpus_en_de_notes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = pd.read_csv('corpus_en_notes.csv',index_col=0)\n",
    "anglais = anglais.reset_index(drop=True)\n",
    "anglais2 = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "anglais2 = anglais.reset_index(drop=True)\n",
    "# attention, il faut les memes colonnes\n",
    "anglais2 = anglais[anglais.columns]\n",
    "anglais = pd.concat([anglais,anglais2],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention certains textes ne sont pas fournies et donc mis en \"Error\" : A supprimer donc\n",
    "# On pourrait éventuellement tester en ne prenant plus les meth similarités ds les predicteurs\n",
    "anglais = anglais[anglais.meth1_similarites!='Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>...</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>Haiti’s leader marks independence day amid sec...</td>\n",
       "      <td>MARTINSBURG, W.Va. — A suspected drunken drive...</td>\n",
       "      <td>PORT-AU-PRINCE, Haiti — Haitian President Jove...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.79</td>\n",
       "      <td>51.00</td>\n",
       "      <td>10.42</td>\n",
       "      <td>8.33</td>\n",
       "      <td>32.09</td>\n",
       "      <td>13.47</td>\n",
       "      <td>99.20</td>\n",
       "      <td>818.0</td>\n",
       "      <td>231.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Fire kills more than 30 animals at zoo in west...</td>\n",
       "      <td>Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>6.44</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2.91</td>\n",
       "      <td>10.57</td>\n",
       "      <td>8.34</td>\n",
       "      <td>28.15</td>\n",
       "      <td>92.87</td>\n",
       "      <td>99.04</td>\n",
       "      <td>129.5</td>\n",
       "      <td>174.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>Trump says he does not expect war with Iran, ‘...</td>\n",
       "      <td>(Breitbart) – President Donald Trump welcomed ...</td>\n",
       "      <td>PALM BEACH, United States — US President Donal...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>20.70</td>\n",
       "      <td>27.45</td>\n",
       "      <td>9.68</td>\n",
       "      <td>13.14</td>\n",
       "      <td>8.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>96.75</td>\n",
       "      <td>827.2</td>\n",
       "      <td>504.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Indian Online Food Delivery Market to Hit $8 B...</td>\n",
       "      <td>Uber has sold its online food-ordering busines...</td>\n",
       "      <td>Rapid digitisation and growth in both online b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.97</td>\n",
       "      <td>27.90</td>\n",
       "      <td>10.34</td>\n",
       "      <td>18.21</td>\n",
       "      <td>8.35</td>\n",
       "      <td>23.79</td>\n",
       "      <td>93.55</td>\n",
       "      <td>94.72</td>\n",
       "      <td>620.0</td>\n",
       "      <td>735.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>India targets new moon mission in 2020</td>\n",
       "      <td>BENGALURU (Reuters) - India has approved its t...</td>\n",
       "      <td>BANGALORE: India plans to make a fresh attempt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.21</td>\n",
       "      <td>32.40</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>15.76</td>\n",
       "      <td>8.35</td>\n",
       "      <td>26.28</td>\n",
       "      <td>74.48</td>\n",
       "      <td>93.05</td>\n",
       "      <td>473.0</td>\n",
       "      <td>559.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>3444</td>\n",
       "      <td>Migrate or Clone VMs to new vCenter at other site</td>\n",
       "      <td>vCenter Email Alerts not working anymore?</td>\n",
       "      <td>Hello,\\n\\nWe are preparing to move our environ...</td>\n",
       "      <td>I'm running vCenter 6.7 w/ three host also run...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>3445</td>\n",
       "      <td>You can now consult with your doctors through ...</td>\n",
       "      <td>Never waste a crisis</td>\n",
       "      <td>You can now consult with your doctors through ...</td>\n",
       "      <td>India is doing a commendable job in fighting t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>3446</td>\n",
       "      <td>Thai soldier who killed 20 is shot dead</td>\n",
       "      <td>Thai soldier shot dead after killing 26 in cou...</td>\n",
       "      <td>Jakraphanth Thomma on Saturday killed his comm...</td>\n",
       "      <td>Medics carry a stretcher towards a Thai shoppi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>3447</td>\n",
       "      <td>More than 80 people taken in for questioning a...</td>\n",
       "      <td>Gauteng police take in 87 people for questioni...</td>\n",
       "      <td>The bodies of the victims were found lying in ...</td>\n",
       "      <td>Johannesburg - Gauteng police on Saturday said...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>3448</td>\n",
       "      <td>Migrant caravan crosses into Mexico, walks alo...</td>\n",
       "      <td>Migrant caravan crosses into Mexico, walks alo...</td>\n",
       "      <td>CIUDAD HIDALGO, Mexico — Hundreds of Central A...</td>\n",
       "      <td>Hundreds of Central American migrants crossed ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3402 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ligne                                            title_1  \\\n",
       "0         0  Virginia man arrested in fatal DUI crash in We...   \n",
       "1         1  Guyana: Three injured after car crashes into u...   \n",
       "2         2  Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3         3  Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4         4  India approves third moon mission, months afte...   \n",
       "...     ...                                                ...   \n",
       "3591   3444  Migrate or Clone VMs to new vCenter at other site   \n",
       "3592   3445  You can now consult with your doctors through ...   \n",
       "3593   3446            Thai soldier who killed 20 is shot dead   \n",
       "3594   3447  More than 80 people taken in for questioning a...   \n",
       "3595   3448  Migrant caravan crosses into Mexico, walks alo...   \n",
       "\n",
       "                                                title_2  \\\n",
       "0     Haiti’s leader marks independence day amid sec...   \n",
       "1     Fire kills more than 30 animals at zoo in west...   \n",
       "2     Trump says he does not expect war with Iran, ‘...   \n",
       "3     Indian Online Food Delivery Market to Hit $8 B...   \n",
       "4                India targets new moon mission in 2020   \n",
       "...                                                 ...   \n",
       "3591          vCenter Email Alerts not working anymore?   \n",
       "3592                               Never waste a crisis   \n",
       "3593  Thai soldier shot dead after killing 26 in cou...   \n",
       "3594  Gauteng police take in 87 people for questioni...   \n",
       "3595  Migrant caravan crosses into Mexico, walks alo...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     MARTINSBURG, W.Va. — A suspected drunken drive...   \n",
       "1     Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...   \n",
       "2     (Breitbart) – President Donald Trump welcomed ...   \n",
       "3     Uber has sold its online food-ordering busines...   \n",
       "4     BENGALURU (Reuters) - India has approved its t...   \n",
       "...                                                 ...   \n",
       "3591  Hello,\\n\\nWe are preparing to move our environ...   \n",
       "3592  You can now consult with your doctors through ...   \n",
       "3593  Jakraphanth Thomma on Saturday killed his comm...   \n",
       "3594  The bodies of the victims were found lying in ...   \n",
       "3595  CIUDAD HIDALGO, Mexico — Hundreds of Central A...   \n",
       "\n",
       "                                                 text_2  Geography  Entities  \\\n",
       "0     PORT-AU-PRINCE, Haiti — Haitian President Jove...        4.0  4.000000   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...        4.0  4.000000   \n",
       "2     PALM BEACH, United States — US President Donal...        1.0  2.000000   \n",
       "3     Rapid digitisation and growth in both online b...        1.0  2.333333   \n",
       "4     BANGALORE: India plans to make a fresh attempt...        1.0  1.250000   \n",
       "...                                                 ...        ...       ...   \n",
       "3591  I'm running vCenter 6.7 w/ three host also run...        4.0  3.000000   \n",
       "3592  India is doing a commendable job in fighting t...        1.0  4.000000   \n",
       "3593  Medics carry a stretcher towards a Thai shoppi...        1.0  2.000000   \n",
       "3594  Johannesburg - Gauteng police on Saturday said...        1.0  1.000000   \n",
       "3595  Hundreds of Central American migrants crossed ...        1.0  1.000000   \n",
       "\n",
       "          Time  Narrative   Overall  ...  score_similarite_titres  \\\n",
       "0     1.000000   4.000000  4.000000  ...                     0.80   \n",
       "1     1.000000   4.000000  3.666667  ...                     6.44   \n",
       "2     1.000000   2.333333  2.333333  ...                    20.70   \n",
       "3     2.666667   1.666667  2.000000  ...                    24.97   \n",
       "4     1.000000   1.250000  1.250000  ...                    29.21   \n",
       "...        ...        ...       ...  ...                      ...   \n",
       "3591  1.000000   2.000000  3.000000  ...                    15.18   \n",
       "3592  3.000000   4.000000  4.000000  ...                     4.29   \n",
       "3593  1.000000   2.000000  1.000000  ...                    40.45   \n",
       "3594  1.000000   1.000000  1.000000  ...                    22.58   \n",
       "3595  1.000000   1.000000  1.000000  ...                    51.00   \n",
       "\n",
       "      score_similarite_resume1 score_similarite_resume2 score_classif1  \\\n",
       "0                         3.79                    51.00          10.42   \n",
       "1                         9.10                     2.91          10.57   \n",
       "2                        27.45                     9.68          13.14   \n",
       "3                        27.90                    10.34          18.21   \n",
       "4                        32.40                    -1.95          15.76   \n",
       "...                        ...                      ...            ...   \n",
       "3591                      0.96                    -0.44          52.18   \n",
       "3592                     14.06                     1.64          27.53   \n",
       "3593                     40.11                    24.78          10.46   \n",
       "3594                     29.80                    -0.50          10.97   \n",
       "3595                     44.02                    16.45          16.61   \n",
       "\n",
       "     score_classif2 score_sentiment1  score_sentiment2  score_sentiment3  \\\n",
       "0              8.33            32.09             13.47             99.20   \n",
       "1              8.34            28.15             92.87             99.04   \n",
       "2              8.33            25.00              2.56             96.75   \n",
       "3              8.35            23.79             93.55             94.72   \n",
       "4              8.35            26.28             74.48             93.05   \n",
       "...             ...              ...               ...               ...   \n",
       "3591           9.54            28.40             97.16             99.92   \n",
       "3592           8.29            31.73              1.55             13.10   \n",
       "3593           8.36            46.47             84.41             97.96   \n",
       "3594           8.42            19.91              1.06             93.64   \n",
       "3595           8.50            18.34             27.16             99.71   \n",
       "\n",
       "      meth1_similarites meth2_similarites  \n",
       "0                 818.0             231.9  \n",
       "1                 129.5             174.9  \n",
       "2                 827.2             504.8  \n",
       "3                 620.0             735.1  \n",
       "4                 473.0             559.4  \n",
       "...                 ...               ...  \n",
       "3591              289.7             418.5  \n",
       "3592               40.4             150.6  \n",
       "3593              547.7             717.2  \n",
       "3594             1364.2             440.1  \n",
       "3595             1445.6            1377.2  \n",
       "\n",
       "[3402 rows x 32 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = anglais.round({'Geography':0, 'Entities':0,'Time':0, 'Narrative':0, 'Overall':0, 'Style':0, 'Tone':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "partiel = anglais[['Geography', 'Entities','Time', 'Narrative', 'Overall', 'Style', 'Tone']].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = pd.concat([anglais[['ligne', 'title_1', 'title_2', 'text_1', 'text_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2']],\n",
    "        partiel,anglais[['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "       'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "       'score_sentiment2', 'score_sentiment3', 'meth1_similarites', 'meth2_similarites']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>summary1_text1</th>\n",
       "      <th>summary2_text1</th>\n",
       "      <th>summary1_text2</th>\n",
       "      <th>summary2_text2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>...</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>Haiti’s leader marks independence day amid sec...</td>\n",
       "      <td>MARTINSBURG, W.Va. — A suspected drunken drive...</td>\n",
       "      <td>PORT-AU-PRINCE, Haiti — Haitian President Jove...</td>\n",
       "      <td>Cody Wade Braithwaite, 32, of Winchester, Vir...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>New Year's Day marked by protests over lack o...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.79</td>\n",
       "      <td>51.00</td>\n",
       "      <td>10.42</td>\n",
       "      <td>8.33</td>\n",
       "      <td>32.09</td>\n",
       "      <td>13.47</td>\n",
       "      <td>99.20</td>\n",
       "      <td>818.0</td>\n",
       "      <td>231.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Fire kills more than 30 animals at zoo in west...</td>\n",
       "      <td>Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>Motorcar PNN 7976 driven by 22-year-old Seera...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>Fire at a zoo in western Germany in the first...</td>\n",
       "      <td>A fire at a zoo in western Germany in the firs...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.44</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2.91</td>\n",
       "      <td>10.57</td>\n",
       "      <td>8.34</td>\n",
       "      <td>28.15</td>\n",
       "      <td>92.87</td>\n",
       "      <td>99.04</td>\n",
       "      <td>129.5</td>\n",
       "      <td>174.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>Trump says he does not expect war with Iran, ‘...</td>\n",
       "      <td>(Breitbart) – President Donald Trump welcomed ...</td>\n",
       "      <td>PALM BEACH, United States — US President Donal...</td>\n",
       "      <td>President Trump welcomed guests to Mar-a-Lago...</td>\n",
       "      <td>It’s a new year, but it’s also a new president.</td>\n",
       "      <td>U.S. President Donald Trump says he does not ...</td>\n",
       "      <td>US President Donald Trump says he does not for...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.70</td>\n",
       "      <td>27.45</td>\n",
       "      <td>9.68</td>\n",
       "      <td>13.14</td>\n",
       "      <td>8.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>96.75</td>\n",
       "      <td>827.2</td>\n",
       "      <td>504.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Indian Online Food Delivery Market to Hit $8 B...</td>\n",
       "      <td>Uber has sold its online food-ordering busines...</td>\n",
       "      <td>Rapid digitisation and growth in both online b...</td>\n",
       "      <td>Uber has sold its online food-ordering busine...</td>\n",
       "      <td>It's food for thought for Uber.</td>\n",
       "      <td>India's online food industry to become an $8 ...</td>\n",
       "      <td>\"Ordering food online is now a habit.\"</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>24.97</td>\n",
       "      <td>27.90</td>\n",
       "      <td>10.34</td>\n",
       "      <td>18.21</td>\n",
       "      <td>8.35</td>\n",
       "      <td>23.79</td>\n",
       "      <td>93.55</td>\n",
       "      <td>94.72</td>\n",
       "      <td>620.0</td>\n",
       "      <td>735.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>India targets new moon mission in 2020</td>\n",
       "      <td>BENGALURU (Reuters) - India has approved its t...</td>\n",
       "      <td>BANGALORE: India plans to make a fresh attempt...</td>\n",
       "      <td>India has approved its third lunar mission mo...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>Work is going \"smoothly\" on the Chandrayaan-3...</td>\n",
       "      <td>\"We are targeting the launch for this year but...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.21</td>\n",
       "      <td>32.40</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>15.76</td>\n",
       "      <td>8.35</td>\n",
       "      <td>26.28</td>\n",
       "      <td>74.48</td>\n",
       "      <td>93.05</td>\n",
       "      <td>473.0</td>\n",
       "      <td>559.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>3444</td>\n",
       "      <td>Migrate or Clone VMs to new vCenter at other site</td>\n",
       "      <td>vCenter Email Alerts not working anymore?</td>\n",
       "      <td>Hello,\\n\\nWe are preparing to move our environ...</td>\n",
       "      <td>I'm running vCenter 6.7 w/ three host also run...</td>\n",
       "      <td>We are preparing to move our environment to a...</td>\n",
       "      <td>Is there a way to clone VMs to a new site whil...</td>\n",
       "      <td>I'm not sure if some updates has stopped this...</td>\n",
       "      <td>I'm trying to get Office 365 to send me email ...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>3445</td>\n",
       "      <td>You can now consult with your doctors through ...</td>\n",
       "      <td>Never waste a crisis</td>\n",
       "      <td>You can now consult with your doctors through ...</td>\n",
       "      <td>India is doing a commendable job in fighting t...</td>\n",
       "      <td>The government has released the much-awaited ...</td>\n",
       "      <td>Can’t make it to the hospital? The guidelines ...</td>\n",
       "      <td>India is doing a commendable job in fighting ...</td>\n",
       "      <td>As the World Health Organization (WHO) reports...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>3446</td>\n",
       "      <td>Thai soldier who killed 20 is shot dead</td>\n",
       "      <td>Thai soldier shot dead after killing 26 in cou...</td>\n",
       "      <td>Jakraphanth Thomma on Saturday killed his comm...</td>\n",
       "      <td>Medics carry a stretcher towards a Thai shoppi...</td>\n",
       "      <td>Jakraphanth Thomma on Saturday killed his com...</td>\n",
       "      <td>Thailand's health minister has praised the sec...</td>\n",
       "      <td>Sergeant Major Jakrapanth Thomma killed 26 pe...</td>\n",
       "      <td>Thai police have shot dead a soldier who kille...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>3447</td>\n",
       "      <td>More than 80 people taken in for questioning a...</td>\n",
       "      <td>Gauteng police take in 87 people for questioni...</td>\n",
       "      <td>The bodies of the victims were found lying in ...</td>\n",
       "      <td>Johannesburg - Gauteng police on Saturday said...</td>\n",
       "      <td>The bodies of the victims were found lying in...</td>\n",
       "      <td>South African police have launched a manhunt a...</td>\n",
       "      <td>Nine Lesotho nationals stoned to death in Mat...</td>\n",
       "      <td>All images are copyrighted.</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>3448</td>\n",
       "      <td>Migrant caravan crosses into Mexico, walks alo...</td>\n",
       "      <td>Migrant caravan crosses into Mexico, walks alo...</td>\n",
       "      <td>CIUDAD HIDALGO, Mexico — Hundreds of Central A...</td>\n",
       "      <td>Hundreds of Central American migrants crossed ...</td>\n",
       "      <td>Hundreds of Central American migrants crossed...</td>\n",
       "      <td>Members of a migrant caravan making its way fr...</td>\n",
       "      <td>Hundreds of migrants crossed the border into ...</td>\n",
       "      <td>Mexico's National Guard has been deployed alon...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3402 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ligne                                            title_1  \\\n",
       "0         0  Virginia man arrested in fatal DUI crash in We...   \n",
       "1         1  Guyana: Three injured after car crashes into u...   \n",
       "2         2  Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3         3  Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4         4  India approves third moon mission, months afte...   \n",
       "...     ...                                                ...   \n",
       "3397   3444  Migrate or Clone VMs to new vCenter at other site   \n",
       "3398   3445  You can now consult with your doctors through ...   \n",
       "3399   3446            Thai soldier who killed 20 is shot dead   \n",
       "3400   3447  More than 80 people taken in for questioning a...   \n",
       "3401   3448  Migrant caravan crosses into Mexico, walks alo...   \n",
       "\n",
       "                                                title_2  \\\n",
       "0     Haiti’s leader marks independence day amid sec...   \n",
       "1     Fire kills more than 30 animals at zoo in west...   \n",
       "2     Trump says he does not expect war with Iran, ‘...   \n",
       "3     Indian Online Food Delivery Market to Hit $8 B...   \n",
       "4                India targets new moon mission in 2020   \n",
       "...                                                 ...   \n",
       "3397          vCenter Email Alerts not working anymore?   \n",
       "3398                               Never waste a crisis   \n",
       "3399  Thai soldier shot dead after killing 26 in cou...   \n",
       "3400  Gauteng police take in 87 people for questioni...   \n",
       "3401  Migrant caravan crosses into Mexico, walks alo...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     MARTINSBURG, W.Va. — A suspected drunken drive...   \n",
       "1     Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...   \n",
       "2     (Breitbart) – President Donald Trump welcomed ...   \n",
       "3     Uber has sold its online food-ordering busines...   \n",
       "4     BENGALURU (Reuters) - India has approved its t...   \n",
       "...                                                 ...   \n",
       "3397  Hello,\\n\\nWe are preparing to move our environ...   \n",
       "3398  You can now consult with your doctors through ...   \n",
       "3399  Jakraphanth Thomma on Saturday killed his comm...   \n",
       "3400  The bodies of the victims were found lying in ...   \n",
       "3401  CIUDAD HIDALGO, Mexico — Hundreds of Central A...   \n",
       "\n",
       "                                                 text_2  \\\n",
       "0     PORT-AU-PRINCE, Haiti — Haitian President Jove...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     PALM BEACH, United States — US President Donal...   \n",
       "3     Rapid digitisation and growth in both online b...   \n",
       "4     BANGALORE: India plans to make a fresh attempt...   \n",
       "...                                                 ...   \n",
       "3397  I'm running vCenter 6.7 w/ three host also run...   \n",
       "3398  India is doing a commendable job in fighting t...   \n",
       "3399  Medics carry a stretcher towards a Thai shoppi...   \n",
       "3400  Johannesburg - Gauteng police on Saturday said...   \n",
       "3401  Hundreds of Central American migrants crossed ...   \n",
       "\n",
       "                                         summary1_text1  \\\n",
       "0      Cody Wade Braithwaite, 32, of Winchester, Vir...   \n",
       "1      Motorcar PNN 7976 driven by 22-year-old Seera...   \n",
       "2      President Trump welcomed guests to Mar-a-Lago...   \n",
       "3      Uber has sold its online food-ordering busine...   \n",
       "4      India has approved its third lunar mission mo...   \n",
       "...                                                 ...   \n",
       "3397   We are preparing to move our environment to a...   \n",
       "3398   The government has released the much-awaited ...   \n",
       "3399   Jakraphanth Thomma on Saturday killed his com...   \n",
       "3400   The bodies of the victims were found lying in...   \n",
       "3401   Hundreds of Central American migrants crossed...   \n",
       "\n",
       "                                         summary2_text1  \\\n",
       "0                           All images are copyrighted.   \n",
       "1                           All images are copyrighted.   \n",
       "2       It’s a new year, but it’s also a new president.   \n",
       "3                       It's food for thought for Uber.   \n",
       "4                           All images are copyrighted.   \n",
       "...                                                 ...   \n",
       "3397  Is there a way to clone VMs to a new site whil...   \n",
       "3398  Can’t make it to the hospital? The guidelines ...   \n",
       "3399  Thailand's health minister has praised the sec...   \n",
       "3400  South African police have launched a manhunt a...   \n",
       "3401  Members of a migrant caravan making its way fr...   \n",
       "\n",
       "                                         summary1_text2  \\\n",
       "0      New Year's Day marked by protests over lack o...   \n",
       "1      Fire at a zoo in western Germany in the first...   \n",
       "2      U.S. President Donald Trump says he does not ...   \n",
       "3      India's online food industry to become an $8 ...   \n",
       "4      Work is going \"smoothly\" on the Chandrayaan-3...   \n",
       "...                                                 ...   \n",
       "3397   I'm not sure if some updates has stopped this...   \n",
       "3398   India is doing a commendable job in fighting ...   \n",
       "3399   Sergeant Major Jakrapanth Thomma killed 26 pe...   \n",
       "3400   Nine Lesotho nationals stoned to death in Mat...   \n",
       "3401   Hundreds of migrants crossed the border into ...   \n",
       "\n",
       "                                         summary2_text2  Geography  ...  \\\n",
       "0                           All images are copyrighted.          4  ...   \n",
       "1     A fire at a zoo in western Germany in the firs...          4  ...   \n",
       "2     US President Donald Trump says he does not for...          1  ...   \n",
       "3                \"Ordering food online is now a habit.\"          1  ...   \n",
       "4     \"We are targeting the launch for this year but...          1  ...   \n",
       "...                                                 ...        ...  ...   \n",
       "3397  I'm trying to get Office 365 to send me email ...          4  ...   \n",
       "3398  As the World Health Organization (WHO) reports...          1  ...   \n",
       "3399  Thai police have shot dead a soldier who kille...          1  ...   \n",
       "3400                        All images are copyrighted.          1  ...   \n",
       "3401  Mexico's National Guard has been deployed alon...          1  ...   \n",
       "\n",
       "      score_similarite_titres  score_similarite_resume1  \\\n",
       "0                        0.80                      3.79   \n",
       "1                        6.44                      9.10   \n",
       "2                       20.70                     27.45   \n",
       "3                       24.97                     27.90   \n",
       "4                       29.21                     32.40   \n",
       "...                       ...                       ...   \n",
       "3397                    15.18                      0.96   \n",
       "3398                     4.29                     14.06   \n",
       "3399                    40.45                     40.11   \n",
       "3400                    22.58                     29.80   \n",
       "3401                    51.00                     44.02   \n",
       "\n",
       "      score_similarite_resume2  score_classif1  score_classif2  \\\n",
       "0                        51.00           10.42            8.33   \n",
       "1                         2.91           10.57            8.34   \n",
       "2                         9.68           13.14            8.33   \n",
       "3                        10.34           18.21            8.35   \n",
       "4                        -1.95           15.76            8.35   \n",
       "...                        ...             ...             ...   \n",
       "3397                     -0.44           52.18            9.54   \n",
       "3398                      1.64           27.53            8.29   \n",
       "3399                     24.78           10.46            8.36   \n",
       "3400                     -0.50           10.97            8.42   \n",
       "3401                     16.45           16.61            8.50   \n",
       "\n",
       "      score_sentiment1  score_sentiment2  score_sentiment3  meth1_similarites  \\\n",
       "0                32.09             13.47             99.20              818.0   \n",
       "1                28.15             92.87             99.04              129.5   \n",
       "2                25.00              2.56             96.75              827.2   \n",
       "3                23.79             93.55             94.72              620.0   \n",
       "4                26.28             74.48             93.05              473.0   \n",
       "...                ...               ...               ...                ...   \n",
       "3397             28.40             97.16             99.92              289.7   \n",
       "3398             31.73              1.55             13.10               40.4   \n",
       "3399             46.47             84.41             97.96              547.7   \n",
       "3400             19.91              1.06             93.64             1364.2   \n",
       "3401             18.34             27.16             99.71             1445.6   \n",
       "\n",
       "     meth2_similarites  \n",
       "0                231.9  \n",
       "1                174.9  \n",
       "2                504.8  \n",
       "3                735.1  \n",
       "4                559.4  \n",
       "...                ...  \n",
       "3397             418.5  \n",
       "3398             150.6  \n",
       "3399             717.2  \n",
       "3400             440.1  \n",
       "3401            1377.2  \n",
       "\n",
       "[3402 rows x 31 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anglais = anglais.reset_index(drop=True)\n",
    "anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_train = 500\n",
    "dernier_test = 3400    # en fait 2 lignes avec un score nan : 469 et 2170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteurs = ['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1',\n",
    "    'score_similarite_resume2', 'score_classif1', 'score_classif2','score_sentiment1', \n",
    "    'score_sentiment2', 'score_sentiment3', 'meth1_similarites','meth2_similarites']\n",
    "# 2e test sans les predicteurs entites et méthodes similarités\n",
    "# predicteurs1 = ['score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "#            'score_sentiment1','score_sentiment2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "english_classif = setup(data = anglais[predicteurs + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.7950</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>0.8332</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.7668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.7928</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.7070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.9513</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>0.7832</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.6947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8058</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>0.7282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.6896</td>\n",
       "      <td>0.6953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.7606</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>0.7387</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.7848</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>0.7842</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.6840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7479</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.6877</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.7412</td>\n",
       "      <td>0.6248</td>\n",
       "      <td>0.6268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.7353</td>\n",
       "      <td>0.7832</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.6907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7933</td>\n",
       "      <td>0.9449</td>\n",
       "      <td>0.7372</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.6899</td>\n",
       "      <td>0.6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.0356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.8410  0.9589  0.7950  0.8436  0.8332  0.7603  0.7668\n",
       "1       0.8025  0.9453  0.7428  0.7943  0.7928  0.7026  0.7070\n",
       "2       0.7941  0.9513  0.7366  0.7858  0.7832  0.6895  0.6947\n",
       "3       0.8151  0.9489  0.7675  0.8074  0.8058  0.7249  0.7282\n",
       "4       0.7941  0.9474  0.7437  0.7800  0.7797  0.6896  0.6953\n",
       "5       0.7689  0.9368  0.7050  0.7632  0.7606  0.6534  0.6571\n",
       "6       0.7941  0.9442  0.7387  0.7930  0.7848  0.6903  0.6956\n",
       "7       0.7857  0.9296  0.7199  0.7842  0.7721  0.6750  0.6840\n",
       "8       0.7479  0.9393  0.6877  0.7410  0.7412  0.6248  0.6268\n",
       "9       0.7899  0.9470  0.7353  0.7832  0.7825  0.6880  0.6907\n",
       "Mean    0.7933  0.9449  0.7372  0.7876  0.7836  0.6899  0.6946\n",
       "SD      0.0236  0.0077  0.0285  0.0254  0.0235  0.0348  0.0356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.8473</td>\n",
       "      <td>0.8729</td>\n",
       "      <td>0.8729</td>\n",
       "      <td>0.8140</td>\n",
       "      <td>0.8148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.8296</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.8139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8866</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.8498</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>0.8838</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8866</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.8501</td>\n",
       "      <td>0.8854</td>\n",
       "      <td>0.8843</td>\n",
       "      <td>0.8318</td>\n",
       "      <td>0.8329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.8434</td>\n",
       "      <td>0.8448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.8249</td>\n",
       "      <td>0.8260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8697</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.8280</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.8072</td>\n",
       "      <td>0.8097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8655</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.8208</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>0.8587</td>\n",
       "      <td>0.7994</td>\n",
       "      <td>0.8040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8655</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.8637</td>\n",
       "      <td>0.8023</td>\n",
       "      <td>0.8028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.8526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.8799</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.8217</td>\n",
       "      <td>0.8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.8745  0.9821  0.8473  0.8729  0.8729  0.8140  0.8148\n",
       "1       0.8739  0.9665  0.8296  0.8727  0.8703  0.8111  0.8139\n",
       "2       0.8866  0.9824  0.8498  0.8873  0.8838  0.8310  0.8333\n",
       "3       0.8866  0.9849  0.8501  0.8854  0.8843  0.8318  0.8329\n",
       "4       0.8950  0.9784  0.8585  0.8934  0.8928  0.8434  0.8448\n",
       "5       0.8824  0.9744  0.8361  0.8796  0.8800  0.8249  0.8260\n",
       "6       0.8697  0.9821  0.8280  0.8688  0.8640  0.8072  0.8097\n",
       "7       0.8655  0.9643  0.8208  0.8664  0.8587  0.7994  0.8040\n",
       "8       0.8655  0.9783  0.8377  0.8636  0.8637  0.8023  0.8028\n",
       "9       0.8992  0.9781  0.8682  0.8984  0.8974  0.8518  0.8526\n",
       "Mean    0.8799  0.9771  0.8426  0.8788  0.8768  0.8217  0.8235\n",
       "SD      0.0113  0.0065  0.0140  0.0113  0.0123  0.0168  0.0163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.8351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8319</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8319</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.7533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8655</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.8651</td>\n",
       "      <td>0.8642</td>\n",
       "      <td>0.8011</td>\n",
       "      <td>0.8018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.8275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.8461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8866</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.8433</td>\n",
       "      <td>0.8847</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.8324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8697</td>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.8060</td>\n",
       "      <td>0.8106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.8403</td>\n",
       "      <td>0.8574</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>0.7912</td>\n",
       "      <td>0.7916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.8716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.8770</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.8188</td>\n",
       "      <td>0.8197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.8870  0.9814  0.8693  0.8882  0.8874  0.8350  0.8351\n",
       "1       0.8319  0.9605  0.7876  0.8322  0.8319  0.7532  0.7533\n",
       "2       0.8655  0.9738  0.8287  0.8651  0.8642  0.8011  0.8018\n",
       "3       0.8824  0.9787  0.8561  0.8813  0.8814  0.8272  0.8275\n",
       "4       0.8950  0.9724  0.8777  0.8971  0.8956  0.8459  0.8461\n",
       "5       0.8866  0.9693  0.8433  0.8847  0.8841  0.8310  0.8324\n",
       "6       0.8824  0.9760  0.8465  0.8793  0.8793  0.8262  0.8273\n",
       "7       0.8697  0.9547  0.8251  0.8724  0.8635  0.8060  0.8106\n",
       "8       0.8571  0.9729  0.8403  0.8574  0.8563  0.7912  0.7916\n",
       "9       0.9118  0.9756  0.8895  0.9128  0.9112  0.8710  0.8716\n",
       "Mean    0.8769  0.9715  0.8464  0.8770  0.8755  0.8188  0.8197\n",
       "SD      0.0210  0.0078  0.0278  0.0211  0.0212  0.0309  0.0308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6653</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.6231</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>0.4990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>0.5398</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>0.5999</td>\n",
       "      <td>0.4624</td>\n",
       "      <td>0.4826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6681</td>\n",
       "      <td>0.8146</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>0.6163</td>\n",
       "      <td>0.6252</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.5056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.5279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6639</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>0.5904</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.6408</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.4994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6765</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>0.6039</td>\n",
       "      <td>0.6661</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.5203</td>\n",
       "      <td>0.5219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7017</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.6420</td>\n",
       "      <td>0.5393</td>\n",
       "      <td>0.5643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6639</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.5601</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.6136</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>0.4947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6975</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.6231</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>0.5499</td>\n",
       "      <td>0.5554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6471</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>0.5732</td>\n",
       "      <td>0.5953</td>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.4797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.6350</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.5131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.6653  0.8573  0.5600  0.6231  0.6266  0.4870  0.4990\n",
       "1       0.6555  0.8339  0.5398  0.6052  0.5999  0.4624  0.4826\n",
       "2       0.6681  0.8146  0.5695  0.6163  0.6252  0.4937  0.5056\n",
       "3       0.6849  0.8375  0.5850  0.6571  0.6561  0.5180  0.5279\n",
       "4       0.6639  0.8351  0.5904  0.6296  0.6408  0.4946  0.4994\n",
       "5       0.6765  0.8377  0.6039  0.6661  0.6680  0.5203  0.5219\n",
       "6       0.7017  0.8792  0.6133  0.6886  0.6420  0.5393  0.5643\n",
       "7       0.6639  0.8357  0.5601  0.5922  0.6136  0.4785  0.4947\n",
       "8       0.6975  0.8617  0.6231  0.6856  0.6821  0.5499  0.5554\n",
       "9       0.6471  0.8471  0.5335  0.5732  0.5953  0.4662  0.4797\n",
       "Mean    0.6724  0.8440  0.5779  0.6337  0.6350  0.5010  0.5131\n",
       "SD      0.0167  0.0171  0.0288  0.0373  0.0270  0.0283  0.0275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.9414</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.7699</td>\n",
       "      <td>0.7724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.7470</td>\n",
       "      <td>0.8181</td>\n",
       "      <td>0.7753</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.6728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8109</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.8104</td>\n",
       "      <td>0.8105</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7563</td>\n",
       "      <td>0.8536</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.7999</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>0.6528</td>\n",
       "      <td>0.6609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.8092</td>\n",
       "      <td>0.8265</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>0.7405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.8484</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>0.6785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8109</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.7679</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.7229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7773</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>0.7932</td>\n",
       "      <td>0.7811</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>0.6785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.6637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.7830</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>0.7944</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.7032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7904</td>\n",
       "      <td>0.8854</td>\n",
       "      <td>0.7694</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.6972</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.8410  0.9414  0.8320  0.8555  0.8440  0.7699  0.7724\n",
       "1       0.7647  0.8619  0.7470  0.8181  0.7753  0.6622  0.6728\n",
       "2       0.8109  0.9044  0.7738  0.8104  0.8105  0.7223  0.7224\n",
       "3       0.7563  0.8536  0.7547  0.7999  0.7684  0.6528  0.6609\n",
       "4       0.8193  0.8874  0.8092  0.8265  0.8210  0.7391  0.7405\n",
       "5       0.7689  0.8484  0.7405  0.8261  0.7758  0.6654  0.6785\n",
       "6       0.8109  0.9158  0.7679  0.8184  0.8126  0.7221  0.7229\n",
       "7       0.7773  0.8677  0.7404  0.7932  0.7811  0.6765  0.6785\n",
       "8       0.7647  0.8708  0.7455  0.7751  0.7677  0.6619  0.6637\n",
       "9       0.7899  0.9030  0.7830  0.8075  0.7944  0.7001  0.7032\n",
       "Mean    0.7904  0.8854  0.7694  0.8131  0.7951  0.6972  0.7016\n",
       "SD      0.0271  0.0286  0.0295  0.0206  0.0245  0.0377  0.0352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.8657</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.6884</td>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.5498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.8782</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.7011</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.5637</td>\n",
       "      <td>0.5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.6609</td>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.5062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.8854</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.5341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.5673</td>\n",
       "      <td>0.5673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.8767</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>0.5142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7017</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.6838</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.5594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6681</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.6003</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.5119</td>\n",
       "      <td>0.5123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6975</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.6224</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.6882</td>\n",
       "      <td>0.5541</td>\n",
       "      <td>0.5552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.6438</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>0.7092</td>\n",
       "      <td>0.5786</td>\n",
       "      <td>0.5798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.6827</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.5445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.6946  0.8657  0.6368  0.6857  0.6884  0.5490  0.5498\n",
       "1       0.7059  0.8782  0.6462  0.7011  0.6970  0.5637  0.5664\n",
       "2       0.6597  0.8607  0.6034  0.6637  0.6609  0.5057  0.5062\n",
       "3       0.6849  0.8854  0.6071  0.6720  0.6775  0.5333  0.5341\n",
       "4       0.7059  0.8769  0.6491  0.7032  0.7045  0.5673  0.5673\n",
       "5       0.6723  0.8767  0.5930  0.6612  0.6648  0.5130  0.5142\n",
       "6       0.7017  0.8814  0.6296  0.6838  0.6856  0.5555  0.5594\n",
       "7       0.6681  0.8693  0.6003  0.6650  0.6660  0.5119  0.5123\n",
       "8       0.6975  0.8819  0.6224  0.6831  0.6882  0.5541  0.5552\n",
       "9       0.7143  0.9023  0.6438  0.7080  0.7092  0.5786  0.5798\n",
       "Mean    0.6905  0.8779  0.6232  0.6827  0.6842  0.5432  0.5445\n",
       "SD      0.0175  0.0110  0.0198  0.0163  0.0159  0.0244  0.0248"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.8651</td>\n",
       "      <td>0.8666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.8701</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.7961</td>\n",
       "      <td>0.7984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8782</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>0.8221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8655</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.8054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.8515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>0.8548</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.7893</td>\n",
       "      <td>0.7896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.8782</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>0.8297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8529</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.8106</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.7859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.8331</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.8559</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>0.7908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8908</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.8411</td>\n",
       "      <td>0.8413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.8752</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.8165</td>\n",
       "      <td>0.8181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.9079  0.9864  0.8932  0.9136  0.9079  0.8651  0.8666\n",
       "1       0.8613  0.9738  0.8279  0.8701  0.8604  0.7961  0.7984\n",
       "2       0.8782  0.9776  0.8478  0.8818  0.8783  0.8212  0.8221\n",
       "3       0.8655  0.9780  0.8435  0.8720  0.8678  0.8047  0.8054\n",
       "4       0.8992  0.9875  0.8733  0.9010  0.8985  0.8505  0.8515\n",
       "5       0.8571  0.9759  0.8129  0.8548  0.8555  0.7893  0.7896\n",
       "6       0.8824  0.9797  0.8461  0.8869  0.8782  0.8270  0.8297\n",
       "7       0.8529  0.9744  0.8106  0.8592  0.8459  0.7797  0.7859\n",
       "8       0.8571  0.9691  0.8331  0.8562  0.8559  0.7904  0.7908\n",
       "9       0.8908  0.9834  0.8680  0.8922  0.8910  0.8411  0.8413\n",
       "Mean    0.8752  0.9786  0.8456  0.8788  0.8740  0.8165  0.8181\n",
       "SD      0.0184  0.0055  0.0251  0.0188  0.0194  0.0275  0.0270"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.5537</td>\n",
       "      <td>0.5357</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>0.3595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>0.5352</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.3144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.4149</td>\n",
       "      <td>0.4348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.6114</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.3710</td>\n",
       "      <td>0.4023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4248</td>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.4964</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.3627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>0.4514</td>\n",
       "      <td>0.2655</td>\n",
       "      <td>0.3359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.6018</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.4361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5813</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>0.4871</td>\n",
       "      <td>0.5032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.4690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5194</td>\n",
       "      <td>0.6107</td>\n",
       "      <td>0.5928</td>\n",
       "      <td>0.4567</td>\n",
       "      <td>0.4696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.5294</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>0.4087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.0604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.5690  0.0  0.4324  0.5537  0.5357  0.3512  0.3595\n",
       "1       0.4538  0.0  0.4028  0.5352  0.4423  0.2586  0.3144\n",
       "2       0.6050  0.0  0.5144  0.5920  0.5467  0.4149  0.4348\n",
       "3       0.6050  0.0  0.4673  0.6114  0.5426  0.3710  0.4023\n",
       "4       0.5882  0.0  0.4248  0.5467  0.4964  0.2914  0.3627\n",
       "5       0.4748  0.0  0.3955  0.7178  0.4514  0.2655  0.3359\n",
       "6       0.5714  0.0  0.4903  0.6018  0.5156  0.3804  0.4361\n",
       "7       0.6513  0.0  0.5813  0.7223  0.6116  0.4871  0.5032\n",
       "8       0.6134  0.0  0.5318  0.6286  0.5585  0.4386  0.4690\n",
       "9       0.6345  0.0  0.5194  0.6107  0.5928  0.4567  0.4696\n",
       "Mean    0.5767  0.0  0.4760  0.6120  0.5294  0.3715  0.4087\n",
       "SD      0.0613  0.0  0.0585  0.0614  0.0521  0.0761  0.0604"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7238</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.5882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7017</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.6007</td>\n",
       "      <td>0.6749</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.5436</td>\n",
       "      <td>0.5508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6681</td>\n",
       "      <td>0.8885</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.6446</td>\n",
       "      <td>0.6524</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>0.5027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>0.6493</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.7048</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7353</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.6640</td>\n",
       "      <td>0.7244</td>\n",
       "      <td>0.7244</td>\n",
       "      <td>0.6015</td>\n",
       "      <td>0.6056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6891</td>\n",
       "      <td>0.8842</td>\n",
       "      <td>0.6132</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.5342</td>\n",
       "      <td>0.5391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7311</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>0.6003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.6891</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>0.5615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.6214</td>\n",
       "      <td>0.6838</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.5626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.7077</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>0.5789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7094</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.6288</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.5614</td>\n",
       "      <td>0.5674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.7238  0.9139  0.6588  0.7101  0.7133  0.5850  0.5882\n",
       "1       0.7017  0.8913  0.6007  0.6749  0.6796  0.5436  0.5508\n",
       "2       0.6681  0.8885  0.5765  0.6446  0.6524  0.4993  0.5027\n",
       "3       0.7185  0.9051  0.6493  0.7083  0.7048  0.5791  0.5840\n",
       "4       0.7353  0.8956  0.6640  0.7244  0.7244  0.6015  0.6056\n",
       "5       0.6891  0.8842  0.6132  0.6824  0.6768  0.5342  0.5391\n",
       "6       0.7311  0.9193  0.6507  0.7107  0.7060  0.5888  0.6003\n",
       "7       0.7059  0.8976  0.6200  0.6891  0.6835  0.5520  0.5615\n",
       "8       0.7059  0.9165  0.6214  0.6838  0.6897  0.5584  0.5626\n",
       "9       0.7143  0.8934  0.6338  0.7077  0.6992  0.5725  0.5789\n",
       "Mean    0.7094  0.9005  0.6288  0.6936  0.6930  0.5614  0.5674\n",
       "SD      0.0191  0.0118  0.0264  0.0222  0.0198  0.0289  0.0295"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7615</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.6972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.8654</td>\n",
       "      <td>0.7473</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.6371</td>\n",
       "      <td>0.6666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.8629</td>\n",
       "      <td>0.7293</td>\n",
       "      <td>0.8449</td>\n",
       "      <td>0.7472</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.6413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.7317</td>\n",
       "      <td>0.6010</td>\n",
       "      <td>0.6279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.7732</td>\n",
       "      <td>0.8590</td>\n",
       "      <td>0.7863</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.6927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.7705</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>0.6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6891</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.7169</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.6142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.7399</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.6381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>0.7359</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.7472</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.6485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.7435</td>\n",
       "      <td>0.8337</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.6523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7329</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.8407</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.6293</td>\n",
       "      <td>0.6577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.7615  0.8732  0.7965  0.8555  0.7799  0.6707  0.6972\n",
       "1       0.7395  0.8654  0.7473  0.8481  0.7610  0.6371  0.6666\n",
       "2       0.7185  0.8629  0.7293  0.8449  0.7472  0.6095  0.6413\n",
       "3       0.7101  0.8370  0.7338  0.8119  0.7317  0.6010  0.6279\n",
       "4       0.7647  0.8766  0.7732  0.8590  0.7863  0.6698  0.6927\n",
       "5       0.7689  0.8912  0.7705  0.8573  0.7886  0.6765  0.6983\n",
       "6       0.6891  0.8582  0.6989  0.8438  0.7169  0.5719  0.6142\n",
       "7       0.7227  0.8650  0.7088  0.8234  0.7399  0.6112  0.6381\n",
       "8       0.7269  0.8550  0.7359  0.8294  0.7472  0.6207  0.6485\n",
       "9       0.7269  0.8645  0.7435  0.8337  0.7505  0.6245  0.6523\n",
       "Mean    0.7329  0.8649  0.7438  0.8407  0.7549  0.6293  0.6577\n",
       "SD      0.0245  0.0135  0.0282  0.0149  0.0226  0.0325  0.0284"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8285</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.8502</td>\n",
       "      <td>0.8257</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.7485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.8515</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.7059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.9527</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>0.8373</td>\n",
       "      <td>0.7979</td>\n",
       "      <td>0.6887</td>\n",
       "      <td>0.7116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.7722</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>0.8332</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.7630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>0.7240</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.7140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>0.8543</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>0.7124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.8406</td>\n",
       "      <td>0.7851</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.7047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.6760</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.7590</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.6692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>0.7157</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.7877</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.7055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.7683</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.7435</td>\n",
       "      <td>0.7666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.9515</td>\n",
       "      <td>0.7295</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>0.7994</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.7201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.8285  0.9577  0.7762  0.8502  0.8257  0.7350  0.7485\n",
       "1       0.7941  0.9431  0.7073  0.8515  0.7875  0.6694  0.7059\n",
       "2       0.8025  0.9527  0.7321  0.8373  0.7979  0.6887  0.7116\n",
       "3       0.8361  0.9588  0.7722  0.8671  0.8332  0.7436  0.7630\n",
       "4       0.8025  0.9462  0.7240  0.8442  0.7966  0.6867  0.7140\n",
       "5       0.7983  0.9568  0.7096  0.8543  0.7888  0.6765  0.7124\n",
       "6       0.7941  0.9454  0.7133  0.8406  0.7851  0.6732  0.7047\n",
       "7       0.7689  0.9485  0.6760  0.8295  0.7590  0.6282  0.6692\n",
       "8       0.7941  0.9442  0.7157  0.8464  0.7877  0.6726  0.7055\n",
       "9       0.8361  0.9620  0.7683  0.8713  0.8323  0.7435  0.7666\n",
       "Mean    0.8055  0.9515  0.7295  0.8492  0.7994  0.6917  0.7201\n",
       "SD      0.0205  0.0065  0.0312  0.0122  0.0227  0.0357  0.0287"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = create_model('lr')\n",
    "rf = create_model('rf')\n",
    "xgb = create_model('xgboost')\n",
    "ada = create_model('ada')\n",
    "lda = create_model('lda')  # linear discriminant\n",
    "knn = create_model('knn')\n",
    "mlp = create_model('mlp')\n",
    "svm = create_model('svm')\n",
    "rbfsvm = create_model('rbfsvm')\n",
    "nb = create_model('nb')\n",
    "gpc = create_model('gpc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicteurs : Les plus satisfaisants : ADA - LDA - KNN - LR : pluto moins bien en accuracy .... <br/>\n",
    "predicteurs 1 : Les plus satisfaisants : LR - LDA - RF - XGB - NB : environ 40% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai_classif = anglais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'score_sentiment3','meth1_similarites','meth2_similarites']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography                     int32\n",
       "Entities                      int32\n",
       "Time                          int32\n",
       "Narrative                     int32\n",
       "Overall                       int32\n",
       "Style                         int32\n",
       "Tone                          int32\n",
       "nb_entites_idem               int64\n",
       "nb_lieux_idem                 int64\n",
       "nb_dates_idem                 int64\n",
       "score_similarite_titres     float64\n",
       "score_similarite_resume1    float64\n",
       "score_similarite_resume2    float64\n",
       "score_classif1              float64\n",
       "score_classif2              float64\n",
       "score_sentiment1            float64\n",
       "score_sentiment2            float64\n",
       "score_sentiment3            float64\n",
       "meth1_similarites           float64\n",
       "meth2_similarites           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si on veut utiliser faire un classemen,t supprimer ligne error puis changer les types pour meth1 meth2\n",
    "essai_classif = essai_classif[essai_classif.meth1_similarites != 'Error']\n",
    "essai_classif['meth1_similarites'] = essai_classif['meth1_similarites'].astype('float')\n",
    "essai_classif['meth2_similarites'] = essai_classif['meth2_similarites'].astype('float')\n",
    "essai_classif.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain = essai_classif[predicteurs + ['Overall']]\n",
    "# eng_classif = setup(data = Xtrain,  target = 'Overall', html=False, silent=True, verbose=False)\n",
    "# rf = create_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict_model(rf)  # ne marche pas ????\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random Forest simple sur scikit learn\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ne passe pas car il y a un nan ligne 469\n",
    "# rf = RandomForestClassifier()\n",
    "# rf.fit(Xtrain[:taille_train],ytrain[:taille_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nb_entites_idem             0\n",
       "nb_lieux_idem               0\n",
       "nb_dates_idem               0\n",
       "score_similarite_titres     0\n",
       "score_similarite_resume1    0\n",
       "score_similarite_resume2    0\n",
       "score_classif1              2\n",
       "score_classif2              0\n",
       "score_sentiment1            0\n",
       "score_sentiment2            0\n",
       "score_sentiment3            0\n",
       "meth1_similarites           0\n",
       "meth2_similarites           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 469, 2170], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(Xtrain['score_classif1'].isnull())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nb_entites_idem              22.00\n",
       "nb_lieux_idem                 4.00\n",
       "nb_dates_idem                 0.00\n",
       "score_similarite_titres      24.51\n",
       "score_similarite_resume1     27.73\n",
       "score_similarite_resume2      1.89\n",
       "score_classif1                 NaN\n",
       "score_classif2                9.77\n",
       "score_sentiment1             19.44\n",
       "score_sentiment2             42.57\n",
       "score_sentiment3             23.53\n",
       "meth1_similarites           325.20\n",
       "meth2_similarites           427.30\n",
       "Name: 469, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.loc[469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.loc[np.where(Xtrain['score_classif1'].notnull())[0]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = ytrain[(ytrain.index != 469) & (ytrain.index != 2170)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=1016, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(Xtrain[:taille_train],ytrain[:taille_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.38</td>\n",
       "      <td>40.52</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>11.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>28.23</td>\n",
       "      <td>84.30</td>\n",
       "      <td>99.21</td>\n",
       "      <td>836.8</td>\n",
       "      <td>955.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.84</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>6.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>21.31</td>\n",
       "      <td>39.07</td>\n",
       "      <td>64.69</td>\n",
       "      <td>406.8</td>\n",
       "      <td>505.5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.27</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.04</td>\n",
       "      <td>20.11</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.28</td>\n",
       "      <td>14.97</td>\n",
       "      <td>5.67</td>\n",
       "      <td>10.96</td>\n",
       "      <td>8.33</td>\n",
       "      <td>21.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>95.43</td>\n",
       "      <td>722.7</td>\n",
       "      <td>314.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.36</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1.09</td>\n",
       "      <td>9.68</td>\n",
       "      <td>8.32</td>\n",
       "      <td>22.96</td>\n",
       "      <td>24.46</td>\n",
       "      <td>91.60</td>\n",
       "      <td>141.8</td>\n",
       "      <td>270.2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "500                12              0              6                    50.38   \n",
       "501                 0              0              5                     4.40   \n",
       "502                 0              0              0                     1.54   \n",
       "503                10              0              0                    12.28   \n",
       "504                 1              0              0                    15.36   \n",
       "...               ...            ...            ...                      ...   \n",
       "3395                0              0              0                    15.18   \n",
       "3396                2              0              0                     4.29   \n",
       "3397                7              0              6                    40.45   \n",
       "3398                9              0              1                    22.58   \n",
       "3399               18              1             12                    51.00   \n",
       "\n",
       "      score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "500                      40.52                     -1.43           11.16   \n",
       "501                       4.84                     -3.35            6.38   \n",
       "502                       1.41                     15.27            8.01   \n",
       "503                      14.97                      5.67           10.96   \n",
       "504                      -0.60                      1.09            9.68   \n",
       "...                        ...                       ...             ...   \n",
       "3395                      0.96                     -0.44           52.18   \n",
       "3396                     14.06                      1.64           27.53   \n",
       "3397                     40.11                     24.78           10.46   \n",
       "3398                     29.80                     -0.50           10.97   \n",
       "3399                     44.02                     16.45           16.61   \n",
       "\n",
       "      score_classif2  score_sentiment1  score_sentiment2  score_sentiment3  \\\n",
       "500             8.37             28.23             84.30             99.21   \n",
       "501             8.40             21.31             39.07             64.69   \n",
       "502             8.33              9.04             20.11              3.27   \n",
       "503             8.33             21.39              8.42             95.43   \n",
       "504             8.32             22.96             24.46             91.60   \n",
       "...              ...               ...               ...               ...   \n",
       "3395            9.54             28.40             97.16             99.92   \n",
       "3396            8.29             31.73              1.55             13.10   \n",
       "3397            8.36             46.47             84.41             97.96   \n",
       "3398            8.42             19.91              1.06             93.64   \n",
       "3399            8.50             18.34             27.16             99.71   \n",
       "\n",
       "      meth1_similarites  meth2_similarites  Overall  RF  \n",
       "500               836.8              955.1        1   1  \n",
       "501               406.8              505.5        4   4  \n",
       "502                 0.0                0.0        4   4  \n",
       "503               722.7              314.2        4   3  \n",
       "504               141.8              270.2        4   4  \n",
       "...                 ...                ...      ...  ..  \n",
       "3395              289.7              418.5        3   4  \n",
       "3396               40.4              150.6        4   4  \n",
       "3397              547.7              717.2        1   1  \n",
       "3398             1364.2              440.1        1   2  \n",
       "3399             1445.6             1377.2        1   1  \n",
       "\n",
       "[2900 rows x 15 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf = rf.predict(Xtrain[taille_train:])\n",
    "res_rf = pd.concat([Xtrain[taille_train:],ytrain[taille_train:],pd.DataFrame(res_rf,columns = ['RF'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 373,   92,    4,   12],\n",
       "       [ 108,  295,   70,   34],\n",
       "       [  16,   92,  239,  212],\n",
       "       [   4,   56,   84, 1209]], dtype=int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résultats corrects : 2116/2900 - 658/2900 : 1 d'écart 110/2900 : 2 d'écart et 16/2900 : 3 écart \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(res_rf.Overall,res_rf.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr, _ = pearsonr(res_rf.Overall, res_rf.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8408801525339181"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 10, 11,  7,  9,  8,  1,  5,  6,  0, 12,  4,  3], dtype=int64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(rf, Xtrain, ytrain, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "tree_feature_importances = rf.feature_importances_\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(predicteurs))\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.array(predicteurs)[sorted_idx])\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  RF  LDA\n",
       "500         1   1    1\n",
       "501         4   4    4\n",
       "502         4   4    4\n",
       "503         4   3    4\n",
       "504         4   4    4\n",
       "...       ...  ..  ...\n",
       "3395        3   4    3\n",
       "3396        4   4    4\n",
       "3397        1   1    1\n",
       "3398        1   2    2\n",
       "3399        1   1    1\n",
       "\n",
       "[2900 rows x 3 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_lda = lda.predict(Xtrain[taille_train:])\n",
    "res_final = pd.concat([res_rf[['Overall','RF']],pd.DataFrame(res_lda,columns = ['LDA'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99.  ,  1.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.28, 10.45, 89.27],\n",
       "       [ 0.  ,  0.01,  1.82, 98.16],\n",
       "       ...,\n",
       "       [94.6 ,  5.37,  0.03,  0.  ],\n",
       "       [22.98, 58.67, 15.21,  3.14],\n",
       "       [98.63,  1.36,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import around\n",
    "import numpy\n",
    "np.set_printoptions(suppress=True)  # supprime notation exp\n",
    "res_lda2 = around(lda.predict_proba(Xtrain[taille_train:])*100, decimals=2)\n",
    "res_lda2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82., 15.,  3.,  0.],\n",
       "       [ 0.,  1.,  7., 92.],\n",
       "       [ 0.,  0., 12., 88.],\n",
       "       ...,\n",
       "       [70., 22.,  4.,  4.],\n",
       "       [20., 42., 33.,  5.],\n",
       "       [71., 24.,  4.,  1.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf2 = around(rf.predict_proba(Xtrain[taille_train:])*100, decimals=2)\n",
    "res_rf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Remarquer que la classification ne tient pas compte du fait que c'est ordonné en classement 1-2-3-4 : ce qui est TRES important (ex : ligne 55% de 1 - 43% de 4) !! : il faudrait donc faire ressortir un score avec les probas plutot !!!_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau programme basé sur les scores probas : si plus de 50% mettre catégorie obtenue sinon, faire la somme 1-2 et 3/4 \n",
    "# et prendre le plus gros score puis regarder si ce sore > 65% alors à ce moment là prendre le plus gros de la catégorie \n",
    "# sinon prendre 2 ou 3\n",
    "def choix_classes(score_prob):\n",
    "    classe_finale = []\n",
    "    for i in range(len(score_prob)):\n",
    "        res = list(score_prob[i,:])\n",
    "        max_res = max(res)\n",
    "        if max_res > 50:\n",
    "            classe_finale.append(res.index(max_res)+1)\n",
    "        else:\n",
    "            som1 = res[0]+res[1]\n",
    "            som2 = res[2]+res[3]\n",
    "            if som1 > som2:\n",
    "                if som1 >= 65:\n",
    "                    choix = 1 if res[0]>res[1] else 2\n",
    "                else:\n",
    "                    choix = 2\n",
    "            else:\n",
    "                if som2 >= 65:\n",
    "                    choix = 4 if res[3]>res[2] else 3\n",
    "                else:\n",
    "                    choix = 3\n",
    "            classe_finale.append(choix)\n",
    "    return classe_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_rf = choix_classes(res_rf2)\n",
    "liste_lda = choix_classes(res_lda2)\n",
    "res_final = pd.concat([res_final,pd.DataFrame(liste_lda,columns = ['LDA_Prob'],index = range(taille_train,dernier_test)),\n",
    "                       pd.DataFrame(liste_rf,columns = ['RF_Prob'],index = range(taille_train,dernier_test))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_knn = knn.predict(Xtrain[taille_train:])\n",
    "liste_knn = choix_classes(around(knn.predict_proba(Xtrain[taille_train:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['KNN'],index = range(taille_train,dernier_test)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['KNN_Prob'],index = range(taille_train,dernier_test))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_logreg = logreg.predict(Xtrain[taille_train:])\n",
    "liste_logreg = choix_classes(around(logreg.predict_proba(Xtrain[taille_train:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_logreg,columns = ['LOGR'],index = range(taille_train,dernier_test)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['LOGR_Prob'],index = range(taille_train,dernier_test))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_ada = ada.predict(Xtrain[taille_train:])\n",
    "liste_ada = choix_classes(around(ada.predict_proba(Xtrain[taille_train:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['ADA'],index = range(taille_train,dernier_test)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['ADA_Prob'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_final = res_final [['Overall','RF','LDA','KNN','LOGR','ADA','RF_Prob','LDA_Prob','KNN_Prob','LOGR_Prob','ADA_Prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 373,   92,    4,   12],\n",
       "       [ 108,  295,   70,   34],\n",
       "       [  16,   92,  239,  212],\n",
       "       [   4,   56,   84, 1209]], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 365,  102,    2,   12],\n",
       "       [  98,  287,   96,   26],\n",
       "       [  12,   78,  259,  210],\n",
       "       [   4,   34,  108, 1207]], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.RF_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 370,   81,   19,   11],\n",
       "       [ 138,  229,   94,   46],\n",
       "       [  15,  100,  167,  277],\n",
       "       [  14,   39,   80, 1220]], dtype=int64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 370,   82,   18,   11],\n",
       "       [ 138,  213,  112,   44],\n",
       "       [  15,   87,  180,  277],\n",
       "       [  14,   37,   82, 1220]], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.LDA_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 285,  102,   40,   54],\n",
       "       [ 153,  148,   84,  122],\n",
       "       [  87,  105,  131,  236],\n",
       "       [  69,   74,  204, 1006]], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148, 226,  70,  37],\n",
       "       [ 81, 184, 141, 101],\n",
       "       [ 40, 101, 189, 229],\n",
       "       [ 31,  64, 282, 976]], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.KNN_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 351,   89,   18,   23],\n",
       "       [ 157,  184,  110,   56],\n",
       "       [  26,  106,  150,  277],\n",
       "       [  26,   38,  101, 1188]], dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.LOGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148, 226,  70,  37],\n",
       "       [ 81, 184, 141, 101],\n",
       "       [ 40, 101, 189, 229],\n",
       "       [ 31,  64, 282, 976]], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention, ce n'est plus bon du tout ....\n",
    "confusion_matrix(res_final.Overall,res_final.LOGR_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 285,  102,   40,   54],\n",
       "       [ 153,  148,   84,  122],\n",
       "       [  87,  105,  131,  236],\n",
       "       [  69,   74,  204, 1006]], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.ADA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148, 226,  70,  37],\n",
       "       [ 81, 184, 141, 101],\n",
       "       [ 40, 101, 189, 229],\n",
       "       [ 31,  64, 282, 976]], dtype=int64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(res_final.Overall,res_final.ADA_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "anglais = pd.read_csv('corpus_en_notes.csv',index_col=0)\n",
    "anglais = anglais.reset_index(drop=True)\n",
    "anglais2 = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "anglais2 = anglais.reset_index(drop=True)\n",
    "# attention, il faut les memes colonnes\n",
    "anglais2 = anglais[anglais.columns]\n",
    "anglais = pd.concat([anglais,anglais2],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = anglais[anglais.meth1_similarites!='Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.2279</td>\n",
       "      <td>17.7539</td>\n",
       "      <td>4.2135</td>\n",
       "      <td>-12.3815</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>1.5291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5226</td>\n",
       "      <td>42.5755</td>\n",
       "      <td>6.5250</td>\n",
       "      <td>-37.9037</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>1.8592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.1452</td>\n",
       "      <td>28.4365</td>\n",
       "      <td>5.3326</td>\n",
       "      <td>-22.1416</td>\n",
       "      <td>0.7047</td>\n",
       "      <td>1.6180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.8254</td>\n",
       "      <td>14.4516</td>\n",
       "      <td>3.8015</td>\n",
       "      <td>-10.5123</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>1.2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.9235</td>\n",
       "      <td>42.6111</td>\n",
       "      <td>6.5277</td>\n",
       "      <td>-34.3677</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>1.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.2684</td>\n",
       "      <td>18.4333</td>\n",
       "      <td>4.2934</td>\n",
       "      <td>-15.3940</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>1.3161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.8391</td>\n",
       "      <td>99.0721</td>\n",
       "      <td>9.9535</td>\n",
       "      <td>-80.4637</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>2.5391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.3502</td>\n",
       "      <td>63.0546</td>\n",
       "      <td>7.9407</td>\n",
       "      <td>-51.9265</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>2.1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.2868</td>\n",
       "      <td>8.3131</td>\n",
       "      <td>2.8833</td>\n",
       "      <td>-5.8671</td>\n",
       "      <td>0.5610</td>\n",
       "      <td>1.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.7859</td>\n",
       "      <td>12.5460</td>\n",
       "      <td>3.5420</td>\n",
       "      <td>-10.2608</td>\n",
       "      <td>0.5891</td>\n",
       "      <td>1.0047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>3.7175</td>\n",
       "      <td>34.7248</td>\n",
       "      <td>5.5013</td>\n",
       "      <td>-28.1219</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>1.5465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>1.1305</td>\n",
       "      <td>26.9452</td>\n",
       "      <td>2.1119</td>\n",
       "      <td>22.3851</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.4783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE      MSE    RMSE       R2   RMSLE    MAPE\n",
       "0     3.2279  17.7539  4.2135 -12.3815  0.7085  1.5291\n",
       "1     4.5226  42.5755  6.5250 -37.9037  0.7880  1.8592\n",
       "2     4.1452  28.4365  5.3326 -22.1416  0.7047  1.6180\n",
       "3     2.8254  14.4516  3.8015 -10.5123  0.6264  1.2016\n",
       "4     2.9235  42.6111  6.5277 -34.3677  0.6416  1.2376\n",
       "5     3.2684  18.4333  4.2934 -15.3940  0.6389  1.3161\n",
       "6     5.8391  99.0721  9.9535 -80.4637  0.9300  2.5391\n",
       "7     5.3502  63.0546  7.9407 -51.9265  0.8439  2.1435\n",
       "8     2.2868   8.3131  2.8833  -5.8671  0.5610  1.0157\n",
       "9     2.7859  12.5460  3.5420 -10.2608  0.5891  1.0047\n",
       "Mean  3.7175  34.7248  5.5013 -28.1219  0.7032  1.5465\n",
       "SD    1.1305  26.9452  2.1119  22.3851  0.1120  0.4783"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5089</td>\n",
       "      <td>0.4207</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.5572</td>\n",
       "      <td>0.7163</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.2474</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3932</td>\n",
       "      <td>0.2348</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>0.1544</td>\n",
       "      <td>0.2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.4658</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.6134</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4520</td>\n",
       "      <td>0.4445</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6047</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.2327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.3247</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4697</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>0.6078</td>\n",
       "      <td>0.6899</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3954</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.5063</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.1809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4666</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.6320</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>0.7072</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.2144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.5089  0.4207  0.6486  0.6829  0.2114  0.2872\n",
       "1     0.4312  0.3105  0.5572  0.7163  0.1632  0.1920\n",
       "2     0.3850  0.2474  0.4974  0.7987  0.1433  0.1695\n",
       "3     0.3932  0.2348  0.4846  0.8130  0.1544  0.2005\n",
       "4     0.5151  0.4658  0.6825  0.6134  0.2055  0.2413\n",
       "5     0.4520  0.4445  0.6667  0.6047  0.2016  0.2327\n",
       "6     0.4050  0.3247  0.5698  0.7330  0.1714  0.1875\n",
       "7     0.4697  0.3694  0.6078  0.6899  0.1837  0.2264\n",
       "8     0.3954  0.2564  0.5063  0.7882  0.1508  0.1809\n",
       "9     0.4666  0.4100  0.6403  0.6320  0.1906  0.2255\n",
       "Mean  0.4422  0.3484  0.5861  0.7072  0.1776  0.2144\n",
       "SD    0.0454  0.0813  0.0698  0.0726  0.0232  0.0334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3591</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3809</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.2359</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2979</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.4301</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.1364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.5159</td>\n",
       "      <td>0.7182</td>\n",
       "      <td>0.5718</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>0.2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4045</td>\n",
       "      <td>0.4183</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3338</td>\n",
       "      <td>0.3016</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.7520</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4282</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.1755</td>\n",
       "      <td>0.1761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.4774</td>\n",
       "      <td>0.8118</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4279</td>\n",
       "      <td>0.4243</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>0.1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.3274</td>\n",
       "      <td>0.5653</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.0933</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.3591  0.2440  0.4939  0.8161  0.1598  0.1927\n",
       "1     0.3809  0.3449  0.5873  0.6849  0.1730  0.1576\n",
       "2     0.3125  0.2359  0.4857  0.8080  0.1432  0.1422\n",
       "3     0.2979  0.1850  0.4301  0.8527  0.1303  0.1364\n",
       "4     0.4811  0.5159  0.7182  0.5718  0.2121  0.2034\n",
       "5     0.4045  0.4183  0.6468  0.6280  0.1875  0.1810\n",
       "6     0.3338  0.3016  0.5492  0.7520  0.1620  0.1464\n",
       "7     0.4282  0.3758  0.6131  0.6845  0.1755  0.1761\n",
       "8     0.2947  0.2279  0.4774  0.8118  0.1354  0.1314\n",
       "9     0.4279  0.4243  0.6514  0.6192  0.1994  0.1967\n",
       "Mean  0.3721  0.3274  0.5653  0.7229  0.1678  0.1664\n",
       "SD    0.0600  0.1010  0.0883  0.0933  0.0257  0.0255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4555</td>\n",
       "      <td>0.3809</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.2637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.7165</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.1791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3477</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.4642</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>0.1773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4798</td>\n",
       "      <td>0.4635</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.6153</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.6181</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3558</td>\n",
       "      <td>0.2568</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.1649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4293</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.5919</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3292</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.4644</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.4323</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.2198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4031</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0914</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.4555  0.3809  0.6172  0.7129  0.2028  0.2637\n",
       "1     0.3978  0.3103  0.5570  0.7165  0.1646  0.1791\n",
       "2     0.3474  0.2276  0.4771  0.8148  0.1407  0.1542\n",
       "3     0.3477  0.2155  0.4642  0.8284  0.1479  0.1773\n",
       "4     0.4798  0.4635  0.6808  0.6153  0.2069  0.2241\n",
       "5     0.4349  0.4295  0.6553  0.6181  0.2006  0.2291\n",
       "6     0.3558  0.2568  0.5068  0.7888  0.1487  0.1649\n",
       "7     0.4293  0.3503  0.5919  0.7060  0.1773  0.2030\n",
       "8     0.3292  0.2156  0.4644  0.8219  0.1422  0.1592\n",
       "9     0.4540  0.4323  0.6575  0.6120  0.1955  0.2198\n",
       "Mean  0.4031  0.3282  0.5672  0.7234  0.1727  0.1974\n",
       "SD    0.0518  0.0914  0.0806  0.0831  0.0257  0.0343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5784</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.6712</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.3007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5569</td>\n",
       "      <td>0.4164</td>\n",
       "      <td>0.6453</td>\n",
       "      <td>0.6195</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>0.2343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5523</td>\n",
       "      <td>0.3787</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.2355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5240</td>\n",
       "      <td>0.3576</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>0.1828</td>\n",
       "      <td>0.2538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5938</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>0.5812</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.2572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6110</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>0.2722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5941</td>\n",
       "      <td>0.4698</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>0.2558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5593</td>\n",
       "      <td>0.4382</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.6322</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.2534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4611</td>\n",
       "      <td>0.3270</td>\n",
       "      <td>0.5718</td>\n",
       "      <td>0.7299</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.4355</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.6092</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>0.6374</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.5784  0.4506  0.6712  0.6604  0.2119  0.3007\n",
       "1     0.5569  0.4164  0.6453  0.6195  0.1816  0.2343\n",
       "2     0.5523  0.3787  0.6154  0.6918  0.1741  0.2355\n",
       "3     0.5240  0.3576  0.5980  0.7152  0.1828  0.2538\n",
       "4     0.5938  0.5046  0.7103  0.5812  0.2057  0.2572\n",
       "5     0.6110  0.5391  0.7342  0.5206  0.2122  0.2722\n",
       "6     0.5941  0.4698  0.6854  0.6137  0.1946  0.2558\n",
       "7     0.5593  0.4382  0.6619  0.6322  0.1929  0.2534\n",
       "8     0.4611  0.3270  0.5718  0.7299  0.1660  0.2042\n",
       "9     0.5390  0.4355  0.6599  0.6092  0.1933  0.2453\n",
       "Mean  0.5570  0.4317  0.6554  0.6374  0.1915  0.2512\n",
       "SD    0.0409  0.0618  0.0474  0.0605  0.0148  0.0239"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5813</td>\n",
       "      <td>0.5220</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.3037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4644</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>0.7182</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4473</td>\n",
       "      <td>0.3223</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.7433</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.2290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6252</td>\n",
       "      <td>0.9349</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.2622</td>\n",
       "      <td>0.2745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>0.2107</td>\n",
       "      <td>0.2436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4873</td>\n",
       "      <td>0.4155</td>\n",
       "      <td>0.6446</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.1907</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5917</td>\n",
       "      <td>0.5569</td>\n",
       "      <td>0.7463</td>\n",
       "      <td>0.5325</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4415</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5479</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.7062</td>\n",
       "      <td>0.5524</td>\n",
       "      <td>0.2065</td>\n",
       "      <td>0.2523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.5988</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.2368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.5813  0.5220  0.7225  0.6065  0.2230  0.3037\n",
       "1     0.4784  0.3978  0.6307  0.6365  0.1797  0.2040\n",
       "2     0.4644  0.3462  0.5884  0.7182  0.1618  0.1874\n",
       "3     0.4473  0.3223  0.5677  0.7433  0.1773  0.2290\n",
       "4     0.6252  0.9349  0.9669  0.2240  0.2622  0.2745\n",
       "5     0.5016  0.4754  0.6895  0.5772  0.2107  0.2436\n",
       "6     0.4873  0.4155  0.6446  0.6584  0.1907  0.2244\n",
       "7     0.5917  0.5569  0.7463  0.5325  0.2114  0.2497\n",
       "8     0.4415  0.3161  0.5622  0.7389  0.1650  0.1989\n",
       "9     0.5479  0.4987  0.7062  0.5524  0.2065  0.2523\n",
       "Mean  0.5167  0.4786  0.6825  0.5988  0.1988  0.2368\n",
       "SD    0.0619  0.1719  0.1130  0.1440  0.0289  0.0339"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = create_model('lr')\n",
    "rr = create_model('lasso')\n",
    "etr = create_model('et')\n",
    "svr = create_model('svm')\n",
    "adar = create_model('ada')\n",
    "mlpr = create_model('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression simple sur scikit learn\n",
    "essai_classif = anglais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'score_sentiment3','meth1_similarites','meth2_similarites']]\n",
    "lr = LinearRegression()\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.loc[np.where(Xtrain['score_classif1'].notnull())[0]].reset_index(drop=True)\n",
    "ytrain = ytrain[(ytrain.index != 469) & (ytrain.index != 2170)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.38</td>\n",
       "      <td>40.52</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>11.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>28.23</td>\n",
       "      <td>84.30</td>\n",
       "      <td>99.21</td>\n",
       "      <td>836.8</td>\n",
       "      <td>955.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.612669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.84</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>6.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>21.31</td>\n",
       "      <td>39.07</td>\n",
       "      <td>64.69</td>\n",
       "      <td>406.8</td>\n",
       "      <td>505.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.711447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.27</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.04</td>\n",
       "      <td>20.11</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.141353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.28</td>\n",
       "      <td>14.97</td>\n",
       "      <td>5.67</td>\n",
       "      <td>10.96</td>\n",
       "      <td>8.33</td>\n",
       "      <td>21.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>95.43</td>\n",
       "      <td>722.7</td>\n",
       "      <td>314.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.131612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.36</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1.09</td>\n",
       "      <td>9.68</td>\n",
       "      <td>8.32</td>\n",
       "      <td>22.96</td>\n",
       "      <td>24.46</td>\n",
       "      <td>91.60</td>\n",
       "      <td>141.8</td>\n",
       "      <td>270.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.505050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.115016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.404905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.102186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.267368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "500                12              0              6                    50.38   \n",
       "501                 0              0              5                     4.40   \n",
       "502                 0              0              0                     1.54   \n",
       "503                10              0              0                    12.28   \n",
       "504                 1              0              0                    15.36   \n",
       "...               ...            ...            ...                      ...   \n",
       "3395                0              0              0                    15.18   \n",
       "3396                2              0              0                     4.29   \n",
       "3397                7              0              6                    40.45   \n",
       "3398                9              0              1                    22.58   \n",
       "3399               18              1             12                    51.00   \n",
       "\n",
       "      score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "500                      40.52                     -1.43           11.16   \n",
       "501                       4.84                     -3.35            6.38   \n",
       "502                       1.41                     15.27            8.01   \n",
       "503                      14.97                      5.67           10.96   \n",
       "504                      -0.60                      1.09            9.68   \n",
       "...                        ...                       ...             ...   \n",
       "3395                      0.96                     -0.44           52.18   \n",
       "3396                     14.06                      1.64           27.53   \n",
       "3397                     40.11                     24.78           10.46   \n",
       "3398                     29.80                     -0.50           10.97   \n",
       "3399                     44.02                     16.45           16.61   \n",
       "\n",
       "      score_classif2  score_sentiment1  score_sentiment2  score_sentiment3  \\\n",
       "500             8.37             28.23             84.30             99.21   \n",
       "501             8.40             21.31             39.07             64.69   \n",
       "502             8.33              9.04             20.11              3.27   \n",
       "503             8.33             21.39              8.42             95.43   \n",
       "504             8.32             22.96             24.46             91.60   \n",
       "...              ...               ...               ...               ...   \n",
       "3395            9.54             28.40             97.16             99.92   \n",
       "3396            8.29             31.73              1.55             13.10   \n",
       "3397            8.36             46.47             84.41             97.96   \n",
       "3398            8.42             19.91              1.06             93.64   \n",
       "3399            8.50             18.34             27.16             99.71   \n",
       "\n",
       "     meth1_similarites meth2_similarites  Overall        LR  \n",
       "500              836.8             955.1      1.0  0.612669  \n",
       "501              406.8             505.5      4.0  3.711447  \n",
       "502                  0                 0      4.0  4.141353  \n",
       "503              722.7             314.2      4.0  3.131612  \n",
       "504              141.8             270.2      4.0  3.505050  \n",
       "...                ...               ...      ...       ...  \n",
       "3395             289.7             418.5      3.0  3.115016  \n",
       "3396              40.4             150.6      4.0  3.404905  \n",
       "3397             547.7             717.2      1.0  1.102186  \n",
       "3398            1364.2             440.1      1.0  2.267368  \n",
       "3399            1445.6            1377.2      1.0  0.373753  \n",
       "\n",
       "[2900 rows x 15 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_lr = lr.predict(Xtrain[taille_train:])\n",
    "res_lr = pd.concat([Xtrain[taille_train:],ytrain[taille_train:],pd.DataFrame(res_lr,columns = ['LR'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,res_lr['LR']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>score_sentiment3</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.38</td>\n",
       "      <td>40.52</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>11.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>28.23</td>\n",
       "      <td>84.30</td>\n",
       "      <td>99.21</td>\n",
       "      <td>836.8</td>\n",
       "      <td>955.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.612669</td>\n",
       "      <td>0.937624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.84</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>6.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>21.31</td>\n",
       "      <td>39.07</td>\n",
       "      <td>64.69</td>\n",
       "      <td>406.8</td>\n",
       "      <td>505.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.711447</td>\n",
       "      <td>3.728716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.27</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.04</td>\n",
       "      <td>20.11</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.141353</td>\n",
       "      <td>4.156205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.28</td>\n",
       "      <td>14.97</td>\n",
       "      <td>5.67</td>\n",
       "      <td>10.96</td>\n",
       "      <td>8.33</td>\n",
       "      <td>21.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>95.43</td>\n",
       "      <td>722.7</td>\n",
       "      <td>314.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.131612</td>\n",
       "      <td>3.213291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.36</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1.09</td>\n",
       "      <td>9.68</td>\n",
       "      <td>8.32</td>\n",
       "      <td>22.96</td>\n",
       "      <td>24.46</td>\n",
       "      <td>91.60</td>\n",
       "      <td>141.8</td>\n",
       "      <td>270.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.505050</td>\n",
       "      <td>3.609757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.54</td>\n",
       "      <td>28.40</td>\n",
       "      <td>97.16</td>\n",
       "      <td>99.92</td>\n",
       "      <td>289.7</td>\n",
       "      <td>418.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.115016</td>\n",
       "      <td>2.596694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>31.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>13.10</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.404905</td>\n",
       "      <td>3.375768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.45</td>\n",
       "      <td>40.11</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.36</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84.41</td>\n",
       "      <td>97.96</td>\n",
       "      <td>547.7</td>\n",
       "      <td>717.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.102186</td>\n",
       "      <td>1.170204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>10.97</td>\n",
       "      <td>8.42</td>\n",
       "      <td>19.91</td>\n",
       "      <td>1.06</td>\n",
       "      <td>93.64</td>\n",
       "      <td>1364.2</td>\n",
       "      <td>440.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.267368</td>\n",
       "      <td>2.449016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51.00</td>\n",
       "      <td>44.02</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.61</td>\n",
       "      <td>8.50</td>\n",
       "      <td>18.34</td>\n",
       "      <td>27.16</td>\n",
       "      <td>99.71</td>\n",
       "      <td>1445.6</td>\n",
       "      <td>1377.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373753</td>\n",
       "      <td>0.438791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "500                12              0              6                    50.38   \n",
       "501                 0              0              5                     4.40   \n",
       "502                 0              0              0                     1.54   \n",
       "503                10              0              0                    12.28   \n",
       "504                 1              0              0                    15.36   \n",
       "...               ...            ...            ...                      ...   \n",
       "3395                0              0              0                    15.18   \n",
       "3396                2              0              0                     4.29   \n",
       "3397                7              0              6                    40.45   \n",
       "3398                9              0              1                    22.58   \n",
       "3399               18              1             12                    51.00   \n",
       "\n",
       "      score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "500                      40.52                     -1.43           11.16   \n",
       "501                       4.84                     -3.35            6.38   \n",
       "502                       1.41                     15.27            8.01   \n",
       "503                      14.97                      5.67           10.96   \n",
       "504                      -0.60                      1.09            9.68   \n",
       "...                        ...                       ...             ...   \n",
       "3395                      0.96                     -0.44           52.18   \n",
       "3396                     14.06                      1.64           27.53   \n",
       "3397                     40.11                     24.78           10.46   \n",
       "3398                     29.80                     -0.50           10.97   \n",
       "3399                     44.02                     16.45           16.61   \n",
       "\n",
       "      score_classif2  score_sentiment1  score_sentiment2  score_sentiment3  \\\n",
       "500             8.37             28.23             84.30             99.21   \n",
       "501             8.40             21.31             39.07             64.69   \n",
       "502             8.33              9.04             20.11              3.27   \n",
       "503             8.33             21.39              8.42             95.43   \n",
       "504             8.32             22.96             24.46             91.60   \n",
       "...              ...               ...               ...               ...   \n",
       "3395            9.54             28.40             97.16             99.92   \n",
       "3396            8.29             31.73              1.55             13.10   \n",
       "3397            8.36             46.47             84.41             97.96   \n",
       "3398            8.42             19.91              1.06             93.64   \n",
       "3399            8.50             18.34             27.16             99.71   \n",
       "\n",
       "     meth1_similarites meth2_similarites  Overall        LR       PLS  \n",
       "500              836.8             955.1      1.0  0.612669  0.937624  \n",
       "501              406.8             505.5      4.0  3.711447  3.728716  \n",
       "502                  0                 0      4.0  4.141353  4.156205  \n",
       "503              722.7             314.2      4.0  3.131612  3.213291  \n",
       "504              141.8             270.2      4.0  3.505050  3.609757  \n",
       "...                ...               ...      ...       ...       ...  \n",
       "3395             289.7             418.5      3.0  3.115016  2.596694  \n",
       "3396              40.4             150.6      4.0  3.404905  3.375768  \n",
       "3397             547.7             717.2      1.0  1.102186  1.170204  \n",
       "3398            1364.2             440.1      1.0  2.267368  2.449016  \n",
       "3399            1445.6            1377.2      1.0  0.373753  0.438791  \n",
       "\n",
       "[2900 rows x 16 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls = PLSRegression()\n",
    "pls.fit(Xtrain[:taille_train],ytrain[:taille_train])\n",
    "res_pls = list(pls.predict(Xtrain[taille_train:]).flatten())\n",
    "res_pls = pd.concat([res_lr,pd.DataFrame(res_pls,columns = ['PLS'],index = range(taille_train,dernier_test))],axis=1)\n",
    "res_pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,res_pls['PLS']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>ADA</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>KNN_Prob</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>ADA_Prob</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612669</td>\n",
       "      <td>0.937624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.711447</td>\n",
       "      <td>3.728716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.141353</td>\n",
       "      <td>4.156205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.131612</td>\n",
       "      <td>3.213291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.505050</td>\n",
       "      <td>3.609757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.115016</td>\n",
       "      <td>2.596694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.404905</td>\n",
       "      <td>3.375768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.102186</td>\n",
       "      <td>1.170204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.267368</td>\n",
       "      <td>2.449016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.373753</td>\n",
       "      <td>0.438791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  RF  LDA  KNN  LOGR  ADA  RF_Prob  LDA_Prob  KNN_Prob  \\\n",
       "500         1   1    1    1     1    1        1         1         1   \n",
       "501         4   4    4    2     4    2        4         4         3   \n",
       "502         4   4    4    4     4    4        4         4         4   \n",
       "503         4   3    4    2     3    2        3         4         3   \n",
       "504         4   4    4    4     4    4        4         4         4   \n",
       "...       ...  ..  ...  ...   ...  ...      ...       ...       ...   \n",
       "3395        3   4    3    3     4    3        4         3         3   \n",
       "3396        4   4    4    4     4    4        4         4         4   \n",
       "3397        1   1    1    2     1    2        1         1         2   \n",
       "3398        1   2    2    4     2    4        2         2         4   \n",
       "3399        1   1    1    1     1    1        1         1         1   \n",
       "\n",
       "      LOGR_Prob  ADA_Prob        LR       PLS  \n",
       "500           1         1  0.612669  0.937624  \n",
       "501           3         3  3.711447  3.728716  \n",
       "502           4         4  4.141353  4.156205  \n",
       "503           3         3  3.131612  3.213291  \n",
       "504           4         4  3.505050  3.609757  \n",
       "...         ...       ...       ...       ...  \n",
       "3395          3         3  3.115016  2.596694  \n",
       "3396          4         4  3.404905  3.375768  \n",
       "3397          2         2  1.102186  1.170204  \n",
       "3398          4         4  2.267368  2.449016  \n",
       "3399          1         1  0.373753  0.438791  \n",
       "\n",
       "[2900 rows x 13 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour le classement final utiliser aussi la stade de base des notations : si plus de 4 ....** <br/>\n",
    "**Pour le seuils : Le mieux est d'utiliser un algo qui regrade les erreurs des autres ... NB / LR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on ne garde finalement que LDA - RF et LR en classif et sans les probas qui changent peu finalement\n",
    "def choix_final(df):\n",
    "    res = pd.DataFrame(columns = ['Overall','Classif_value','Regression_value','Classif','Regression','Final','Final_aide'])\n",
    "    for i in range(df.index[0],df.index[len(df)-1]):\n",
    "        my_dic = {}\n",
    "        my_dic['Overall'] = df.Overall[i]                   \n",
    "        my_dic['Classif_value'] = round((df.RF[i] + df.LDA[i] + df.LOGR[i])/3,2)\n",
    "        my_dic['Regression_value'] = round((df.LR[i] + df.PLS[i])/2,2)\n",
    "        if my_dic['Classif_value'] < 1.7:\n",
    "            my_dic['Classif'] = 1\n",
    "        elif my_dic['Classif_value'] < 2.5:\n",
    "            my_dic['Classif'] = 2\n",
    "        elif my_dic['Classif_value'] < 3.25:\n",
    "            my_dic['Classif'] = 3\n",
    "        else:\n",
    "            my_dic['Classif'] = 4\n",
    "        if my_dic['Regression_value'] <= 1.6:\n",
    "            my_dic['Regression'] = 1\n",
    "        elif my_dic['Regression_value'] < 2.5:\n",
    "            my_dic['Regression'] = 2\n",
    "        elif my_dic['Regression_value'] < 3.5:\n",
    "            my_dic['Regression'] = 3\n",
    "        else:\n",
    "            my_dic['Regression'] = 4\n",
    "        diff = 0.01 if my_dic['Classif'] != my_dic['Regression'] else 0\n",
    "        diff += 0.005 if abs(my_dic['Classif']-my_dic['Regression'])>=2 else 0\n",
    "        my_dic['Final'] = round((my_dic['Classif']+my_dic['Regression'])/2,0)\n",
    "        my_dic['Final_aide'] = round((my_dic['Classif']+my_dic['Regression'])/2,0)+diff\n",
    "        res.loc[len(res)] = my_dic\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Classif_value</th>\n",
       "      <th>Regression_value</th>\n",
       "      <th>Classif</th>\n",
       "      <th>Regression</th>\n",
       "      <th>Final</th>\n",
       "      <th>Final_aide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.72</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.86</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2899 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  Classif_value  Regression_value  Classif  Regression  Final  \\\n",
       "0         1.0           1.00              0.78      1.0         1.0    1.0   \n",
       "1         4.0           4.00              3.72      4.0         4.0    4.0   \n",
       "2         4.0           4.00              4.15      4.0         4.0    4.0   \n",
       "3         4.0           3.33              3.17      4.0         3.0    4.0   \n",
       "4         4.0           4.00              3.56      4.0         4.0    4.0   \n",
       "...       ...            ...               ...      ...         ...    ...   \n",
       "2894      1.0           1.00              1.77      1.0         2.0    2.0   \n",
       "2895      3.0           3.67              2.86      4.0         3.0    4.0   \n",
       "2896      4.0           4.00              3.39      4.0         3.0    4.0   \n",
       "2897      1.0           1.00              1.14      1.0         1.0    1.0   \n",
       "2898      1.0           2.00              2.36      2.0         2.0    2.0   \n",
       "\n",
       "      Final_aide  \n",
       "0           1.00  \n",
       "1           4.00  \n",
       "2           4.00  \n",
       "3           4.01  \n",
       "4           4.00  \n",
       "...          ...  \n",
       "2894        2.01  \n",
       "2895        4.01  \n",
       "2896        4.01  \n",
       "2897        1.00  \n",
       "2898        2.00  \n",
       "\n",
       "[2899 rows x 7 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote = choix_final(res_final)\n",
    "vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[280, 165,  25,  10],\n",
       "       [ 71, 247, 178,  11],\n",
       "       [  4,  77, 354, 124],\n",
       "       [  4,  32, 350, 967]], dtype=int64)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plutôt moins bon que la classif : peut etre question de seuil ...\n",
    "confusion_matrix(vote.Overall,vote.Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 278,  177,   15,   10],\n",
       "       [  64,  301,   91,   51],\n",
       "       [   4,  113,  110,  332],\n",
       "       [   4,   46,   46, 1257]], dtype=int64)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ne sert à rien pratiquement, mais seuils à voir\n",
    "confusion_matrix(vote.Overall,vote.Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8183695680938456"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr, _ = pearsonr(vote.Overall, vote.Final)\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMARQUE GENERALE : IL Y A BCP DE 4 ce qui aide beaucoup pour la performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

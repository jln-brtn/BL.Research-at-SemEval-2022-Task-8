{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de classification en Allemand\n",
    "\n",
    "    - Transformers : Summarization : 2 modèles --> 2 Résumés / Puis score de similarités de ces 2 résumés\n",
    "    Noter que l'on peut faire aussi la similarité des textes (autre note ?) et non du résumé\n",
    "    - Text classification sur une base de catégories \"Presse\" \n",
    "    - Sentiment analysis : voir si le ton du texte est de même type \n",
    "    - Les 2 derniers classifier seronts utilisés en produit scalaire : Par Catégorie : texte1: note1 - texte2 : note2\n",
    "    et donc sum(notes_par_catégorie) = sum(note1*note2) * 100 au bout (note sur 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pke\n",
    "import spacy\n",
    "import torch\n",
    "import stanza\n",
    "import spacy_stanza\n",
    "import warnings\n",
    "import string\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import enchant    # Pour correction orthographique de synonymes\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection des modèles NLP : ici ALLEMAND**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement pour l'utilisation de Spacy  - Français\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_spacy = {'de':nlp_de}   # 'en':nlp_en,'de':nlp_de,'es':nlp_es,'pl':nlp_pl  - POUR MEMOIRE\n",
    "langues = ['en','fr','es','de','pl','ar','tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle Word2Vec pour utilisation de synonymes\n",
    "from gensim.models import Word2Vec\n",
    "model_gensim = gensim.models.KeyedVectors.load_word2vec_format(\"D:/Users/STG-SDU/Documents/NLP/german.model\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords Français NLTK + Spacy \n",
    "stopWords = list(nlp_de.Defaults.stop_words)\n",
    "stopwords_de = list(stopwords.words('german'))  \n",
    "stopwords_de = list(set(stopwords_de + stopWords))\n",
    "stopwds_lg = {'de':stopwords_de}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcteur orthographique pour validation des synonymes OPTIONNEL CAR NON NECESSAIRE\n",
    "# d = enchant.Dict(\"de\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection des modèles Transformers : Summary - Text Classification - Sentiment Analysis - Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèles Transformers de Résumé (NB : Ne pas oublier d'ajouter la truncation pour tous les modèles, peut être source d'erreur)\n",
    "summarizer1 = pipeline(\"summarization\", model=\"ml6team/mt5-small-german-finetune-mlsum\", truncation = \"only_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    }
   ],
   "source": [
    "# 2e résumé\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckpt = 'mrm8488/bert2bert_shared-german-finetuned-summarization'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(ckpt)\n",
    "model = EncoderDecoderModel.from_pretrained(ckpt).to(device)\n",
    "def summarizer2(text):\n",
    "    inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plus proche du sentiment analysis ....\n",
    "text_clf1 = pipeline(\"text-classification\", model = \"symanto/xlm-roberta-base-snli-mnli-anli-xnli\", truncation = \"only_first\")   # 10 actégories, voir hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero shot classification (permet de chosir nos propres thèmes)\n",
    "text_clf2 = pipeline('zero-shot-classification', model=\"Sahajtomar/German_Zeroshot\",truncation = \"only_first\")\n",
    "# ce modèle est un zero shot classification : catégories possibles choisies par mes soins (dans la presse)\n",
    "candidate_labels = ['Wissenschaft','Politik','Bildung','Nachrichten','Gesundheit','Technologie','Gesellschaft','Sport','Wirtschaft','Kultur','International','Umwelt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "sentiment1 = pipeline(\"text-classification\", model = 'oliverguhr/german-sentiment-bert', truncation = \"only_first\")\n",
    "# ATTENTION CE MODELE n°2 SE DEFINIT SUR 5 niveaux\n",
    "sentiment2 = pipeline(\"text-classification\", model = 'nlptown/bert-base-multilingual-uncased-sentiment', truncation = \"only_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\stg-sdu/.cache\\torch\\sentence_transformers\\Sahajtomar_German_Zeroshot. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\stg-sdu/.cache\\torch\\sentence_transformers\\Sahajtomar_German_Zeroshot were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# ENCODAGE AVEC SENTENCE TRANSFORMER\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.nn import CosineSimilarity\n",
    "cos = CosineSimilarity()\n",
    "encoder = SentenceTransformer(\"Sahajtomar/German_Zeroshot\")\n",
    "def score_similarite(sentence1,sentence2):\n",
    "    # attention, pour que torch fonctionne en dimension sentence1 (et 2) est une liste simple\n",
    "    embed1 = encoder.encode(sentence1, convert_to_tensor=True)\n",
    "    embed2 = encoder.encode(sentence2, convert_to_tensor=True)\n",
    "    cos = CosineSimilarity()\n",
    "    cosine_scores = cos(embed1, embed2)\n",
    "    return round(float(cosine_scores)*100,2)\n",
    "\n",
    "# print(score_similarite(['Die Katze sitzt draußen'],['Der Hund spielt im Garten']))\n",
    "# print(score_similarite(['Ein Mann spielt Gitarre'],['Eine Frau sieht fern']))\n",
    "# print(score_similarite(['Der neue Film ist großartig'],['Der neue Film ist so toll']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection Data par langues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data_prep_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>pair_lang</th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>title_1</th>\n",
       "      <th>text_1</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>...</th>\n",
       "      <th>text_2</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Style</th>\n",
       "      <th>Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1484084337_1484110209</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>MARTINSBURG, W.Va. — A suspected drunken drive...</td>\n",
       "      <td>Police in West Virginia say a suspected drunke...</td>\n",
       "      <td>['Highway Fatal-DUI-West Virginia', 'Martinsbu...</td>\n",
       "      <td>...</td>\n",
       "      <td>PORT-AU-PRINCE, Haiti — Haitian President Jove...</td>\n",
       "      <td>Haitian President Jovenel Moïse has broken wit...</td>\n",
       "      <td>['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1484396422_1483924666</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.stlucianewsonline.com</td>\n",
       "      <td>Wed Jan  1 21:17:15 2020</td>\n",
       "      <td>https://www.thestar.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...</td>\n",
       "      <td>-</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>['smg2_world', 'smg_europe', 'smg2_news']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1484698254_1483758694</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.teaparty.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.timesofisrael.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>(Breitbart) – President Donald Trump welcomed ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>PALM BEACH, United States — US President Donal...</td>\n",
       "      <td>US president says response to rioting by pro-I...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1576314516_1576455088</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Uber has sold its online food-ordering busines...</td>\n",
       "      <td>Zomato on Tuesday announced it has acquired Ub...</td>\n",
       "      <td>['zomato uber eats business acquisition india ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rapid digitisation and growth in both online b...</td>\n",
       "      <td>The report by Google and Boston Consulting Gro...</td>\n",
       "      <td>['indian online food delivery market to hit us...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484036253_1483894099</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://news.yahoo.com</td>\n",
       "      <td>Wed Jan  1 08:57:59 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>BENGALURU (Reuters) - India has approved its t...</td>\n",
       "      <td>India has approved its third lunar mission mon...</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>1586195445_1598778991</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...</td>\n",
       "      <td>...</td>\n",
       "      <td>BM'den Yemen'de kadınların doğumda ölüm riski ...</td>\n",
       "      <td>BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>1590915424_1590940388</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.aksam.com.tr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['İspanya 1. Futbol Ligi', 'la liga', 'koronav...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>1526157103_1492737005</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.samanyoluhaber.com</td>\n",
       "      <td>Thu Feb 20 10:47:10 2020</td>\n",
       "      <td>https://www.fotomac.com.tr</td>\n",
       "      <td>Sun Jan 12 00:00:00 2020</td>\n",
       "      <td>Saray da çare olmadı: 'Borca boğulan dev kulüp...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...</td>\n",
       "      <td>SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...</td>\n",
       "      <td>['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...</td>\n",
       "      <td>...</td>\n",
       "      <td>TFF, resmi internet sitesinden Beşiktaş'ın fai...</td>\n",
       "      <td>Federasyon, Başkan Çebi’nin yaptığı açıklamala...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>1603274500_1618292937</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...</td>\n",
       "      <td>['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...</td>\n",
       "      <td>...</td>\n",
       "      <td>Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...</td>\n",
       "      <td>Covid-19 salgınından vatandaşların korunması i...</td>\n",
       "      <td>['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>1597247537_1604202164</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.takvim.com.tr</td>\n",
       "      <td>Tue May  5 00:00:00 2020</td>\n",
       "      <td>https://www.yeniasir.com.tr</td>\n",
       "      <td>Tue May 12 00:00:00 2020</td>\n",
       "      <td>Grup Yorum üyeleri zorla başlatmıştı... İbrahi...</td>\n",
       "      <td>DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4964 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pair_id pair_lang                       source_url_1  \\\n",
       "0     1484084337_1484110209     en_en     https://www.washingtonpost.com   \n",
       "1     1484396422_1483924666     en_en  https://www.stlucianewsonline.com   \n",
       "2     1484698254_1483758694     en_en           https://www.teaparty.org   \n",
       "3     1576314516_1576455088     en_en           https://gadgets.ndtv.com   \n",
       "4     1484036253_1483894099     en_en             https://news.yahoo.com   \n",
       "...                     ...       ...                                ...   \n",
       "4959  1586195445_1598778991     tr_tr            http://www.haberler.com   \n",
       "4960  1590915424_1590940388     tr_tr           https://www.haberler.com   \n",
       "4961  1526157103_1492737005     tr_tr      http://www.samanyoluhaber.com   \n",
       "4962  1603274500_1618292937     tr_tr           https://www.haberler.com   \n",
       "4963  1597247537_1604202164     tr_tr          https://www.takvim.com.tr   \n",
       "\n",
       "                publish_date_1                    source_url_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020  https://www.washingtonpost.com   \n",
       "1     Wed Jan  1 21:17:15 2020         https://www.thestar.com   \n",
       "2                          NaN   https://www.timesofisrael.com   \n",
       "3                          NaN        https://gadgets.ndtv.com   \n",
       "4     Wed Jan  1 08:57:59 2020                             NaN   \n",
       "...                        ...                             ...   \n",
       "4959                       NaN        https://www.haberler.com   \n",
       "4960                       NaN        https://www.aksam.com.tr   \n",
       "4961  Thu Feb 20 10:47:10 2020      https://www.fotomac.com.tr   \n",
       "4962                       NaN        https://www.haberler.com   \n",
       "4963  Tue May  5 00:00:00 2020     https://www.yeniasir.com.tr   \n",
       "\n",
       "                publish_date_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020   \n",
       "1     Wed Jan  1 00:00:00 2020   \n",
       "2                          NaN   \n",
       "3                          NaN   \n",
       "4                          NaN   \n",
       "...                        ...   \n",
       "4959                       NaN   \n",
       "4960                       NaN   \n",
       "4961  Sun Jan 12 00:00:00 2020   \n",
       "4962                       NaN   \n",
       "4963  Tue May 12 00:00:00 2020   \n",
       "\n",
       "                                                title_1  \\\n",
       "0     Virginia man arrested in fatal DUI crash in We...   \n",
       "1     Guyana: Three injured after car crashes into u...   \n",
       "2     Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3     Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4     India approves third moon mission, months afte...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  Saray da çare olmadı: 'Borca boğulan dev kulüp...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  Grup Yorum üyeleri zorla başlatmıştı... İbrahi...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     MARTINSBURG, W.Va. — A suspected drunken drive...   \n",
       "1     Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...   \n",
       "2     (Breitbart) – President Donald Trump welcomed ...   \n",
       "3     Uber has sold its online food-ordering busines...   \n",
       "4     BENGALURU (Reuters) - India has approved its t...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  \\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...   \n",
       "\n",
       "                                     meta_description_1  \\\n",
       "0     Police in West Virginia say a suspected drunke...   \n",
       "1                                                     -   \n",
       "2                                                   NaN   \n",
       "3     Zomato on Tuesday announced it has acquired Ub...   \n",
       "4     India has approved its third lunar mission mon...   \n",
       "...                                                 ...   \n",
       "4959  Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...   \n",
       "4962  Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_1  ...  \\\n",
       "0     ['Highway Fatal-DUI-West Virginia', 'Martinsbu...  ...   \n",
       "1                                                  ['']  ...   \n",
       "2                                                  ['']  ...   \n",
       "3     ['zomato uber eats business acquisition india ...  ...   \n",
       "4                                                  ['']  ...   \n",
       "...                                                 ...  ...   \n",
       "4959  ['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...  ...   \n",
       "4960  ['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...  ...   \n",
       "4961  ['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...  ...   \n",
       "4962  ['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...  ...   \n",
       "4963                                               ['']  ...   \n",
       "\n",
       "                                                 text_2  \\\n",
       "0     PORT-AU-PRINCE, Haiti — Haitian President Jove...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     PALM BEACH, United States — US President Donal...   \n",
       "3     Rapid digitisation and growth in both online b...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "4959  BM'den Yemen'de kadınların doğumda ölüm riski ...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  TFF, resmi internet sitesinden Beşiktaş'ın fai...   \n",
       "4962  Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...   \n",
       "4963  Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...   \n",
       "\n",
       "                                     meta_description_2  \\\n",
       "0     Haitian President Jovenel Moïse has broken wit...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     US president says response to rioting by pro-I...   \n",
       "3     The report by Google and Boston Consulting Gro...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "4959  BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  Federasyon, Başkan Çebi’nin yaptığı açıklamala...   \n",
       "4962  Covid-19 salgınından vatandaşların korunması i...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_2 Geography  Entities  \\\n",
       "0     ['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...       4.0  4.000000   \n",
       "1             ['smg2_world', 'smg_europe', 'smg2_news']       4.0  4.000000   \n",
       "2                                                  ['']       1.0  2.000000   \n",
       "3     ['indian online food delivery market to hit us...       1.0  2.333333   \n",
       "4                                                   NaN       1.0  1.250000   \n",
       "...                                                 ...       ...       ...   \n",
       "4959  ['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...       1.0  2.000000   \n",
       "4960  ['İspanya 1. Futbol Ligi', 'la liga', 'koronav...       1.0  1.000000   \n",
       "4961                                               ['']       1.0  2.000000   \n",
       "4962     ['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']       1.0  2.000000   \n",
       "4963                                               ['']       2.0  2.000000   \n",
       "\n",
       "          Time  Narrative   Overall     Style      Tone  \n",
       "0     1.000000   4.000000  4.000000  1.666667  2.000000  \n",
       "1     1.000000   4.000000  3.666667  1.666667  1.333333  \n",
       "2     1.000000   2.333333  2.333333  1.000000  1.333333  \n",
       "3     2.666667   1.666667  2.000000  1.666667  1.666667  \n",
       "4     1.000000   1.250000  1.250000  1.000000  1.000000  \n",
       "...        ...        ...       ...       ...       ...  \n",
       "4959  2.000000   4.000000  3.000000  1.000000  1.000000  \n",
       "4960  1.000000   1.000000  1.000000  1.000000  1.000000  \n",
       "4961  3.000000   4.000000  3.000000  1.000000  2.000000  \n",
       "4962  3.000000   3.000000  3.000000  1.000000  1.000000  \n",
       "4963  1.000000   2.000000  2.000000  3.000000  1.000000  \n",
       "\n",
       "[4964 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remémorer numéro de ligne - compléter les Nan\n",
    "data['ligne'] = data.index\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation des datasets, le dernier étant à traduire en plus\n",
    "allemand = data.loc[data.pair_lang == 'de_de',['ligne','title_1','title_2','text_1','text_2','Geography', 'Entities',\n",
    "       'Time', 'Narrative', 'Overall', 'Style', 'Tone']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests divers et Fonctions nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Jahresmeisterschaft entscheidet der Durchschnitt der besten zehn Serien im Lauf des Jahres.\n",
      "Die deutsche Melodie Bob Geldofs steht in einer Reihe mit Ohr\n",
      "90.23\n"
     ]
    }
   ],
   "source": [
    "# Résumés, attention le string de la sentence doit être fourni en liste, pour dim ds torch\n",
    "resume1 = summarizer1(allemand.text_1[1])[0]['summary_text']\n",
    "resume2 = summarizer1(allemand.text_2[1])[0]['summary_text']\n",
    "print(resume1)\n",
    "print(resume2)\n",
    "print(score_similarite([resume1],[resume2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silberdistel Neutras ehrt Jahresmeister Von den Namen her bietet die Siegerehrung wenig Überraschendes, aber die eine oder andere Entscheidung fällt doch sehr knapp aus.\n",
      "In der Weihnachtszeit ist die Zahl der Weihnachtslieder in Deutschland so sehr gestiegen wie im Vorjahr. Aber es ist schwer, die Weihnachtslieder zu finden.\n",
      "67.07\n"
     ]
    }
   ],
   "source": [
    "resume1 = summarizer2(allemand.text_1[1])\n",
    "resume2 = summarizer2(allemand.text_2[1])\n",
    "print(resume1)\n",
    "print(resume2)\n",
    "print(score_similarite([resume1],[resume2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de calcul du score (produit scalaire) pour résultats de classifaction\n",
    "def fonction_produit_dotcom(liste_categor, dico_scores1,dico_scores2):\n",
    "    \"\"\"\"dico scores sont les résultats obtenus pour chaque catégorie des textes 1 et 2\"\"\"\n",
    "    result = 0.0\n",
    "    for cat in liste_categor:\n",
    "        result += round(dico_scores1[cat] * dico_scores2[cat],4)\n",
    "    return result * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type1\n",
    "def transform_text_clf1(liste_dico):\n",
    "    res = {}\n",
    "    for dic in liste_dico:\n",
    "        res[dic['label']] = dic['score']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type2\n",
    "def transform_text_clf2(liste_cat,liste_sc):\n",
    "    res = {}\n",
    "    for i in range(len(liste_cat)):\n",
    "        res[liste_cat[i]] = liste_sc[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ENTAILMENT': 0.029949994757771492, 'NEUTRAL': 0.9699869155883789, 'CONTRADICTION': 6.301972462097183e-05}\n",
      "{'ENTAILMENT': 0.4363759160041809, 'NEUTRAL': 0.5626500248908997, 'CONTRADICTION': 0.0009741269168443978}\n",
      "55.88999999999999\n"
     ]
    }
   ],
   "source": [
    "# Test sur CLF1\n",
    "liste_categories = ['ENTAILMENT','NEUTRAL','CONTRADICTION']\n",
    "scores1 = transform_text_clf1(text_clf1(allemand.text_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(text_clf1(allemand.text_2[3],return_all_scores=True)[0])\n",
    "print(scores1)\n",
    "print(scores2)\n",
    "print(fonction_produit_dotcom(liste_categories, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.59\n"
     ]
    }
   ],
   "source": [
    "classes = text_clf2(allemand.text_1[2], candidate_labels)\n",
    "scores1 = transform_text_clf2(classes['labels'],classes['scores'])\n",
    "classes2 = text_clf2(allemand.text_2[2], candidate_labels)\n",
    "scores2 = transform_text_clf2(classes2['labels'],classes2['scores'])\n",
    "print(fonction_produit_dotcom(candidate_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '1 star', 'score': 0.0035264366306364536},\n",
       " {'label': '2 stars', 'score': 0.007172734942287207},\n",
       " {'label': '3 stars', 'score': 0.0627947449684143},\n",
       " {'label': '4 stars', 'score': 0.44613808393478394},\n",
       " {'label': '5 stars', 'score': 0.48036807775497437}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment2(allemand.text_1[3],return_all_scores=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0.16152270138263702, 'negative': 0.1037590354681015, 'neutral': 0.7347182631492615}\n",
      "{'positive': 0.00013322454469744116, 'negative': 0.0002798540808726102, 'neutral': 0.9995868802070618}\n",
      "73.44000000000001\n"
     ]
    }
   ],
   "source": [
    "# Tests sentiment analysis\n",
    "liste_labels = ['positive','negative','neutral']\n",
    "scores1 = transform_text_clf1(sentiment1(allemand.text_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(sentiment1(allemand.text_2[3],return_all_scores=True)[0])\n",
    "print(scores1)\n",
    "print(scores2)\n",
    "print(fonction_produit_dotcom(liste_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.39\n",
      "32.63\n"
     ]
    }
   ],
   "source": [
    "# ATTENTION CE MODELE SE DEFINIT SUR 4 CLASSES : mixed, positif, negatif, objectif\n",
    "liste_sentiments = ['1 star','2 stars','3 stars','4 stars','5 stars']\n",
    "scores1 = transform_text_clf1(sentiment2(allemand.title_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(sentiment2(allemand.title_2[3],return_all_scores=True)[0])\n",
    "scores3 = transform_text_clf1(sentiment2(allemand.text_1[3],return_all_scores=True)[0])\n",
    "scores4 = transform_text_clf1(sentiment2(allemand.text_2[3],return_all_scores=True)[0])\n",
    "print(fonction_produit_dotcom(liste_sentiments, scores1,scores2))\n",
    "print(fonction_produit_dotcom(liste_sentiments, scores3,scores4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.22\n",
      "94.59\n",
      "97.8\n",
      "86.47\n"
     ]
    }
   ],
   "source": [
    "# TESTS SCORES DE SIMILARITES : Titres, Textes complets (attention Truncation ...)\n",
    "print(score_similarite([allemand.title_1[3]],[allemand.title_2[3]]))\n",
    "print(score_similarite([allemand.text_1[3]],[allemand.text_2[3]]))\n",
    "print(score_similarite([summarizer1(allemand.text_1[0])[0]['summary_text']],[summarizer1(allemand.text_2[0])[0]['summary_text']]))\n",
    "print(score_similarite([summarizer2(allemand.text_1[0])],[summarizer2(allemand.text_2[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tode', 0.712026834487915),\n",
       " ('tragischen_Tod', 0.702599048614502),\n",
       " ('Freitod', 0.699851393699646),\n",
       " ('Ableben', 0.698720395565033),\n",
       " ('Unfalltod', 0.698566198348999),\n",
       " ('Selbstmord', 0.6980338096618652),\n",
       " ('ploetzlichen_Tod', 0.6917396783828735),\n",
       " ('Suizid', 0.6767473220825195),\n",
       " ('Tod_Bruders', 0.6639395952224731),\n",
       " ('Tod_geliebten', 0.6626296043395996)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essais de synonymies à utiliser pour sorties PKE, termes prinicpaux\n",
    "syns = model_gensim.most_similar(\"Tod\", topn=10)\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de summarization \n",
    "def summarization(texte):\n",
    "    return summarizer1(texte)[0]['summary_text'], summarizer2(texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_classifiers = {'text_clf1': 'score_classif1','text_clf2':'score_classif2','sentiment1':'score_sentiment1',\n",
    "                    'sentiment2': 'score_sentiment2'}\n",
    "dico_categories = {'text_clf1': liste_categories,'text_clf2':candidate_labels,'sentiment1':liste_labels,\n",
    "                    'sentiment2': liste_sentiments}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de classification et sentiment analysis\n",
    "def classification(texte,clf):\n",
    "    # assume nms des claasifiers et methode de transformation\n",
    "    if clf == \"text_clf1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(text_clf1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"text_clf2\":                                 \n",
    "        try:\n",
    "            classes = text_clf2(texte,candidate_labels)\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return transform_text_clf2(classes['labels'],classes['scores'])                          \n",
    "    elif clf == \"sentiment1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"sentiment2\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment2(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    else:\n",
    "        return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des mots de moins de 2 lettres non numériques\n",
    "def supp_moins_2_lettres_stopwords(phrase,stopwd):\n",
    "    temp = phrase.split(' ')\n",
    "    res = ''\n",
    "    for mot in temp:\n",
    "        if mot not in stopwd and (len(mot)>2 or (len(mot)>0 and mot[0] in ['0','1','2','3','4','5','6','7','8','9'])):\n",
    "            res += mot + ' '\n",
    "    return res[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des traits d'union(regroupe)/ des apostrophes / ponctuations\n",
    "def modif(texte,stopmots):\n",
    "    # modifications simples des textes : ponctuations, petits mots, stopwords (à faire pour entités et pke textes)\n",
    "    texte=re.sub('\\'',' ',texte)   # suppression apostrophe\n",
    "    texte=re.sub('-','',texte)    # suppression trait union\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation)) # suppression de toutes les ponctuations\n",
    "    texte=regex.sub(' ',texte)\n",
    "    texte = supp_moins_2_lettres_stopwords(texte,stopmots)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des synonymes (existants en orthographe) à la suite de l'analyse pke\n",
    "def ajout_synonymes(mot, correct_ortho = False):\n",
    "    # on ajoute les 10 premiers synonymes existants, on vérifie orthographe (optionnel)\n",
    "    syns = model_gensim.most_similar(mot,topn = 20)\n",
    "    if correct_ortho == True:\n",
    "        res = []\n",
    "        for m in syns:\n",
    "            if d.check(m[0]):   #  il y a le mot et son pourcentage d'importance\n",
    "                res.append(m)\n",
    "        syns = res\n",
    "    return syns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la bonne méthodologie à appliquer PKE ??? : Noms Ok - Verbes ? - Adjectifs ? - Noms propres ?\n",
    "Quelle quantité de mots prendre ?\n",
    "Ne pas noter les titres seuls ? : trop peu de mots !  Et du coup note peut être forte avec un seul mot !\n",
    "Supprimer en en-tête les stopwords, ponctuation, les apostrophes - AUTRES ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres de la méthode : A revoir ?\n",
    "methode1 = {\"NOUN\", \"PROPN\", \"ADJ\",\"VERB\"}\n",
    "methode2 = {\"NOUN\", \"PROPN\", \"ADJ\"}\n",
    "nb_mots = {'meth1': 30, 'meth2':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKE : Analyse des termes principaux dans les textes et titres \n",
    "# Problème \n",
    "def transformation_pke_results(res1,res2, correct_ortho = False):\n",
    "    \"\"\"\n",
    "    Transformation des resultats de PKE : Pb bigramme peuvent ne pas être ds les 2 textes mais 1 mot seulement\n",
    "    liste de clés et dictionnaires de valeurs, bigrammes jouera ainsi de maniere coefficientée \n",
    "    Exemple : fuite eau:0.05 --> 3 mots au final : fuite, eau, fuite eau : 0.05\n",
    "    De plus on ajoute les synonymes issus de gensim en les coefficiant et vérifiant que cela \"\"\"\n",
    "    \n",
    "    liste1 = []; liste2 = [] ; dico1 = {}; dico2 = {}\n",
    "    for elt in res1:\n",
    "        liste1.append(elt[0])\n",
    "        dico1[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:    # bigramme dans ce cas, ajout des 2 mots\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste1.append(mot)\n",
    "                dico1[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste1.append(syn[0])   # Ajout du mot \n",
    "                        dico1[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "                    \n",
    "    for elt in res2:\n",
    "        liste2.append(elt[0])\n",
    "        dico2[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste2.append(mot)\n",
    "                dico2[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste2.append(syn[0])   # Ajout du mot \n",
    "                        dico2[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "    \n",
    "    # similarites entre les 2 listes issus de pke avec poids\n",
    "    sim = 0\n",
    "    for elt in liste1:\n",
    "        if elt in liste2:\n",
    "            sim += (dico1[elt] + dico2[elt])/2\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entites_communes(nlp,text1,text2):\n",
    "    \"\"\"\"\n",
    "    Cette première fonction ne regarde que les entités communes : personnes, dates, groupe, localisations\n",
    "    Elle sera appliquée aux textes et aux titres et cumulé : si cumul en titre et texte : compte double !\"\"\"\n",
    "    \n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    nb_commun_ent = 0; liste_commun_ent = []\n",
    "    nb_commun_geo = 0; liste_commun_geo = []\n",
    "    nb_commun_dat = 0; liste_commun_dat = []\n",
    "    \n",
    "    if len(doc1.ents)>0 and len(doc2.ents)>0:\n",
    "        liste1 = []; dico1 = {}\n",
    "        for elt in doc1.ents:\n",
    "            if elt.label_ == 'PERSON' and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste1:\n",
    "                        liste1.append(mot)\n",
    "                        dico1[mot] = elt.label_\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste1:\n",
    "                    liste1.append(elt.text)\n",
    "                    dico1[elt.text] = elt.label_\n",
    "        liste2 = []\n",
    "        for elt in doc2.ents:\n",
    "            if elt.label_ == 'PERSON' and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste2:\n",
    "                        liste2.append(mot)\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste2:\n",
    "                    liste2.append(elt.text)\n",
    "        \n",
    "        # points communs des listes        \n",
    "        for elt in liste1:\n",
    "            if elt in liste2:\n",
    "                if dico1[elt] == 'LOC':\n",
    "                    nb_commun_geo += 1\n",
    "                    liste_commun_geo.append(elt)\n",
    "                elif dico1[elt] in ['DATE','TIME']:\n",
    "                    nb_commun_dat += 1\n",
    "                    liste_commun_dat.append(elt)\n",
    "                else:\n",
    "                    nb_commun_ent += 1\n",
    "                    liste_commun_ent.append(elt)\n",
    "                    \n",
    "    return nb_commun_ent, liste_commun_ent,nb_commun_geo, liste_commun_geo,nb_commun_dat, liste_commun_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Creation_features_comparaison(df,langue, test_position = [methode1,methode2]):\n",
    "    \"\"\"Création des notes pour classification ensuite\"\"\"\n",
    "    \n",
    "    resultats = pd.DataFrame(columns = ['summary1_text1','summary2_text1','summary1_text2','summary2_text2',\n",
    "            'nb_entites_idem','nb_lieux_idem', 'nb_dates_idem','entites_idem','lieux_idem','dates_idem',\n",
    "            'score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "            'score_sentiment1','score_sentiment2','meth1_similarites','meth2_similarites'])\n",
    "    \n",
    "    # initialisation de la langue stanza\n",
    "    stanza.download(langue)\n",
    "    nlp_stanza = spacy_stanza.load_pipeline(langue)\n",
    "    stopmts = stopwds_lg[langue]\n",
    "    if langue in dico_spacy.keys():\n",
    "        nlp_spacy = dico_spacy[langue]\n",
    "    else:\n",
    "        nlp_spacy = None\n",
    "        \n",
    "    for i in tqdm(range(len(df))):\n",
    "        dico_res = {}\n",
    "        \n",
    "        # Summary et comparatifs \n",
    "        dico_res['summary1_text1'],dico_res['summary2_text1'] = summarization(df.text_1[i])\n",
    "        dico_res['summary1_text2'],dico_res['summary2_text2'] = summarization(df.text_2[i])\n",
    "        dico_res['score_similarite_titres'] = score_similarite([df.title_1[i]],[df.title_2[i]])\n",
    "        dico_res['score_similarite_resume1'] = score_similarite([dico_res['summary1_text1']],[dico_res['summary1_text2']])\n",
    "        dico_res['score_similarite_resume2'] = score_similarite([dico_res['summary2_text1']],[dico_res['summary2_text2']])\n",
    "        \n",
    "        # analyse de textes classification et de sentiments\n",
    "        texte1 = df.title_1[i] + ' ' + df.text_1[i]\n",
    "        texte2 = df.title_2[i] + ' ' + df.text_2[i]\n",
    "        if len(texte1)>0 and len(texte2)>0:\n",
    "            for classifier in dico_classifiers.keys():\n",
    "                scores1 = classification(texte1,'text_clf1')\n",
    "                scores2 = classification(texte2,'text_clf1')\n",
    "                if scores1 != 'error' and scores2 != 'error':\n",
    "                    dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(liste_categories, scores1,scores2)\n",
    "                else:\n",
    "                    scores1 = classification(df.title_1[i],'text_clf1')\n",
    "                    scores2 = classification(df.title_2[i],'text_clf1')\n",
    "                    if scores1 != 'error' and scores2 != 'error':\n",
    "                        dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                    else:\n",
    "                        dico_res[dico_classifiers[classifier]] = None\n",
    "                \n",
    "        # pré traitement des textes pour entités et PKE\n",
    "        texte1 = modif(texte1, stopmts)\n",
    "        texte2 = modif(texte2, stopmts)\n",
    "        \n",
    "        # ENTITES COMMUNES : on tient compte des bigrammes Noms qui posent erreurs ex: Joe Biden et Biden \n",
    "        # Ici, on considère mieux le CUMUl titres et Textes avec une pondération double pour le titre \n",
    "        # Il faut aussi enlever les petits mots donc pré-traitement en texte\n",
    "        \n",
    "        nb_ent1,list_ent1,nb_geo1,list_geo1,nb_dat1,list_dat1 = entites_communes(nlp_stanza,df.title_1[i],df.title_2[i])\n",
    "        nb_ent2,list_ent2,nb_geo2,list_geo2,nb_dat2,list_dat2 = entites_communes(nlp_stanza,df.text_1[i],df.text_2[i])\n",
    "        if nlp_spacy != None:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = entites_communes(nlp_spacy,df.title_1[i],df.title_2[i])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = entites_communes(nlp_spacy,df.text_1[i],df.text_2[i])\n",
    "        else:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = (0,[],0,[],0,[])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = (0,[],0,[],0,[])\n",
    "        dico_res['nb_entites_idem'] = nb_ent1 * 2 + nb_ent2 + nb_ent3 * 2 + nb_ent4\n",
    "        dico_res['nb_lieux_idem'] = nb_geo1  * 2 + nb_geo2 + nb_geo3  * 2 + nb_geo4\n",
    "        dico_res['nb_dates_idem'] = nb_dat1 * 2 + nb_dat2 + nb_dat3 * 2 + nb_dat4\n",
    "        # fusion des listes en supprimant les doublons\n",
    "        dico_res['entites_idem'] = list(set(list_ent1+list_ent2+ list_ent3+list_ent4))\n",
    "        dico_res['lieux_idem'] = list(set(list_geo1+list_geo2+list_geo3+list_geo4))\n",
    "        dico_res['dates_idem'] = list(set(list_dat1+list_dat2+list_dat3+list_dat4))\n",
    "        \n",
    "        for j,meth in enumerate(test_position):\n",
    "            nom ='meth'+str(j+1)\n",
    "            nb_mots_meth = nb_mots[nom]\n",
    "            if len(texte1)>0 and len(texte2)>0:\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte1,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases3 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte2,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases4 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                dico_res[nom+'_similarites'] = round(100*transformation_pke_results(keyphrases3,keyphrases4),1)\n",
    "            else:\n",
    "                dico_res[nom+'_similarites'] = 'Error'\n",
    "\n",
    "        resultats.loc[len(resultats)] = dico_res\n",
    "        \n",
    "    newdf = pd.concat([df,resultats],axis=1)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7553d08abd7c4940a0c37ca131f161fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 17:33:43 INFO: Downloading default packages for language: de (German)...\n",
      "INFO:stanza:Downloading default packages for language: de (German)...\n",
      "2021-12-15 17:33:44 INFO: File exists: C:\\Users\\stg-sdu\\stanza_resources\\de\\default.zip.\n",
      "INFO:stanza:File exists: C:\\Users\\stg-sdu\\stanza_resources\\de\\default.zip.\n",
      "2021-12-15 17:33:47 INFO: Finished downloading models and saved to C:\\Users\\stg-sdu\\stanza_resources.\n",
      "INFO:stanza:Finished downloading models and saved to C:\\Users\\stg-sdu\\stanza_resources.\n",
      "2021-12-15 17:33:48 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "| sentiment | sb10k   |\n",
      "| ner       | conll03 |\n",
      "=======================\n",
      "\n",
      "INFO:stanza:Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "| sentiment | sb10k   |\n",
      "| ner       | conll03 |\n",
      "=======================\n",
      "\n",
      "2021-12-15 17:33:48 INFO: Use device: cpu\n",
      "INFO:stanza:Use device: cpu\n",
      "2021-12-15 17:33:48 INFO: Loading: tokenize\n",
      "INFO:stanza:Loading: tokenize\n",
      "2021-12-15 17:33:48 INFO: Loading: mwt\n",
      "INFO:stanza:Loading: mwt\n",
      "2021-12-15 17:33:48 INFO: Loading: pos\n",
      "INFO:stanza:Loading: pos\n",
      "2021-12-15 17:33:48 INFO: Loading: lemma\n",
      "INFO:stanza:Loading: lemma\n",
      "2021-12-15 17:33:48 INFO: Loading: depparse\n",
      "INFO:stanza:Loading: depparse\n",
      "2021-12-15 17:33:48 INFO: Loading: sentiment\n",
      "INFO:stanza:Loading: sentiment\n",
      "2021-12-15 17:33:49 INFO: Loading: ner\n",
      "INFO:stanza:Loading: ner\n",
      "2021-12-15 17:33:50 INFO: Done loading processors!\n",
      "INFO:stanza:Done loading processors!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b4105f70414d2092b1c52db9b5caa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 20, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 20, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 20, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 20, but you input_length is only 1. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "# Attention, problème de mémoire : faire par steps de 200\n",
    "similarites = Creation_features_comparaison(allemand[376:576].reset_index(drop=True),'de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "precedent = pd.read_csv('corpus_de_notes2.csv',index_col=0)\n",
    "similarites2 = pd.concat([precedent,similarites], axis=0)\n",
    "similarites2.to_csv('corpus_de_notes2.csv')\n",
    "similarites.to_csv('corpus_de_notes.csv')   # A ELIMINER SI CONCAT OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "allemand = pd.read_csv('corpus_de_notes2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>...</th>\n",
       "      <th>dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1591</td>\n",
       "      <td>Atomkraftwerk Philippsburg stillgelegt: KKP2 h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atomkraftwerk Philippsburg stillgelegt\\n\\nKKP2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>94.56</td>\n",
       "      <td>91.64</td>\n",
       "      <td>9.84</td>\n",
       "      <td>42.84</td>\n",
       "      <td>42.84</td>\n",
       "      <td>42.84</td>\n",
       "      <td>42.84</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Koalitionsverhandlungen in Wien zwischen ÖVP u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Die Koalitionsverhandlungen in Österreich zwis...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>95.46</td>\n",
       "      <td>97.04</td>\n",
       "      <td>93.48</td>\n",
       "      <td>22.86</td>\n",
       "      <td>22.86</td>\n",
       "      <td>22.86</td>\n",
       "      <td>22.86</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ligne                                            title_1  \\\n",
       "10   1591  Atomkraftwerk Philippsburg stillgelegt: KKP2 h...   \n",
       "90   1671                                                NaN   \n",
       "\n",
       "                                              title_2  \\\n",
       "10                                                NaN   \n",
       "90  Koalitionsverhandlungen in Wien zwischen ÖVP u...   \n",
       "\n",
       "                                               text_1  \\\n",
       "10  Atomkraftwerk Philippsburg stillgelegt\\n\\nKKP2...   \n",
       "90                                                NaN   \n",
       "\n",
       "                                               text_2  Geography  Entities  \\\n",
       "10                                                NaN        2.0  3.000000   \n",
       "90  Die Koalitionsverhandlungen in Österreich zwis...        1.0  1.333333   \n",
       "\n",
       "    Time  Narrative  Overall  ...  dates_idem  score_similarite_titres  \\\n",
       "10   1.0        4.0      3.0  ...          []                    94.56   \n",
       "90   1.0        1.0      1.0  ...          []                    95.46   \n",
       "\n",
       "   score_similarite_resume1 score_similarite_resume2 score_classif1  \\\n",
       "10                    91.64                     9.84          42.84   \n",
       "90                    97.04                    93.48          22.86   \n",
       "\n",
       "   score_classif2  score_sentiment1  score_sentiment2  meth1_similarites  \\\n",
       "10          42.84             42.84             42.84              Error   \n",
       "90          22.86             22.86             22.86              Error   \n",
       "\n",
       "   meth2_similarites  \n",
       "10             Error  \n",
       "90             Error  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention certains textes ne sont pas fournies et mis en \"Error\" : A supprimer donc\n",
    "allemand[allemand.meth1_similarites=='Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "allemand = allemand.round({'Geography':0, 'Entities':0,'Time':0, 'Narrative':0, 'Overall':0, 'Style':0, 'Tone':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "partiel = allemand[['Geography', 'Entities','Time', 'Narrative', 'Overall', 'Style', 'Tone']].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "allemand = pd.concat([allemand[['ligne', 'title_1', 'title_2', 'text_1', 'text_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2']],\n",
    "        partiel,allemand[['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "       'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "       'score_sentiment2', 'meth1_similarites', 'meth2_similarites']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>summary1_text1</th>\n",
       "      <th>summary2_text1</th>\n",
       "      <th>summary1_text2</th>\n",
       "      <th>summary2_text2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>...</th>\n",
       "      <th>dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1581</td>\n",
       "      <td>Dschungelcamp 2020: Marco Cerullo - Übernimmt ...</td>\n",
       "      <td>Dschungelcamp bei RTL: Ex-Minister Günther Kra...</td>\n",
       "      <td>Kürzlich war er noch bei „Bachelor in Paradise...</td>\n",
       "      <td>Ex-Bundesverkehrsminister Günther Krause, 66, ...</td>\n",
       "      <td>Dschungelcamp-Kandidat Marco Cerullo suchte in...</td>\n",
       "      <td>Dschungelcamp - Kandidat Marco Cerullo suchte ...</td>\n",
       "      <td>Der frühere Politiker Günther Krause hatte 199...</td>\n",
       "      <td>Ex - Bundesverkehrsminister Günther Krause, 66...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>94.74</td>\n",
       "      <td>97.80</td>\n",
       "      <td>86.47</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.27</td>\n",
       "      <td>58.5</td>\n",
       "      <td>40.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1582</td>\n",
       "      <td>Silberdistel Neutras ehrt Jahresmeister</td>\n",
       "      <td>Fröhliche Weise mit ernster Botschaft</td>\n",
       "      <td>Silberdistel Neutras ehrt Jahresmeister\\n\\nVon...</td>\n",
       "      <td>Fröhliche Weise mit ernster Botschaft\\n\\nMit s...</td>\n",
       "      <td>Die Jahresmeisterschaft entscheidet der Durchs...</td>\n",
       "      <td>Silberdistel Neutras ehrt Jahresmeister Von de...</td>\n",
       "      <td>Die deutsche Melodie Bob Geldofs steht in eine...</td>\n",
       "      <td>In der Weihnachtszeit ist die Zahl der Weihnac...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>84.74</td>\n",
       "      <td>90.23</td>\n",
       "      <td>67.07</td>\n",
       "      <td>96.21</td>\n",
       "      <td>96.21</td>\n",
       "      <td>96.21</td>\n",
       "      <td>96.21</td>\n",
       "      <td>23.8</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1583</td>\n",
       "      <td>Das grosse Rätsel um die Flucht des Autozaren</td>\n",
       "      <td>Überraschende Flucht aus Japan: Ex-Renault-Bos...</td>\n",
       "      <td>Tragen Sie mit Hinweisen zu diesem Artikel bei...</td>\n",
       "      <td>Der in Japan auf Kaution freigelassene frühere...</td>\n",
       "      <td>Sehr gut möglich, dass die Geschichte dieser F...</td>\n",
       "      <td>Der libanesischen Automanager Carlos Ghosn ist...</td>\n",
       "      <td>Der in Japan auf Kaution freigelassene frühere...</td>\n",
       "      <td>Er sei \" nicht länger eine Geisel des manipuli...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>78.85</td>\n",
       "      <td>95.10</td>\n",
       "      <td>85.10</td>\n",
       "      <td>11.07</td>\n",
       "      <td>11.07</td>\n",
       "      <td>11.07</td>\n",
       "      <td>11.07</td>\n",
       "      <td>151.5</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1584</td>\n",
       "      <td>Zum Jahresende legen die Velpker noch mal rich...</td>\n",
       "      <td>Léon Berben auf der Vater-Orgel : Ein Meisterk...</td>\n",
       "      <td>Das alte Jahr ausklingen lassen und das neue m...</td>\n",
       "      <td>Melle. Die Ev. luth. St. Petri-Kirchengemeinde...</td>\n",
       "      <td>Das alte Jahr ausklingen lassen und das neue m...</td>\n",
       "      <td>Das alte Jahr ausklingen lassen und das neue m...</td>\n",
       "      <td>Der deutsche Musiker Léon Berben feiert seine ...</td>\n",
       "      <td>Der Interpret genießt in der festlich erleucht...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>96.22</td>\n",
       "      <td>97.57</td>\n",
       "      <td>84.40</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1585</td>\n",
       "      <td>Neun Personen festgenommen: Viel Arbeit für di...</td>\n",
       "      <td>Polizei berichtet von ruhiger Silvesternacht</td>\n",
       "      <td>Neun Personen festgenommen: Viel Arbeit für di...</td>\n",
       "      <td>Lediglich zwei Verstöße gegen das Feuerwerksve...</td>\n",
       "      <td>Vor allem in der Stadt und Agglomeration war d...</td>\n",
       "      <td>Vor allem in der Stadt und Agglomeration war d...</td>\n",
       "      <td>Die Polizei hat zwei Verstöße gegen das Feuerw...</td>\n",
       "      <td>Der Inhalt ist älter als 30 Stunden und steht ...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>80.39</td>\n",
       "      <td>98.61</td>\n",
       "      <td>92.36</td>\n",
       "      <td>90.97</td>\n",
       "      <td>90.97</td>\n",
       "      <td>90.97</td>\n",
       "      <td>90.97</td>\n",
       "      <td>36.1</td>\n",
       "      <td>31.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1676</td>\n",
       "      <td>Fünf Verletzte und ein Brand</td>\n",
       "      <td>Brand in Silvesternacht: 40 Hausbewohner müsse...</td>\n",
       "      <td>Bitte melden Sie sich an!\\n\\nSie haben noch ke...</td>\n",
       "      <td>Der zuständigen Einsatzzentrale wurde der Bran...</td>\n",
       "      <td>Bitte melden Sie sich an! Sie haben noch keine...</td>\n",
       "      <td>Bitte melden Sie sich an! Sie haben noch keine...</td>\n",
       "      <td>Die Polizei hat die Ermittlungen übernommen un...</td>\n",
       "      <td>Der Brand in der Ritter - von - Hellberg - Str...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>85.23</td>\n",
       "      <td>69.50</td>\n",
       "      <td>69.43</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>68.3</td>\n",
       "      <td>60.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1677</td>\n",
       "      <td>Mindestens 16 Tote bei Kämpfen in mexikanische...</td>\n",
       "      <td>16 Tote bei Massenschlägerei in mexikanischem ...</td>\n",
       "      <td>Wie lange ist die frist bei einer Kündigung?\\n...</td>\n",
       "      <td>Mindestens 16 Menschen sind kurz vor dem Jahre...</td>\n",
       "      <td>Wie lange ist die frist bei einer Kündigung? H...</td>\n",
       "      <td>Wie lange ist die frist bei einer Kündigung? H...</td>\n",
       "      <td>Mindestens 16 Menschen sind kurz vor dem Jahre...</td>\n",
       "      <td>Die Sicherheitskräfte stellten Waffen sicher -...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>97.85</td>\n",
       "      <td>96.70</td>\n",
       "      <td>59.74</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>146.7</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1678</td>\n",
       "      <td>Der neue Soccerpark The Bolz im Test: Spielspa...</td>\n",
       "      <td>Frohes Neues! Das sind die Bilder vom Feuerwer...</td>\n",
       "      <td>Hannover hat einen neuen Soccerpark: The Bolz ...</td>\n",
       "      <td>In der Region Hannover haben die Bürger das ne...</td>\n",
       "      <td>Hannover hat einen neuen Soccerpark: The Bolz ...</td>\n",
       "      <td>Die HAZ hat die Fußballkäfige ausprobiert und ...</td>\n",
       "      <td>In Hannover haben die Bürger das neue Jahr mit...</td>\n",
       "      <td>In der Region Hannover haben die Bürger das ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>66.62</td>\n",
       "      <td>96.05</td>\n",
       "      <td>65.97</td>\n",
       "      <td>90.60</td>\n",
       "      <td>90.60</td>\n",
       "      <td>90.60</td>\n",
       "      <td>90.60</td>\n",
       "      <td>0</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1679</td>\n",
       "      <td>Dschungelcamp 2020: Anastasiya Avilova kommt v...</td>\n",
       "      <td>Dschungelcamp 2020: Das sind die Kandidaten</td>\n",
       "      <td>Anastasiya Avilova zieht im Januar 2020 als Ka...</td>\n",
       "      <td>Die Kandidaten für die 14. Staffel \"Ich bin ei...</td>\n",
       "      <td>Anastasiya Avilova (31) ist laut Bild-Zeitung ...</td>\n",
       "      <td>Anastasiya Avilova zieht im Januar 2020 als Ka...</td>\n",
       "      <td>Die Kandidaten für die 14. Staffel \"Ich bin ei...</td>\n",
       "      <td>Die Kandidaten für die 14. Staffel \" Ich bin e...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>96.37</td>\n",
       "      <td>94.95</td>\n",
       "      <td>71.50</td>\n",
       "      <td>53.40</td>\n",
       "      <td>53.40</td>\n",
       "      <td>53.40</td>\n",
       "      <td>53.40</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1680</td>\n",
       "      <td>Jahresausblick mit Astrologin Monica Kissling:...</td>\n",
       "      <td>Ein Lichtblick zu Jahresbeginn</td>\n",
       "      <td>Video Jahresausblick mit Astrologin Monica Kis...</td>\n",
       "      <td>US-Präsident Donald Trump (im Bild links mit C...</td>\n",
       "      <td>Monica Kissling alias \"Madame Etoile\" hat in d...</td>\n",
       "      <td>Monica Kissling alias Madame Etoile hat in die...</td>\n",
       "      <td>Der US-Präsident lässt am Silvestertag verlaut...</td>\n",
       "      <td>Der US - Präsident will in den USA den ersten ...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>85.77</td>\n",
       "      <td>83.04</td>\n",
       "      <td>71.56</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ligne                                            title_1  \\\n",
       "0    1581  Dschungelcamp 2020: Marco Cerullo - Übernimmt ...   \n",
       "1    1582            Silberdistel Neutras ehrt Jahresmeister   \n",
       "2    1583      Das grosse Rätsel um die Flucht des Autozaren   \n",
       "3    1584  Zum Jahresende legen die Velpker noch mal rich...   \n",
       "4    1585  Neun Personen festgenommen: Viel Arbeit für di...   \n",
       "..    ...                                                ...   \n",
       "95   1676                       Fünf Verletzte und ein Brand   \n",
       "96   1677  Mindestens 16 Tote bei Kämpfen in mexikanische...   \n",
       "97   1678  Der neue Soccerpark The Bolz im Test: Spielspa...   \n",
       "98   1679  Dschungelcamp 2020: Anastasiya Avilova kommt v...   \n",
       "99   1680  Jahresausblick mit Astrologin Monica Kissling:...   \n",
       "\n",
       "                                              title_2  \\\n",
       "0   Dschungelcamp bei RTL: Ex-Minister Günther Kra...   \n",
       "1               Fröhliche Weise mit ernster Botschaft   \n",
       "2   Überraschende Flucht aus Japan: Ex-Renault-Bos...   \n",
       "3   Léon Berben auf der Vater-Orgel : Ein Meisterk...   \n",
       "4        Polizei berichtet von ruhiger Silvesternacht   \n",
       "..                                                ...   \n",
       "95  Brand in Silvesternacht: 40 Hausbewohner müsse...   \n",
       "96  16 Tote bei Massenschlägerei in mexikanischem ...   \n",
       "97  Frohes Neues! Das sind die Bilder vom Feuerwer...   \n",
       "98        Dschungelcamp 2020: Das sind die Kandidaten   \n",
       "99                     Ein Lichtblick zu Jahresbeginn   \n",
       "\n",
       "                                               text_1  \\\n",
       "0   Kürzlich war er noch bei „Bachelor in Paradise...   \n",
       "1   Silberdistel Neutras ehrt Jahresmeister\\n\\nVon...   \n",
       "2   Tragen Sie mit Hinweisen zu diesem Artikel bei...   \n",
       "3   Das alte Jahr ausklingen lassen und das neue m...   \n",
       "4   Neun Personen festgenommen: Viel Arbeit für di...   \n",
       "..                                                ...   \n",
       "95  Bitte melden Sie sich an!\\n\\nSie haben noch ke...   \n",
       "96  Wie lange ist die frist bei einer Kündigung?\\n...   \n",
       "97  Hannover hat einen neuen Soccerpark: The Bolz ...   \n",
       "98  Anastasiya Avilova zieht im Januar 2020 als Ka...   \n",
       "99  Video Jahresausblick mit Astrologin Monica Kis...   \n",
       "\n",
       "                                               text_2  \\\n",
       "0   Ex-Bundesverkehrsminister Günther Krause, 66, ...   \n",
       "1   Fröhliche Weise mit ernster Botschaft\\n\\nMit s...   \n",
       "2   Der in Japan auf Kaution freigelassene frühere...   \n",
       "3   Melle. Die Ev. luth. St. Petri-Kirchengemeinde...   \n",
       "4   Lediglich zwei Verstöße gegen das Feuerwerksve...   \n",
       "..                                                ...   \n",
       "95  Der zuständigen Einsatzzentrale wurde der Bran...   \n",
       "96  Mindestens 16 Menschen sind kurz vor dem Jahre...   \n",
       "97  In der Region Hannover haben die Bürger das ne...   \n",
       "98  Die Kandidaten für die 14. Staffel \"Ich bin ei...   \n",
       "99  US-Präsident Donald Trump (im Bild links mit C...   \n",
       "\n",
       "                                       summary1_text1  \\\n",
       "0   Dschungelcamp-Kandidat Marco Cerullo suchte in...   \n",
       "1   Die Jahresmeisterschaft entscheidet der Durchs...   \n",
       "2   Sehr gut möglich, dass die Geschichte dieser F...   \n",
       "3   Das alte Jahr ausklingen lassen und das neue m...   \n",
       "4   Vor allem in der Stadt und Agglomeration war d...   \n",
       "..                                                ...   \n",
       "95  Bitte melden Sie sich an! Sie haben noch keine...   \n",
       "96  Wie lange ist die frist bei einer Kündigung? H...   \n",
       "97  Hannover hat einen neuen Soccerpark: The Bolz ...   \n",
       "98  Anastasiya Avilova (31) ist laut Bild-Zeitung ...   \n",
       "99  Monica Kissling alias \"Madame Etoile\" hat in d...   \n",
       "\n",
       "                                       summary2_text1  \\\n",
       "0   Dschungelcamp - Kandidat Marco Cerullo suchte ...   \n",
       "1   Silberdistel Neutras ehrt Jahresmeister Von de...   \n",
       "2   Der libanesischen Automanager Carlos Ghosn ist...   \n",
       "3   Das alte Jahr ausklingen lassen und das neue m...   \n",
       "4   Vor allem in der Stadt und Agglomeration war d...   \n",
       "..                                                ...   \n",
       "95  Bitte melden Sie sich an! Sie haben noch keine...   \n",
       "96  Wie lange ist die frist bei einer Kündigung? H...   \n",
       "97  Die HAZ hat die Fußballkäfige ausprobiert und ...   \n",
       "98  Anastasiya Avilova zieht im Januar 2020 als Ka...   \n",
       "99  Monica Kissling alias Madame Etoile hat in die...   \n",
       "\n",
       "                                       summary1_text2  \\\n",
       "0   Der frühere Politiker Günther Krause hatte 199...   \n",
       "1   Die deutsche Melodie Bob Geldofs steht in eine...   \n",
       "2   Der in Japan auf Kaution freigelassene frühere...   \n",
       "3   Der deutsche Musiker Léon Berben feiert seine ...   \n",
       "4   Die Polizei hat zwei Verstöße gegen das Feuerw...   \n",
       "..                                                ...   \n",
       "95  Die Polizei hat die Ermittlungen übernommen un...   \n",
       "96  Mindestens 16 Menschen sind kurz vor dem Jahre...   \n",
       "97  In Hannover haben die Bürger das neue Jahr mit...   \n",
       "98  Die Kandidaten für die 14. Staffel \"Ich bin ei...   \n",
       "99  Der US-Präsident lässt am Silvestertag verlaut...   \n",
       "\n",
       "                                       summary2_text2  Geography  ...  \\\n",
       "0   Ex - Bundesverkehrsminister Günther Krause, 66...          2  ...   \n",
       "1   In der Weihnachtszeit ist die Zahl der Weihnac...          2  ...   \n",
       "2   Er sei \" nicht länger eine Geisel des manipuli...          1  ...   \n",
       "3   Der Interpret genießt in der festlich erleucht...          3  ...   \n",
       "4   Der Inhalt ist älter als 30 Stunden und steht ...          4  ...   \n",
       "..                                                ...        ...  ...   \n",
       "95  Der Brand in der Ritter - von - Hellberg - Str...          3  ...   \n",
       "96  Die Sicherheitskräfte stellten Waffen sicher -...          1  ...   \n",
       "97  In der Region Hannover haben die Bürger das ne...          1  ...   \n",
       "98  Die Kandidaten für die 14. Staffel \" Ich bin e...          1  ...   \n",
       "99  Der US - Präsident will in den USA den ersten ...          4  ...   \n",
       "\n",
       "    dates_idem  score_similarite_titres  score_similarite_resume1  \\\n",
       "0           []                    94.74                     97.80   \n",
       "1           []                    84.74                     90.23   \n",
       "2           []                    78.85                     95.10   \n",
       "3           []                    96.22                     97.57   \n",
       "4           []                    80.39                     98.61   \n",
       "..         ...                      ...                       ...   \n",
       "95          []                    85.23                     69.50   \n",
       "96          []                    97.85                     96.70   \n",
       "97          []                    66.62                     96.05   \n",
       "98          []                    96.37                     94.95   \n",
       "99          []                    85.77                     83.04   \n",
       "\n",
       "    score_similarite_resume2  score_classif1  score_classif2  \\\n",
       "0                      86.47           20.27           20.27   \n",
       "1                      67.07           96.21           96.21   \n",
       "2                      85.10           11.07           11.07   \n",
       "3                      84.40           16.50           16.50   \n",
       "4                      92.36           90.97           90.97   \n",
       "..                       ...             ...             ...   \n",
       "95                     69.43            4.50            4.50   \n",
       "96                     59.74            0.17            0.17   \n",
       "97                     65.97           90.60           90.60   \n",
       "98                     71.50           53.40           53.40   \n",
       "99                     71.56            0.16            0.16   \n",
       "\n",
       "    score_sentiment1  score_sentiment2  meth1_similarites meth2_similarites  \n",
       "0              20.27             20.27               58.5              40.7  \n",
       "1              96.21             96.21               23.8               6.9  \n",
       "2              11.07             11.07              151.5             173.0  \n",
       "3              16.50             16.50                0.0             137.4  \n",
       "4              90.97             90.97               36.1              31.7  \n",
       "..               ...               ...                ...               ...  \n",
       "95              4.50              4.50               68.3              60.2  \n",
       "96              0.17              0.17              146.7              64.0  \n",
       "97             90.60             90.60                  0              27.8  \n",
       "98             53.40             53.40               46.0              62.6  \n",
       "99              0.16              0.16                  0              10.7  \n",
       "\n",
       "[100 rows x 30 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allemand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteurs1 = ['score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "            'score_sentiment1','score_sentiment2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:PyCaret Supervised Module\n",
      "INFO:logs:ML Usecase: classification\n",
      "INFO:logs:version 2.2.2\n",
      "INFO:logs:Initializing setup()\n",
      "INFO:logs:setup(target=Overall, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=False, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=False, profile=False, profile_kwargs=None, display=None)\n",
      "INFO:logs:Checking environment\n",
      "INFO:logs:python_version: 3.8.12\n",
      "INFO:logs:python_build: ('default', 'Oct 12 2021 03:01:40')\n",
      "INFO:logs:machine: AMD64\n",
      "INFO:logs:platform: Windows-10-10.0.19041-SP0\n",
      "INFO:logs:Memory: svmem(total=34157522944, available=13156388864, percent=61.5, used=21001134080, free=13156388864)\n",
      "INFO:logs:Physical Core: 6\n",
      "INFO:logs:Logical Core: 12\n",
      "INFO:logs:Checking libraries\n",
      "INFO:logs:pd==1.0.5\n",
      "INFO:logs:numpy==1.21.4\n",
      "INFO:logs:sklearn==0.23.2\n",
      "INFO:logs:xgboost==1.2.1\n",
      "INFO:logs:lightgbm==3.1.0\n",
      "INFO:logs:catboost==0.24.3\n",
      "INFO:logs:mlflow==1.12.1\n",
      "INFO:logs:Checking Exceptions\n",
      "INFO:logs:Declaring global variables\n",
      "INFO:logs:USI: 4181\n",
      "INFO:logs:pycaret_globals: {'fix_imbalance_method_param', 'html_param', '_ml_usecase', 'fold_param', 'master_model_container', 'log_plots_param', 'fold_groups_param', '_all_models_internal', 'iterative_imputation_iters_param', '_available_plots', 'USI', 'logging_param', 'fold_shuffle_param', '_all_models', 'y', 'fix_imbalance_param', 'pycaret_globals', 'transform_target_method_param', 'stratify_param', 'fold_generator', 'X_test', 'exp_name_log', 'experiment__', 'data_before_preprocess', 'X', '_internal_pipeline', 'n_jobs_param', '_all_metrics', 'imputation_classifier', 'display_container', 'target_param', 'prep_pipe', '_gpu_n_jobs_param', 'transform_target_param', 'X_train', 'y_train', 'create_model_container', 'seed', 'imputation_regressor', 'y_test', 'gpu_param'}\n",
      "INFO:logs:Preparing display monitor\n",
      "INFO:logs:Importing libraries\n",
      "INFO:logs:Copying data for preprocessing\n",
      "INFO:logs:Declaring preprocessing parameters\n",
      "INFO:logs:Creating preprocessing pipeline\n",
      "INFO:logs:Preprocessing pipeline created successfully\n",
      "ERROR:logs:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.\n",
      "INFO:logs:Creating global containers\n",
      "INFO:logs:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)\n",
      "INFO:logs:Creating grid variables\n",
      "INFO:logs:create_model_container: 0\n",
      "INFO:logs:master_model_container: 0\n",
      "INFO:logs:display_container: 0\n",
      "INFO:logs:Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=[],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=[], target='Overall',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_available',\n",
      "                                fill_value_categorical=None,\n",
      "                                fill_value_numerical=None,\n",
      "                                numeric_str...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='Overall')),\n",
      "                ('fix_perfect', Remove_100(target='Overall')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False)\n",
      "INFO:logs:setup() succesfully completed......................................\n"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "german_classif = setup(data = allemand[predicteurs1 + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:Initializing create_model()\n",
      "INFO:logs:create_model(estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, display=None, kwargs={})\n",
      "INFO:logs:Checking exceptions\n",
      "INFO:logs:Preparing display monitor\n",
      "INFO:logs:Importing libraries\n",
      "INFO:logs:Copying training dataset\n",
      "INFO:logs:Defining folds\n",
      "INFO:logs:Declaring metric variables\n",
      "INFO:logs:Importing untrained model\n",
      "INFO:logs:Logistic Regression Imported succesfully\n",
      "INFO:logs:Starting cross validation\n",
      "INFO:logs:Cross validating with StratifiedKFold(n_splits=10, random_state=6619, shuffle=False), n_jobs=-1\n",
      "INFO:logs:Calculating mean and std\n",
      "INFO:logs:Creating metrics dataframe\n",
      "INFO:logs:Finalizing model\n",
      "INFO:logs:Uploading results into container\n",
      "INFO:logs:Uploading model into container now\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.7238</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.2429</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.5905</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.3878</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>-0.3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.2364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4286  0.7238  0.2500  0.1837  0.2571  0.0000  0.0000\n",
       "1       0.4286  0.5405  0.2917  0.4286  0.4286  0.1765  0.1765\n",
       "2       0.4286  0.3310  0.4167  0.2429  0.3095  0.1250  0.1534\n",
       "3       0.4286  0.5905  0.2500  0.2571  0.3214  0.0968  0.1097\n",
       "4       0.0000  0.5690  0.0000  0.0000  0.0000 -0.4000 -0.4384\n",
       "5       0.4286  0.7952  0.2500  0.2143  0.2857  0.0345  0.0495\n",
       "6       0.4286  0.7738  0.2917  0.3571  0.3878  0.1250  0.1296\n",
       "7       0.2857  0.5286  0.2500  0.1143  0.1633  0.0000  0.0000\n",
       "8       0.5714  0.6429  0.5000  0.4286  0.4762  0.4000  0.4410\n",
       "9       0.1667  0.4250  0.1250  0.0667  0.0952 -0.2000 -0.3101\n",
       "Mean    0.3595  0.5920  0.2625  0.2293  0.2725  0.0358  0.0311\n",
       "SD      0.1567  0.1406  0.1305  0.1383  0.1417  0.2050  0.2364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:create_model_container: 1\n",
      "INFO:logs:master_model_container: 1\n",
      "INFO:logs:display_container: 1\n",
      "INFO:logs:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=6619, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "INFO:logs:create_model() succesfully completed......................................\n",
      "INFO:logs:Initializing create_model()\n",
      "INFO:logs:create_model(estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, display=None, kwargs={})\n",
      "INFO:logs:Checking exceptions\n",
      "INFO:logs:Preparing display monitor\n",
      "INFO:logs:Importing libraries\n",
      "INFO:logs:Copying training dataset\n",
      "INFO:logs:Defining folds\n",
      "INFO:logs:Declaring metric variables\n",
      "INFO:logs:Importing untrained model\n",
      "INFO:logs:Random Forest Classifier Imported succesfully\n",
      "INFO:logs:Starting cross validation\n",
      "INFO:logs:Cross validating with StratifiedKFold(n_splits=10, random_state=6619, shuffle=False), n_jobs=-1\n",
      "INFO:logs:Calculating mean and std\n",
      "INFO:logs:Creating metrics dataframe\n",
      "INFO:logs:Finalizing model\n",
      "INFO:logs:Uploading results into container\n",
      "INFO:logs:Uploading model into container now\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.6216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.5476</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2653</td>\n",
       "      <td>-0.0606</td>\n",
       "      <td>-0.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4095</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2895</td>\n",
       "      <td>-0.3335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>-0.1290</td>\n",
       "      <td>-0.1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.5762</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.4706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>-0.1667</td>\n",
       "      <td>-0.1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3476</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.0915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.2959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.7143  0.6190  0.6250  0.6857  0.6548  0.5484  0.6216\n",
       "1       0.2857  0.5476  0.2083  0.3571  0.3143  0.0278  0.0286\n",
       "2       0.2857  0.4000  0.3333  0.2500  0.2653 -0.0606 -0.0626\n",
       "3       0.0000  0.4095  0.0000  0.0000  0.0000 -0.2895 -0.3335\n",
       "4       0.2857  0.6071  0.1667  0.1714  0.2143 -0.1290 -0.1463\n",
       "5       0.5714  0.7857  0.7083  0.6905  0.5762  0.4324  0.4706\n",
       "6       0.1429  0.5274  0.1250  0.1429  0.1429 -0.1667 -0.1715\n",
       "7       0.2857  0.7000  0.2500  0.1143  0.1633  0.0278  0.0355\n",
       "8       0.5714  0.9000  0.5000  0.5714  0.5333  0.4000  0.4260\n",
       "9       0.3333  0.6333  0.2500  0.4167  0.3333  0.0400  0.0462\n",
       "Mean    0.3476  0.6130  0.3167  0.3400  0.3198  0.0831  0.0915\n",
       "SD      0.2032  0.1479  0.2151  0.2332  0.1990  0.2672  0.2959"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:create_model_container: 2\n",
      "INFO:logs:master_model_container: 2\n",
      "INFO:logs:display_container: 2\n",
      "INFO:logs:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=6619, verbose=0,\n",
      "                       warm_start=False)\n",
      "INFO:logs:create_model() succesfully completed......................................\n",
      "INFO:logs:Initializing create_model()\n",
      "INFO:logs:create_model(estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, display=None, kwargs={})\n",
      "INFO:logs:Checking exceptions\n",
      "INFO:logs:Preparing display monitor\n",
      "INFO:logs:Importing libraries\n",
      "INFO:logs:Copying training dataset\n",
      "INFO:logs:Defining folds\n",
      "INFO:logs:Declaring metric variables\n",
      "INFO:logs:Importing untrained model\n",
      "INFO:logs:Extreme Gradient Boosting Imported succesfully\n",
      "INFO:logs:Starting cross validation\n",
      "INFO:logs:Cross validating with StratifiedKFold(n_splits=10, random_state=6619, shuffle=False), n_jobs=-1\n",
      "INFO:logs:Calculating mean and std\n",
      "INFO:logs:Creating metrics dataframe\n",
      "INFO:logs:Finalizing model\n",
      "INFO:logs:Uploading results into container\n",
      "INFO:logs:Uploading model into container now\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.3961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>-0.1351</td>\n",
       "      <td>-0.1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.5143</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2653</td>\n",
       "      <td>-0.0606</td>\n",
       "      <td>-0.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>-0.2727</td>\n",
       "      <td>-0.2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.0588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.6216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>-0.1667</td>\n",
       "      <td>-0.1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>-0.1667</td>\n",
       "      <td>-0.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.7048</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.6288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>0.3203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.5630</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.3463</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.1164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2269</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.3294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.5714  0.6190  0.3750  0.5000  0.4762  0.2759  0.3961\n",
       "1       0.1429  0.4857  0.1250  0.0952  0.1143 -0.1351 -0.1471\n",
       "2       0.2857  0.5143  0.3333  0.2500  0.2653 -0.0606 -0.0626\n",
       "3       0.1429  0.3167  0.0833  0.1071  0.1224 -0.2727 -0.2917\n",
       "4       0.2857  0.4500  0.3750  0.2381  0.2571  0.0541  0.0588\n",
       "5       0.7143  0.8500  0.6250  0.6857  0.6548  0.5484  0.6216\n",
       "6       0.1429  0.4310  0.1250  0.1429  0.1429 -0.1667 -0.1715\n",
       "7       0.1429  0.6190  0.1250  0.0714  0.0952 -0.1667 -0.1890\n",
       "8       0.7143  0.8857  0.7500  0.7619  0.7048  0.6111  0.6288\n",
       "9       0.5000  0.4583  0.5000  0.6111  0.5222  0.3077  0.3203\n",
       "Mean    0.3643  0.5630  0.3417  0.3463  0.3355  0.0995  0.1164\n",
       "SD      0.2269  0.1741  0.2195  0.2529  0.2221  0.3001  0.3294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:create_model_container: 3\n",
      "INFO:logs:master_model_container: 3\n",
      "INFO:logs:display_container: 3\n",
      "INFO:logs:XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=6619, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "INFO:logs:create_model() succesfully completed......................................\n"
     ]
    }
   ],
   "source": [
    "lr = create_model('lr')\n",
    "rf = create_model('rf')\n",
    "xgb = create_model('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai_classif = allemand[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites','meth2_similarites']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography                     int32\n",
       "Entities                      int32\n",
       "Time                          int32\n",
       "Narrative                     int32\n",
       "Overall                       int32\n",
       "Style                         int32\n",
       "Tone                          int32\n",
       "nb_entites_idem               int64\n",
       "nb_lieux_idem                 int64\n",
       "nb_dates_idem                 int64\n",
       "score_similarite_titres     float64\n",
       "score_similarite_resume1    float64\n",
       "score_similarite_resume2    float64\n",
       "score_classif1              float64\n",
       "score_classif2              float64\n",
       "score_sentiment1            float64\n",
       "score_sentiment2            float64\n",
       "meth1_similarites           float64\n",
       "meth2_similarites           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si on veut utiliser faire un classemen,t supprimer ligne error puis changer les types pour meth1 meth2\n",
    "essai_classif = essai_classif[essai_classif.meth1_similarites != 'Error']\n",
    "essai_classif['meth1_similarites'] = essai_classif['meth1_similarites'].astype('float')\n",
    "essai_classif['meth2_similarites'] = essai_classif['meth2_similarites'].astype('float')\n",
    "essai_classif.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteurs = ['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1',\n",
    "    'score_similarite_resume2', 'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites',\n",
    "    'meth2_similarites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:PyCaret Supervised Module\n",
      "INFO:logs:ML Usecase: classification\n",
      "INFO:logs:version 2.2.2\n",
      "INFO:logs:Initializing setup()\n",
      "INFO:logs:setup(target=Overall, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=False, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=False, profile=False, profile_kwargs=None, display=None)\n",
      "INFO:logs:Checking environment\n",
      "INFO:logs:python_version: 3.8.12\n",
      "INFO:logs:python_build: ('default', 'Oct 12 2021 03:01:40')\n",
      "INFO:logs:machine: AMD64\n",
      "INFO:logs:platform: Windows-10-10.0.19041-SP0\n",
      "INFO:logs:Memory: svmem(total=34157522944, available=10049892352, percent=70.6, used=24107630592, free=10049892352)\n",
      "INFO:logs:Physical Core: 6\n",
      "INFO:logs:Logical Core: 12\n",
      "INFO:logs:Checking libraries\n",
      "INFO:logs:pd==1.0.5\n",
      "INFO:logs:numpy==1.21.4\n",
      "INFO:logs:sklearn==0.23.2\n",
      "INFO:logs:xgboost==1.2.1\n",
      "INFO:logs:lightgbm==3.1.0\n",
      "INFO:logs:catboost==0.24.3\n",
      "INFO:logs:mlflow==1.12.1\n",
      "INFO:logs:Checking Exceptions\n",
      "INFO:logs:Declaring global variables\n",
      "INFO:logs:USI: 049b\n",
      "INFO:logs:pycaret_globals: {'fix_imbalance_method_param', 'html_param', '_ml_usecase', 'fold_param', 'master_model_container', 'log_plots_param', 'fold_groups_param', '_all_models_internal', 'iterative_imputation_iters_param', '_available_plots', 'USI', 'logging_param', 'fold_shuffle_param', '_all_models', 'y', 'fix_imbalance_param', 'pycaret_globals', 'transform_target_method_param', 'stratify_param', 'fold_generator', 'X_test', 'exp_name_log', 'experiment__', 'data_before_preprocess', 'X', '_internal_pipeline', 'n_jobs_param', '_all_metrics', 'imputation_classifier', 'display_container', 'target_param', 'prep_pipe', '_gpu_n_jobs_param', 'transform_target_param', 'X_train', 'y_train', 'create_model_container', 'seed', 'imputation_regressor', 'y_test', 'gpu_param'}\n",
      "INFO:logs:Preparing display monitor\n",
      "INFO:logs:Importing libraries\n",
      "INFO:logs:Copying data for preprocessing\n",
      "INFO:logs:Declaring preprocessing parameters\n",
      "INFO:logs:Creating preprocessing pipeline\n",
      "INFO:logs:Preprocessing pipeline created successfully\n",
      "ERROR:logs:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.\n",
      "INFO:logs:Creating global containers\n",
      "INFO:logs:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)\n",
      "INFO:logs:Creating grid variables\n",
      "INFO:logs:create_model_container: 0\n",
      "INFO:logs:master_model_container: 0\n",
      "INFO:logs:display_container: 0\n",
      "INFO:logs:Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=[],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=[], target='Overall',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_available',\n",
      "                                fill_value_categorical=None,\n",
      "                                fill_value_numerical=None,\n",
      "                                numeric_str...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='Overall')),\n",
      "                ('fix_perfect', Remove_100(target='Overall')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False)\n",
      "INFO:logs:setup() succesfully completed......................................\n",
      "INFO:logs:Initializing create_model()\n",
      "INFO:logs:create_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=6619, verbose=0,\n",
      "                       warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, display=None, kwargs={})\n",
      "INFO:logs:Checking exceptions\n",
      "INFO:logs:Preparing display monitor\n",
      "INFO:logs:Importing libraries\n",
      "INFO:logs:Copying training dataset\n",
      "INFO:logs:Defining folds\n",
      "INFO:logs:Declaring metric variables\n",
      "INFO:logs:Importing untrained model\n",
      "INFO:logs:Declaring custom model\n",
      "INFO:logs:Random Forest Classifier Imported succesfully\n",
      "INFO:logs:Starting cross validation\n",
      "INFO:logs:Cross validating with StratifiedKFold(n_splits=10, random_state=8339, shuffle=False), n_jobs=-1\n",
      "INFO:logs:Calculating mean and std\n",
      "INFO:logs:Creating metrics dataframe\n",
      "INFO:logs:Finalizing model\n",
      "INFO:logs:Uploading results into container\n",
      "INFO:logs:Uploading model into container now\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.6216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.5782</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.3757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.4452</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>-0.0606</td>\n",
       "      <td>-0.0648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.5524</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2449</td>\n",
       "      <td>-0.0606</td>\n",
       "      <td>-0.0648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.4287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4643</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>0.4022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5306</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>0.3565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>0.3922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>0.5854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.4487</td>\n",
       "      <td>0.4581</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>0.3252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1372</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.2226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.7143  0.9881  0.6250  0.6857  0.6548  0.5484  0.6216\n",
       "1       0.5714  0.6690  0.5417  0.6429  0.5782  0.3636  0.3757\n",
       "2       0.2857  0.4452  0.3333  0.1786  0.2177 -0.0606 -0.0648\n",
       "3       0.2857  0.5524  0.1667  0.2143  0.2449 -0.0606 -0.0648\n",
       "4       0.4286  0.6738  0.4167  0.3333  0.3571  0.2000  0.2192\n",
       "5       0.5714  0.7500  0.5833  0.6429  0.6000  0.4167  0.4287\n",
       "6       0.5714  0.9476  0.5000  0.4000  0.4643  0.3438  0.4022\n",
       "7       0.5714  0.8310  0.5417  0.5000  0.5306  0.3438  0.3565\n",
       "8       0.5000  0.8000  0.5000  0.2500  0.3333  0.3077  0.3922\n",
       "9       0.6667  0.7750  0.6250  0.6389  0.6000  0.5385  0.5854\n",
       "Mean    0.5167  0.7432  0.4833  0.4487  0.4581  0.2941  0.3252\n",
       "SD      0.1372  0.1579  0.1359  0.1880  0.1509  0.2024  0.2226"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:create_model_container: 1\n",
      "INFO:logs:master_model_container: 1\n",
      "INFO:logs:display_container: 1\n",
      "INFO:logs:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=6619, verbose=0,\n",
      "                       warm_start=False)\n",
      "INFO:logs:create_model() succesfully completed......................................\n"
     ]
    }
   ],
   "source": [
    "Xtrain = essai_classif[predicteurs + ['Overall']]\n",
    "german_classif = setup(data = Xtrain,  target = 'Overall', html=False, silent=True, verbose=False)\n",
    "rf = create_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict_model(rf)  # ne marche pas ????\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:PyCaret Supervised Module\n",
      "INFO:logs:ML Usecase: classification\n",
      "INFO:logs:version 2.2.2\n",
      "INFO:logs:Initializing setup()\n",
      "INFO:logs:setup(target=Entities, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=False, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=False, profile=False, profile_kwargs=None, display=None)\n",
      "INFO:logs:Checking environment\n",
      "INFO:logs:python_version: 3.8.12\n",
      "INFO:logs:python_build: ('default', 'Oct 12 2021 03:01:40')\n",
      "INFO:logs:machine: AMD64\n",
      "INFO:logs:platform: Windows-10-10.0.19041-SP0\n",
      "INFO:logs:Memory: svmem(total=34157522944, available=10035384320, percent=70.6, used=24122138624, free=10035384320)\n",
      "INFO:logs:Physical Core: 6\n",
      "INFO:logs:Logical Core: 12\n",
      "INFO:logs:Checking libraries\n",
      "INFO:logs:pd==1.0.5\n",
      "INFO:logs:numpy==1.21.4\n",
      "INFO:logs:sklearn==0.23.2\n",
      "INFO:logs:xgboost==1.2.1\n",
      "INFO:logs:lightgbm==3.1.0\n",
      "INFO:logs:catboost==0.24.3\n",
      "INFO:logs:mlflow==1.12.1\n",
      "INFO:logs:Checking Exceptions\n",
      "INFO:logs:Declaring global variables\n",
      "INFO:logs:USI: 6d7b\n",
      "INFO:logs:pycaret_globals: {'fix_imbalance_method_param', 'html_param', '_ml_usecase', 'fold_param', 'master_model_container', 'log_plots_param', 'fold_groups_param', '_all_models_internal', 'iterative_imputation_iters_param', '_available_plots', 'USI', 'logging_param', 'fold_shuffle_param', '_all_models', 'y', 'fix_imbalance_param', 'pycaret_globals', 'transform_target_method_param', 'stratify_param', 'fold_generator', 'X_test', 'exp_name_log', 'experiment__', 'data_before_preprocess', 'X', '_internal_pipeline', 'n_jobs_param', '_all_metrics', 'imputation_classifier', 'display_container', 'target_param', 'prep_pipe', '_gpu_n_jobs_param', 'transform_target_param', 'X_train', 'y_train', 'create_model_container', 'seed', 'imputation_regressor', 'y_test', 'gpu_param'}\n",
      "INFO:logs:Preparing display monitor\n",
      "INFO:logs:Importing libraries\n",
      "INFO:logs:Copying data for preprocessing\n",
      "INFO:logs:Declaring preprocessing parameters\n",
      "INFO:logs:Creating preprocessing pipeline\n",
      "INFO:logs:Preprocessing pipeline created successfully\n",
      "ERROR:logs:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.\n",
      "INFO:logs:Creating global containers\n",
      "INFO:logs:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)\n",
      "INFO:logs:Creating grid variables\n",
      "INFO:logs:create_model_container: 0\n",
      "INFO:logs:master_model_container: 0\n",
      "INFO:logs:display_container: 0\n",
      "INFO:logs:Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=[],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=[], target='Entities',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_available',\n",
      "                                fill_value_categorical=None,\n",
      "                                fill_value_numerical=None,\n",
      "                                numeric_st...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='Entities')),\n",
      "                ('fix_perfect', Remove_100(target='Entities')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False)\n",
      "INFO:logs:setup() succesfully completed......................................\n",
      "INFO:logs:Initializing create_model()\n",
      "INFO:logs:create_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=6619, verbose=0,\n",
      "                       warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, display=None, kwargs={})\n",
      "INFO:logs:Checking exceptions\n",
      "INFO:logs:Preparing display monitor\n",
      "INFO:logs:Importing libraries\n",
      "INFO:logs:Copying training dataset\n",
      "INFO:logs:Defining folds\n",
      "INFO:logs:Declaring metric variables\n",
      "INFO:logs:Importing untrained model\n",
      "INFO:logs:Declaring custom model\n",
      "INFO:logs:Random Forest Classifier Imported succesfully\n",
      "INFO:logs:Starting cross validation\n",
      "INFO:logs:Cross validating with StratifiedKFold(n_splits=10, random_state=7804, shuffle=False), n_jobs=-1\n",
      "INFO:logs:Calculating mean and std\n",
      "INFO:logs:Creating metrics dataframe\n",
      "INFO:logs:Finalizing model\n",
      "INFO:logs:Uploading results into container\n",
      "INFO:logs:Uploading model into container now\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.4456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.4697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>-0.1290</td>\n",
       "      <td>-0.1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.6417</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.4456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>-0.2582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>0.3563</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.2721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4286  0.5250  0.2500  0.2143  0.2857  0.0667  0.0990\n",
       "1       0.4286  0.3214  0.2500  0.1837  0.2571  0.0000  0.0000\n",
       "2       0.5714  0.7702  0.5000  0.3571  0.4286  0.3000  0.4456\n",
       "3       0.5714  0.8429  0.6667  0.4762  0.5000  0.4167  0.4697\n",
       "4       0.4286  0.4560  0.4167  0.3143  0.3571  0.0968  0.1097\n",
       "5       0.2857  0.3690  0.1667  0.1714  0.2143 -0.1290 -0.1463\n",
       "6       0.5714  0.6417  0.5000  0.3571  0.4286  0.3000  0.4456\n",
       "7       0.4286  0.5738  0.2500  0.2143  0.2857  0.0667  0.0990\n",
       "8       0.3333  0.4000  0.1667  0.2000  0.2500 -0.2000 -0.2582\n",
       "9       0.6667  0.7833  0.5000  0.5000  0.5556  0.5000  0.5883\n",
       "Mean    0.4714  0.5683  0.3667  0.2988  0.3563  0.1418  0.1852\n",
       "SD      0.1136  0.1764  0.1633  0.1151  0.1105  0.2185  0.2721"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:create_model_container: 1\n",
      "INFO:logs:master_model_container: 1\n",
      "INFO:logs:display_container: 1\n",
      "INFO:logs:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=6619, verbose=0,\n",
      "                       warm_start=False)\n",
      "INFO:logs:create_model() succesfully completed......................................\n"
     ]
    }
   ],
   "source": [
    "german_classif = setup(data = essai_classif[['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem','Entities']],  target = 'Entities', html=False, silent=True, verbose=False)\n",
    "rf = create_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = predict_model(rf,essai_classif[['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem','Entities']])\n",
    "# pred = pd.concat([pred,essai_classif.Entities],axis=1)\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random Forest simple sur scikit learn\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xtrain[:50],ytrain[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.90</td>\n",
       "      <td>91.90</td>\n",
       "      <td>93.73</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.53</td>\n",
       "      <td>73.86</td>\n",
       "      <td>66.92</td>\n",
       "      <td>43.59</td>\n",
       "      <td>43.59</td>\n",
       "      <td>43.59</td>\n",
       "      <td>43.59</td>\n",
       "      <td>33.8</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.62</td>\n",
       "      <td>81.50</td>\n",
       "      <td>74.30</td>\n",
       "      <td>44.15</td>\n",
       "      <td>44.15</td>\n",
       "      <td>44.15</td>\n",
       "      <td>44.15</td>\n",
       "      <td>126.1</td>\n",
       "      <td>65.8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.27</td>\n",
       "      <td>70.24</td>\n",
       "      <td>96.42</td>\n",
       "      <td>19.94</td>\n",
       "      <td>19.94</td>\n",
       "      <td>19.94</td>\n",
       "      <td>19.94</td>\n",
       "      <td>67.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>95.98</td>\n",
       "      <td>84.03</td>\n",
       "      <td>66.23</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>96.56</td>\n",
       "      <td>85.30</td>\n",
       "      <td>83.06</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.91</td>\n",
       "      <td>36.0</td>\n",
       "      <td>67.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.13</td>\n",
       "      <td>96.47</td>\n",
       "      <td>67.91</td>\n",
       "      <td>77.35</td>\n",
       "      <td>77.35</td>\n",
       "      <td>77.35</td>\n",
       "      <td>77.35</td>\n",
       "      <td>220.1</td>\n",
       "      <td>97.4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83.67</td>\n",
       "      <td>83.48</td>\n",
       "      <td>89.13</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96.39</td>\n",
       "      <td>67.07</td>\n",
       "      <td>91.31</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>98.0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.18</td>\n",
       "      <td>78.72</td>\n",
       "      <td>95.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>7.6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>96.97</td>\n",
       "      <td>65.02</td>\n",
       "      <td>66.93</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.76</td>\n",
       "      <td>53.6</td>\n",
       "      <td>116.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>76.98</td>\n",
       "      <td>96.92</td>\n",
       "      <td>89.50</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.91</td>\n",
       "      <td>90.7</td>\n",
       "      <td>87.3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.61</td>\n",
       "      <td>92.20</td>\n",
       "      <td>97.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>106.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96.91</td>\n",
       "      <td>47.66</td>\n",
       "      <td>33.34</td>\n",
       "      <td>94.21</td>\n",
       "      <td>94.21</td>\n",
       "      <td>94.21</td>\n",
       "      <td>94.21</td>\n",
       "      <td>263.0</td>\n",
       "      <td>102.7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87.67</td>\n",
       "      <td>61.42</td>\n",
       "      <td>98.15</td>\n",
       "      <td>36.76</td>\n",
       "      <td>36.76</td>\n",
       "      <td>36.76</td>\n",
       "      <td>36.76</td>\n",
       "      <td>42.5</td>\n",
       "      <td>26.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>97.33</td>\n",
       "      <td>71.24</td>\n",
       "      <td>80.38</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>404.8</td>\n",
       "      <td>223.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95.29</td>\n",
       "      <td>96.72</td>\n",
       "      <td>87.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>94.8</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89.10</td>\n",
       "      <td>88.09</td>\n",
       "      <td>35.56</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.50</td>\n",
       "      <td>195.3</td>\n",
       "      <td>143.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.00</td>\n",
       "      <td>96.81</td>\n",
       "      <td>65.17</td>\n",
       "      <td>48.38</td>\n",
       "      <td>48.38</td>\n",
       "      <td>48.38</td>\n",
       "      <td>48.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.84</td>\n",
       "      <td>76.27</td>\n",
       "      <td>42.92</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>38.3</td>\n",
       "      <td>39.8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>98.24</td>\n",
       "      <td>81.64</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>23.6</td>\n",
       "      <td>25.4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.81</td>\n",
       "      <td>93.30</td>\n",
       "      <td>23.80</td>\n",
       "      <td>96.51</td>\n",
       "      <td>96.51</td>\n",
       "      <td>96.51</td>\n",
       "      <td>96.51</td>\n",
       "      <td>41.3</td>\n",
       "      <td>70.3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>95.26</td>\n",
       "      <td>97.54</td>\n",
       "      <td>93.86</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>346.5</td>\n",
       "      <td>257.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.87</td>\n",
       "      <td>69.15</td>\n",
       "      <td>6.20</td>\n",
       "      <td>24.73</td>\n",
       "      <td>24.73</td>\n",
       "      <td>24.73</td>\n",
       "      <td>24.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.43</td>\n",
       "      <td>96.32</td>\n",
       "      <td>52.66</td>\n",
       "      <td>99.39</td>\n",
       "      <td>99.39</td>\n",
       "      <td>99.39</td>\n",
       "      <td>99.39</td>\n",
       "      <td>18.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.58</td>\n",
       "      <td>93.33</td>\n",
       "      <td>85.70</td>\n",
       "      <td>99.49</td>\n",
       "      <td>99.49</td>\n",
       "      <td>99.49</td>\n",
       "      <td>99.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.16</td>\n",
       "      <td>94.38</td>\n",
       "      <td>84.77</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.97</td>\n",
       "      <td>84.21</td>\n",
       "      <td>61.89</td>\n",
       "      <td>99.77</td>\n",
       "      <td>99.77</td>\n",
       "      <td>99.77</td>\n",
       "      <td>99.77</td>\n",
       "      <td>66.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.57</td>\n",
       "      <td>88.78</td>\n",
       "      <td>69.77</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.74</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>97.32</td>\n",
       "      <td>79.41</td>\n",
       "      <td>87.30</td>\n",
       "      <td>66.07</td>\n",
       "      <td>66.07</td>\n",
       "      <td>66.07</td>\n",
       "      <td>66.07</td>\n",
       "      <td>2.1</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94.10</td>\n",
       "      <td>93.80</td>\n",
       "      <td>97.03</td>\n",
       "      <td>93.89</td>\n",
       "      <td>93.89</td>\n",
       "      <td>93.89</td>\n",
       "      <td>93.89</td>\n",
       "      <td>152.7</td>\n",
       "      <td>140.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>86.66</td>\n",
       "      <td>71.96</td>\n",
       "      <td>72.82</td>\n",
       "      <td>99.67</td>\n",
       "      <td>99.67</td>\n",
       "      <td>99.67</td>\n",
       "      <td>99.67</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.62</td>\n",
       "      <td>77.94</td>\n",
       "      <td>72.41</td>\n",
       "      <td>99.83</td>\n",
       "      <td>99.83</td>\n",
       "      <td>99.83</td>\n",
       "      <td>99.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>76.59</td>\n",
       "      <td>91.62</td>\n",
       "      <td>82.81</td>\n",
       "      <td>95.96</td>\n",
       "      <td>95.96</td>\n",
       "      <td>95.96</td>\n",
       "      <td>95.96</td>\n",
       "      <td>41.8</td>\n",
       "      <td>50.2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>90.21</td>\n",
       "      <td>82.69</td>\n",
       "      <td>44.62</td>\n",
       "      <td>88.36</td>\n",
       "      <td>88.36</td>\n",
       "      <td>88.36</td>\n",
       "      <td>88.36</td>\n",
       "      <td>11.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.14</td>\n",
       "      <td>93.98</td>\n",
       "      <td>54.64</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>35.1</td>\n",
       "      <td>51.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>87.11</td>\n",
       "      <td>85.75</td>\n",
       "      <td>92.82</td>\n",
       "      <td>26.35</td>\n",
       "      <td>26.35</td>\n",
       "      <td>26.35</td>\n",
       "      <td>26.35</td>\n",
       "      <td>285.1</td>\n",
       "      <td>147.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>93.82</td>\n",
       "      <td>99.90</td>\n",
       "      <td>92.26</td>\n",
       "      <td>90.90</td>\n",
       "      <td>90.90</td>\n",
       "      <td>90.90</td>\n",
       "      <td>90.90</td>\n",
       "      <td>349.3</td>\n",
       "      <td>257.2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97.43</td>\n",
       "      <td>89.37</td>\n",
       "      <td>73.11</td>\n",
       "      <td>14.02</td>\n",
       "      <td>14.02</td>\n",
       "      <td>14.02</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.75</td>\n",
       "      <td>87.56</td>\n",
       "      <td>98.29</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>148.2</td>\n",
       "      <td>119.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.83</td>\n",
       "      <td>64.94</td>\n",
       "      <td>82.11</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>420.5</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.49</td>\n",
       "      <td>62.12</td>\n",
       "      <td>56.41</td>\n",
       "      <td>30.69</td>\n",
       "      <td>30.69</td>\n",
       "      <td>30.69</td>\n",
       "      <td>30.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.02</td>\n",
       "      <td>94.04</td>\n",
       "      <td>91.45</td>\n",
       "      <td>97.76</td>\n",
       "      <td>97.76</td>\n",
       "      <td>97.76</td>\n",
       "      <td>97.76</td>\n",
       "      <td>25.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.23</td>\n",
       "      <td>69.50</td>\n",
       "      <td>69.43</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>68.3</td>\n",
       "      <td>60.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.85</td>\n",
       "      <td>96.70</td>\n",
       "      <td>59.74</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>146.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.62</td>\n",
       "      <td>96.05</td>\n",
       "      <td>65.97</td>\n",
       "      <td>90.60</td>\n",
       "      <td>90.60</td>\n",
       "      <td>90.60</td>\n",
       "      <td>90.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.37</td>\n",
       "      <td>94.95</td>\n",
       "      <td>71.50</td>\n",
       "      <td>53.40</td>\n",
       "      <td>53.40</td>\n",
       "      <td>53.40</td>\n",
       "      <td>53.40</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.77</td>\n",
       "      <td>83.04</td>\n",
       "      <td>71.56</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50                0              1              0                    92.90   \n",
       "51                0              0              0                    95.53   \n",
       "52                0              0              0                    84.62   \n",
       "53                0              1              0                    90.27   \n",
       "54                0              6              0                    95.98   \n",
       "55                1              2              0                    96.56   \n",
       "56                0              0              0                    92.13   \n",
       "57                0              1              0                    83.67   \n",
       "58                1              1              0                    96.39   \n",
       "59                0              0              0                    96.18   \n",
       "60                0              2              0                    96.97   \n",
       "61                0             10              0                    76.98   \n",
       "62                7              1              0                    92.61   \n",
       "63                0              1              0                    96.91   \n",
       "64                2              1              0                    87.67   \n",
       "65                3              4              0                    97.33   \n",
       "66                1              2              0                    95.29   \n",
       "67                0              1              0                    89.10   \n",
       "68                0              0              0                    98.00   \n",
       "69                0              0              0                    73.84   \n",
       "70                0              4              0                    98.24   \n",
       "71                0              0              0                    55.81   \n",
       "72                6             28              0                    95.26   \n",
       "73                0              0              0                    86.87   \n",
       "74                0              0              0                    98.43   \n",
       "75                0              0              0                    90.58   \n",
       "76                0              1              0                    90.16   \n",
       "77                4              0              0                    97.97   \n",
       "78                0              0              0                    63.57   \n",
       "79                0              3              0                    97.32   \n",
       "80                0              2              0                    94.10   \n",
       "81                0              2              0                    86.66   \n",
       "82                0              0              0                    96.62   \n",
       "83                0              2              0                    76.59   \n",
       "84                0              7              0                    90.21   \n",
       "85                1              0              0                    87.14   \n",
       "86                1              3              0                    87.11   \n",
       "87                0              2              0                    93.82   \n",
       "88                0              1              0                    97.43   \n",
       "89                0              0              0                    85.75   \n",
       "90                1              0              0                    99.83   \n",
       "91                0              0              0                    92.49   \n",
       "92                0              1              0                    88.02   \n",
       "93                0              0              0                    85.23   \n",
       "94                0              0              0                    97.85   \n",
       "95                0              0              0                    66.62   \n",
       "96                1              0              0                    96.37   \n",
       "97                0              1              0                    85.77   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                     91.90                     93.73            0.02   \n",
       "51                     73.86                     66.92           43.59   \n",
       "52                     81.50                     74.30           44.15   \n",
       "53                     70.24                     96.42           19.94   \n",
       "54                     84.03                     66.23            1.58   \n",
       "55                     85.30                     83.06            4.91   \n",
       "56                     96.47                     67.91           77.35   \n",
       "57                     83.48                     89.13           99.93   \n",
       "58                     67.07                     91.31            0.22   \n",
       "59                     78.72                     95.03            0.18   \n",
       "60                     65.02                     66.93            3.76   \n",
       "61                     96.92                     89.50            4.91   \n",
       "62                     92.20                     97.55            0.56   \n",
       "63                     47.66                     33.34           94.21   \n",
       "64                     61.42                     98.15           36.76   \n",
       "65                     71.24                     80.38            0.16   \n",
       "66                     96.72                     87.10            0.08   \n",
       "67                     88.09                     35.56           43.50   \n",
       "68                     96.81                     65.17           48.38   \n",
       "69                     76.27                     42.92            0.03   \n",
       "70                     81.64                     93.88            0.07   \n",
       "71                     93.30                     23.80           96.51   \n",
       "72                     97.54                     93.86            0.16   \n",
       "73                     69.15                      6.20           24.73   \n",
       "74                     96.32                     52.66           99.39   \n",
       "75                     93.33                     85.70           99.49   \n",
       "76                     94.38                     84.77            0.66   \n",
       "77                     84.21                     61.89           99.77   \n",
       "78                     88.78                     69.77            4.74   \n",
       "79                     79.41                     87.30           66.07   \n",
       "80                     93.80                     97.03           93.89   \n",
       "81                     71.96                     72.82           99.67   \n",
       "82                     77.94                     72.41           99.83   \n",
       "83                     91.62                     82.81           95.96   \n",
       "84                     82.69                     44.62           88.36   \n",
       "85                     93.98                     54.64            0.33   \n",
       "86                     85.75                     92.82           26.35   \n",
       "87                     99.90                     92.26           90.90   \n",
       "88                     89.37                     73.11           14.02   \n",
       "89                     87.56                     98.29            0.05   \n",
       "90                     64.94                     82.11            0.82   \n",
       "91                     62.12                     56.41           30.69   \n",
       "92                     94.04                     91.45           97.76   \n",
       "93                     69.50                     69.43            4.50   \n",
       "94                     96.70                     59.74            0.17   \n",
       "95                     96.05                     65.97           90.60   \n",
       "96                     94.95                     71.50           53.40   \n",
       "97                     83.04                     71.56            0.16   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2  meth1_similarites  \\\n",
       "50            0.02              0.02              0.02                0.0   \n",
       "51           43.59             43.59             43.59               33.8   \n",
       "52           44.15             44.15             44.15              126.1   \n",
       "53           19.94             19.94             19.94               67.5   \n",
       "54            1.58              1.58              1.58                0.0   \n",
       "55            4.91              4.91              4.91               36.0   \n",
       "56           77.35             77.35             77.35              220.1   \n",
       "57           99.93             99.93             99.93                0.0   \n",
       "58            0.22              0.22              0.22               98.0   \n",
       "59            0.18              0.18              0.18                7.6   \n",
       "60            3.76              3.76              3.76               53.6   \n",
       "61            4.91              4.91              4.91               90.7   \n",
       "62            0.56              0.56              0.56              106.3   \n",
       "63           94.21             94.21             94.21              263.0   \n",
       "64           36.76             36.76             36.76               42.5   \n",
       "65            0.16              0.16              0.16              404.8   \n",
       "66            0.08              0.08              0.08               94.8   \n",
       "67           43.50             43.50             43.50              195.3   \n",
       "68           48.38             48.38             48.38                0.0   \n",
       "69            0.03              0.03              0.03               38.3   \n",
       "70            0.07              0.07              0.07               23.6   \n",
       "71           96.51             96.51             96.51               41.3   \n",
       "72            0.16              0.16              0.16              346.5   \n",
       "73           24.73             24.73             24.73                0.0   \n",
       "74           99.39             99.39             99.39               18.4   \n",
       "75           99.49             99.49             99.49                0.0   \n",
       "76            0.66              0.66              0.66                0.0   \n",
       "77           99.77             99.77             99.77               66.5   \n",
       "78            4.74              4.74              4.74                8.2   \n",
       "79           66.07             66.07             66.07                2.1   \n",
       "80           93.89             93.89             93.89              152.7   \n",
       "81           99.67             99.67             99.67               55.0   \n",
       "82           99.83             99.83             99.83                0.0   \n",
       "83           95.96             95.96             95.96               41.8   \n",
       "84           88.36             88.36             88.36               11.6   \n",
       "85            0.33              0.33              0.33               35.1   \n",
       "86           26.35             26.35             26.35              285.1   \n",
       "87           90.90             90.90             90.90              349.3   \n",
       "88           14.02             14.02             14.02                0.0   \n",
       "89            0.05              0.05              0.05              148.2   \n",
       "90            0.82              0.82              0.82              420.5   \n",
       "91           30.69             30.69             30.69                0.0   \n",
       "92           97.76             97.76             97.76               25.4   \n",
       "93            4.50              4.50              4.50               68.3   \n",
       "94            0.17              0.17              0.17              146.7   \n",
       "95           90.60             90.60             90.60                0.0   \n",
       "96           53.40             53.40             53.40               46.0   \n",
       "97            0.16              0.16              0.16                0.0   \n",
       "\n",
       "    meth2_similarites  Overall  RF  \n",
       "50               42.5        3   4  \n",
       "51               37.4        4   4  \n",
       "52               65.8        3   2  \n",
       "53               13.1        4   2  \n",
       "54               45.9        2   4  \n",
       "55               67.4        3   2  \n",
       "56               97.4        3   3  \n",
       "57                8.1        4   4  \n",
       "58               53.1        4   2  \n",
       "59               17.2        4   4  \n",
       "60              116.3        2   2  \n",
       "61               87.3        4   2  \n",
       "62              100.0        1   2  \n",
       "63              102.7        2   3  \n",
       "64               26.4        4   2  \n",
       "65              223.7        1   1  \n",
       "66              147.0        2   2  \n",
       "67              143.3        2   3  \n",
       "68                0.0        4   4  \n",
       "69               39.8        3   4  \n",
       "70               25.4        1   4  \n",
       "71               70.3        3   3  \n",
       "72              257.8        1   1  \n",
       "73                0.0        4   4  \n",
       "74               18.2        2   3  \n",
       "75                0.0        4   3  \n",
       "76               74.6        3   4  \n",
       "77               51.2        2   3  \n",
       "78                8.1        4   4  \n",
       "79               37.4        4   4  \n",
       "80              140.2        4   3  \n",
       "81               20.2        4   4  \n",
       "82               12.2        4   3  \n",
       "83               50.2        4   4  \n",
       "84               29.7        3   4  \n",
       "85               51.3        2   2  \n",
       "86              147.4        1   1  \n",
       "87              257.2        4   1  \n",
       "88                6.3        4   4  \n",
       "89              119.8        1   4  \n",
       "90              122.0        1   4  \n",
       "91                0.0        3   4  \n",
       "92               14.0        4   4  \n",
       "93               60.2        2   2  \n",
       "94               64.0        1   2  \n",
       "95               27.8        4   3  \n",
       "96               62.6        2   2  \n",
       "97               10.7        4   4  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résultats corrects : 6/17 - 8/17 : 1 d'écart et 3/17 : 2 écart \n",
    "res_rf = rf.predict(Xtrain[50:])\n",
    "res_rf = pd.concat([Xtrain[50:],ytrain[50:],pd.DataFrame(res_rf,columns = ['RF'],index = range(50,98))],axis=1)\n",
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  6,  9,  8,  1,  0,  2,  5,  3,  4, 11, 10], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(rf, Xtrain, ytrain, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "tree_feature_importances = rf.feature_importances_\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(predicteurs))\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.array(predicteurs)[sorted_idx])\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>summary1_text1</th>\n",
       "      <th>summary2_text1</th>\n",
       "      <th>summary1_text2</th>\n",
       "      <th>summary2_text2</th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>entites_idem</th>\n",
       "      <th>...</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dschungelcamp 2020: Marco Cerullo - Übernimmt ...</td>\n",
       "      <td>Dschungelcamp bei RTL: Ex-Minister Günther Kra...</td>\n",
       "      <td>Dschungelcamp-Kandidat Marco Cerullo suchte in...</td>\n",
       "      <td>Dschungelcamp - Kandidat Marco Cerullo suchte ...</td>\n",
       "      <td>Der frühere Politiker Günther Krause hatte 199...</td>\n",
       "      <td>Ex - Bundesverkehrsminister Günther Krause, 66...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['RTL']</td>\n",
       "      <td>...</td>\n",
       "      <td>94.74</td>\n",
       "      <td>97.80</td>\n",
       "      <td>86.47</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.27</td>\n",
       "      <td>58.5</td>\n",
       "      <td>40.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silberdistel Neutras ehrt Jahresmeister</td>\n",
       "      <td>Fröhliche Weise mit ernster Botschaft</td>\n",
       "      <td>Die Jahresmeisterschaft entscheidet der Durchs...</td>\n",
       "      <td>Silberdistel Neutras ehrt Jahresmeister Von de...</td>\n",
       "      <td>Die deutsche Melodie Bob Geldofs steht in eine...</td>\n",
       "      <td>In der Weihnachtszeit ist die Zahl der Weihnac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>84.74</td>\n",
       "      <td>90.23</td>\n",
       "      <td>67.07</td>\n",
       "      <td>96.21</td>\n",
       "      <td>96.21</td>\n",
       "      <td>96.21</td>\n",
       "      <td>96.21</td>\n",
       "      <td>23.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das grosse Rätsel um die Flucht des Autozaren</td>\n",
       "      <td>Überraschende Flucht aus Japan: Ex-Renault-Bos...</td>\n",
       "      <td>Sehr gut möglich, dass die Geschichte dieser F...</td>\n",
       "      <td>Der libanesischen Automanager Carlos Ghosn ist...</td>\n",
       "      <td>Der in Japan auf Kaution freigelassene frühere...</td>\n",
       "      <td>Er sei \" nicht länger eine Geisel des manipuli...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>['Renault', 'Nissan', 'Mitsubishi']</td>\n",
       "      <td>...</td>\n",
       "      <td>78.85</td>\n",
       "      <td>95.10</td>\n",
       "      <td>85.10</td>\n",
       "      <td>11.07</td>\n",
       "      <td>11.07</td>\n",
       "      <td>11.07</td>\n",
       "      <td>11.07</td>\n",
       "      <td>151.5</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zum Jahresende legen die Velpker noch mal rich...</td>\n",
       "      <td>Léon Berben auf der Vater-Orgel : Ein Meisterk...</td>\n",
       "      <td>Das alte Jahr ausklingen lassen und das neue m...</td>\n",
       "      <td>Das alte Jahr ausklingen lassen und das neue m...</td>\n",
       "      <td>Der deutsche Musiker Léon Berben feiert seine ...</td>\n",
       "      <td>Der Interpret genießt in der festlich erleucht...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>96.22</td>\n",
       "      <td>97.57</td>\n",
       "      <td>84.40</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neun Personen festgenommen: Viel Arbeit für di...</td>\n",
       "      <td>Polizei berichtet von ruhiger Silvesternacht</td>\n",
       "      <td>Vor allem in der Stadt und Agglomeration war d...</td>\n",
       "      <td>Vor allem in der Stadt und Agglomeration war d...</td>\n",
       "      <td>Die Polizei hat zwei Verstöße gegen das Feuerw...</td>\n",
       "      <td>Der Inhalt ist älter als 30 Stunden und steht ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>80.39</td>\n",
       "      <td>98.61</td>\n",
       "      <td>92.36</td>\n",
       "      <td>90.97</td>\n",
       "      <td>90.97</td>\n",
       "      <td>90.97</td>\n",
       "      <td>90.97</td>\n",
       "      <td>36.1</td>\n",
       "      <td>31.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fünf Verletzte und ein Brand</td>\n",
       "      <td>Brand in Silvesternacht: 40 Hausbewohner müsse...</td>\n",
       "      <td>Bitte melden Sie sich an! Sie haben noch keine...</td>\n",
       "      <td>Bitte melden Sie sich an! Sie haben noch keine...</td>\n",
       "      <td>Die Polizei hat die Ermittlungen übernommen un...</td>\n",
       "      <td>Der Brand in der Ritter - von - Hellberg - Str...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>85.23</td>\n",
       "      <td>69.50</td>\n",
       "      <td>69.43</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>68.3</td>\n",
       "      <td>60.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Mindestens 16 Tote bei Kämpfen in mexikanische...</td>\n",
       "      <td>16 Tote bei Massenschlägerei in mexikanischem ...</td>\n",
       "      <td>Wie lange ist die frist bei einer Kündigung? H...</td>\n",
       "      <td>Wie lange ist die frist bei einer Kündigung? H...</td>\n",
       "      <td>Mindestens 16 Menschen sind kurz vor dem Jahre...</td>\n",
       "      <td>Die Sicherheitskräfte stellten Waffen sicher -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>97.85</td>\n",
       "      <td>96.70</td>\n",
       "      <td>59.74</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>146.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Der neue Soccerpark The Bolz im Test: Spielspa...</td>\n",
       "      <td>Frohes Neues! Das sind die Bilder vom Feuerwer...</td>\n",
       "      <td>Hannover hat einen neuen Soccerpark: The Bolz ...</td>\n",
       "      <td>Die HAZ hat die Fußballkäfige ausprobiert und ...</td>\n",
       "      <td>In Hannover haben die Bürger das neue Jahr mit...</td>\n",
       "      <td>In der Region Hannover haben die Bürger das ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>66.62</td>\n",
       "      <td>96.05</td>\n",
       "      <td>65.97</td>\n",
       "      <td>90.60</td>\n",
       "      <td>90.60</td>\n",
       "      <td>90.60</td>\n",
       "      <td>90.60</td>\n",
       "      <td>0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dschungelcamp 2020: Anastasiya Avilova kommt v...</td>\n",
       "      <td>Dschungelcamp 2020: Das sind die Kandidaten</td>\n",
       "      <td>Anastasiya Avilova (31) ist laut Bild-Zeitung ...</td>\n",
       "      <td>Anastasiya Avilova zieht im Januar 2020 als Ka...</td>\n",
       "      <td>Die Kandidaten für die 14. Staffel \"Ich bin ei...</td>\n",
       "      <td>Die Kandidaten für die 14. Staffel \" Ich bin e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['RTL']</td>\n",
       "      <td>...</td>\n",
       "      <td>96.37</td>\n",
       "      <td>94.95</td>\n",
       "      <td>71.50</td>\n",
       "      <td>53.40</td>\n",
       "      <td>53.40</td>\n",
       "      <td>53.40</td>\n",
       "      <td>53.40</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jahresausblick mit Astrologin Monica Kissling:...</td>\n",
       "      <td>Ein Lichtblick zu Jahresbeginn</td>\n",
       "      <td>Monica Kissling alias \"Madame Etoile\" hat in d...</td>\n",
       "      <td>Monica Kissling alias Madame Etoile hat in die...</td>\n",
       "      <td>Der US-Präsident lässt am Silvestertag verlaut...</td>\n",
       "      <td>Der US - Präsident will in den USA den ersten ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>85.77</td>\n",
       "      <td>83.04</td>\n",
       "      <td>71.56</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title_1  \\\n",
       "0   Dschungelcamp 2020: Marco Cerullo - Übernimmt ...   \n",
       "1             Silberdistel Neutras ehrt Jahresmeister   \n",
       "2       Das grosse Rätsel um die Flucht des Autozaren   \n",
       "3   Zum Jahresende legen die Velpker noch mal rich...   \n",
       "4   Neun Personen festgenommen: Viel Arbeit für di...   \n",
       "..                                                ...   \n",
       "95                       Fünf Verletzte und ein Brand   \n",
       "96  Mindestens 16 Tote bei Kämpfen in mexikanische...   \n",
       "97  Der neue Soccerpark The Bolz im Test: Spielspa...   \n",
       "98  Dschungelcamp 2020: Anastasiya Avilova kommt v...   \n",
       "99  Jahresausblick mit Astrologin Monica Kissling:...   \n",
       "\n",
       "                                              title_2  \\\n",
       "0   Dschungelcamp bei RTL: Ex-Minister Günther Kra...   \n",
       "1               Fröhliche Weise mit ernster Botschaft   \n",
       "2   Überraschende Flucht aus Japan: Ex-Renault-Bos...   \n",
       "3   Léon Berben auf der Vater-Orgel : Ein Meisterk...   \n",
       "4        Polizei berichtet von ruhiger Silvesternacht   \n",
       "..                                                ...   \n",
       "95  Brand in Silvesternacht: 40 Hausbewohner müsse...   \n",
       "96  16 Tote bei Massenschlägerei in mexikanischem ...   \n",
       "97  Frohes Neues! Das sind die Bilder vom Feuerwer...   \n",
       "98        Dschungelcamp 2020: Das sind die Kandidaten   \n",
       "99                     Ein Lichtblick zu Jahresbeginn   \n",
       "\n",
       "                                       summary1_text1  \\\n",
       "0   Dschungelcamp-Kandidat Marco Cerullo suchte in...   \n",
       "1   Die Jahresmeisterschaft entscheidet der Durchs...   \n",
       "2   Sehr gut möglich, dass die Geschichte dieser F...   \n",
       "3   Das alte Jahr ausklingen lassen und das neue m...   \n",
       "4   Vor allem in der Stadt und Agglomeration war d...   \n",
       "..                                                ...   \n",
       "95  Bitte melden Sie sich an! Sie haben noch keine...   \n",
       "96  Wie lange ist die frist bei einer Kündigung? H...   \n",
       "97  Hannover hat einen neuen Soccerpark: The Bolz ...   \n",
       "98  Anastasiya Avilova (31) ist laut Bild-Zeitung ...   \n",
       "99  Monica Kissling alias \"Madame Etoile\" hat in d...   \n",
       "\n",
       "                                       summary2_text1  \\\n",
       "0   Dschungelcamp - Kandidat Marco Cerullo suchte ...   \n",
       "1   Silberdistel Neutras ehrt Jahresmeister Von de...   \n",
       "2   Der libanesischen Automanager Carlos Ghosn ist...   \n",
       "3   Das alte Jahr ausklingen lassen und das neue m...   \n",
       "4   Vor allem in der Stadt und Agglomeration war d...   \n",
       "..                                                ...   \n",
       "95  Bitte melden Sie sich an! Sie haben noch keine...   \n",
       "96  Wie lange ist die frist bei einer Kündigung? H...   \n",
       "97  Die HAZ hat die Fußballkäfige ausprobiert und ...   \n",
       "98  Anastasiya Avilova zieht im Januar 2020 als Ka...   \n",
       "99  Monica Kissling alias Madame Etoile hat in die...   \n",
       "\n",
       "                                       summary1_text2  \\\n",
       "0   Der frühere Politiker Günther Krause hatte 199...   \n",
       "1   Die deutsche Melodie Bob Geldofs steht in eine...   \n",
       "2   Der in Japan auf Kaution freigelassene frühere...   \n",
       "3   Der deutsche Musiker Léon Berben feiert seine ...   \n",
       "4   Die Polizei hat zwei Verstöße gegen das Feuerw...   \n",
       "..                                                ...   \n",
       "95  Die Polizei hat die Ermittlungen übernommen un...   \n",
       "96  Mindestens 16 Menschen sind kurz vor dem Jahre...   \n",
       "97  In Hannover haben die Bürger das neue Jahr mit...   \n",
       "98  Die Kandidaten für die 14. Staffel \"Ich bin ei...   \n",
       "99  Der US-Präsident lässt am Silvestertag verlaut...   \n",
       "\n",
       "                                       summary2_text2  nb_entites_idem  \\\n",
       "0   Ex - Bundesverkehrsminister Günther Krause, 66...                1   \n",
       "1   In der Weihnachtszeit ist die Zahl der Weihnac...                0   \n",
       "2   Er sei \" nicht länger eine Geisel des manipuli...                3   \n",
       "3   Der Interpret genießt in der festlich erleucht...                0   \n",
       "4   Der Inhalt ist älter als 30 Stunden und steht ...                0   \n",
       "..                                                ...              ...   \n",
       "95  Der Brand in der Ritter - von - Hellberg - Str...                0   \n",
       "96  Die Sicherheitskräfte stellten Waffen sicher -...                0   \n",
       "97  In der Region Hannover haben die Bürger das ne...                0   \n",
       "98  Die Kandidaten für die 14. Staffel \" Ich bin e...                1   \n",
       "99  Der US - Präsident will in den USA den ersten ...                0   \n",
       "\n",
       "    nb_lieux_idem  nb_dates_idem                         entites_idem  ...  \\\n",
       "0               0              0                              ['RTL']  ...   \n",
       "1               0              0                                   []  ...   \n",
       "2               7              0  ['Renault', 'Nissan', 'Mitsubishi']  ...   \n",
       "3               0              0                                   []  ...   \n",
       "4               0              0                                   []  ...   \n",
       "..            ...            ...                                  ...  ...   \n",
       "95              0              0                                   []  ...   \n",
       "96              0              0                                   []  ...   \n",
       "97              0              0                                   []  ...   \n",
       "98              0              0                              ['RTL']  ...   \n",
       "99              1              0                                   []  ...   \n",
       "\n",
       "   score_similarite_titres  score_similarite_resume1  \\\n",
       "0                    94.74                     97.80   \n",
       "1                    84.74                     90.23   \n",
       "2                    78.85                     95.10   \n",
       "3                    96.22                     97.57   \n",
       "4                    80.39                     98.61   \n",
       "..                     ...                       ...   \n",
       "95                   85.23                     69.50   \n",
       "96                   97.85                     96.70   \n",
       "97                   66.62                     96.05   \n",
       "98                   96.37                     94.95   \n",
       "99                   85.77                     83.04   \n",
       "\n",
       "    score_similarite_resume2  score_classif1  score_classif2  \\\n",
       "0                      86.47           20.27           20.27   \n",
       "1                      67.07           96.21           96.21   \n",
       "2                      85.10           11.07           11.07   \n",
       "3                      84.40           16.50           16.50   \n",
       "4                      92.36           90.97           90.97   \n",
       "..                       ...             ...             ...   \n",
       "95                     69.43            4.50            4.50   \n",
       "96                     59.74            0.17            0.17   \n",
       "97                     65.97           90.60           90.60   \n",
       "98                     71.50           53.40           53.40   \n",
       "99                     71.56            0.16            0.16   \n",
       "\n",
       "    score_sentiment1  score_sentiment2  meth1_similarites meth2_similarites  \\\n",
       "0              20.27             20.27               58.5              40.7   \n",
       "1              96.21             96.21               23.8               6.9   \n",
       "2              11.07             11.07              151.5             173.0   \n",
       "3              16.50             16.50                0.0             137.4   \n",
       "4              90.97             90.97               36.1              31.7   \n",
       "..               ...               ...                ...               ...   \n",
       "95              4.50              4.50               68.3              60.2   \n",
       "96              0.17              0.17              146.7              64.0   \n",
       "97             90.60             90.60                  0              27.8   \n",
       "98             53.40             53.40               46.0              62.6   \n",
       "99              0.16              0.16                  0              10.7   \n",
       "\n",
       "   Overall  \n",
       "0        3  \n",
       "1        4  \n",
       "2        1  \n",
       "3        4  \n",
       "4        3  \n",
       "..     ...  \n",
       "95       2  \n",
       "96       1  \n",
       "97       4  \n",
       "98       2  \n",
       "99       4  \n",
       "\n",
       "[100 rows x 21 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visuel = allemand[['title_1', 'title_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2',\n",
    "    'nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "    'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "    'score_sentiment2', 'meth1_similarites', 'meth2_similarites','Overall']]\n",
    "visuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compléments d'information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pair_id', 'pair_lang', 'source_url_1', 'publish_date_1',\n",
       "       'source_url_2', 'publish_date_2', 'title_1', 'text_1',\n",
       "       'meta_description_1', 'meta_keywords_1', 'title_2', 'text_2',\n",
       "       'meta_description_2', 'meta_keywords_2', 'Geography', 'Entities',\n",
       "       'Time', 'Narrative', 'Overall', 'Style', 'Tone', 'ligne'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_francais = data.loc[data.pair_lang == 'fr_fr',['source_url_1', 'publish_date_1','source_url_2', 'publish_date_2', \n",
    "       'meta_description_1', 'meta_keywords_1', 'meta_description_2', 'meta_keywords_2','Overall']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://votreargent.lexpress.fr</td>\n",
       "      <td>Wed Mar 25 20:11:35 2020</td>\n",
       "      <td>https://www.lexpress.fr</td>\n",
       "      <td>Wed Mar 25 07:00:00 2020</td>\n",
       "      <td>Le cap du million de ventes a été dépassé l'an...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Stocks réduits ou distribués au \"compte-goutte...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.coupdoeil.info</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>http://www.lechodelaval.ca</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://ici.radio-canada.ca</td>\n",
       "      <td></td>\n",
       "      <td>https://www.lapresse.ca</td>\n",
       "      <td>Wed Mar 25 05:00:00 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>Des Québécois coincés au Pérou qualifient de «...</td>\n",
       "      <td>['']</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://beninsite.net</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>http://www.togolais.info</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>En l'espace de quelques jours, deux piliers de...</td>\n",
       "      <td>[\"L'Afrique pleure Manu Dibango\", '', 'info', ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.lareleve.qc.ca</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>https://canadianwomen.org</td>\n",
       "      <td>Wed Mar 25 21:15:26 2020</td>\n",
       "      <td>La MRC a décidé de mettre de l’avant différent...</td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>https://www.bladi.net</td>\n",
       "      <td></td>\n",
       "      <td>https://www.bladi.net</td>\n",
       "      <td></td>\n",
       "      <td>Les forces de l’ordre effectuent des inspectio...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>http://ici.radio-canada.ca</td>\n",
       "      <td></td>\n",
       "      <td>https://www.journalexpress.ca</td>\n",
       "      <td>Wed May 27 00:00:00 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>http://fr.nhandan.com.vn</td>\n",
       "      <td></td>\n",
       "      <td>http://fr.nhandan.com.vn</td>\n",
       "      <td></td>\n",
       "      <td>Nhân Dân en ligne - Asiatoday, l'un des princi...</td>\n",
       "      <td>['Le journal Nhân Dân', 'politique', 'économie...</td>\n",
       "      <td>Nhân Dân en ligne - Le Premier ministre (PM) v...</td>\n",
       "      <td>['Le journal Nhân Dân', 'politique', 'économie...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>https://www.acadienouvelle.com</td>\n",
       "      <td>Thu Jun 11 00:00:00 2020</td>\n",
       "      <td>https://www.telecablesat.fr</td>\n",
       "      <td></td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>['Acadie']</td>\n",
       "      <td>Comment avez-vous vécu le confinement?Au début...</td>\n",
       "      <td>['']</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>https://benin24tv.com</td>\n",
       "      <td>Mon Mar  2 18:47:14 2020</td>\n",
       "      <td>https://www.seneplus.com</td>\n",
       "      <td>Sat Mar 28 14:02:20 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>Alors que le directeur de l’Organisation mondi...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source_url_1            publish_date_1  \\\n",
       "0   https://votreargent.lexpress.fr  Wed Mar 25 20:11:35 2020   \n",
       "1        https://www.coupdoeil.info  Wed Mar 25 00:00:00 2020   \n",
       "2        http://ici.radio-canada.ca                             \n",
       "3              http://beninsite.net  Wed Mar 25 00:00:00 2020   \n",
       "4        https://www.lareleve.qc.ca  Wed Mar 25 00:00:00 2020   \n",
       "..                              ...                       ...   \n",
       "67            https://www.bladi.net                             \n",
       "68       http://ici.radio-canada.ca                             \n",
       "69         http://fr.nhandan.com.vn                             \n",
       "70   https://www.acadienouvelle.com  Thu Jun 11 00:00:00 2020   \n",
       "71            https://benin24tv.com  Mon Mar  2 18:47:14 2020   \n",
       "\n",
       "                     source_url_2            publish_date_2  \\\n",
       "0         https://www.lexpress.fr  Wed Mar 25 07:00:00 2020   \n",
       "1      http://www.lechodelaval.ca                             \n",
       "2         https://www.lapresse.ca  Wed Mar 25 05:00:00 2020   \n",
       "3        http://www.togolais.info                             \n",
       "4       https://canadianwomen.org  Wed Mar 25 21:15:26 2020   \n",
       "..                            ...                       ...   \n",
       "67          https://www.bladi.net                             \n",
       "68  https://www.journalexpress.ca  Wed May 27 00:00:00 2020   \n",
       "69       http://fr.nhandan.com.vn                             \n",
       "70    https://www.telecablesat.fr                             \n",
       "71       https://www.seneplus.com  Sat Mar 28 14:02:20 2020   \n",
       "\n",
       "                                   meta_description_1  \\\n",
       "0   Le cap du million de ventes a été dépassé l'an...   \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4   La MRC a décidé de mettre de l’avant différent...   \n",
       "..                                                ...   \n",
       "67  Les forces de l’ordre effectuent des inspectio...   \n",
       "68                                                      \n",
       "69  Nhân Dân en ligne - Asiatoday, l'un des princi...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71                                                      \n",
       "\n",
       "                                      meta_keywords_1  \\\n",
       "0                                                ['']   \n",
       "1                                                ['']   \n",
       "2                                                ['']   \n",
       "3                                                ['']   \n",
       "4                                                ['']   \n",
       "..                                                ...   \n",
       "67                                               ['']   \n",
       "68                                               ['']   \n",
       "69  ['Le journal Nhân Dân', 'politique', 'économie...   \n",
       "70                                         ['Acadie']   \n",
       "71                                               ['']   \n",
       "\n",
       "                                   meta_description_2  \\\n",
       "0   Stocks réduits ou distribués au \"compte-goutte...   \n",
       "1                                                       \n",
       "2   Des Québécois coincés au Pérou qualifient de «...   \n",
       "3   En l'espace de quelques jours, deux piliers de...   \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "67  Suite aux violations du confinement dans les v...   \n",
       "68                                                      \n",
       "69  Nhân Dân en ligne - Le Premier ministre (PM) v...   \n",
       "70  Comment avez-vous vécu le confinement?Au début...   \n",
       "71  Alors que le directeur de l’Organisation mondi...   \n",
       "\n",
       "                                      meta_keywords_2  Overall  \n",
       "0                                                ['']      3.0  \n",
       "1                                                ['']      4.0  \n",
       "2                                                ['']      2.0  \n",
       "3   [\"L'Afrique pleure Manu Dibango\", '', 'info', ...      1.0  \n",
       "4                                                ['']      3.0  \n",
       "..                                                ...      ...  \n",
       "67                                               ['']      3.0  \n",
       "68                                               ['']      3.0  \n",
       "69  ['Le journal Nhân Dân', 'politique', 'économie...      1.0  \n",
       "70                                               ['']      4.0  \n",
       "71                                               ['']      3.0  \n",
       "\n",
       "[72 rows x 9 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_francais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

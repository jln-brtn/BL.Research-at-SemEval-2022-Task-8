{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de classification en Anglais \n",
    "\n",
    "    - Transformers : Summarization : 2 modèles --> 2 Résumés / Puis score de similarités de ces 2 résumés\n",
    "    Noter que l'on peut faire aussi la similarité des textes (autre note ?) et non du résumé\n",
    "    - Text classification sur une base de catégories \"Presse\" : sport - actaulités - économie - etc\n",
    "    - Sentiment analysis : voir si le ton du texte est de même type \n",
    "    - Les 2 derniers classifier seronts utilisés en produit scalaire : Par Catégorie : texte1: note1 - texte2 : note2\n",
    "    et donc sum(notes_par_catégorie) = sum(note1*note2) * 100 au bout (note sur 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pke\n",
    "import spacy\n",
    "import torch\n",
    "import stanza\n",
    "import spacy_stanza\n",
    "import warnings\n",
    "import string\n",
    "from gensim.models import KeyedVectors\n",
    "import enchant    # Pour correction orthographique de synonymes\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection des modèles NLP : ici FRANCAIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement pour l'utilisation de Spacy  - Français\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_spacy = {'en':nlp_en}   # 'en':nlp_en,'de':nlp_de,'es':nlp_es,'pl':nlp_pl  - POUR MEMOIRE\n",
    "langues = ['en','fr','es','de','pl','ar','tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 22.9% 24.0/104.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# Chargement du modèle Word2Vec pour utilisation de synonymes\n",
    "import gensim.downloader\n",
    "model_gensim = gensim.downloader.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords Français NLTK + Spacy \n",
    "stopWords = list(nlp_en.Defaults.stop_words)\n",
    "stopwords_en = list(stopwords.words('english'))  \n",
    "stopwords_en = list(set(stopwords_en + stopWords))\n",
    "stopwds_lg = {'en':stopwords_en}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcteur orthographique pour validation des synonymes OPTIONNEL CAR NON NECESSAIRE\n",
    "d = enchant.Dict(\"en\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection des modèles Transformers : Summary - Text Classification - Sentiment Analysis - Similarity**<br/>\n",
    "    Pour le modèle anglais, on prend 3 summarizer !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2281663a76bb4266aa12062a0d3b4f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261e8d55706a415b9eaff326a509d0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Errno 28] No space left on device\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6025da99d0e4deaa50494f711fcdf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Errno 28] No space left on device\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model google/bigbird-pegasus-large-arxiv with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>, <class 'transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForConditionalGeneration'>).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13392/4016578086.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Modèles Transformers de Résumé (NB : Ne pas oublier d'ajouter la truncation pour tous les modèles, peut être source d'erreur)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msummarizer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"summarization\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"google/bigbird-pegasus-large-arxiv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"only_first\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msummarizer2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"summarization\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"google/pegasus-multi_news\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"only_first\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msummarizer3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"summarization\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sshleifer/distilbart-xsum-12-3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"only_first\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[1;31m# Will load the correct model if possible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[0mmodel_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m     framework, model = infer_framework_load_model(\n\u001b[0m\u001b[0;32m    509\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mmodel_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Could not load model {model} with any of the following classes: {class_tuple}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mframework\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"tf\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TF\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model google/bigbird-pegasus-large-arxiv with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>, <class 'transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForConditionalGeneration'>)."
     ]
    }
   ],
   "source": [
    "# Modèles Transformers de Résumé (NB : Ne pas oublier d'ajouter la truncation pour tous les modèles, peut être source d'erreur)\n",
    "# Visiblement le modèle google/bigbird-pegasus-large-arxiv est trop gros\n",
    "summarizer1 = pipeline(\"summarization\", model=\"google/bigbird-pegasus-large-arxiv\", truncation = \"only_first\")\n",
    "summarizer2 = pipeline(\"summarization\", model=\"google/pegasus-multi_news\", truncation = \"only_first\")\n",
    "summarizer3 = pipeline(\"summarization\", model=\"sshleifer/distilbart-xsum-12-3\", truncation = \"only_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textes classification ou Zero shot classification (permet de chosir nos propres thèmes)\n",
    "text_clf1 = pipeline(\"text-classification\", model = \"joeddav/bart-large-mnli-yahoo-answers\", truncation = \"only_first\")   # 10 actégories, voir hugging face\n",
    "text_clf2 = pipeline('zero-shot-classification', model='cross-encoder/nli-MiniLM2-L6-H768',truncation = \"only_first\")\n",
    "# ces modèles sont zero shot classification : catégories possibles choisies par mes soins (dans la presse)\n",
    "candidate_labels = ['Science', 'Politics', 'Education', 'News', 'Health', 'Technology', 'Society', 'Sport', 'Economy', 'Culture', 'International', 'Environment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DemangeJeremy/4-sentiments-with-flaubert were not used when initializing FlaubertForSequenceClassification: ['transformer.position_ids']\n",
      "- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis : base de 1 à 5 stars\n",
    "sentiment1 = pipeline(\"text-classification\", model = 'nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "# Sur la base des sentiments classiques : joy, anger, suprise, sadness, love, fear\n",
    "sentiment2 = pipeline(\"text-classification\", model = 'bhadresh-savani/distilbert-base-uncased-emotion')\n",
    "\n",
    "# Sur la base des sentiments classiques : NEGATIVE / POSITIVE\n",
    "sentiment3 = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODAGE AVEC SENTENCE TRANSFORMER 2 modfèles et moyenne\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "encoder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "encoder2 = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "def score_similarite(sentence1,sentence2):\n",
    "    # attention, pour que torch fonctionne en dimension sentence1 (et 2) est une liste simple\n",
    "    embed1 = encoder.encode(sentence1, convert_to_tensor=True)\n",
    "    embed2 = encoder.encode(sentence2, convert_to_tensor=True)\n",
    "    embed3 = encoder2.encode(sentence1, convert_to_tensor=True)\n",
    "    embed4 = encoder2.encode(sentence2, convert_to_tensor=True)\n",
    "    return round(float(util.pytorch_cos_sim(embed1,embed2))+float(util.pytorch_cos_sim(embed3,embed4))*100/2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection Data par langues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data_prep_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>pair_lang</th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>title_1</th>\n",
       "      <th>text_1</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>...</th>\n",
       "      <th>text_2</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Style</th>\n",
       "      <th>Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1484084337_1484110209</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>MARTINSBURG, W.Va. — A suspected drunken drive...</td>\n",
       "      <td>Police in West Virginia say a suspected drunke...</td>\n",
       "      <td>['Highway Fatal-DUI-West Virginia', 'Martinsbu...</td>\n",
       "      <td>...</td>\n",
       "      <td>PORT-AU-PRINCE, Haiti — Haitian President Jove...</td>\n",
       "      <td>Haitian President Jovenel Moïse has broken wit...</td>\n",
       "      <td>['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1484396422_1483924666</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.stlucianewsonline.com</td>\n",
       "      <td>Wed Jan  1 21:17:15 2020</td>\n",
       "      <td>https://www.thestar.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...</td>\n",
       "      <td>-</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>['smg2_world', 'smg_europe', 'smg2_news']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1484698254_1483758694</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.teaparty.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.timesofisrael.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>(Breitbart) – President Donald Trump welcomed ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>PALM BEACH, United States — US President Donal...</td>\n",
       "      <td>US president says response to rioting by pro-I...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1576314516_1576455088</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Uber has sold its online food-ordering busines...</td>\n",
       "      <td>Zomato on Tuesday announced it has acquired Ub...</td>\n",
       "      <td>['zomato uber eats business acquisition india ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rapid digitisation and growth in both online b...</td>\n",
       "      <td>The report by Google and Boston Consulting Gro...</td>\n",
       "      <td>['indian online food delivery market to hit us...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484036253_1483894099</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://news.yahoo.com</td>\n",
       "      <td>Wed Jan  1 08:57:59 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>BENGALURU (Reuters) - India has approved its t...</td>\n",
       "      <td>India has approved its third lunar mission mon...</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>1586195445_1598778991</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...</td>\n",
       "      <td>...</td>\n",
       "      <td>BM'den Yemen'de kadınların doğumda ölüm riski ...</td>\n",
       "      <td>BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>1590915424_1590940388</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.aksam.com.tr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['İspanya 1. Futbol Ligi', 'la liga', 'koronav...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>1526157103_1492737005</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.samanyoluhaber.com</td>\n",
       "      <td>Thu Feb 20 10:47:10 2020</td>\n",
       "      <td>https://www.fotomac.com.tr</td>\n",
       "      <td>Sun Jan 12 00:00:00 2020</td>\n",
       "      <td>Saray da çare olmadı: 'Borca boğulan dev kulüp...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...</td>\n",
       "      <td>SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...</td>\n",
       "      <td>['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...</td>\n",
       "      <td>...</td>\n",
       "      <td>TFF, resmi internet sitesinden Beşiktaş'ın fai...</td>\n",
       "      <td>Federasyon, Başkan Çebi’nin yaptığı açıklamala...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>1603274500_1618292937</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...</td>\n",
       "      <td>['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...</td>\n",
       "      <td>...</td>\n",
       "      <td>Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...</td>\n",
       "      <td>Covid-19 salgınından vatandaşların korunması i...</td>\n",
       "      <td>['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>1597247537_1604202164</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.takvim.com.tr</td>\n",
       "      <td>Tue May  5 00:00:00 2020</td>\n",
       "      <td>https://www.yeniasir.com.tr</td>\n",
       "      <td>Tue May 12 00:00:00 2020</td>\n",
       "      <td>Grup Yorum üyeleri zorla başlatmıştı... İbrahi...</td>\n",
       "      <td>DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4964 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pair_id pair_lang                       source_url_1  \\\n",
       "0     1484084337_1484110209     en_en     https://www.washingtonpost.com   \n",
       "1     1484396422_1483924666     en_en  https://www.stlucianewsonline.com   \n",
       "2     1484698254_1483758694     en_en           https://www.teaparty.org   \n",
       "3     1576314516_1576455088     en_en           https://gadgets.ndtv.com   \n",
       "4     1484036253_1483894099     en_en             https://news.yahoo.com   \n",
       "...                     ...       ...                                ...   \n",
       "4959  1586195445_1598778991     tr_tr            http://www.haberler.com   \n",
       "4960  1590915424_1590940388     tr_tr           https://www.haberler.com   \n",
       "4961  1526157103_1492737005     tr_tr      http://www.samanyoluhaber.com   \n",
       "4962  1603274500_1618292937     tr_tr           https://www.haberler.com   \n",
       "4963  1597247537_1604202164     tr_tr          https://www.takvim.com.tr   \n",
       "\n",
       "                publish_date_1                    source_url_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020  https://www.washingtonpost.com   \n",
       "1     Wed Jan  1 21:17:15 2020         https://www.thestar.com   \n",
       "2                          NaN   https://www.timesofisrael.com   \n",
       "3                          NaN        https://gadgets.ndtv.com   \n",
       "4     Wed Jan  1 08:57:59 2020                             NaN   \n",
       "...                        ...                             ...   \n",
       "4959                       NaN        https://www.haberler.com   \n",
       "4960                       NaN        https://www.aksam.com.tr   \n",
       "4961  Thu Feb 20 10:47:10 2020      https://www.fotomac.com.tr   \n",
       "4962                       NaN        https://www.haberler.com   \n",
       "4963  Tue May  5 00:00:00 2020     https://www.yeniasir.com.tr   \n",
       "\n",
       "                publish_date_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020   \n",
       "1     Wed Jan  1 00:00:00 2020   \n",
       "2                          NaN   \n",
       "3                          NaN   \n",
       "4                          NaN   \n",
       "...                        ...   \n",
       "4959                       NaN   \n",
       "4960                       NaN   \n",
       "4961  Sun Jan 12 00:00:00 2020   \n",
       "4962                       NaN   \n",
       "4963  Tue May 12 00:00:00 2020   \n",
       "\n",
       "                                                title_1  \\\n",
       "0     Virginia man arrested in fatal DUI crash in We...   \n",
       "1     Guyana: Three injured after car crashes into u...   \n",
       "2     Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3     Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4     India approves third moon mission, months afte...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  Saray da çare olmadı: 'Borca boğulan dev kulüp...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  Grup Yorum üyeleri zorla başlatmıştı... İbrahi...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     MARTINSBURG, W.Va. — A suspected drunken drive...   \n",
       "1     Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...   \n",
       "2     (Breitbart) – President Donald Trump welcomed ...   \n",
       "3     Uber has sold its online food-ordering busines...   \n",
       "4     BENGALURU (Reuters) - India has approved its t...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  \\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...   \n",
       "\n",
       "                                     meta_description_1  \\\n",
       "0     Police in West Virginia say a suspected drunke...   \n",
       "1                                                     -   \n",
       "2                                                   NaN   \n",
       "3     Zomato on Tuesday announced it has acquired Ub...   \n",
       "4     India has approved its third lunar mission mon...   \n",
       "...                                                 ...   \n",
       "4959  Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...   \n",
       "4962  Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_1  ...  \\\n",
       "0     ['Highway Fatal-DUI-West Virginia', 'Martinsbu...  ...   \n",
       "1                                                  ['']  ...   \n",
       "2                                                  ['']  ...   \n",
       "3     ['zomato uber eats business acquisition india ...  ...   \n",
       "4                                                  ['']  ...   \n",
       "...                                                 ...  ...   \n",
       "4959  ['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...  ...   \n",
       "4960  ['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...  ...   \n",
       "4961  ['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...  ...   \n",
       "4962  ['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...  ...   \n",
       "4963                                               ['']  ...   \n",
       "\n",
       "                                                 text_2  \\\n",
       "0     PORT-AU-PRINCE, Haiti — Haitian President Jove...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     PALM BEACH, United States — US President Donal...   \n",
       "3     Rapid digitisation and growth in both online b...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "4959  BM'den Yemen'de kadınların doğumda ölüm riski ...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  TFF, resmi internet sitesinden Beşiktaş'ın fai...   \n",
       "4962  Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...   \n",
       "4963  Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...   \n",
       "\n",
       "                                     meta_description_2  \\\n",
       "0     Haitian President Jovenel Moïse has broken wit...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     US president says response to rioting by pro-I...   \n",
       "3     The report by Google and Boston Consulting Gro...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "4959  BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  Federasyon, Başkan Çebi’nin yaptığı açıklamala...   \n",
       "4962  Covid-19 salgınından vatandaşların korunması i...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_2 Geography  Entities  \\\n",
       "0     ['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...       4.0  4.000000   \n",
       "1             ['smg2_world', 'smg_europe', 'smg2_news']       4.0  4.000000   \n",
       "2                                                  ['']       1.0  2.000000   \n",
       "3     ['indian online food delivery market to hit us...       1.0  2.333333   \n",
       "4                                                   NaN       1.0  1.250000   \n",
       "...                                                 ...       ...       ...   \n",
       "4959  ['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...       1.0  2.000000   \n",
       "4960  ['İspanya 1. Futbol Ligi', 'la liga', 'koronav...       1.0  1.000000   \n",
       "4961                                               ['']       1.0  2.000000   \n",
       "4962     ['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']       1.0  2.000000   \n",
       "4963                                               ['']       2.0  2.000000   \n",
       "\n",
       "          Time  Narrative   Overall     Style      Tone  \n",
       "0     1.000000   4.000000  4.000000  1.666667  2.000000  \n",
       "1     1.000000   4.000000  3.666667  1.666667  1.333333  \n",
       "2     1.000000   2.333333  2.333333  1.000000  1.333333  \n",
       "3     2.666667   1.666667  2.000000  1.666667  1.666667  \n",
       "4     1.000000   1.250000  1.250000  1.000000  1.000000  \n",
       "...        ...        ...       ...       ...       ...  \n",
       "4959  2.000000   4.000000  3.000000  1.000000  1.000000  \n",
       "4960  1.000000   1.000000  1.000000  1.000000  1.000000  \n",
       "4961  3.000000   4.000000  3.000000  1.000000  2.000000  \n",
       "4962  3.000000   3.000000  3.000000  1.000000  1.000000  \n",
       "4963  1.000000   2.000000  2.000000  3.000000  1.000000  \n",
       "\n",
       "[4964 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remémorer numéro de ligne - compléter les Nan\n",
    "data['ligne'] = data.index\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation des datasets, le dernier étant à traduire en plus\n",
    "anglais = data.loc[data.pair_lang == 'fr_fr',['ligne','title_1','title_2','text_1','text_2','Geography', 'Entities',\n",
    "       'Time', 'Narrative', 'Overall', 'Style', 'Tone']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter aussi le modèle anglais_all_traduit \n",
    "anglais_all_traduit = pd.read_csv('allemand_anglais_traduit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests divers et Fonctions nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus : le chanteur et chanteur camerounais Manu Dibango est décédé\n",
      "Coronavirus : l'Afrique pleure Manu Dibango victime du coronavirus\n"
     ]
    }
   ],
   "source": [
    "# Résumés\n",
    "print(summarizer1(anglais.text_1[3])[0]['summary_text'])\n",
    "print(summarizer1(anglais.text_2[3])[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summarizer2(anglais.text_1[3])[0]['summary_text'])\n",
    "print(summarizer2(anglais.text_2[3])[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atteint par le covid-19, l'artiste camerounais est mort mardi matin des suites de la maladie, à l'âge de 86 ans.\n",
      "En l'espace de quelques jours, deux piliers de la musique du continent sont morts des suites du coronavirus.\n"
     ]
    }
   ],
   "source": [
    "print(summarizer3(anglais.text_1[3])[0]['summary_text'])\n",
    "print(summarizer3(anglais.text_2[3])[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de calcul du score (produit scalaire) pour résultats de classifaction\n",
    "def fonction_produit_dotcom(liste_categor, dico_scores1,dico_scores2):\n",
    "    \"\"\"\"dico scores sont les résultats obtenus pour chaque catégorie des textes 1 et 2\"\"\"\n",
    "    result = 0.0\n",
    "    for cat in liste_categor:\n",
    "        result += round(dico_scores1[cat] * dico_scores2[cat],4)\n",
    "    return result * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type1\n",
    "def transform_text_clf1(liste_dico):\n",
    "    res = {}\n",
    "    for dic in liste_dico:\n",
    "        res[dic['label']] = dic['score']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type2\n",
    "def transform_text_clf2(liste_cat,liste_sc):\n",
    "    res = {}\n",
    "    for i in range(len(liste_cat)):\n",
    "        res[liste_cat[i]] = liste_sc[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Culture': 0.8504540324211121, 'Economie': 0.016547387465834618, 'Education': 0.0012981998734176159, 'Environement': 0.004739915020763874, 'Justice': 0.005226531997323036, 'Opinion': 0.006533971522003412, 'Politique': 0.010109643451869488, 'Societe': 0.09446243196725845, 'Sport': 0.0021014309022575617, 'Technologie': 0.008526437915861607}\n",
      "{'Culture': 0.27542635798454285, 'Economie': 0.01746021956205368, 'Education': 0.014121604152023792, 'Environement': 0.13672736287117004, 'Justice': 0.00473390007391572, 'Opinion': 0.11063723266124725, 'Politique': 0.007973399013280869, 'Societe': 0.13605180382728577, 'Sport': 0.14063476026058197, 'Technologie': 0.1562332957983017}\n",
      "25.039999999999996\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "classes = text_clf1(anglais.text_1[3], candidate_labels)\n",
    "scores1 = transform_text_clf2(classes['labels'],classes['scores'])\n",
    "classes2 = text_clf1(anglais.text_2[3], candidate_labels)\n",
    "scores2 = transform_text_clf2(classes2['labels'],classes2['scores'])\n",
    "print(fonction_produit_dotcom(candidate_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.45\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "classes = text_clf2(anglais.text_1[3], candidate_labels)\n",
    "scores1 = transform_text_clf2(classes['labels'],classes['scores'])\n",
    "classes2 = text_clf2(anglais.text_2[3], candidate_labels)\n",
    "scores2 = transform_text_clf2(classes2['labels'],classes2['scores'])\n",
    "print(fonction_produit_dotcom(candidate_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negative': 0.0010380344465374947, 'Positive': 0.9989619255065918}\n",
      "{'Negative': 0.0012133318232372403, 'Positive': 0.9987866282463074}\n",
      "99.77000000000001\n"
     ]
    }
   ],
   "source": [
    "# Tests sentiment analysis\n",
    "liste_labels = ['1 star','2 stars','3 stars','4 stars','5 stars']\n",
    "scores1 = transform_text_clf1(sentiment1(anglais.text_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(sentiment1(anglais.text_2[3],return_all_scores=True)[0])\n",
    "print(scores1)\n",
    "print(scores2)\n",
    "print(fonction_produit_dotcom(liste_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.889999999999997\n",
      "41.05\n"
     ]
    }
   ],
   "source": [
    "# ATTENTION CE MODELE SE DEFINIT SUR 4 CLASSES : mixed, positif, negatif, objectif\n",
    "liste_sentiments = ['joy','anger','sadness','love','surprise','fear']\n",
    "scores1 = transform_text_clf1(sentiment2(anglais.title_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(sentiment2(anglais.title_2[3],return_all_scores=True)[0])\n",
    "scores3 = transform_text_clf1(sentiment2(anglais.text_1[3],return_all_scores=True)[0])\n",
    "scores4 = transform_text_clf1(sentiment2(anglais.text_2[3],return_all_scores=True)[0])\n",
    "print(fonction_produit_dotcom(liste_sentiments, scores1,scores2))\n",
    "print(fonction_produit_dotcom(liste_sentiments, scores3,scores4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_sentiments2 = ['NEGATIVE','POSITIVE']\n",
    "scores1 = transform_text_clf1(sentiment3(anglais.text_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(sentiment3(anglais.text_2[3],return_all_scores=True)[0])\n",
    "print(scores1)\n",
    "print(scores2)\n",
    "print(fonction_produit_dotcom(liste_sentiments2, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.10126805305481\n",
      "95.87915539741516\n",
      "0.2433039015159011\n",
      "0.5122576840221882\n"
     ]
    }
   ],
   "source": [
    "# TESTS SCORES DE SIMILARITES : Titres, Textes complets (attention Truncation ...)\n",
    "print(score_similarite(anglais.title_1[3],anglais.title_2[3]))\n",
    "print(score_similarite(anglais.text_1[3],anglais.text_2[3]))\n",
    "print(score_similarite(summarizer1(anglais.text_1[0])[0]['summary_text'],summarizer1(anglais.text_2[0])[0]['summary_text']))\n",
    "print(score_similarite(summarizer2(anglais.text_1[0])[0]['summary_text'],summarizer2(anglais.text_2[0])[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('décéder', 0.6537684202194214),\n",
       " ('décé', 0.5344727039337158),\n",
       " ('deces', 0.5302326679229736),\n",
       " ('survenir', 0.5168903470039368),\n",
       " ('accident', 0.5078858137130737),\n",
       " ('surmortalité', 0.4999918043613434),\n",
       " ('obsèque', 0.49124661087989807),\n",
       " ('invalidité', 0.4891868233680725),\n",
       " ('mortalité', 0.48478570580482483),\n",
       " ('défunt', 0.48272594809532166)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essais de synonymies à utiliser pour sorties PKE, termes prinicpaux\n",
    "syns = model_gensim.most_similar(\"death\", topn=10)\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de summarization \n",
    "def summarization(texte):\n",
    "    return summarizer1(texte)[0]['summary_text'], summarizer2(texte)[0]['summary_text'], summarizer3(texte)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_classifiers = {'text_clf1': 'score_classif1','text_clf2':'score_classif2','sentiment1':'score_sentiment1',\n",
    "                    'sentiment2': 'score_sentiment2','sentiment3': 'score_sentiment3'}\n",
    "dico_categories = {'text_clf1': candidate_labels,'text_clf2':candidate_labels,'sentiment1':liste_labels,\n",
    "                    'sentiment2': liste_sentiments,'sentiment3': liste_sentiments2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de classification et sentiment analysis\n",
    "def classification(texte,clf):\n",
    "    # assume nms des claasifiers et methode de transformation\n",
    "    if clf == \"text_clf1\":\n",
    "        try:\n",
    "            classes = text_clf1(texte,dico_categories['text_clf1'])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"text_clf2\":                                 \n",
    "        try:\n",
    "            classes = text_clf2(texte,dico_categories['text_clf2'])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return transform_text_clf2(classes['labels'],classes['scores'])                          \n",
    "    elif clf == \"sentiment1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"sentiment2\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment2(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    else:\n",
    "        return 'error'\n",
    "    elif clf == \"sentiment3\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment3(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    else:\n",
    "        return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des mots de moins de 2 lettres non numériques\n",
    "def supp_moins_2_lettres_stopwords(phrase,stopwd):\n",
    "    temp = phrase.split(' ')\n",
    "    res = ''\n",
    "    for mot in temp:\n",
    "        if mot not in stopwd and (len(mot)>2 or (len(mot)>0 and mot[0] in ['0','1','2','3','4','5','6','7','8','9'])):\n",
    "            res += mot + ' '\n",
    "    return res[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des traits d'union(regroupe)/ des apostrophes / ponctuations\n",
    "def modif(texte,stopmots):\n",
    "    # modifications simples des textes : ponctuations, petits mots, stopwords (à faire pour entités et pke textes)\n",
    "    texte=re.sub('\\'',' ',texte)   # suppression apostrophe\n",
    "    texte=re.sub('-','',texte)    # suppression trait union\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation)) # suppression de toutes les ponctuations\n",
    "    texte=regex.sub(' ',texte)\n",
    "    texte = supp_moins_2_lettres_stopwords(texte,stopmots)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des synonymes (existants en orthographe) à la suite de l'analyse pke\n",
    "def ajout_synonymes(mot, correct_ortho = True):\n",
    "    # on ajoute les 10 premiers synonymes existants, on vérifie orthographe (optionnel)\n",
    "    syns = model_gensim.most_similar(mot,topn = 20)\n",
    "    if correct_ortho == True:\n",
    "        res = []\n",
    "        for m in syns:\n",
    "            if d.check(m[0]):   #  il y a le mot et son pourcentage d'importance\n",
    "                res.append(m)\n",
    "        syns = res\n",
    "    return syns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la bonne méthodologie à appliquer PKE ??? : Noms Ok - Verbes ? - Adjectifs ? - Noms propres ?\n",
    "Quelle quantité de mots prendre ?\n",
    "Ne pas noter les titres seuls ? : trop peu de mots !  Et du coup note peut être forte avec un seul mot !\n",
    "Supprimer en en-tête les stopwords, ponctuation, les apostrophes - AUTRES ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres de la méthode : A revoir ?\n",
    "methode1 = {\"NOUN\", \"PROPN\", \"ADJ\",\"VERB\"}\n",
    "methode2 = {\"NOUN\", \"PROPN\", \"ADJ\"}\n",
    "nb_mots = {'meth1': 30, 'meth2':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKE : Analyse des termes principaux dans les textes et titres \n",
    "# Problème \n",
    "def transformation_pke_results(res1,res2, correct_ortho = True):\n",
    "    \"\"\"\n",
    "    Transformation des resultats de PKE : Pb bigramme peuvent ne pas être ds les 2 textes mais 1 mot seulement\n",
    "    liste de clés et dictionnaires de valeurs, bigrammes jouera ainsi de maniere coefficientée \n",
    "    Exemple : fuite eau:0.05 --> 3 mots au final : fuite, eau, fuite eau : 0.05\n",
    "    De plus on ajoute les synonymes issus de gensim en les coefficiant et vérifiant que cela \"\"\"\n",
    "    \n",
    "    liste1 = []; liste2 = [] ; dico1 = {}; dico2 = {}\n",
    "    for elt in res1:\n",
    "        liste1.append(elt[0])\n",
    "        dico1[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:    # bigramme dans ce cas, ajout des 2 mots\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste1.append(mot)\n",
    "                dico1[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste1.append(syn[0])   # Ajout du mot \n",
    "                        dico1[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "                    \n",
    "    for elt in res2:\n",
    "        liste2.append(elt[0])\n",
    "        dico2[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste2.append(mot)\n",
    "                dico2[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste2.append(syn[0])   # Ajout du mot \n",
    "                        dico2[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "    \n",
    "    # similarites entre les 2 listes issus de pke avec poids\n",
    "    sim = 0\n",
    "    for elt in liste1:\n",
    "        if elt in liste2:\n",
    "            sim += (dico1[elt] + dico2[elt])/2\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entites_communes(nlp,text1,text2):\n",
    "    \"\"\"\"\n",
    "    Cette première fonction ne regarde que les entités communes : personnes, dates, groupe, localisations\n",
    "    Elle sera appliquée aux textes et aux titres et cumulé : si cumul en titre et texte : compte double !\"\"\"\n",
    "    \n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    nb_commun_ent = 0; liste_commun_ent = []\n",
    "    nb_commun_geo = 0; liste_commun_geo = []\n",
    "    nb_commun_dat = 0; liste_commun_dat = []\n",
    "    \n",
    "    if len(doc1.ents)>0 and len(doc2.ents)>0:\n",
    "        liste1 = []; dico1 = {}\n",
    "        for elt in doc1.ents:\n",
    "            if elt.label_ == 'PERSON' and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste1:\n",
    "                        liste1.append(mot)\n",
    "                        dico1[mot] = elt.label_\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste1:\n",
    "                    liste1.append(elt.text)\n",
    "                    dico1[elt.text] = elt.label_\n",
    "        liste2 = []\n",
    "        for elt in doc2.ents:\n",
    "            if elt.label_ == 'PERSON' and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste2:\n",
    "                        liste2.append(mot)\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste2:\n",
    "                    liste2.append(elt.text)\n",
    "        \n",
    "        # points communs des listes        \n",
    "        for elt in liste1:\n",
    "            if elt in liste2:\n",
    "                if dico1[elt] == 'LOC':\n",
    "                    nb_commun_geo += 1\n",
    "                    liste_commun_geo.append(elt)\n",
    "                elif dico1[elt] in ['DATE','TIME']:\n",
    "                    nb_commun_dat += 1\n",
    "                    liste_commun_dat.append(elt)\n",
    "                else:\n",
    "                    nb_commun_ent += 1\n",
    "                    liste_commun_ent.append(elt)\n",
    "                    \n",
    "    return nb_commun_ent, liste_commun_ent,nb_commun_geo, liste_commun_geo,nb_commun_dat, liste_commun_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Creation_features_comparaison(df,langue, test_position = [methode1,methode2]):\n",
    "    \"\"\"Création des notes pour classification ensuite\"\"\"\n",
    "    \n",
    "    resultats = pd.DataFrame(columns = ['summary1_text1','summary2_text1','summary3_text1','summary1_text2','summary2_text2','summary3_text2',\n",
    "            'nb_entites_idem','nb_lieux_idem', 'nb_dates_idem','entites_idem','lieux_idem','dates_idem',\n",
    "            'score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_similarite_resume3','score_classif1','score_classif2',\n",
    "            'score_sentiment1','score_sentiment2','score_sentiment3','meth1_similarites','meth2_similarites'])\n",
    "    \n",
    "    # initialisation de la langue stanza\n",
    "    stanza.download(langue)\n",
    "    nlp_stanza = spacy_stanza.load_pipeline(langue)\n",
    "    stopmts = stopwds_lg[langue]\n",
    "    if langue in dico_spacy.keys():\n",
    "        nlp_spacy = dico_spacy[langue]\n",
    "    else:\n",
    "        nlp_spacy = None\n",
    "        \n",
    "    for i in tqdm(range(len(df))):\n",
    "        dico_res = {}\n",
    "        \n",
    "        # Summary et comparatifs \n",
    "        dico_res['summary1_text1'],dico_res['summary2_text1'],dico_res['summary3_text1'] = summarization(df.text_1[i])\n",
    "        dico_res['summary1_text2'],dico_res['summary2_text2'],dico_res['summary3_text2'] = summarization(df.text_2[i])\n",
    "        dico_res['score_similarite_titres'] = score_similarite(df.title_1[i],df.title_2[i])\n",
    "        dico_res['score_similarite_resume1'] = score_similarite(dico_res['summary1_text1'],dico_res['summary1_text2'])\n",
    "        dico_res['score_similarite_resume2'] = score_similarite(dico_res['summary2_text1'],dico_res['summary2_text2'])\n",
    "        dico_res['score_similarite_resume3'] = score_similarite(dico_res['summary3_text1'],dico_res['summary3_text2'])\n",
    "        \n",
    "        # analyse de textes classification et de sentiments\n",
    "        texte1 = df.title_1[i] + ' ' + df.text_1[i]\n",
    "        texte2 = df.title_2[i] + ' ' + df.text_2[i]\n",
    "        if len(texte1)>0 and len(texte2)>0:\n",
    "            for classifier in dico_classifiers.keys():\n",
    "                scores1 = classification(texte1,classifier)\n",
    "                scores2 = classification(texte2,classifier)\n",
    "                if scores1 != 'error' and scores2 != 'error':\n",
    "                    dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                else:\n",
    "                    scores1 = classification(df.title_1[i],classifier)\n",
    "                    scores2 = classification(df.title_2[i],classifier)\n",
    "                    if scores1 != 'error' and scores2 != 'error':\n",
    "                        dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                    else:\n",
    "                        dico_res[dico_classifiers[classifier]] = None\n",
    "                \n",
    "        # pré traitement des textes pour entités et PKE\n",
    "        texte1 = modif(texte1, stopmts)\n",
    "        texte2 = modif(texte2, stopmts)\n",
    "        \n",
    "        # ENTITES COMMUNES : on tient compte des bigrammes Noms qui posent erreurs ex: Joe Biden et Biden \n",
    "        # Ici, on considère mieux le CUMUl titres et Textes avec une pondération double pour le titre \n",
    "        # Il faut aussi enlever les petits mots donc pré-traitement en texte\n",
    "        \n",
    "        nb_ent1,list_ent1,nb_geo1,list_geo1,nb_dat1,list_dat1 = entites_communes(nlp_stanza,df.title_1[i],df.title_2[i])\n",
    "        nb_ent2,list_ent2,nb_geo2,list_geo2,nb_dat2,list_dat2 = entites_communes(nlp_stanza,df.text_1[i],df.text_2[i])\n",
    "        if nlp_spacy != None:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = entites_communes(nlp_spacy,df.title_1[i],df.title_2[i])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = entites_communes(nlp_spacy,df.text_1[i],df.text_2[i])\n",
    "        else:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = (0,[],0,[],0,[])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = (0,[],0,[],0,[])\n",
    "        dico_res['nb_entites_idem'] = nb_ent1 * 2 + nb_ent2 + nb_ent3 * 2 + nb_ent4\n",
    "        dico_res['nb_lieux_idem'] = nb_geo1  * 2 + nb_geo2 + nb_geo3  * 2 + nb_geo4\n",
    "        dico_res['nb_dates_idem'] = nb_dat1 * 2 + nb_dat2 + nb_dat3 * 2 + nb_dat4\n",
    "        # fusion des listes en supprimant les doublons\n",
    "        dico_res['entites_idem'] = list(set(list_ent1+list_ent2+ list_ent3+list_ent4))\n",
    "        dico_res['lieux_idem'] = list(set(list_geo1+list_geo2+list_geo3+list_geo4))\n",
    "        dico_res['dates_idem'] = list(set(list_dat1+list_dat2+list_dat3+list_dat4))\n",
    "        \n",
    "        for j,meth in enumerate(test_position):\n",
    "            nom ='meth'+str(j+1)\n",
    "            nb_mots_meth = nb_mots[nom]\n",
    "            if len(texte1)>0 and len(texte2)>0:\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte1,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases3 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte2,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases4 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                dico_res[nom+'_similarites'] = round(100*transformation_pke_results(keyphrases3,keyphrases4),1)\n",
    "            else:\n",
    "                dico_res[nom+'_similarites'] = 'Error'\n",
    "        \n",
    "        resultats.loc[len(resultats)] = dico_res\n",
    "        \n",
    "    newdf = pd.concat([df,resultats],axis=1)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention, problème de mémoire : faire par steps de 200, voir pb (peut arriver sur certains textes pourris)\n",
    "similarites = Creation_features_comparaison(anglais[:200].reset_index(drop=True),'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#similarites.to_csv('corpus_en_notes.csv')   # A Utiliser pour le premier\n",
    "precedent = pd.read_csv('corpus_en_notes.csv',index_col=0)\n",
    "similarites2 = pd.concat([precedent,similarites], axis=0)\n",
    "similarites2 = similarites2.reset_index(drop=True)\n",
    "similarites2.to_csv('corpus_en_notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifivation concat\n",
    "precedent = pd.read_csv('corpus_en_notes.csv',index_col=0)\n",
    "precedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention, problème de mémoire : faire par steps de 200, voir pb (peut arriver sur certains textes pourris)\n",
    "similarites = Creation_features_comparaison(anglais_all_traduit[:200].reset_index(drop=True),'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarites.to_csv('corpus_en_notes.csv')   # A Utiliser pour le premier\n",
    "precedent = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "similarites2 = pd.concat([precedent,similarites], axis=0)\n",
    "similarites2 = similarites2.reset_index(drop=True)\n",
    "similarites2.to_csv('corpus_en_de_notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifivation concat\n",
    "precedent = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "precedent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = pd.read_csv('corpus_en_notes.csv',index_col=0)\n",
    "anglais2 = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "anglais = pd.concat([anglais,anglais2],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>...</th>\n",
       "      <th>dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus et confinement : la nouvelle attes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le décret n° 2020–293 du 23 mars 2020 prescriv...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>16.549815</td>\n",
       "      <td>1.566217</td>\n",
       "      <td>5.871220</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.52</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>98.656267</td>\n",
       "      <td>99.788433</td>\n",
       "      <td>99.734575</td>\n",
       "      <td>21.02</td>\n",
       "      <td>21.02</td>\n",
       "      <td>21.02</td>\n",
       "      <td>21.02</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amérique latine. Luis Almagro à la tête de l’O...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pas de trêve pour les basses œuvres. Malgré la...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>6.548393</td>\n",
       "      <td>0.363918</td>\n",
       "      <td>0.143218</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.08</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3460</td>\n",
       "      <td>Un policier impliqué dans le meurtre de George...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L’un des quatre policiers impliqués dans le me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>9.102526</td>\n",
       "      <td>25.414255</td>\n",
       "      <td>5.925642</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3464</td>\n",
       "      <td>Décès des petites Lila et Adélaïde : l’auteur ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le 3 avril 2018, Lila, 3 ans et demi, et Adéla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>46.629348</td>\n",
       "      <td>77.575225</td>\n",
       "      <td>3.172508</td>\n",
       "      <td>6.06</td>\n",
       "      <td>6.06</td>\n",
       "      <td>6.06</td>\n",
       "      <td>6.06</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ligne                                            title_1  \\\n",
       "13   2330                                                NaN   \n",
       "14   2331                                                NaN   \n",
       "25   2357                                                NaN   \n",
       "48   3460  Un policier impliqué dans le meurtre de George...   \n",
       "52   3464  Décès des petites Lila et Adélaïde : l’auteur ...   \n",
       "\n",
       "                                              title_2  \\\n",
       "13  Coronavirus et confinement : la nouvelle attes...   \n",
       "14                                                NaN   \n",
       "25  Amérique latine. Luis Almagro à la tête de l’O...   \n",
       "48                                                NaN   \n",
       "52                                                NaN   \n",
       "\n",
       "                                               text_1  \\\n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "25                                                NaN   \n",
       "48  L’un des quatre policiers impliqués dans le me...   \n",
       "52  Le 3 avril 2018, Lila, 3 ans et demi, et Adéla...   \n",
       "\n",
       "                                               text_2  Geography  Entities  \\\n",
       "13  Le décret n° 2020–293 du 23 mars 2020 prescriv...        4.0       4.0   \n",
       "14                                                NaN        4.0       4.0   \n",
       "25  Pas de trêve pour les basses œuvres. Malgré la...        1.0       2.0   \n",
       "48                                                NaN        1.0       2.0   \n",
       "52                                                NaN        1.0       1.0   \n",
       "\n",
       "    Time  Narrative  Overall  ...  dates_idem  score_similarite_titres  \\\n",
       "13   1.0        4.0      4.0  ...          []                16.549815   \n",
       "14   2.0        4.0      4.0  ...          []                98.656267   \n",
       "25   2.0        2.0      2.0  ...          []                 6.548393   \n",
       "48   3.0        3.0      3.0  ...          []                 9.102526   \n",
       "52   1.0        1.0      1.0  ...          []                46.629348   \n",
       "\n",
       "   score_similarite_resume1 score_similarite_resume2 score_classif1  \\\n",
       "13                 1.566217                 5.871220           7.52   \n",
       "14                99.788433                99.734575          21.02   \n",
       "25                 0.363918                 0.143218           8.08   \n",
       "48                25.414255                 5.925642           7.33   \n",
       "52                77.575225                 3.172508           6.06   \n",
       "\n",
       "   score_classif2  score_sentiment1  score_sentiment2  meth1_similarites  \\\n",
       "13           7.52              7.52              7.52              Error   \n",
       "14          21.02             21.02             21.02              Error   \n",
       "25           8.08              8.08              8.08              Error   \n",
       "48           7.33              7.33              7.33              Error   \n",
       "52           6.06              6.06              6.06              Error   \n",
       "\n",
       "   meth2_similarites  \n",
       "13             Error  \n",
       "14             Error  \n",
       "25             Error  \n",
       "48             Error  \n",
       "52             Error  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention certains textes ne sont pas fournies et donc mis en \"Error\" : A supprimer donc\n",
    "# On pourrait éventuellement tester en ne prenant plus les meth similarités ds les predicteurs\n",
    "anglais = anglais[anglais.meth1_similarites!='Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = anglais.round({'Geography':0, 'Entities':0,'Time':0, 'Narrative':0, 'Overall':0, 'Style':0, 'Tone':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "partiel = anglais[['Geography', 'Entities','Time', 'Narrative', 'Overall', 'Style', 'Tone']].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "anglais = pd.concat([francais[['ligne', 'title_1', 'title_2', 'text_1', 'text_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2']],\n",
    "        partiel,francais[['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "       'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "       'score_sentiment2', 'meth1_similarites', 'meth2_similarites']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>summary1_text1</th>\n",
       "      <th>summary2_text1</th>\n",
       "      <th>summary1_text2</th>\n",
       "      <th>summary2_text2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>...</th>\n",
       "      <th>dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2317</td>\n",
       "      <td>L'euphorie du marché résistera-t-elle au coron...</td>\n",
       "      <td>De nombreux médecins toujours sans masques, ma...</td>\n",
       "      <td>Le cap du million de ventes a été dépassé l'an...</td>\n",
       "      <td>Stocks réduits ou distribués au \"compte-goutte...</td>\n",
       "      <td>Immobilier : le cap du million de ventes dépas...</td>\n",
       "      <td>L'empressement des acheteurs à devenir proprié...</td>\n",
       "      <td>Coronavirus : les soignants manquent toujours ...</td>\n",
       "      <td>Les soignants français manquent toujours de ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.257540</td>\n",
       "      <td>0.243304</td>\n",
       "      <td>0.512258</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.90</td>\n",
       "      <td>164.8</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2318</td>\n",
       "      <td>Clarenceville: Alexandre et Ilana Dupont n’iro...</td>\n",
       "      <td>COVID-19 : le fédéral donnera 2 000 $ par mois...</td>\n",
       "      <td>SPORTS – La majorité des activités sportives d...</td>\n",
       "      <td>Cette nuit, la Chambre des communes a adopté l...</td>\n",
       "      <td>Coronavirus : le Canada n'enverrait pas ses at...</td>\n",
       "      <td>La majorité des activités sportives de la plan...</td>\n",
       "      <td>Canada : 82 G d'aide d'urgence pour les Canadiens</td>\n",
       "      <td>Cette nuit, la Chambre des communes a adopté l...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.562345</td>\n",
       "      <td>0.345925</td>\n",
       "      <td>0.688642</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>160.8</td>\n",
       "      <td>84.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2319</td>\n",
       "      <td>Deux retraités matanais sont coincés en Équateur</td>\n",
       "      <td>L'opération de rapatriement est un «fiasco», d...</td>\n",
       "      <td>Deux Matanais, Hélène Gagnon et Clarence Bouff...</td>\n",
       "      <td>Sarah Mahu est coincée au Pérou. Elle a réussi...</td>\n",
       "      <td>Coronavirus : des Canadiens coincés en Équateu...</td>\n",
       "      <td>Un couple de Québécois, coincés en Équateur, a...</td>\n",
       "      <td>Coronavirus : des Québécois coincés au Pérou q...</td>\n",
       "      <td>Un mois après la proclamation de l'état d'urge...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.865864</td>\n",
       "      <td>0.165310</td>\n",
       "      <td>3.719397</td>\n",
       "      <td>34.85</td>\n",
       "      <td>34.85</td>\n",
       "      <td>34.85</td>\n",
       "      <td>34.85</td>\n",
       "      <td>136.0</td>\n",
       "      <td>234.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2320</td>\n",
       "      <td>Coronavirus : le musicien et chanteur cameroun...</td>\n",
       "      <td>L'Afrique pleure Manu Dibango, victime du coro...</td>\n",
       "      <td>Atteint par le covid-19, l’artiste camerounais...</td>\n",
       "      <td>L'Afrique pleure Manu Dibango, victime du coro...</td>\n",
       "      <td>Coronavirus : le chanteur et chanteur cameroun...</td>\n",
       "      <td>Atteint par le covid-19, l'artiste camerounais...</td>\n",
       "      <td>Coronavirus : l'Afrique pleure Manu Dibango vi...</td>\n",
       "      <td>En l'espace de quelques jours, deux piliers de...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>69.101268</td>\n",
       "      <td>54.083824</td>\n",
       "      <td>73.070240</td>\n",
       "      <td>35.05</td>\n",
       "      <td>35.05</td>\n",
       "      <td>35.05</td>\n",
       "      <td>35.05</td>\n",
       "      <td>148.4</td>\n",
       "      <td>134.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2321</td>\n",
       "      <td>La MRC de Marguerite-D’Youville prend les gran...</td>\n",
       "      <td>Le travail inquiétant des femmes dans la pandé...</td>\n",
       "      <td>C’est dans le cadre de la crise générée par la...</td>\n",
       "      <td>Pour la version anglais, cliquez ici. / For th...</td>\n",
       "      <td>Crise de la Covid-19 : la MRC de Marguerite-D’...</td>\n",
       "      <td>Dans le cadre de la crise générée par la COVID...</td>\n",
       "      <td>Coronavirus : les femmes sont nettement plus i...</td>\n",
       "      <td>Pour lutter contre la pauvreté et les inégalit...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.536262</td>\n",
       "      <td>6.568666</td>\n",
       "      <td>7.904146</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.27</td>\n",
       "      <td>107.4</td>\n",
       "      <td>117.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4879</td>\n",
       "      <td>Maroc : la location aux touristes interdite</td>\n",
       "      <td>Maroc : la justice ouvre une enquête pour viol...</td>\n",
       "      <td>Les forces de l’ordre effectuent des inspectio...</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>Maroc : la police inspecte les appartements de...</td>\n",
       "      <td>Les forces de l'ordre effectuent des inspectio...</td>\n",
       "      <td>Confinement : le parquet de Tanger ouvre une e...</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.525972</td>\n",
       "      <td>2.350808</td>\n",
       "      <td>1.427066</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.06</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4880</td>\n",
       "      <td>Loi sur la relance : l'opposition « à plus de ...</td>\n",
       "      <td>10Â 000 prÃ©posÃ©s aux bÃ©nÃ©ficiaires recherc...</td>\n",
       "      <td>Deux journées de commission parlementaire n'au...</td>\n",
       "      <td>CORONAVIRUS. QuÃ©bec veut lancer une opÃ©ratio...</td>\n",
       "      <td>Projet de loi 61 : l'opposition accuse le gouv...</td>\n",
       "      <td>Le projet de loi sur la relance de l'économie ...</td>\n",
       "      <td>Qubec : 10 000 prposs aux bnficiaires, annonce...</td>\n",
       "      <td>Le gouvernement souhaite que les militaires de...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.025582</td>\n",
       "      <td>0.605789</td>\n",
       "      <td>0.211583</td>\n",
       "      <td>14.24</td>\n",
       "      <td>14.24</td>\n",
       "      <td>14.24</td>\n",
       "      <td>14.24</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4881</td>\n",
       "      <td>Média sud-coréen : “Avec le rôle de président ...</td>\n",
       "      <td>Le 36e Sommet de l’ASEAN couronné de succès</td>\n",
       "      <td>En 2020, le Vietnam assume un double rôle de p...</td>\n",
       "      <td>Le chef du gouvernement vietnamien, qui est ég...</td>\n",
       "      <td>Le Vietnam devient président de l'ASEAN et mem...</td>\n",
       "      <td>En 2020, le Vietnam devient un double rôle de ...</td>\n",
       "      <td>Le Vietnam salue le succès du Sommet de l'ASEA...</td>\n",
       "      <td>Le chef du gouvernement vietnamien, qui est ég...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.696385</td>\n",
       "      <td>6.677561</td>\n",
       "      <td>9.799521</td>\n",
       "      <td>93.14</td>\n",
       "      <td>93.14</td>\n",
       "      <td>93.14</td>\n",
       "      <td>93.14</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4882</td>\n",
       "      <td>Adieu à Muriel Roy</td>\n",
       "      <td>«Les pouvoirs extraordinaire du corps humain»:...</td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>Comment avez-vous vécu le confinement?\\n\\nAu d...</td>\n",
       "      <td>Muriel Roy est décédée à l'âge de 100 ans</td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>Comment avez-vous vécu le confinement?</td>\n",
       "      <td>C'est à voir. Le 3 mars, on avait des pseudo-c...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.246647</td>\n",
       "      <td>8.124105</td>\n",
       "      <td>27.358809</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4883</td>\n",
       "      <td>Congo : des experts africains formés à Brazzav...</td>\n",
       "      <td>«EN AFRIQUE, L’EVOLUTION DE LA PANDEMIE EST TR...</td>\n",
       "      <td>Congo : des experts africains formés à Brazzav...</td>\n",
       "      <td>Alors que le directeur de l’Organisation mondi...</td>\n",
       "      <td>Coronavirus : des experts africains formés à B...</td>\n",
       "      <td>Des professionnels de santé de 24 pays d'Afriq...</td>\n",
       "      <td>Coronavirus : l'Afrique «très préoccupante» av...</td>\n",
       "      <td>La directrice Afrique de l'Organisation mondia...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.380968</td>\n",
       "      <td>2.075366</td>\n",
       "      <td>15.512067</td>\n",
       "      <td>26.10</td>\n",
       "      <td>26.10</td>\n",
       "      <td>26.10</td>\n",
       "      <td>26.10</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ligne                                            title_1  \\\n",
       "0    2317  L'euphorie du marché résistera-t-elle au coron...   \n",
       "1    2318  Clarenceville: Alexandre et Ilana Dupont n’iro...   \n",
       "2    2319   Deux retraités matanais sont coincés en Équateur   \n",
       "3    2320  Coronavirus : le musicien et chanteur cameroun...   \n",
       "4    2321  La MRC de Marguerite-D’Youville prend les gran...   \n",
       "..    ...                                                ...   \n",
       "67   4879        Maroc : la location aux touristes interdite   \n",
       "68   4880  Loi sur la relance : l'opposition « à plus de ...   \n",
       "69   4881  Média sud-coréen : “Avec le rôle de président ...   \n",
       "70   4882                                 Adieu à Muriel Roy   \n",
       "71   4883  Congo : des experts africains formés à Brazzav...   \n",
       "\n",
       "                                              title_2  \\\n",
       "0   De nombreux médecins toujours sans masques, ma...   \n",
       "1   COVID-19 : le fédéral donnera 2 000 $ par mois...   \n",
       "2   L'opération de rapatriement est un «fiasco», d...   \n",
       "3   L'Afrique pleure Manu Dibango, victime du coro...   \n",
       "4   Le travail inquiétant des femmes dans la pandé...   \n",
       "..                                                ...   \n",
       "67  Maroc : la justice ouvre une enquête pour viol...   \n",
       "68  10Â 000 prÃ©posÃ©s aux bÃ©nÃ©ficiaires recherc...   \n",
       "69        Le 36e Sommet de l’ASEAN couronné de succès   \n",
       "70  «Les pouvoirs extraordinaire du corps humain»:...   \n",
       "71  «EN AFRIQUE, L’EVOLUTION DE LA PANDEMIE EST TR...   \n",
       "\n",
       "                                               text_1  \\\n",
       "0   Le cap du million de ventes a été dépassé l'an...   \n",
       "1   SPORTS – La majorité des activités sportives d...   \n",
       "2   Deux Matanais, Hélène Gagnon et Clarence Bouff...   \n",
       "3   Atteint par le covid-19, l’artiste camerounais...   \n",
       "4   C’est dans le cadre de la crise générée par la...   \n",
       "..                                                ...   \n",
       "67  Les forces de l’ordre effectuent des inspectio...   \n",
       "68  Deux journées de commission parlementaire n'au...   \n",
       "69  En 2020, le Vietnam assume un double rôle de p...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71  Congo : des experts africains formés à Brazzav...   \n",
       "\n",
       "                                               text_2  \\\n",
       "0   Stocks réduits ou distribués au \"compte-goutte...   \n",
       "1   Cette nuit, la Chambre des communes a adopté l...   \n",
       "2   Sarah Mahu est coincée au Pérou. Elle a réussi...   \n",
       "3   L'Afrique pleure Manu Dibango, victime du coro...   \n",
       "4   Pour la version anglais, cliquez ici. / For th...   \n",
       "..                                                ...   \n",
       "67  Suite aux violations du confinement dans les v...   \n",
       "68  CORONAVIRUS. QuÃ©bec veut lancer une opÃ©ratio...   \n",
       "69  Le chef du gouvernement vietnamien, qui est ég...   \n",
       "70  Comment avez-vous vécu le confinement?\\n\\nAu d...   \n",
       "71  Alors que le directeur de l’Organisation mondi...   \n",
       "\n",
       "                                       summary1_text1  \\\n",
       "0   Immobilier : le cap du million de ventes dépas...   \n",
       "1   Coronavirus : le Canada n'enverrait pas ses at...   \n",
       "2   Coronavirus : des Canadiens coincés en Équateu...   \n",
       "3   Coronavirus : le chanteur et chanteur cameroun...   \n",
       "4   Crise de la Covid-19 : la MRC de Marguerite-D’...   \n",
       "..                                                ...   \n",
       "67  Maroc : la police inspecte les appartements de...   \n",
       "68  Projet de loi 61 : l'opposition accuse le gouv...   \n",
       "69  Le Vietnam devient président de l'ASEAN et mem...   \n",
       "70          Muriel Roy est décédée à l'âge de 100 ans   \n",
       "71  Coronavirus : des experts africains formés à B...   \n",
       "\n",
       "                                       summary2_text1  \\\n",
       "0   L'empressement des acheteurs à devenir proprié...   \n",
       "1   La majorité des activités sportives de la plan...   \n",
       "2   Un couple de Québécois, coincés en Équateur, a...   \n",
       "3   Atteint par le covid-19, l'artiste camerounais...   \n",
       "4   Dans le cadre de la crise générée par la COVID...   \n",
       "..                                                ...   \n",
       "67  Les forces de l'ordre effectuent des inspectio...   \n",
       "68  Le projet de loi sur la relance de l'économie ...   \n",
       "69  En 2020, le Vietnam devient un double rôle de ...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71  Des professionnels de santé de 24 pays d'Afriq...   \n",
       "\n",
       "                                       summary1_text2  \\\n",
       "0   Coronavirus : les soignants manquent toujours ...   \n",
       "1   Canada : 82 G d'aide d'urgence pour les Canadiens   \n",
       "2   Coronavirus : des Québécois coincés au Pérou q...   \n",
       "3   Coronavirus : l'Afrique pleure Manu Dibango vi...   \n",
       "4   Coronavirus : les femmes sont nettement plus i...   \n",
       "..                                                ...   \n",
       "67  Confinement : le parquet de Tanger ouvre une e...   \n",
       "68  Qubec : 10 000 prposs aux bnficiaires, annonce...   \n",
       "69  Le Vietnam salue le succès du Sommet de l'ASEA...   \n",
       "70             Comment avez-vous vécu le confinement?   \n",
       "71  Coronavirus : l'Afrique «très préoccupante» av...   \n",
       "\n",
       "                                       summary2_text2  Geography  ...  \\\n",
       "0   Les soignants français manquent toujours de ma...          1  ...   \n",
       "1   Cette nuit, la Chambre des communes a adopté l...          3  ...   \n",
       "2   Un mois après la proclamation de l'état d'urge...          3  ...   \n",
       "3   En l'espace de quelques jours, deux piliers de...          1  ...   \n",
       "4   Pour lutter contre la pauvreté et les inégalit...          3  ...   \n",
       "..                                                ...        ...  ...   \n",
       "67  Suite aux violations du confinement dans les v...          2  ...   \n",
       "68  Le gouvernement souhaite que les militaires de...          1  ...   \n",
       "69  Le chef du gouvernement vietnamien, qui est ég...          1  ...   \n",
       "70  C'est à voir. Le 3 mars, on avait des pseudo-c...          4  ...   \n",
       "71  La directrice Afrique de l'Organisation mondia...          3  ...   \n",
       "\n",
       "    dates_idem  score_similarite_titres  score_similarite_resume1  \\\n",
       "0           []                 3.257540                  0.243304   \n",
       "1           []                 0.562345                  0.345925   \n",
       "2           []                 5.865864                  0.165310   \n",
       "3           []                69.101268                 54.083824   \n",
       "4           []                 0.536262                  6.568666   \n",
       "..         ...                      ...                       ...   \n",
       "67          []                 2.525972                  2.350808   \n",
       "68          []                 2.025582                  0.605789   \n",
       "69          []                 5.696385                  6.677561   \n",
       "70          []                 0.246647                  8.124105   \n",
       "71          []                 2.380968                  2.075366   \n",
       "\n",
       "    score_similarite_resume2  score_classif1  score_classif2  \\\n",
       "0                   0.512258            5.90            5.90   \n",
       "1                   0.688642            0.10            0.10   \n",
       "2                   3.719397           34.85           34.85   \n",
       "3                  73.070240           35.05           35.05   \n",
       "4                   7.904146            5.27            5.27   \n",
       "..                       ...             ...             ...   \n",
       "67                  1.427066           35.06           35.06   \n",
       "68                  0.211583           14.24           14.24   \n",
       "69                  9.799521           93.14           93.14   \n",
       "70                 27.358809            6.09            6.09   \n",
       "71                 15.512067           26.10           26.10   \n",
       "\n",
       "    score_sentiment1  score_sentiment2  meth1_similarites meth2_similarites  \n",
       "0               5.90              5.90              164.8             249.0  \n",
       "1               0.10              0.10              160.8              84.6  \n",
       "2              34.85             34.85              136.0             234.2  \n",
       "3              35.05             35.05              148.4             134.8  \n",
       "4               5.27              5.27              107.4             117.8  \n",
       "..               ...               ...                ...               ...  \n",
       "67             35.06             35.06               21.2              35.8  \n",
       "68             14.24             14.24              174.0             179.9  \n",
       "69             93.14             93.14              176.2             258.7  \n",
       "70              6.09              6.09                8.8              28.4  \n",
       "71             26.10             26.10              150.3             114.6  \n",
       "\n",
       "[72 rows x 30 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteurs = ['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1',\n",
    "    'score_similarite_resume2', 'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites',\n",
    "    'meth2_similarites']\n",
    "# 2e test sans les predicteurs entites et méthodes similarités\n",
    "# predicteurs1 = ['score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "#            'score_sentiment1','score_sentiment2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "french_classif = setup(data = francais[predicteurs1 + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.2034</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.2529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0         0.00  0.5167   0.000  0.0000  0.0000 -0.3158 -0.3780\n",
       "1         0.40  0.6333   0.500  0.2667  0.3000  0.2105  0.2520\n",
       "2         0.20  0.6667   0.250  0.0500  0.0800  0.0000  0.0000\n",
       "3         0.20  0.6333   0.250  0.0500  0.0800  0.0000  0.0000\n",
       "4         0.60  0.7000   0.500  0.4667  0.5200  0.4118  0.4410\n",
       "5         0.20  0.6500   0.250  0.0500  0.0800  0.0000  0.0000\n",
       "6         0.40  0.5667   0.250  0.2000  0.2667  0.0625  0.0833\n",
       "7         0.40  0.7667   0.375  0.3333  0.3600  0.1176  0.1260\n",
       "8         0.60  0.9333   0.625  0.6667  0.5667  0.4737  0.5669\n",
       "9         0.40  0.8500   0.500  0.3000  0.3333  0.2500  0.2946\n",
       "Mean      0.34  0.6917   0.350  0.2383  0.2587  0.1210  0.1386\n",
       "SD        0.18  0.1202   0.175  0.2034  0.1853  0.2172  0.2529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.360</td>\n",
       "      <td>0.6642</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>0.1637</td>\n",
       "      <td>0.1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.196</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.2878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0        0.200  0.7000  0.1250  0.2000  0.2000 -0.1111 -0.1179\n",
       "1        0.400  0.5500  0.5000  0.2667  0.3000  0.2105  0.2520\n",
       "2        0.200  0.3750  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "3        0.600  0.9500  0.7500  0.4667  0.5000  0.5000  0.6299\n",
       "4        0.800  0.9500  0.7500  0.7000  0.7333  0.7222  0.7660\n",
       "5        0.200  0.6667  0.2500  0.0500  0.0800  0.0000  0.0000\n",
       "6        0.200  0.4000  0.1250  0.4000  0.2667 -0.0526 -0.0630\n",
       "7        0.200  0.4833  0.2500  0.1000  0.1333 -0.0526 -0.0589\n",
       "8        0.400  0.8500  0.3750  0.5000  0.4000  0.2105  0.2357\n",
       "9        0.400  0.7167  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "Mean     0.360  0.6642  0.3750  0.3190  0.3047  0.1637  0.1896\n",
       "SD       0.196  0.2003  0.2165  0.2105  0.1959  0.2558  0.2878"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>0.1478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0          0.4  0.7500  0.2500  0.2667  0.3200  0.1176  0.1260\n",
       "1          0.2  0.4000  0.2500  0.2000  0.2000 -0.1111 -0.1179\n",
       "2          0.2  0.3500  0.2500  0.0667  0.1000  0.0000  0.0000\n",
       "3          0.4  0.9500  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "4          0.4  0.8500  0.2500  0.2667  0.3200  0.1176  0.1260\n",
       "5          0.2  0.7333  0.2500  0.1000  0.1333  0.0000  0.0000\n",
       "6          0.2  0.5000  0.1250  0.4000  0.2667 -0.0526 -0.0630\n",
       "7          0.2  0.4333  0.2500  0.0667  0.1000 -0.0526 -0.0630\n",
       "8          0.4  0.7667  0.3750  0.5000  0.4000  0.2105  0.2357\n",
       "9          0.4  0.7000  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "Mean       0.3  0.6433  0.2875  0.2500  0.2440  0.0690  0.0836\n",
       "SD         0.1  0.1961  0.0976  0.1522  0.1035  0.1221  0.1478"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = create_model('lr')\n",
    "rf = create_model('rf')\n",
    "xgb = create_model('xgboost')\n",
    "ada = create_model('ada')\n",
    "lda = create_model('lda')  # linear discriminant\n",
    "knn = create_model('knn')\n",
    "mlp = create_model('mlp')\n",
    "svm = create_model('svm')\n",
    "rbfsvm = create_model('rbfsvm')\n",
    "nb = create_model('nb')\n",
    "gpc = create_model('gpc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicteurs : Les plus satisfaisants : ADA - LDA - KNN - LR : pluto moins bien en accuracy .... <br/>\n",
    "predicteurs 1 : Les plus satisfaisants : LR - LDA - RF - XGB - NB : environ 40% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai_classif = anglais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites','meth2_similarites']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography                     int32\n",
       "Entities                      int32\n",
       "Time                          int32\n",
       "Narrative                     int32\n",
       "Overall                       int32\n",
       "Style                         int32\n",
       "Tone                          int32\n",
       "nb_entites_idem               int64\n",
       "nb_lieux_idem                 int64\n",
       "nb_dates_idem                 int64\n",
       "score_similarite_titres     float64\n",
       "score_similarite_resume1    float64\n",
       "score_similarite_resume2    float64\n",
       "score_classif1              float64\n",
       "score_classif2              float64\n",
       "score_sentiment1            float64\n",
       "score_sentiment2            float64\n",
       "meth1_similarites           float64\n",
       "meth2_similarites           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si on veut utiliser faire un classemen,t supprimer ligne error puis changer les types pour meth1 meth2\n",
    "essai_classif = essai_classif[essai_classif.meth1_similarites != 'Error']\n",
    "essai_classif['meth1_similarites'] = essai_classif['meth1_similarites'].astype('float')\n",
    "essai_classif['meth2_similarites'] = essai_classif['meth2_similarites'].astype('float')\n",
    "essai_classif.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2152</td>\n",
       "      <td>-0.0030</td>\n",
       "      <td>-0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.3288</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>0.2076</td>\n",
       "      <td>0.2648</td>\n",
       "      <td>0.2861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.0000  0.0000  0.0000  0.0000  0.0000 -0.3158 -0.3536\n",
       "1       0.2000  0.0000  0.1667  0.1333  0.1600 -0.1765 -0.2165\n",
       "2       0.2000  0.0000  0.1667  0.2000  0.2000 -0.1111 -0.1443\n",
       "3       0.2000  0.3500  0.2500  0.0667  0.1000 -0.0526 -0.0630\n",
       "4       0.8000  0.8167  0.8750  0.9000  0.8000  0.7368  0.7778\n",
       "5       0.2000  0.4500  0.2500  0.0667  0.1000 -0.1111 -0.1361\n",
       "6       0.2500  0.7500  0.2500  0.2500  0.2500  0.0000  0.0000\n",
       "7       0.2500  0.7500  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "8       0.2500  0.8333  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "9       0.2500  0.5000  0.2500  0.2500  0.2500  0.0000  0.0000\n",
       "Mean    0.2600  0.4450  0.2708  0.2075  0.2152 -0.0030 -0.0136\n",
       "SD      0.1934  0.3288  0.2151  0.2437  0.2076  0.2648  0.2861"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xtrain = essai_classif[predicteurs + ['Overall']]\n",
    "eng_classif = setup(data = Xtrain,  target = 'Overall', html=False, silent=True, verbose=False)\n",
    "rf = create_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict_model(rf)  # ne marche pas ????\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random Forest simple sur scikit learn\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xtrain[:1000],ytrain[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555854</td>\n",
       "      <td>0.696767</td>\n",
       "      <td>0.730857</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.73</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118170</td>\n",
       "      <td>81.606245</td>\n",
       "      <td>11.231397</td>\n",
       "      <td>66.44</td>\n",
       "      <td>66.44</td>\n",
       "      <td>66.44</td>\n",
       "      <td>66.44</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517862</td>\n",
       "      <td>1.265746</td>\n",
       "      <td>0.578345</td>\n",
       "      <td>46.37</td>\n",
       "      <td>46.37</td>\n",
       "      <td>46.37</td>\n",
       "      <td>46.37</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>8.411857</td>\n",
       "      <td>0.591390</td>\n",
       "      <td>32.87</td>\n",
       "      <td>32.87</td>\n",
       "      <td>32.87</td>\n",
       "      <td>32.87</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753880</td>\n",
       "      <td>0.112734</td>\n",
       "      <td>1.404673</td>\n",
       "      <td>44.72</td>\n",
       "      <td>44.72</td>\n",
       "      <td>44.72</td>\n",
       "      <td>44.72</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.731849</td>\n",
       "      <td>2.119863</td>\n",
       "      <td>4.331705</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.34</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.243836</td>\n",
       "      <td>10.719655</td>\n",
       "      <td>2.124799</td>\n",
       "      <td>81.74</td>\n",
       "      <td>81.74</td>\n",
       "      <td>81.74</td>\n",
       "      <td>81.74</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228036</td>\n",
       "      <td>0.743514</td>\n",
       "      <td>0.274295</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.77</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.437511</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.123428</td>\n",
       "      <td>29.07</td>\n",
       "      <td>29.07</td>\n",
       "      <td>29.07</td>\n",
       "      <td>29.07</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24.831590</td>\n",
       "      <td>12.139147</td>\n",
       "      <td>22.218409</td>\n",
       "      <td>60.62</td>\n",
       "      <td>60.62</td>\n",
       "      <td>60.62</td>\n",
       "      <td>60.62</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479445</td>\n",
       "      <td>0.094885</td>\n",
       "      <td>0.350741</td>\n",
       "      <td>42.65</td>\n",
       "      <td>42.65</td>\n",
       "      <td>42.65</td>\n",
       "      <td>42.65</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.359629</td>\n",
       "      <td>7.380410</td>\n",
       "      <td>0.761940</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525972</td>\n",
       "      <td>2.350808</td>\n",
       "      <td>1.427066</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.06</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.025582</td>\n",
       "      <td>0.605789</td>\n",
       "      <td>0.211583</td>\n",
       "      <td>14.24</td>\n",
       "      <td>14.24</td>\n",
       "      <td>14.24</td>\n",
       "      <td>14.24</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.696385</td>\n",
       "      <td>6.677561</td>\n",
       "      <td>9.799521</td>\n",
       "      <td>93.14</td>\n",
       "      <td>93.14</td>\n",
       "      <td>93.14</td>\n",
       "      <td>93.14</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246647</td>\n",
       "      <td>8.124105</td>\n",
       "      <td>27.358809</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.380968</td>\n",
       "      <td>2.075366</td>\n",
       "      <td>15.512067</td>\n",
       "      <td>26.10</td>\n",
       "      <td>26.10</td>\n",
       "      <td>26.10</td>\n",
       "      <td>26.10</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50                0              0              0                 0.555854   \n",
       "51                4              0              0                 0.118170   \n",
       "52                1              3              0                 0.517862   \n",
       "53                1              0              0                 0.332000   \n",
       "54                0              3              0                 0.753880   \n",
       "55                0              0              0                 7.731849   \n",
       "56                0              4              0                 5.243836   \n",
       "57                0              0              0                 0.228036   \n",
       "58                1              2              0                 2.437511   \n",
       "59                1              3              0                24.831590   \n",
       "60                0             22              0                 0.479445   \n",
       "61                0             10              0                 0.359629   \n",
       "62                1              4              0                 2.525972   \n",
       "63                2              0              0                 2.025582   \n",
       "64                2              4              0                 5.696385   \n",
       "65                0              0              0                 0.246647   \n",
       "66                0              4              0                 2.380968   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                  0.696767                  0.730857            4.73   \n",
       "51                 81.606245                 11.231397           66.44   \n",
       "52                  1.265746                  0.578345           46.37   \n",
       "53                  8.411857                  0.591390           32.87   \n",
       "54                  0.112734                  1.404673           44.72   \n",
       "55                  2.119863                  4.331705           10.34   \n",
       "56                 10.719655                  2.124799           81.74   \n",
       "57                  0.743514                  0.274295            3.77   \n",
       "58                  0.075943                  0.123428           29.07   \n",
       "59                 12.139147                 22.218409           60.62   \n",
       "60                  0.094885                  0.350741           42.65   \n",
       "61                  7.380410                  0.761940            1.49   \n",
       "62                  2.350808                  1.427066           35.06   \n",
       "63                  0.605789                  0.211583           14.24   \n",
       "64                  6.677561                  9.799521           93.14   \n",
       "65                  8.124105                 27.358809            6.09   \n",
       "66                  2.075366                 15.512067           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2  meth1_similarites  \\\n",
       "50            4.73              4.73              4.73               80.7   \n",
       "51           66.44             66.44             66.44              564.1   \n",
       "52           46.37             46.37             46.37              374.8   \n",
       "53           32.87             32.87             32.87              130.0   \n",
       "54           44.72             44.72             44.72              138.8   \n",
       "55           10.34             10.34             10.34               21.1   \n",
       "56           81.74             81.74             81.74              223.8   \n",
       "57            3.77              3.77              3.77               50.7   \n",
       "58           29.07             29.07             29.07              120.0   \n",
       "59           60.62             60.62             60.62              437.9   \n",
       "60           42.65             42.65             42.65              344.5   \n",
       "61            1.49              1.49              1.49              142.0   \n",
       "62           35.06             35.06             35.06               21.2   \n",
       "63           14.24             14.24             14.24              174.0   \n",
       "64           93.14             93.14             93.14              176.2   \n",
       "65            6.09              6.09              6.09                8.8   \n",
       "66           26.10             26.10             26.10              150.3   \n",
       "\n",
       "    meth2_similarites  Overall  RF  \n",
       "50              215.1        4   3  \n",
       "51              248.6        1   1  \n",
       "52              339.8        1   2  \n",
       "53              159.8        2   2  \n",
       "54               74.0        2   4  \n",
       "55               54.1        4   4  \n",
       "56              170.8        2   1  \n",
       "57               68.7        2   4  \n",
       "58              228.2        4   2  \n",
       "59              301.2        2   1  \n",
       "60              485.7        1   2  \n",
       "61              289.0        2   3  \n",
       "62               35.8        3   4  \n",
       "63              179.9        3   3  \n",
       "64              258.7        1   1  \n",
       "65               28.4        4   4  \n",
       "66              114.6        3   2  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf = rf.predict(Xtrain[50:])\n",
    "res_rf = pd.concat([Xtrain[50:],ytrain[50:],pd.DataFrame(res_rf,columns = ['RF'],index = range(50,67))],axis=1)\n",
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résultats corrects : 6/17 - 8/17 : 1 d'écart et 3/17 : 2 écart \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(res_rf.Overall,res_rf.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  5,  7,  1,  8,  9, 10,  4,  6, 11,  3], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(rf, Xtrain, ytrain, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "tree_feature_importances = rf.feature_importances_\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(predicteurs))\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.array(predicteurs)[sorted_idx])\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Xtrain[:50],ytrain[:50])\n",
    "res_lda = lda.predict(Xtrain[50:])\n",
    "res_final = pd.concat([res_rf[['Overall','RF']],pd.DataFrame(res_lda,columns = ['LDA'],index = range(50,67))],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import around\n",
    "import numpy\n",
    "np.set_printoptions(suppress=True)  # supprime notation exp\n",
    "res_lda2 = around(lda.predict_proba(Xtrain[50:])*100, decimals=2)\n",
    "res_lda2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rf2 = around(rf.predict_proba(Xtrain[50:])*100, decimals=2)\n",
    "res_rf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Remarquer que la classification ne tient pas compte du fait que c'est ordonné en classement 1-2-3-4 : ce qui est TRES important (ex : ligne 55% de 1 - 43% de 4) !! : il faudrait donc faire ressortir un score avec les probas plutot !!!_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau programme basé sur les scores probas : si plus de 50% mettre catégorie obtenue sinon, faire la somme 1-2 et 3/4 \n",
    "# et prendre le plus gros score puis regarder si ce sore > 65% alors à ce moment là prendre le plus gros de la catégorie \n",
    "# sinon prendre 2 ou 3\n",
    "def choix_classes(score_prob):\n",
    "    classe_finale = []\n",
    "    for i in range(len(score_prob)):\n",
    "        res = list(score_prob[i,:])\n",
    "        max_res = max(res)\n",
    "        if max_res > 50:\n",
    "            classe_finale.append(res.index(max_res)+1)\n",
    "        else:\n",
    "            som1 = res[0]+res[1]\n",
    "            som2 = res[2]+res[3]\n",
    "            if som1 > som2:\n",
    "                if som1 >= 65:\n",
    "                    choix = 1 if res[0]>res[1] else 2\n",
    "                else:\n",
    "                    choix = 2\n",
    "            else:\n",
    "                if som2 >= 65:\n",
    "                    choix = 4 if res[3]>res[2] else 3\n",
    "                else:\n",
    "                    choix = 3\n",
    "            classe_finale.append(choix)\n",
    "    return classe_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_rf = choix_classes(res_rf2)\n",
    "liste_lda = choix_classes(res_lda2)\n",
    "res_final = pd.concat([res_final,pd.DataFrame(liste_lda,columns = ['LDA_Prob'],index = range(50,67)),\n",
    "                       pd.DataFrame(liste_rf,columns = ['RF_Prob'],index = range(50,67))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(Xtrain[:50],ytrain[:50])\n",
    "res_knn = knn.predict(Xtrain[50:])\n",
    "liste_knn = choix_classes(around(knn.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['KNN'],index = range(50,67)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['KNN_Prob'],index = range(50,67))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain[:50],ytrain[:50])\n",
    "res_logreg = logreg.predict(Xtrain[50:])\n",
    "liste_logreg = choix_classes(around(logreg.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_logreg,columns = ['LOGR'],index = range(50,67)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['LOGR_Prob'],index = range(50,67))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(Xtrain[:50],ytrain[:50])\n",
    "res_ada = ada.predict(Xtrain[50:])\n",
    "liste_ada = choix_classes(around(ada.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['ADA'],index = range(50,67)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['ADA_Prob'],index = range(50,67))],axis=1)\n",
    "res_final = res_final [['Overall','RF','LDA','KNN','LOGR','ADA','RF_Prob','LDA_Prob','KNN_Prob','LOGR_Prob','ADA_Prob']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "anglais = pd.read_csv('corpus_en_notes.csv',index_col=0)\n",
    "anglais2 = pd.read_csv('corpus_en_de_notes.csv',index_col=0)\n",
    "anglais = pd.concat([anglais,anglais2],axis=0).reset_index(drop=True)\n",
    "anglais = anglais[anglais.meth1_similarites!='Error']\n",
    "english_classif = setup(data = anglais[predicteurs + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = create_model('lr')\n",
    "rr = create_model('lasso')\n",
    "etr = create_model('et')\n",
    "svr = create_model('svm')\n",
    "adar = create_model('ada')\n",
    "mlpr = create_model('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression simple sur scikit learn\n",
    "essai_classif = anglais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites','meth2_similarites']]\n",
    "lr = LinearRegression()\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(Xtrain[:50],ytrain[:50])\n",
    "res_lr = lr.predict(Xtrain[50:])\n",
    "res_lr = pd.concat([Xtrain[50:],ytrain[50:],pd.DataFrame(res_lr,columns = ['LR'],index = range(50,67))],axis=1)\n",
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,res_lr['LR']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls = PLSRegression()\n",
    "pls.fit(Xtrain[:50],ytrain[:50])\n",
    "res_pls = list(pls.predict(Xtrain[50:]).flatten())\n",
    "res_pls = pd.concat([res_lr,pd.DataFrame(res_pls,columns = ['PLS'],index = range(50,67))],axis=1)\n",
    "res_pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,res_pls['PLS']],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

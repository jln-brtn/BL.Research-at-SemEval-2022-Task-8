{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de classification en Français V2\n",
    "\n",
    "    - Transformers : Summarization : 2 modèles --> 2 Résumés / Puis score de similarités de ces 2 résumés\n",
    "    Noter que l'on peut faire aussi la similarité des textes (autre note ?) et non du résumé\n",
    "    - Text classification sur une base de catégories \"Presse\" : sport - actaulités - économie - etc\n",
    "    - Sentiment analysis : voir si le ton du texte est de même type \n",
    "    - Les 2 derniers classifier seronts utilisés en produit scalaire : Par Catégorie : texte1: note1 - texte2 : note2\n",
    "    et donc sum(notes_par_catégorie) = sum(note1*note2) * 100 au bout (note sur 100)\n",
    "    \n",
    "    ici plus de passage par Stanza : 1 fois avec NER Spacy et une fois avec NER Camembert\n",
    "    Score de similarité par Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pke\n",
    "import spacy\n",
    "import torch\n",
    "import warnings\n",
    "import string\n",
    "from gensim.models import KeyedVectors\n",
    "import enchant    # Pour correction orthographique de synonymes\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection des modèles NLP : ici FRANCAIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement pour l'utilisation de Spacy  - Français\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_spacy = {'fr':nlp_fr}   # 'en':nlp_en,'de':nlp_de,'es':nlp_es,'pl':nlp_pl  - POUR MEMOIRE\n",
    "langues = ['en','fr','es','de','pl','ar','tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle Word2Vec pour utilisation de synonymes\n",
    "model_gensim = KeyedVectors.load_word2vec_format(\"D:/Users/STG-SDU/Documents/NLP/Word2Vec.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords Français NLTK + Spacy \n",
    "stopWords = list(nlp_fr.Defaults.stop_words)\n",
    "stopwords_fr = list(stopwords.words('french'))  \n",
    "stopwords_fr = list(set(stopwords_fr + stopWords))\n",
    "stopwds_lg = {'fr':stopwords_fr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcteur orthographique pour validation des synonymes OPTIONNEL CAR NON NECESSAIRE\n",
    "d = enchant.Dict(\"fr\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection des modèles Transformers : Summary - Text Classification - Sentiment Analysis - Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèles Transformers de Résumé (NB : Ne pas oublier d'ajouter la truncation pour tous les modèles, peut être source d'erreur)\n",
    "\n",
    "summarizer1 = pipeline(\"summarization\", model=\"moussaKam/barthez-orangesum-title\", truncation = \"only_first\")\n",
    "summarizer2 = pipeline(\"summarization\", model=\"lincoln/mbart-mlsum-automatic-summarization\", truncation = \"only_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textes classification ou Zero shot classification (permet de chosiri nos propres thèmes)\n",
    "text_clf1 = pipeline(\"text-classification\", model = \"lincoln/flaubert-mlsum-topic-classification\", truncation = \"only_first\")   # 10 actégories, voir hugging face\n",
    "\n",
    "# NB : BUG : zero_shot_clf = pipeline(\"zero-shot-classification\", model=\"BaptisteDoyen/camembert-base-xlni\") # download ne marche pas, donc manuel\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(\"BaptisteDoyen/camembert-base-xnli\")\n",
    "zero_tokenizer = AutoTokenizer.from_pretrained(\"BaptisteDoyen/camembert-base-xnli\") \n",
    "text_clf2 = pipeline('zero-shot-classification', model=nli_model, tokenizer=zero_tokenizer,truncation = \"only_first\")\n",
    "# ce modèle est un zero shot classification : catégories possibles choisies par mes soins (dans la presse)\n",
    "candidate_labels = ['Sciences','Politique','Education','Actualités','Santé','Technologie','Société', 'Sport','Economie','Culture','International','Environnement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DemangeJeremy/4-sentiments-with-flaubert were not used when initializing FlaubertForSequenceClassification: ['transformer.position_ids']\n",
      "- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "sentiment1 = pipeline(\"text-classification\", model = 'moussaKam/barthez-sentiment-classification')\n",
    "\n",
    "# ATTENTION CE MODELE n°2 SE DEFINIT SUR 4 CLASSES : mixed, positif, negatif, objectif\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained('flaubert/flaubert_large_cased')\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(\"DemangeJeremy/4-sentiments-with-flaubert\")\n",
    "sentiment2 = pipeline('sentiment-analysis', model=loaded_model, tokenizer=loaded_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56334ba81325434e88ea36a5fe6414c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a22990df6754a0993af4d0ec5cd974c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/933 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a60ad71288349109adf311b8868ed0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88aebd5c875045f8bade810a6061c22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b2317df92f4da380f4d772115a5579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/769 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f196a9f798784d77855ec60b54013799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ae9b6629bc449c990d3540147f204f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/683 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e31311d47040c4a1a1859f24ed74d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ff69e7e9624625a44b849456859f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4654e88f92d4292887214fd60cf3c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/809k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8c5ad3e054469eb24827076eea35c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/298 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3dcfadee1c4615976ae4a07547d9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/400 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec4f55321ad4a9c8b8023a09ecb82e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# On utilise ici sentence similarity et sentence transformers\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "encoder = SentenceTransformer(\"Sahajtomar/french_semantic\")\n",
    "def score_similarite(sentence1,sentence2):\n",
    "    # attention, pour que torch fonctionne en dimension sentence1 (et 2) est une liste simple\n",
    "    embed1 = encoder.encode(sentence1, convert_to_tensor=True)\n",
    "    embed2 = encoder.encode(sentence2, convert_to_tensor=True)\n",
    "    return round(float(util.pytorch_cos_sim(embed1,embed2))*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER camembert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "ner = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection Data par langues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data_prep_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>pair_lang</th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>title_1</th>\n",
       "      <th>text_1</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>...</th>\n",
       "      <th>text_2</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Style</th>\n",
       "      <th>Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1484084337_1484110209</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>MARTINSBURG, W.Va. — A suspected drunken drive...</td>\n",
       "      <td>Police in West Virginia say a suspected drunke...</td>\n",
       "      <td>['Highway Fatal-DUI-West Virginia', 'Martinsbu...</td>\n",
       "      <td>...</td>\n",
       "      <td>PORT-AU-PRINCE, Haiti — Haitian President Jove...</td>\n",
       "      <td>Haitian President Jovenel Moïse has broken wit...</td>\n",
       "      <td>['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1484396422_1483924666</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.stlucianewsonline.com</td>\n",
       "      <td>Wed Jan  1 21:17:15 2020</td>\n",
       "      <td>https://www.thestar.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...</td>\n",
       "      <td>-</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>['smg2_world', 'smg_europe', 'smg2_news']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1484698254_1483758694</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.teaparty.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.timesofisrael.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>(Breitbart) – President Donald Trump welcomed ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>PALM BEACH, United States — US President Donal...</td>\n",
       "      <td>US president says response to rioting by pro-I...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1576314516_1576455088</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Uber has sold its online food-ordering busines...</td>\n",
       "      <td>Zomato on Tuesday announced it has acquired Ub...</td>\n",
       "      <td>['zomato uber eats business acquisition india ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rapid digitisation and growth in both online b...</td>\n",
       "      <td>The report by Google and Boston Consulting Gro...</td>\n",
       "      <td>['indian online food delivery market to hit us...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484036253_1483894099</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://news.yahoo.com</td>\n",
       "      <td>Wed Jan  1 08:57:59 2020</td>\n",
       "      <td>https://www.channelnewsasia.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>BENGALURU (Reuters) - India has approved its t...</td>\n",
       "      <td>India has approved its third lunar mission mon...</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>BANGALORE: India plans to make a fresh attempt...</td>\n",
       "      <td>India plans to make a fresh attempt to land an...</td>\n",
       "      <td>['India', 'space']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>1586195445_1598778991</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...</td>\n",
       "      <td>...</td>\n",
       "      <td>BM'den Yemen'de kadınların doğumda ölüm riski ...</td>\n",
       "      <td>BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>1590915424_1590940388</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.aksam.com.tr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['İspanya 1. Futbol Ligi', 'la liga', 'koronav...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>1526157103_1492737005</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.samanyoluhaber.com</td>\n",
       "      <td>Thu Feb 20 10:47:10 2020</td>\n",
       "      <td>https://www.fotomac.com.tr</td>\n",
       "      <td>Sun Jan 12 00:00:00 2020</td>\n",
       "      <td>Saray da çare olmadı: 'Borca boğulan dev kulüp...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...</td>\n",
       "      <td>SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...</td>\n",
       "      <td>['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...</td>\n",
       "      <td>...</td>\n",
       "      <td>TFF, resmi internet sitesinden Beşiktaş'ın fai...</td>\n",
       "      <td>Federasyon, Başkan Çebi’nin yaptığı açıklamala...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>1603274500_1618292937</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...</td>\n",
       "      <td>['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...</td>\n",
       "      <td>...</td>\n",
       "      <td>Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...</td>\n",
       "      <td>Covid-19 salgınından vatandaşların korunması i...</td>\n",
       "      <td>['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>1597247537_1604202164</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.takvim.com.tr</td>\n",
       "      <td>Tue May  5 00:00:00 2020</td>\n",
       "      <td>https://www.yeniasir.com.tr</td>\n",
       "      <td>Tue May 12 00:00:00 2020</td>\n",
       "      <td>Grup Yorum üyeleri zorla başlatmıştı... İbrahi...</td>\n",
       "      <td>DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4964 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pair_id pair_lang                       source_url_1  \\\n",
       "0     1484084337_1484110209     en_en     https://www.washingtonpost.com   \n",
       "1     1484396422_1483924666     en_en  https://www.stlucianewsonline.com   \n",
       "2     1484698254_1483758694     en_en           https://www.teaparty.org   \n",
       "3     1576314516_1576455088     en_en           https://gadgets.ndtv.com   \n",
       "4     1484036253_1483894099     en_en             https://news.yahoo.com   \n",
       "...                     ...       ...                                ...   \n",
       "4959  1586195445_1598778991     tr_tr            http://www.haberler.com   \n",
       "4960  1590915424_1590940388     tr_tr           https://www.haberler.com   \n",
       "4961  1526157103_1492737005     tr_tr      http://www.samanyoluhaber.com   \n",
       "4962  1603274500_1618292937     tr_tr           https://www.haberler.com   \n",
       "4963  1597247537_1604202164     tr_tr          https://www.takvim.com.tr   \n",
       "\n",
       "                publish_date_1                     source_url_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020   https://www.washingtonpost.com   \n",
       "1     Wed Jan  1 21:17:15 2020          https://www.thestar.com   \n",
       "2                          NaN    https://www.timesofisrael.com   \n",
       "3                          NaN         https://gadgets.ndtv.com   \n",
       "4     Wed Jan  1 08:57:59 2020  https://www.channelnewsasia.com   \n",
       "...                        ...                              ...   \n",
       "4959                       NaN         https://www.haberler.com   \n",
       "4960                       NaN         https://www.aksam.com.tr   \n",
       "4961  Thu Feb 20 10:47:10 2020       https://www.fotomac.com.tr   \n",
       "4962                       NaN         https://www.haberler.com   \n",
       "4963  Tue May  5 00:00:00 2020      https://www.yeniasir.com.tr   \n",
       "\n",
       "                publish_date_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020   \n",
       "1     Wed Jan  1 00:00:00 2020   \n",
       "2                          NaN   \n",
       "3                          NaN   \n",
       "4                          NaN   \n",
       "...                        ...   \n",
       "4959                       NaN   \n",
       "4960                       NaN   \n",
       "4961  Sun Jan 12 00:00:00 2020   \n",
       "4962                       NaN   \n",
       "4963  Tue May 12 00:00:00 2020   \n",
       "\n",
       "                                                title_1  \\\n",
       "0     Virginia man arrested in fatal DUI crash in We...   \n",
       "1     Guyana: Three injured after car crashes into u...   \n",
       "2     Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3     Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4     India approves third moon mission, months afte...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  Saray da çare olmadı: 'Borca boğulan dev kulüp...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  Grup Yorum üyeleri zorla başlatmıştı... İbrahi...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     MARTINSBURG, W.Va. — A suspected drunken drive...   \n",
       "1     Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...   \n",
       "2     (Breitbart) – President Donald Trump welcomed ...   \n",
       "3     Uber has sold its online food-ordering busines...   \n",
       "4     BENGALURU (Reuters) - India has approved its t...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  \\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...   \n",
       "\n",
       "                                     meta_description_1  \\\n",
       "0     Police in West Virginia say a suspected drunke...   \n",
       "1                                                     -   \n",
       "2                                                   NaN   \n",
       "3     Zomato on Tuesday announced it has acquired Ub...   \n",
       "4     India has approved its third lunar mission mon...   \n",
       "...                                                 ...   \n",
       "4959  Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...   \n",
       "4962  Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_1  ...  \\\n",
       "0     ['Highway Fatal-DUI-West Virginia', 'Martinsbu...  ...   \n",
       "1                                                  ['']  ...   \n",
       "2                                                  ['']  ...   \n",
       "3     ['zomato uber eats business acquisition india ...  ...   \n",
       "4                                                  ['']  ...   \n",
       "...                                                 ...  ...   \n",
       "4959  ['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...  ...   \n",
       "4960  ['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...  ...   \n",
       "4961  ['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...  ...   \n",
       "4962  ['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...  ...   \n",
       "4963                                               ['']  ...   \n",
       "\n",
       "                                                 text_2  \\\n",
       "0     PORT-AU-PRINCE, Haiti — Haitian President Jove...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     PALM BEACH, United States — US President Donal...   \n",
       "3     Rapid digitisation and growth in both online b...   \n",
       "4     BANGALORE: India plans to make a fresh attempt...   \n",
       "...                                                 ...   \n",
       "4959  BM'den Yemen'de kadınların doğumda ölüm riski ...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  TFF, resmi internet sitesinden Beşiktaş'ın fai...   \n",
       "4962  Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...   \n",
       "4963  Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...   \n",
       "\n",
       "                                     meta_description_2  \\\n",
       "0     Haitian President Jovenel Moïse has broken wit...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     US president says response to rioting by pro-I...   \n",
       "3     The report by Google and Boston Consulting Gro...   \n",
       "4     India plans to make a fresh attempt to land an...   \n",
       "...                                                 ...   \n",
       "4959  BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  Federasyon, Başkan Çebi’nin yaptığı açıklamala...   \n",
       "4962  Covid-19 salgınından vatandaşların korunması i...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_2 Geography  Entities  \\\n",
       "0     ['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...       4.0  4.000000   \n",
       "1             ['smg2_world', 'smg_europe', 'smg2_news']       4.0  4.000000   \n",
       "2                                                  ['']       1.0  2.000000   \n",
       "3     ['indian online food delivery market to hit us...       1.0  2.333333   \n",
       "4                                    ['India', 'space']       1.0  1.250000   \n",
       "...                                                 ...       ...       ...   \n",
       "4959  ['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...       1.0  2.000000   \n",
       "4960  ['İspanya 1. Futbol Ligi', 'la liga', 'koronav...       1.0  1.000000   \n",
       "4961                                               ['']       1.0  2.000000   \n",
       "4962     ['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']       1.0  2.000000   \n",
       "4963                                               ['']       2.0  2.000000   \n",
       "\n",
       "          Time  Narrative   Overall     Style      Tone  \n",
       "0     1.000000   4.000000  4.000000  1.666667  2.000000  \n",
       "1     1.000000   4.000000  3.666667  1.666667  1.333333  \n",
       "2     1.000000   2.333333  2.333333  1.000000  1.333333  \n",
       "3     2.666667   1.666667  2.000000  1.666667  1.666667  \n",
       "4     1.000000   1.250000  1.250000  1.000000  1.000000  \n",
       "...        ...        ...       ...       ...       ...  \n",
       "4959  2.000000   4.000000  3.000000  1.000000  1.000000  \n",
       "4960  1.000000   1.000000  1.000000  1.000000  1.000000  \n",
       "4961  3.000000   4.000000  3.000000  1.000000  2.000000  \n",
       "4962  3.000000   3.000000  3.000000  1.000000  1.000000  \n",
       "4963  1.000000   2.000000  2.000000  3.000000  1.000000  \n",
       "\n",
       "[4964 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remémorer numéro de ligne - compléter les Nan\n",
    "data['ligne'] = data.index\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation des datasets, le dernier étant à traduire en plus\n",
    "francais = data.loc[data.pair_lang == 'fr_fr',['ligne','title_1','title_2','text_1','text_2','Geography', 'Entities',\n",
    "       'Time', 'Narrative', 'Overall', 'Style', 'Tone']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests divers et Fonctions nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus : le chanteur et chanteur camerounais Manu Dibango est décédé\n",
      "Coronavirus : l'Afrique pleure Manu Dibango victime du coronavirus\n"
     ]
    }
   ],
   "source": [
    "# Résumés\n",
    "print(summarizer1(francais.text_1[3])[0]['summary_text'])\n",
    "print(summarizer1(francais.text_2[3])[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atteint par le covid-19, l'artiste camerounais est mort mardi matin des suites de la maladie, à l'âge de 86 ans.\n",
      "En l'espace de quelques jours, deux piliers de la musique du continent sont morts des suites du coronavirus.\n"
     ]
    }
   ],
   "source": [
    "print(summarizer2(francais.text_1[3])[0]['summary_text'])\n",
    "print(summarizer2(francais.text_2[3])[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de calcul du score (produit scalaire) pour résultats de classifaction\n",
    "def fonction_produit_dotcom(liste_categor, dico_scores1,dico_scores2):\n",
    "    \"\"\"\"dico scores sont les résultats obtenus pour chaque catégorie des textes 1 et 2\"\"\"\n",
    "    result = 0.0\n",
    "    for cat in liste_categor:\n",
    "        result += round(dico_scores1[cat] * dico_scores2[cat],4)\n",
    "    return result * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type1\n",
    "def transform_text_clf1(liste_dico):\n",
    "    res = {}\n",
    "    for dic in liste_dico:\n",
    "        res[dic['label']] = dic['score']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type2\n",
    "def transform_text_clf2(liste_cat,liste_sc):\n",
    "    res = {}\n",
    "    for i in range(len(liste_cat)):\n",
    "        res[liste_cat[i]] = liste_sc[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Culture': 0.8504540324211121, 'Economie': 0.016547389328479767, 'Education': 0.001298199757002294, 'Environement': 0.004739914555102587, 'Justice': 0.005226531997323036, 'Opinion': 0.006533971522003412, 'Politique': 0.010109643451869488, 'Societe': 0.09446243196725845, 'Sport': 0.0021014309022575617, 'Technologie': 0.008526437915861607}\n",
      "{'Culture': 0.27542635798454285, 'Economie': 0.01746021956205368, 'Education': 0.014121603220701218, 'Environement': 0.13672736287117004, 'Justice': 0.00473390007391572, 'Opinion': 0.11063723266124725, 'Politique': 0.007973399013280869, 'Societe': 0.13605180382728577, 'Sport': 0.14063476026058197, 'Technologie': 0.1562332808971405}\n",
      "25.039999999999996\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "liste_categories = ['Culture', 'Politique', 'Economie','Education','Technologie','Justice','Sport', 'Environement', 'Societe', 'Opinion']\n",
    "scores1 = transform_text_clf1(text_clf1(francais.text_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(text_clf1(francais.text_2[3],return_all_scores=True)[0])\n",
    "print(scores1)\n",
    "print(scores2)\n",
    "print(fonction_produit_dotcom(liste_categories, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.45\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "classes = text_clf2(francais.text_1[3], candidate_labels)\n",
    "scores1 = transform_text_clf2(classes['labels'],classes['scores'])\n",
    "classes2 = text_clf2(francais.text_2[3], candidate_labels)\n",
    "scores2 = transform_text_clf2(classes2['labels'],classes2['scores'])\n",
    "print(fonction_produit_dotcom(candidate_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negative': 0.0010380345629528165, 'Positive': 0.9989619255065918}\n",
      "{'Negative': 0.0012133318232372403, 'Positive': 0.9987866282463074}\n",
      "99.77000000000001\n"
     ]
    }
   ],
   "source": [
    "# Tests sentiment analysis\n",
    "liste_labels = ['Negative','Positive']\n",
    "scores1 = transform_text_clf1(sentiment1(francais.text_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(sentiment1(francais.text_2[3],return_all_scores=True)[0])\n",
    "print(scores1)\n",
    "print(scores2)\n",
    "print(fonction_produit_dotcom(liste_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.889999999999997\n",
      "41.05\n"
     ]
    }
   ],
   "source": [
    "# ATTENTION CE MODELE SE DEFINIT SUR 4 CLASSES : mixed, positif, negatif, objectif\n",
    "liste_sentiments = ['MIXED','NEGATIVE','POSITIVE','OBJECTIVE']\n",
    "scores1 = transform_text_clf1(sentiment2(francais.title_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(sentiment2(francais.title_2[3],return_all_scores=True)[0])\n",
    "scores3 = transform_text_clf1(sentiment2(francais.text_1[3],return_all_scores=True)[0])\n",
    "scores4 = transform_text_clf1(sentiment2(francais.text_2[3],return_all_scores=True)[0])\n",
    "print(fonction_produit_dotcom(liste_sentiments, scores1,scores2))\n",
    "print(fonction_produit_dotcom(liste_sentiments, scores3,scores4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.88\n",
      "62.73\n",
      "-5.91\n",
      "6.86\n"
     ]
    }
   ],
   "source": [
    "# TESTS SCORES DE SIMILARITES : Titres, Textes complets (attention Truncation ...)\n",
    "print(score_similarite(francais.title_1[3],francais.title_2[3]))\n",
    "print(score_similarite(francais.text_1[3],francais.text_2[3]))\n",
    "print(score_similarite(summarizer1(francais.text_1[0])[0]['summary_text'],summarizer1(francais.text_2[0])[0]['summary_text']))\n",
    "print(score_similarite(summarizer2(francais.text_1[0])[0]['summary_text'],summarizer2(francais.text_2[0])[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'LOC', 'score': 0.9652479, 'word': 'France', 'start': 415, 'end': 422}, {'entity_group': 'PER', 'score': 0.9979259, 'word': 'Philippe Taboret', 'start': 777, 'end': 794}, {'entity_group': 'ORG', 'score': 0.99314994, 'word': 'Cafpi', 'start': 825, 'end': 831}, {'entity_group': 'LOC', 'score': 0.99450064, 'word': 'Paris', 'start': 1373, 'end': 1379}, {'entity_group': 'PER', 'score': 0.99761724, 'word': 'Alexander Kraft', 'start': 1876, 'end': 1892}, {'entity_group': 'ORG', 'score': 0.91406935, 'word': \"Sotheby's Realty France-Mon\", 'start': 1924, 'end': 1952}, {'entity_group': 'LOC', 'score': 0.5419018, 'word': 'aco', 'start': 1952, 'end': 1955}, {'entity_group': 'LOC', 'score': 0.9609206, 'word': 'Province', 'start': 2063, 'end': 2072}, {'entity_group': 'PER', 'score': 0.9981144, 'word': 'Philippe Descampiaux', 'start': 2235, 'end': 2256}, {'entity_group': 'ORG', 'score': 0.9850901, 'word': 'Descampiaux-Dudicourt', 'start': 2279, 'end': 2301}, {'entity_group': 'LOC', 'score': 0.9947326, 'word': 'Lille', 'start': 2303, 'end': 2309}]\n",
      "[{'entity_group': 'PER', 'score': 0.9991065, 'word': 'Manu Dibango', 'start': 46, 'end': 59}, {'entity_group': 'PER', 'score': 0.99902886, 'word': 'Manu Dibango', 'start': 227, 'end': 240}, {'entity_group': 'PER', 'score': 0.9991051, 'word': 'Manu Dibango', 'start': 299, 'end': 312}, {'entity_group': 'MISC', 'score': 0.9612651, 'word': 'Covid-19', 'start': 468, 'end': 477}, {'entity_group': 'PER', 'score': 0.999012, 'word': 'Manu Dibango', 'start': 668, 'end': 681}, {'entity_group': 'PER', 'score': 0.5068006, 'word': 'Papy', 'start': 688, 'end': 693}, {'entity_group': 'ORG', 'score': 0.4932146, 'word': 'Groove', 'start': 693, 'end': 700}, {'entity_group': 'PER', 'score': 0.99833214, 'word': 'Thierry Durepaire', 'start': 781, 'end': 799}, {'entity_group': 'MISC', 'score': 0.9105947, 'word': 'Facebook', 'start': 930, 'end': 939}, {'entity_group': 'PER', 'score': 0.99909014, 'word': 'Manu Dibango', 'start': 1108, 'end': 1121}, {'entity_group': 'MISC', 'score': 0.99628115, 'word': 'Soul Makossa', 'start': 1231, 'end': 1244}, {'entity_group': 'MISC', 'score': 0.78604156, 'word': 'Coronavirus', 'start': 1324, 'end': 1336}, {'entity_group': 'PER', 'score': 0.98029274, 'word': 'Aurlus Mabélé', 'start': 1342, 'end': 1356}, {'entity_group': 'PER', 'score': 0.99836946, 'word': 'Durepaire', 'start': 1445, 'end': 1455}, {'entity_group': 'ORG', 'score': 0.97738045, 'word': 'AFP', 'start': 1460, 'end': 1463}]\n"
     ]
    }
   ],
   "source": [
    "print(ner(francais.text_1[0]))\n",
    "print(ner(francais.text_1[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('décéder', 0.6537684202194214),\n",
       " ('décé', 0.5344727039337158),\n",
       " ('deces', 0.5302326679229736),\n",
       " ('survenir', 0.5168903470039368),\n",
       " ('accident', 0.5078858137130737),\n",
       " ('surmortalité', 0.4999918043613434),\n",
       " ('obsèque', 0.49124661087989807),\n",
       " ('invalidité', 0.4891868233680725),\n",
       " ('mortalité', 0.48478570580482483),\n",
       " ('défunt', 0.48272594809532166)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essais de synonymies à utiliser pour sorties PKE, termes prinicpaux\n",
    "syns = model_gensim.most_similar(\"décès\", topn=10)\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de summarization \n",
    "def summarization(texte):\n",
    "    return summarizer1(texte)[0]['summary_text'], summarizer2(texte)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_classifiers = {'text_clf1': 'score_classif1','text_clf2':'score_classif2','sentiment1':'score_sentiment1',\n",
    "                    'sentiment2': 'score_sentiment2'}\n",
    "dico_categories = {'text_clf1': liste_categories,'text_clf2':candidate_labels,'sentiment1':liste_labels,\n",
    "                    'sentiment2': liste_sentiments}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de classification et sentiment analysis\n",
    "def classification(texte,clf):\n",
    "    # assume nms des classifiers et methode de transformation\n",
    "    if clf == \"text_clf1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(text_clf1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"text_clf2\":                                 \n",
    "        try:\n",
    "            classes = text_clf2(texte,dico_categories['text_clf2'])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return transform_text_clf2(classes['labels'],classes['scores'])                          \n",
    "    elif clf == \"sentiment1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"sentiment2\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment2(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    else:\n",
    "        return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des mots de moins de 2 lettres non numériques\n",
    "def supp_moins_2_lettres_stopwords(phrase,stopwd):\n",
    "    temp = phrase.split(' ')\n",
    "    res = ''\n",
    "    for mot in temp:\n",
    "        if mot not in stopwd and (len(mot)>2 or (len(mot)>0 and mot[0] in ['0','1','2','3','4','5','6','7','8','9'])):\n",
    "            res += mot + ' '\n",
    "    return res[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des traits d'union(regroupe)/ des apostrophes / ponctuations\n",
    "def modif(texte,stopmots):\n",
    "    # modifications simples des textes : ponctuations, petits mots, stopwords (à faire pour entités et pke textes)\n",
    "    texte=re.sub('\\'',' ',texte)   # suppression apostrophe\n",
    "    texte=re.sub('-','',texte)    # suppression trait union\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation)) # suppression de toutes les ponctuations\n",
    "    texte=regex.sub(' ',texte)\n",
    "    texte = supp_moins_2_lettres_stopwords(texte,stopmots)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des synonymes (existants en orthographe) à la suite de l'analyse pke\n",
    "def ajout_synonymes(mot, correct_ortho = True):\n",
    "    # on ajoute les 10 premiers synonymes existants, on vérifie orthographe (optionnel)\n",
    "    syns = model_gensim.most_similar(mot,topn = 20)\n",
    "    if correct_ortho == True:\n",
    "        res = []\n",
    "        for m in syns:\n",
    "            if d.check(m[0]):   #  il y a le mot et son pourcentage d'importance\n",
    "                res.append(m)\n",
    "        syns = res\n",
    "    return syns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la bonne méthodologie à appliquer PKE ??? : Noms Ok - Verbes ? - Adjectifs ? - Noms propres ?\n",
    "Quelle quantité de mots prendre ?\n",
    "Ne pas noter les titres seuls ? : trop peu de mots !  Et du coup note peut être forte avec un seul mot !\n",
    "Supprimer en en-tête les stopwords, ponctuation, les apostrophes - AUTRES ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres de la méthode : A revoir ?\n",
    "methode1 = {\"NOUN\", \"PROPN\", \"ADJ\",\"VERB\"}\n",
    "methode2 = {\"NOUN\", \"PROPN\", \"ADJ\"}\n",
    "nb_mots = {'meth1': 30, 'meth2':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKE : Analyse des termes principaux dans les textes et titres \n",
    "# Problème \n",
    "def transformation_pke_results(res1,res2, correct_ortho = True):\n",
    "    \"\"\"\n",
    "    Transformation des resultats de PKE : Pb bigramme peuvent ne pas être ds les 2 textes mais 1 mot seulement\n",
    "    liste de clés et dictionnaires de valeurs, bigrammes jouera ainsi de maniere coefficientée \n",
    "    Exemple : fuite eau:0.05 --> 3 mots au final : fuite, eau, fuite eau : 0.05\n",
    "    De plus on ajoute les synonymes issus de gensim en les coefficiant et vérifiant que cela \"\"\"\n",
    "    \n",
    "    liste1 = []; liste2 = [] ; dico1 = {}; dico2 = {}\n",
    "    for elt in res1:\n",
    "        liste1.append(elt[0])\n",
    "        dico1[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:    # bigramme dans ce cas, ajout des 2 mots\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste1.append(mot)\n",
    "                dico1[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste1.append(syn[0])   # Ajout du mot \n",
    "                        dico1[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "                    \n",
    "    for elt in res2:\n",
    "        liste2.append(elt[0])\n",
    "        dico2[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste2.append(mot)\n",
    "                dico2[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste2.append(syn[0])   # Ajout du mot \n",
    "                        dico2[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "    \n",
    "    # similarites entre les 2 listes issus de pke avec poids\n",
    "    sim = 0\n",
    "    for elt in liste1:\n",
    "        if elt in liste2:\n",
    "            sim += (dico1[elt] + dico2[elt])/2\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entites_communes(nlp,text1,text2):\n",
    "    \"\"\"\"\n",
    "    Cette première fonction ne regarde que les entités communes : personnes, dates, groupe, localisations\n",
    "    Elle sera appliquée aux textes et aux titres et cumulé : si cumul en titre et texte : compte double !\"\"\"\n",
    "    \n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    nb_commun_ent = 0; liste_commun_ent = []\n",
    "    nb_commun_geo = 0; liste_commun_geo = []\n",
    "    nb_commun_dat = 0; liste_commun_dat = []\n",
    "    \n",
    "    if len(doc1.ents)>0 and len(doc2.ents)>0:\n",
    "        liste1 = []; dico1 = {}\n",
    "        for elt in doc1.ents:\n",
    "            if elt.label_ in ['PERSON','PER'] and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste1:\n",
    "                        liste1.append(mot)\n",
    "                        dico1[mot] = elt.label_\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste1:\n",
    "                    liste1.append(elt.text)\n",
    "                    dico1[elt.text] = elt.label_\n",
    "        liste2 = []\n",
    "        for elt in doc2.ents:\n",
    "            if elt.label_ in ['PERSON','PER'] and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste2:\n",
    "                        liste2.append(mot)\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste2:\n",
    "                    liste2.append(elt.text)\n",
    "        \n",
    "        # points communs des listes        \n",
    "        for elt in liste1:\n",
    "            if elt in liste2:\n",
    "                if dico1[elt] == 'LOC':\n",
    "                    nb_commun_geo += 1\n",
    "                    liste_commun_geo.append(elt)\n",
    "                elif dico1[elt] in ['DATE','TIME']:\n",
    "                    nb_commun_dat += 1\n",
    "                    liste_commun_dat.append(elt)\n",
    "                else:\n",
    "                    nb_commun_ent += 1\n",
    "                    liste_commun_ent.append(elt)\n",
    "                    \n",
    "    return nb_commun_ent, liste_commun_ent,nb_commun_geo, liste_commun_geo,nb_commun_dat, liste_commun_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entites_communes_ner(nlp,text1,text2):\n",
    "    \"\"\"\"\n",
    "    Cette première fonction ne regarde que les entités communes : personnes, dates, groupe, localisations\n",
    "    Elle sera appliquée aux textes et aux titres et cumulé : si cumul en titre et texte : compte double !\"\"\"\n",
    "    \n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    nb_commun_ent = 0; liste_commun_ent = []\n",
    "    nb_commun_geo = 0; liste_commun_geo = []\n",
    "    nb_commun_dat = 0; liste_commun_dat = []\n",
    "    if len(doc1)>0 and len(doc2)>0:\n",
    "        liste1 = []; dico1 = {}\n",
    "        for elt in doc1:\n",
    "            if '-' in elt['entity_group'] and elt['entity_group'].split('-')[1] in ['PERSON','PER','LOC','ORG','GPE','NORP','DATE','TIME']:\n",
    "                liste1.append(elt['word'])\n",
    "                dico1[elt['word']] = elt['entity_group'].split('-')[1]\n",
    "            elif elt['entity_group'] in ['PERSON','PER','LOC','ORG','GPE','NORP','DATE','TIME']:\n",
    "                liste1.append(elt['word'])\n",
    "                dico1[elt['word']] = elt['entity_group']  \n",
    "        liste2 = []\n",
    "        for elt in doc2:\n",
    "            if '-' in elt['entity_group'] and elt['entity_group'].split('-')[1] in ['PERSON','PER','LOC','ORG','GPE','NORP','DATE','TIME']:\n",
    "                liste2.append(elt['word'])\n",
    "            elif elt['entity_group'] in ['LOC','ORG','GPE','NORP','DATE','TIME']:\n",
    "                liste2.append(elt['word'])\n",
    "        \n",
    "        # points communs des listes    \n",
    "        for elt in liste1:\n",
    "            if elt in liste2:\n",
    "                if dico1[elt] == 'LOC':\n",
    "                    nb_commun_geo += 1\n",
    "                    liste_commun_geo.append(elt)\n",
    "                elif dico1[elt] in ['DATE','TIME']:\n",
    "                    nb_commun_dat += 1\n",
    "                    liste_commun_dat.append(elt)\n",
    "                else:\n",
    "                    nb_commun_ent += 1\n",
    "                    liste_commun_ent.append(elt)\n",
    "                    \n",
    "    return nb_commun_ent, liste_commun_ent,nb_commun_geo, liste_commun_geo,nb_commun_dat, liste_commun_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Creation_features_comparaison(df,langue, test_position = [methode1,methode2]):\n",
    "    \"\"\"Création des notes pour classification ensuite\"\"\"\n",
    "    \n",
    "    resultats = pd.DataFrame(columns = ['summary1_text1','summary2_text1','summary1_text2','summary2_text2',\n",
    "            'nb_entites_idem','nb_lieux_idem', 'nb_dates_idem','entites_idem','lieux_idem','dates_idem',\n",
    "            'score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "            'score_sentiment1','score_sentiment2','meth1_similarites','meth2_similarites'])\n",
    "    \n",
    "    # initialisation\n",
    "    stopmts = stopwds_lg[langue]\n",
    "    if langue in dico_spacy.keys():\n",
    "        nlp_spacy = dico_spacy[langue]\n",
    "    else:\n",
    "        nlp_spacy = None\n",
    "        \n",
    "    for i in tqdm(range(len(df))):\n",
    "        dico_res = {}\n",
    "        \n",
    "        # Summary et comparatifs \n",
    "        dico_res['summary1_text1'],dico_res['summary2_text1'] = summarization(df.text_1[i])\n",
    "        dico_res['summary1_text2'],dico_res['summary2_text2'] = summarization(df.text_2[i])\n",
    "        dico_res['score_similarite_titres'] = score_similarite(df.title_1[i],df.title_2[i])\n",
    "        dico_res['score_similarite_resume1'] = score_similarite(dico_res['summary1_text1'],dico_res['summary1_text2'])\n",
    "        dico_res['score_similarite_resume2'] = score_similarite(dico_res['summary2_text1'],dico_res['summary2_text2'])\n",
    "        \n",
    "        # analyse de textes classification et de sentiments\n",
    "        texte1 = df.title_1[i] + ' ' + df.text_1[i]\n",
    "        texte2 = df.title_2[i] + ' ' + df.text_2[i]\n",
    "        if len(texte1)>0 and len(texte2)>0:\n",
    "            for classifier in dico_classifiers.keys():\n",
    "                scores1 = classification(texte1,classifier)\n",
    "                scores2 = classification(texte2,classifier)\n",
    "                if scores1 != 'error' and scores2 != 'error':\n",
    "                    dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                else:\n",
    "                    scores1 = classification(df.title_1[i],classifier)\n",
    "                    scores2 = classification(df.title_2[i],classifier)\n",
    "                    if scores1 != 'error' and scores2 != 'error':\n",
    "                        dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                    else:\n",
    "                        dico_res[dico_classifiers[classifier]] = None\n",
    "                \n",
    "        # pré traitement des textes pour entités et PKE\n",
    "        texte1 = modif(texte1, stopmts)\n",
    "        texte2 = modif(texte2, stopmts)\n",
    "        \n",
    "        # ENTITES COMMUNES : on tient compte des bigrammes Noms qui posent erreurs ex: Joe Biden et Biden \n",
    "        # Ici, on considère mieux le CUMUl titres et Textes avec une pondération double pour le titre \n",
    "        # Il faut aussi enlever les petits mots donc pré-traitement en texte\n",
    "        \n",
    "        nb_ent1,list_ent1,nb_geo1,list_geo1,nb_dat1,list_dat1 = entites_communes_ner(ner,df.title_1[i],df.title_2[i])\n",
    "        nb_ent2,list_ent2,nb_geo2,list_geo2,nb_dat2,list_dat2 = entites_communes_ner(ner,df.text_1[i],df.text_2[i])\n",
    "        if nlp_spacy != None:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = entites_communes(nlp_spacy,df.title_1[i],df.title_2[i])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = entites_communes(nlp_spacy,df.text_1[i],df.text_2[i])\n",
    "        else:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = (0,[],0,[],0,[])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = (0,[],0,[],0,[])\n",
    "        dico_res['nb_entites_idem'] = nb_ent1 * 2 + nb_ent2 + nb_ent3 * 2 + nb_ent4\n",
    "        dico_res['nb_lieux_idem'] = nb_geo1  * 2 + nb_geo2 + nb_geo3  * 2 + nb_geo4\n",
    "        dico_res['nb_dates_idem'] = nb_dat1 * 2 + nb_dat2 + nb_dat3 * 2 + nb_dat4\n",
    "        # fusion des listes en supprimant les doublons\n",
    "        dico_res['entites_idem'] = list(set(list_ent1+list_ent2+ list_ent3+list_ent4))\n",
    "        dico_res['lieux_idem'] = list(set(list_geo1+list_geo2+list_geo3+list_geo4))\n",
    "        dico_res['dates_idem'] = list(set(list_dat1+list_dat2+list_dat3+list_dat4))\n",
    "        \n",
    "        for j,meth in enumerate(test_position):\n",
    "            nom ='meth'+str(j+1)\n",
    "            nb_mots_meth = nb_mots[nom]\n",
    "            if len(texte1)>0 and len(texte2)>0:\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte1,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases3 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte2,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases4 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                dico_res[nom+'_similarites'] = round(100*transformation_pke_results(keyphrases3,keyphrases4),1)\n",
    "            else:\n",
    "                dico_res[nom+'_similarites'] = 'Error'\n",
    "        \n",
    "        resultats.loc[len(resultats)] = dico_res\n",
    "        \n",
    "    newdf = pd.concat([df,resultats],axis=1)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4167a6d283ee4bf4a87b4b82870d0783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 200, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 179. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 150. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 10, but you input_length is only 2. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 100, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 10, but you input_length is only 2. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 100, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 72. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 171. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 177. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 10, but you input_length is only 2. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 100, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 58. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 62. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 155. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 38. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 46. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 173. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 188. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 182. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 133. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 99. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 10, but you input_length is only 2. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 100, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 172. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 159. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 28. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 34. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 173. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 168. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 187. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "# Attention probleme au 16e index non identifié ...\n",
    "similarites = Creation_features_comparaison(francais,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarites.to_csv('corpus_fr_notes_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "francais = pd.read_csv('corpus_fr_notes_v2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention certains textes ne sont pas fournies et donc mis en \"Error\" : A supprimer donc\n",
    "# On pourrait éventuellement tester en ne prenant plus les meth similarités ds les predicteurs\n",
    "francais = francais[francais.meth1_similarites!='Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "francais = francais.round({'Geography':0, 'Entities':0,'Time':0, 'Narrative':0, 'Overall':0, 'Style':0, 'Tone':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "partiel = francais[['Geography', 'Entities','Time', 'Narrative', 'Overall', 'Style', 'Tone']].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "francais = pd.concat([francais[['ligne', 'title_1', 'title_2', 'text_1', 'text_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2']],\n",
    "        partiel,francais[['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "       'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "       'score_sentiment2', 'meth1_similarites', 'meth2_similarites']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>summary1_text1</th>\n",
       "      <th>summary2_text1</th>\n",
       "      <th>summary1_text2</th>\n",
       "      <th>summary2_text2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>...</th>\n",
       "      <th>dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2317</td>\n",
       "      <td>L'euphorie du marché résistera-t-elle au coron...</td>\n",
       "      <td>De nombreux médecins toujours sans masques, ma...</td>\n",
       "      <td>Le cap du million de ventes a été dépassé l'an...</td>\n",
       "      <td>Stocks réduits ou distribués au \"compte-goutte...</td>\n",
       "      <td>Immobilier : le cap du million de ventes dépas...</td>\n",
       "      <td>L'empressement des acheteurs à devenir proprié...</td>\n",
       "      <td>Coronavirus : les soignants manquent toujours ...</td>\n",
       "      <td>Les soignants français manquent toujours de ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>11.36</td>\n",
       "      <td>-5.91</td>\n",
       "      <td>6.86</td>\n",
       "      <td>5.90</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.04</td>\n",
       "      <td>28.06</td>\n",
       "      <td>164.8</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2318</td>\n",
       "      <td>Clarenceville: Alexandre et Ilana Dupont n’iro...</td>\n",
       "      <td>COVID-19 : le fédéral donnera 2 000 $ par mois...</td>\n",
       "      <td>SPORTS – La majorité des activités sportives d...</td>\n",
       "      <td>Cette nuit, la Chambre des communes a adopté l...</td>\n",
       "      <td>Coronavirus : le Canada n'enverrait pas ses at...</td>\n",
       "      <td>La majorité des activités sportives de la plan...</td>\n",
       "      <td>Canada : 82 G d'aide d'urgence pour les Canadiens</td>\n",
       "      <td>Cette nuit, la Chambre des communes a adopté l...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.75</td>\n",
       "      <td>24.51</td>\n",
       "      <td>13.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.02</td>\n",
       "      <td>99.92</td>\n",
       "      <td>31.29</td>\n",
       "      <td>160.8</td>\n",
       "      <td>84.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2319</td>\n",
       "      <td>Deux retraités matanais sont coincés en Équateur</td>\n",
       "      <td>L'opération de rapatriement est un «fiasco», d...</td>\n",
       "      <td>Deux Matanais, Hélène Gagnon et Clarence Bouff...</td>\n",
       "      <td>Sarah Mahu est coincée au Pérou. Elle a réussi...</td>\n",
       "      <td>Coronavirus : des Canadiens coincés en Équateu...</td>\n",
       "      <td>Un couple de Québécois, coincés en Équateur, a...</td>\n",
       "      <td>Coronavirus : des Québécois coincés au Pérou q...</td>\n",
       "      <td>Un mois après la proclamation de l'état d'urge...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>25.75</td>\n",
       "      <td>58.94</td>\n",
       "      <td>23.69</td>\n",
       "      <td>34.85</td>\n",
       "      <td>8.48</td>\n",
       "      <td>98.21</td>\n",
       "      <td>25.93</td>\n",
       "      <td>136.0</td>\n",
       "      <td>234.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2320</td>\n",
       "      <td>Coronavirus : le musicien et chanteur cameroun...</td>\n",
       "      <td>L'Afrique pleure Manu Dibango, victime du coro...</td>\n",
       "      <td>Atteint par le covid-19, l’artiste camerounais...</td>\n",
       "      <td>L'Afrique pleure Manu Dibango, victime du coro...</td>\n",
       "      <td>Coronavirus : le chanteur et chanteur cameroun...</td>\n",
       "      <td>Atteint par le covid-19, l'artiste camerounais...</td>\n",
       "      <td>Coronavirus : l'Afrique pleure Manu Dibango vi...</td>\n",
       "      <td>En l'espace de quelques jours, deux piliers de...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>77.88</td>\n",
       "      <td>78.52</td>\n",
       "      <td>53.12</td>\n",
       "      <td>35.05</td>\n",
       "      <td>9.03</td>\n",
       "      <td>99.62</td>\n",
       "      <td>30.55</td>\n",
       "      <td>148.4</td>\n",
       "      <td>134.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2321</td>\n",
       "      <td>La MRC de Marguerite-D’Youville prend les gran...</td>\n",
       "      <td>Le travail inquiétant des femmes dans la pandé...</td>\n",
       "      <td>C’est dans le cadre de la crise générée par la...</td>\n",
       "      <td>Pour la version anglais, cliquez ici. / For th...</td>\n",
       "      <td>Crise de la Covid-19 : la MRC de Marguerite-D’...</td>\n",
       "      <td>Dans le cadre de la crise générée par la COVID...</td>\n",
       "      <td>Coronavirus : les femmes sont nettement plus i...</td>\n",
       "      <td>Pour lutter contre la pauvreté et les inégalit...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>17.14</td>\n",
       "      <td>15.19</td>\n",
       "      <td>28.43</td>\n",
       "      <td>5.27</td>\n",
       "      <td>8.97</td>\n",
       "      <td>99.97</td>\n",
       "      <td>40.37</td>\n",
       "      <td>107.4</td>\n",
       "      <td>117.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4879</td>\n",
       "      <td>Maroc : la location aux touristes interdite</td>\n",
       "      <td>Maroc : la justice ouvre une enquête pour viol...</td>\n",
       "      <td>Les forces de l’ordre effectuent des inspectio...</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>Maroc : la police inspecte les appartements de...</td>\n",
       "      <td>Les forces de l'ordre effectuent des inspectio...</td>\n",
       "      <td>Confinement : le parquet de Tanger ouvre une e...</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>47.46</td>\n",
       "      <td>47.85</td>\n",
       "      <td>54.29</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4880</td>\n",
       "      <td>Loi sur la relance : l'opposition « à plus de ...</td>\n",
       "      <td>10Â 000 prÃ©posÃ©s aux bÃ©nÃ©ficiaires recherc...</td>\n",
       "      <td>Deux journées de commission parlementaire n'au...</td>\n",
       "      <td>CORONAVIRUS. QuÃ©bec veut lancer une opÃ©ratio...</td>\n",
       "      <td>Projet de loi 61 : l'opposition accuse le gouv...</td>\n",
       "      <td>Le projet de loi sur la relance de l'économie ...</td>\n",
       "      <td>Qubec : 10 000 prposs aux bnficiaires, annonce...</td>\n",
       "      <td>Le gouvernement souhaite que les militaires de...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>6.03</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.99</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4881</td>\n",
       "      <td>Média sud-coréen : “Avec le rôle de président ...</td>\n",
       "      <td>Le 36e Sommet de l’ASEAN couronné de succès</td>\n",
       "      <td>En 2020, le Vietnam assume un double rôle de p...</td>\n",
       "      <td>Le chef du gouvernement vietnamien, qui est ég...</td>\n",
       "      <td>Le Vietnam devient président de l'ASEAN et mem...</td>\n",
       "      <td>En 2020, le Vietnam devient un double rôle de ...</td>\n",
       "      <td>Le Vietnam salue le succès du Sommet de l'ASEA...</td>\n",
       "      <td>Le chef du gouvernement vietnamien, qui est ég...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>38.26</td>\n",
       "      <td>50.95</td>\n",
       "      <td>63.59</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4882</td>\n",
       "      <td>Adieu à Muriel Roy</td>\n",
       "      <td>«Les pouvoirs extraordinaire du corps humain»:...</td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>Comment avez-vous vécu le confinement?\\n\\nAu d...</td>\n",
       "      <td>Muriel Roy est décédée à l'âge de 100 ans</td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>Comment avez-vous vécu le confinement?</td>\n",
       "      <td>C'est à voir. Le 3 mars, on avait des pseudo-c...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>9.48</td>\n",
       "      <td>11.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4883</td>\n",
       "      <td>Congo : des experts africains formés à Brazzav...</td>\n",
       "      <td>«EN AFRIQUE, L’EVOLUTION DE LA PANDEMIE EST TR...</td>\n",
       "      <td>Congo : des experts africains formés à Brazzav...</td>\n",
       "      <td>Alors que le directeur de l’Organisation mondi...</td>\n",
       "      <td>Coronavirus : des experts africains formés à B...</td>\n",
       "      <td>Des professionnels de santé de 24 pays d'Afriq...</td>\n",
       "      <td>Coronavirus : l'Afrique «très préoccupante» av...</td>\n",
       "      <td>La directrice Afrique de l'Organisation mondia...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>26.87</td>\n",
       "      <td>41.90</td>\n",
       "      <td>48.33</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ligne                                            title_1  \\\n",
       "0    2317  L'euphorie du marché résistera-t-elle au coron...   \n",
       "1    2318  Clarenceville: Alexandre et Ilana Dupont n’iro...   \n",
       "2    2319   Deux retraités matanais sont coincés en Équateur   \n",
       "3    2320  Coronavirus : le musicien et chanteur cameroun...   \n",
       "4    2321  La MRC de Marguerite-D’Youville prend les gran...   \n",
       "..    ...                                                ...   \n",
       "67   4879        Maroc : la location aux touristes interdite   \n",
       "68   4880  Loi sur la relance : l'opposition « à plus de ...   \n",
       "69   4881  Média sud-coréen : “Avec le rôle de président ...   \n",
       "70   4882                                 Adieu à Muriel Roy   \n",
       "71   4883  Congo : des experts africains formés à Brazzav...   \n",
       "\n",
       "                                              title_2  \\\n",
       "0   De nombreux médecins toujours sans masques, ma...   \n",
       "1   COVID-19 : le fédéral donnera 2 000 $ par mois...   \n",
       "2   L'opération de rapatriement est un «fiasco», d...   \n",
       "3   L'Afrique pleure Manu Dibango, victime du coro...   \n",
       "4   Le travail inquiétant des femmes dans la pandé...   \n",
       "..                                                ...   \n",
       "67  Maroc : la justice ouvre une enquête pour viol...   \n",
       "68  10Â 000 prÃ©posÃ©s aux bÃ©nÃ©ficiaires recherc...   \n",
       "69        Le 36e Sommet de l’ASEAN couronné de succès   \n",
       "70  «Les pouvoirs extraordinaire du corps humain»:...   \n",
       "71  «EN AFRIQUE, L’EVOLUTION DE LA PANDEMIE EST TR...   \n",
       "\n",
       "                                               text_1  \\\n",
       "0   Le cap du million de ventes a été dépassé l'an...   \n",
       "1   SPORTS – La majorité des activités sportives d...   \n",
       "2   Deux Matanais, Hélène Gagnon et Clarence Bouff...   \n",
       "3   Atteint par le covid-19, l’artiste camerounais...   \n",
       "4   C’est dans le cadre de la crise générée par la...   \n",
       "..                                                ...   \n",
       "67  Les forces de l’ordre effectuent des inspectio...   \n",
       "68  Deux journées de commission parlementaire n'au...   \n",
       "69  En 2020, le Vietnam assume un double rôle de p...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71  Congo : des experts africains formés à Brazzav...   \n",
       "\n",
       "                                               text_2  \\\n",
       "0   Stocks réduits ou distribués au \"compte-goutte...   \n",
       "1   Cette nuit, la Chambre des communes a adopté l...   \n",
       "2   Sarah Mahu est coincée au Pérou. Elle a réussi...   \n",
       "3   L'Afrique pleure Manu Dibango, victime du coro...   \n",
       "4   Pour la version anglais, cliquez ici. / For th...   \n",
       "..                                                ...   \n",
       "67  Suite aux violations du confinement dans les v...   \n",
       "68  CORONAVIRUS. QuÃ©bec veut lancer une opÃ©ratio...   \n",
       "69  Le chef du gouvernement vietnamien, qui est ég...   \n",
       "70  Comment avez-vous vécu le confinement?\\n\\nAu d...   \n",
       "71  Alors que le directeur de l’Organisation mondi...   \n",
       "\n",
       "                                       summary1_text1  \\\n",
       "0   Immobilier : le cap du million de ventes dépas...   \n",
       "1   Coronavirus : le Canada n'enverrait pas ses at...   \n",
       "2   Coronavirus : des Canadiens coincés en Équateu...   \n",
       "3   Coronavirus : le chanteur et chanteur cameroun...   \n",
       "4   Crise de la Covid-19 : la MRC de Marguerite-D’...   \n",
       "..                                                ...   \n",
       "67  Maroc : la police inspecte les appartements de...   \n",
       "68  Projet de loi 61 : l'opposition accuse le gouv...   \n",
       "69  Le Vietnam devient président de l'ASEAN et mem...   \n",
       "70          Muriel Roy est décédée à l'âge de 100 ans   \n",
       "71  Coronavirus : des experts africains formés à B...   \n",
       "\n",
       "                                       summary2_text1  \\\n",
       "0   L'empressement des acheteurs à devenir proprié...   \n",
       "1   La majorité des activités sportives de la plan...   \n",
       "2   Un couple de Québécois, coincés en Équateur, a...   \n",
       "3   Atteint par le covid-19, l'artiste camerounais...   \n",
       "4   Dans le cadre de la crise générée par la COVID...   \n",
       "..                                                ...   \n",
       "67  Les forces de l'ordre effectuent des inspectio...   \n",
       "68  Le projet de loi sur la relance de l'économie ...   \n",
       "69  En 2020, le Vietnam devient un double rôle de ...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71  Des professionnels de santé de 24 pays d'Afriq...   \n",
       "\n",
       "                                       summary1_text2  \\\n",
       "0   Coronavirus : les soignants manquent toujours ...   \n",
       "1   Canada : 82 G d'aide d'urgence pour les Canadiens   \n",
       "2   Coronavirus : des Québécois coincés au Pérou q...   \n",
       "3   Coronavirus : l'Afrique pleure Manu Dibango vi...   \n",
       "4   Coronavirus : les femmes sont nettement plus i...   \n",
       "..                                                ...   \n",
       "67  Confinement : le parquet de Tanger ouvre une e...   \n",
       "68  Qubec : 10 000 prposs aux bnficiaires, annonce...   \n",
       "69  Le Vietnam salue le succès du Sommet de l'ASEA...   \n",
       "70             Comment avez-vous vécu le confinement?   \n",
       "71  Coronavirus : l'Afrique «très préoccupante» av...   \n",
       "\n",
       "                                       summary2_text2  Geography  ...  \\\n",
       "0   Les soignants français manquent toujours de ma...          1  ...   \n",
       "1   Cette nuit, la Chambre des communes a adopté l...          3  ...   \n",
       "2   Un mois après la proclamation de l'état d'urge...          3  ...   \n",
       "3   En l'espace de quelques jours, deux piliers de...          1  ...   \n",
       "4   Pour lutter contre la pauvreté et les inégalit...          3  ...   \n",
       "..                                                ...        ...  ...   \n",
       "67  Suite aux violations du confinement dans les v...          2  ...   \n",
       "68  Le gouvernement souhaite que les militaires de...          1  ...   \n",
       "69  Le chef du gouvernement vietnamien, qui est ég...          1  ...   \n",
       "70  C'est à voir. Le 3 mars, on avait des pseudo-c...          4  ...   \n",
       "71  La directrice Afrique de l'Organisation mondia...          3  ...   \n",
       "\n",
       "    dates_idem  score_similarite_titres  score_similarite_resume1  \\\n",
       "0           []                    11.36                     -5.91   \n",
       "1           []                     2.75                     24.51   \n",
       "2           []                    25.75                     58.94   \n",
       "3           []                    77.88                     78.52   \n",
       "4           []                    17.14                     15.19   \n",
       "..         ...                      ...                       ...   \n",
       "67          []                    47.46                     47.85   \n",
       "68          []                     6.03                     13.21   \n",
       "69          []                    38.26                     50.95   \n",
       "70          []                     9.48                     11.70   \n",
       "71          []                    26.87                     41.90   \n",
       "\n",
       "    score_similarite_resume2  score_classif1  score_classif2  \\\n",
       "0                       6.86            5.90            8.42   \n",
       "1                      13.03            0.10            9.02   \n",
       "2                      23.69           34.85            8.48   \n",
       "3                      53.12           35.05            9.03   \n",
       "4                      28.43            5.27            8.97   \n",
       "..                       ...             ...             ...   \n",
       "67                     54.29           35.06           10.08   \n",
       "68                      3.99           14.24            8.91   \n",
       "69                     63.59           93.14            9.39   \n",
       "70                      3.17            6.09            8.37   \n",
       "71                     48.33           26.10           10.33   \n",
       "\n",
       "    score_sentiment1  score_sentiment2  meth1_similarites meth2_similarites  \n",
       "0               0.04             28.06              164.8             249.0  \n",
       "1              99.92             31.29              160.8              84.6  \n",
       "2              98.21             25.93              136.0             234.2  \n",
       "3              99.62             30.55              148.4             134.8  \n",
       "4              99.97             40.37              107.4             117.8  \n",
       "..               ...               ...                ...               ...  \n",
       "67             97.33             30.89               21.2              35.8  \n",
       "68              1.03             20.16              174.0             179.9  \n",
       "69             99.98             31.05              176.2             258.7  \n",
       "70             99.84             29.93                8.8              28.4  \n",
       "71             99.54             27.09              150.3             114.6  \n",
       "\n",
       "[69 rows x 30 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "francais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteurs = ['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1',\n",
    "    'score_similarite_resume2', 'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites',\n",
    "    'meth2_similarites']\n",
    "# 2e test sans les predicteurs entites et méthodes similarités\n",
    "# predicteurs1 = ['score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "#            'score_sentiment1','score_sentiment2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "french_classif = setup(data = francais[predicteurs + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.6033</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>0.3890</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.3314</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>0.2261</td>\n",
       "      <td>0.2631</td>\n",
       "      <td>0.2792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.7500  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "1       0.4000  0.0000  0.2500  0.2667  0.3200  0.1667  0.2004\n",
       "2       0.8000  0.0000  0.6667  0.6667  0.7200  0.6667  0.7217\n",
       "3       0.2000  0.7500  0.2500  0.2000  0.2000  0.0000  0.0000\n",
       "4       0.4000  0.8167  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "5       0.2000  0.4833  0.2500  0.1000  0.1333 -0.0526 -0.0589\n",
       "6       0.6000  0.9000  0.6250  0.7000  0.6000  0.4737  0.5000\n",
       "7       0.8000  1.0000  0.8750  0.9000  0.8000  0.7368  0.7778\n",
       "8       0.5000  0.7500  0.5000  0.3750  0.4167  0.3333  0.3651\n",
       "9       0.2500  0.5833  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "Mean    0.4550  0.6033  0.4542  0.3767  0.3890  0.2741  0.3050\n",
       "SD      0.2103  0.3314  0.2070  0.2649  0.2261  0.2631  0.2792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.4075</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.2728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1844</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.2411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.8333  0.3750  0.3000  0.3333  0.1667  0.1768\n",
       "1       0.8000  0.0000  0.8333  0.9000  0.8000  0.7059  0.7500\n",
       "2       0.6000  0.0000  0.5000  0.6000  0.6000  0.3750  0.3750\n",
       "3       0.6000  0.7833  0.6250  0.7000  0.6000  0.4737  0.5000\n",
       "4       0.6000  0.7833  0.6250  0.7000  0.6000  0.4737  0.5000\n",
       "5       0.2000  0.7417  0.2500  0.1000  0.1333  0.0000  0.0000\n",
       "6       0.4000  0.8167  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "7       0.4000  0.8167  0.5000  0.3000  0.3333  0.2105  0.2222\n",
       "8       0.2500  0.6250  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "9       0.2500  0.7500  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "Mean    0.4500  0.6150  0.4583  0.4075  0.3992  0.2572  0.2728\n",
       "SD      0.1844  0.3125  0.1854  0.2781  0.2236  0.2293  0.2411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.2646</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.3120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.7667  0.5000  0.2000  0.2667  0.2500  0.2946\n",
       "1       0.6000  0.0000  0.6667  0.8667  0.6333  0.4444  0.5345\n",
       "2       0.0000  0.0000  0.0000  0.0000  0.0000 -0.3158 -0.5303\n",
       "3       0.4000  0.6333  0.5000  0.2667  0.3000  0.2500  0.3150\n",
       "4       0.4000  0.6000  0.3750  0.6000  0.4667  0.2105  0.2222\n",
       "5       0.2000  0.7167  0.2500  0.1000  0.1333 -0.0526 -0.0589\n",
       "6       0.4000  0.7500  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "7       0.4000  0.6833  0.5000  0.3000  0.3333  0.2105  0.2222\n",
       "8       0.0000  0.5000  0.0000  0.0000  0.0000 -0.3333 -0.3651\n",
       "9       0.2500  0.5000  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "Mean    0.3050  0.5150  0.3417  0.2925  0.2667  0.0874  0.0886\n",
       "SD      0.1823  0.2720  0.2082  0.2646  0.1897  0.2434  0.3120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1588</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.7083  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "1       0.4000  0.0000  0.5000  0.4500  0.3467  0.2105  0.3536\n",
       "2       0.2000  0.0000  0.1667  0.1333  0.1600 -0.1765 -0.2165\n",
       "3       0.6000  0.8250  0.7500  0.4000  0.4667  0.5000  0.5893\n",
       "4       0.2000  0.8500  0.2500  0.0500  0.0800 -0.0526 -0.0833\n",
       "5       0.2000  0.6750  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "6       0.4000  0.5333  0.2500  0.2000  0.2667  0.0625  0.0833\n",
       "7       0.4000  0.8250  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "8       0.0000  0.5000  0.0000  0.0000  0.0000 -0.3333 -0.4082\n",
       "9       0.2500  0.5833  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "Mean    0.3050  0.5500  0.3167  0.1890  0.2112  0.0544  0.0726\n",
       "SD      0.1588  0.2985  0.1920  0.1471  0.1397  0.2166  0.2702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.5083</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.3653</td>\n",
       "      <td>0.2337</td>\n",
       "      <td>0.3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.3092</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.2336</td>\n",
       "      <td>0.2633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.4667  0.3750  0.4500  0.3467  0.2105  0.3333\n",
       "1       0.4000  0.0000  0.5000  0.4500  0.3467  0.2105  0.3536\n",
       "2       0.6000  0.0000  0.6667  0.8667  0.6333  0.4444  0.5345\n",
       "3       0.4000  0.8833  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "4       0.4000  0.4167  0.2500  0.2667  0.3200  0.1176  0.1260\n",
       "5       0.4000  0.6333  0.5000  0.2000  0.2667  0.2105  0.2357\n",
       "6       0.2000  0.7167  0.1250  0.1333  0.1600 -0.1765 -0.1890\n",
       "7       0.8000  0.8833  0.8750  0.9000  0.8000  0.7368  0.7778\n",
       "8       0.5000  0.7500  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "9       0.2500  0.3333  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "Mean    0.4350  0.5083  0.4542  0.3933  0.3653  0.2337  0.3060\n",
       "SD      0.1613  0.3092  0.2070  0.2699  0.1951  0.2336  0.2633"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.4883</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.2965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0         0.20  0.5333  0.1250  0.2000  0.2000 -0.1111 -0.1179\n",
       "1         0.80  0.0000  0.8333  0.9000  0.8000  0.7059  0.7500\n",
       "2         0.80  0.0000  0.8333  0.9000  0.8000  0.7059  0.7500\n",
       "3         0.60  0.8417  0.6250  0.6667  0.5667  0.4737  0.5669\n",
       "4         0.40  0.7750  0.3750  0.5000  0.4000  0.2105  0.2222\n",
       "5         0.40  0.8333  0.5000  0.2000  0.2667  0.2500  0.2946\n",
       "6         0.40  0.7583  0.5000  0.2667  0.3000  0.2105  0.2520\n",
       "7         0.60  0.7333  0.6250  0.5000  0.5333  0.4444  0.4714\n",
       "8         0.25  0.5417  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "9         0.75  0.6667  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "Mean      0.52  0.5683  0.5417  0.4883  0.4700  0.3557  0.3920\n",
       "SD        0.21  0.3014  0.2275  0.2715  0.2258  0.2760  0.2965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.5208</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.3649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.2294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.7000  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "1       0.8000  0.0000  0.8333  0.9000  0.8000  0.7059  0.7500\n",
       "2       0.4000  0.0000  0.5000  0.2667  0.3000  0.1667  0.2165\n",
       "3       0.6000  0.7500  0.5000  0.6000  0.6000  0.4444  0.4444\n",
       "4       0.8000  0.8500  0.7500  0.7000  0.7333  0.7222  0.7660\n",
       "5       0.4000  0.7167  0.5000  0.3000  0.3333  0.2500  0.2946\n",
       "6       0.4000  0.4833  0.5000  0.2667  0.3000  0.2105  0.2520\n",
       "7       0.4000  0.6000  0.3750  0.3000  0.3333  0.1667  0.1768\n",
       "8       0.2500  0.5833  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "9       0.5000  0.5833  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "Mean    0.4950  0.5267  0.5208  0.3875  0.4133  0.3250  0.3649\n",
       "SD      0.1739  0.2809  0.1573  0.2422  0.2061  0.2230  0.2294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.2593</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.2412</td>\n",
       "      <td>0.2758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.0  0.5000  0.2667  0.3000  0.2500  0.3150\n",
       "1       0.6000  0.0  0.6667  0.7000  0.6000  0.4118  0.4375\n",
       "2       0.2000  0.0  0.1250  0.1333  0.1600 -0.0526 -0.0722\n",
       "3       0.4000  0.0  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "4       0.2000  0.0  0.2500  0.0667  0.1000  0.0000  0.0000\n",
       "5       0.4000  0.0  0.5000  0.2667  0.3000  0.2500  0.3150\n",
       "6       0.2000  0.0  0.2500  0.2000  0.2000 -0.1111 -0.1179\n",
       "7       0.6000  0.0  0.7500  0.4000  0.4667  0.5000  0.5893\n",
       "8       0.0000  0.0  0.0000  0.0000  0.0000 -0.3333 -0.3651\n",
       "9       0.2500  0.0  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "Mean    0.3250  0.0  0.3667  0.2425  0.2593  0.1081  0.1306\n",
       "SD      0.1806  0.0  0.2250  0.1879  0.1669  0.2412  0.2758"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.3708</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>0.2289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.2000  0.5167  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "1       0.4000  0.0000  0.5000  0.4500  0.3467  0.2105  0.3536\n",
       "2       0.2000  0.0000  0.3333  0.0400  0.0667  0.0000  0.0000\n",
       "3       0.2000  0.1500  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "4       0.2000  0.3167  0.2500  0.0500  0.0800 -0.0526 -0.0833\n",
       "5       0.2000  0.3167  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "6       0.4000  0.3667  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "7       0.6000  0.1333  0.6250  0.6000  0.5333  0.4737  0.5303\n",
       "8       0.5000  0.2500  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "9       0.2500  0.5000  0.2500  0.0625  0.1000  0.0000  0.0000\n",
       "Mean    0.3150  0.2550  0.3708  0.1906  0.1982  0.1215  0.1689\n",
       "SD      0.1415  0.1745  0.1375  0.1964  0.1628  0.1725  0.2289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.420</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.204</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.3245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0        0.200  0.7167  0.1250  0.1333  0.1600 -0.1765 -0.1890\n",
       "1        0.600  0.0000  0.3750  0.8000  0.6667  0.4737  0.5625\n",
       "2        0.600  0.0000  0.3750  0.6000  0.6000  0.4118  0.4375\n",
       "3        0.600  0.8333  0.6250  0.6000  0.5333  0.4737  0.5303\n",
       "4        0.400  0.5250  0.5000  0.3000  0.3333  0.2500  0.2946\n",
       "5        0.600  0.6667  0.7500  0.4667  0.5000  0.5000  0.6299\n",
       "6        0.200  0.5167  0.2500  0.0667  0.1000  0.0000  0.0000\n",
       "7        0.000  0.3000  0.0000  0.0000  0.0000 -0.3158 -0.3780\n",
       "8        0.500  0.8333  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "9        0.500  0.5833  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "Mean     0.420  0.4975  0.4000  0.3467  0.3560  0.2284  0.2704\n",
       "SD       0.204  0.2906  0.2151  0.2476  0.2099  0.2761  0.3245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1  Kappa  MCC\n",
       "0       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "1       0.4000  0.0  0.3333  0.1600  0.2286    0.0  0.0\n",
       "2       0.4000  0.0  0.3333  0.1600  0.2286    0.0  0.0\n",
       "3       0.4000  0.5  0.2500  0.1600  0.2286    0.0  0.0\n",
       "4       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "5       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "6       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "7       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "8       0.2500  0.5  0.2500  0.0625  0.1000    0.0  0.0\n",
       "9       0.2500  0.5  0.2500  0.0625  0.1000    0.0  0.0\n",
       "Mean    0.2700  0.4  0.2667  0.0805  0.1219    0.0  0.0\n",
       "SD      0.0872  0.2  0.0333  0.0527  0.0710    0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = create_model('lr')\n",
    "rf = create_model('rf')\n",
    "xgb = create_model('xgboost')\n",
    "ada = create_model('ada')\n",
    "lda = create_model('lda')  # linear discriminant\n",
    "knn = create_model('knn')\n",
    "mlp = create_model('mlp')\n",
    "svm = create_model('svm')\n",
    "rbfsvm = create_model('rbfsvm')\n",
    "nb = create_model('nb')\n",
    "gpc = create_model('gpc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicteurs : Les plus satisfaisants : ADA - LDA - KNN - LR : pluto moins bien en accuracy .... <br/>\n",
    "predicteurs 1 : Les plus satisfaisants : LR - LDA - RF - XGB - NB : environ 40% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai_classif = francais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites','meth2_similarites']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography                     int32\n",
       "Entities                      int32\n",
       "Time                          int32\n",
       "Narrative                     int32\n",
       "Overall                       int32\n",
       "Style                         int32\n",
       "Tone                          int32\n",
       "nb_entites_idem               int64\n",
       "nb_lieux_idem                 int64\n",
       "nb_dates_idem                 int64\n",
       "score_similarite_titres     float64\n",
       "score_similarite_resume1    float64\n",
       "score_similarite_resume2    float64\n",
       "score_classif1              float64\n",
       "score_classif2              float64\n",
       "score_sentiment1            float64\n",
       "score_sentiment2            float64\n",
       "meth1_similarites           float64\n",
       "meth2_similarites           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si on veut utiliser faire un classemen,t supprimer ligne error puis changer les types pour meth1 meth2\n",
    "essai_classif = essai_classif[essai_classif.meth1_similarites != 'Error']\n",
    "essai_classif['meth1_similarites'] = essai_classif['meth1_similarites'].astype('float')\n",
    "essai_classif['meth2_similarites'] = essai_classif['meth2_similarites'].astype('float')\n",
    "essai_classif.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.4763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.1361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.4860</td>\n",
       "      <td>0.3563</td>\n",
       "      <td>0.3945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1153</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>0.2799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.8000  0.9000  0.7500  0.6667  0.7200  0.7059  0.7559\n",
       "1       0.2000  0.6833  0.1250  0.2000  0.2000 -0.1111 -0.1111\n",
       "2       0.4000  0.8500  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "3       0.6000  0.6833  0.5000  0.3667  0.4533  0.4118  0.4763\n",
       "4       0.4000  0.6333  0.3750  0.6000  0.4667  0.2105  0.2222\n",
       "5       0.4000  0.7500  0.2500  0.2667  0.3200  0.1176  0.1361\n",
       "6       0.6000  0.8500  0.6250  0.6000  0.5333  0.4737  0.5303\n",
       "7       0.4000  0.7167  0.3750  0.6000  0.4667  0.2105  0.2222\n",
       "8       0.7500  0.9167  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "9       0.7500  1.0000  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "Mean    0.5300  0.7983  0.4875  0.5017  0.4860  0.3563  0.3945\n",
       "SD      0.1887  0.1153  0.2125  0.1589  0.1574  0.2590  0.2799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xtrain = essai_classif[predicteurs + ['Overall']]\n",
    "french_classif = setup(data = Xtrain,  target = 'Overall', html=False, silent=True, verbose=False)\n",
    "rf = create_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict_model(rf)  # ne marche pas ????\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.4763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6583</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5917</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3950</td>\n",
       "      <td>0.5792</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>0.2145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.2774</td>\n",
       "      <td>0.3002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.6000  0.8000  0.5000  0.5000  0.5333  0.4444  0.4714\n",
       "1       0.6000  0.5833  0.5000  0.3667  0.4533  0.4118  0.4763\n",
       "2       0.4000  0.6583  0.3750  0.5000  0.4000  0.2105  0.2222\n",
       "3       0.2000  0.5500  0.1250  0.4000  0.2667 -0.0526 -0.0630\n",
       "4       0.4000  0.6250  0.3750  0.5000  0.4000  0.2105  0.2357\n",
       "5       0.2000  0.6000  0.1250  0.2000  0.2000 -0.1111 -0.1111\n",
       "6       0.4000  0.5500  0.3750  0.4000  0.4000  0.1667  0.1768\n",
       "7       0.4000  0.5917  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "8       0.7500  0.6667  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "9       0.0000  0.1667  0.0000  0.0000  0.0000 -0.3333 -0.3333\n",
       "Mean    0.3950  0.5792  0.3625  0.3658  0.3553  0.1864  0.2145\n",
       "SD      0.2103  0.1540  0.2125  0.1801  0.1781  0.2774  0.3002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda = create_model('lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random Forest simple sur scikit learn\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xtrain[:50],ytrain[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>83.65</td>\n",
       "      <td>69.14</td>\n",
       "      <td>26.07</td>\n",
       "      <td>79.42</td>\n",
       "      <td>9.45</td>\n",
       "      <td>95.91</td>\n",
       "      <td>41.50</td>\n",
       "      <td>256.4</td>\n",
       "      <td>301.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>64.23</td>\n",
       "      <td>57.55</td>\n",
       "      <td>70.79</td>\n",
       "      <td>97.61</td>\n",
       "      <td>8.36</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11.05</td>\n",
       "      <td>165.4</td>\n",
       "      <td>389.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.01</td>\n",
       "      <td>25.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.62</td>\n",
       "      <td>99.99</td>\n",
       "      <td>32.26</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>66.92</td>\n",
       "      <td>61.40</td>\n",
       "      <td>66.44</td>\n",
       "      <td>10.38</td>\n",
       "      <td>97.21</td>\n",
       "      <td>16.85</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>48.51</td>\n",
       "      <td>55.93</td>\n",
       "      <td>63.85</td>\n",
       "      <td>46.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>83.60</td>\n",
       "      <td>30.36</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.22</td>\n",
       "      <td>37.96</td>\n",
       "      <td>52.72</td>\n",
       "      <td>32.87</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>38.59</td>\n",
       "      <td>31.92</td>\n",
       "      <td>33.52</td>\n",
       "      <td>44.72</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.46</td>\n",
       "      <td>28.30</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.93</td>\n",
       "      <td>12.74</td>\n",
       "      <td>10.22</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.07</td>\n",
       "      <td>99.87</td>\n",
       "      <td>46.52</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>40.36</td>\n",
       "      <td>72.15</td>\n",
       "      <td>47.00</td>\n",
       "      <td>81.74</td>\n",
       "      <td>11.49</td>\n",
       "      <td>99.90</td>\n",
       "      <td>34.50</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.78</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13.04</td>\n",
       "      <td>91.10</td>\n",
       "      <td>36.71</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>21.72</td>\n",
       "      <td>12.48</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.38</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>74.32</td>\n",
       "      <td>66.79</td>\n",
       "      <td>40.39</td>\n",
       "      <td>60.62</td>\n",
       "      <td>10.50</td>\n",
       "      <td>99.88</td>\n",
       "      <td>19.83</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>56.29</td>\n",
       "      <td>70.34</td>\n",
       "      <td>51.43</td>\n",
       "      <td>42.65</td>\n",
       "      <td>10.45</td>\n",
       "      <td>99.30</td>\n",
       "      <td>42.80</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>28.04</td>\n",
       "      <td>36.26</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>99.97</td>\n",
       "      <td>29.27</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>47.46</td>\n",
       "      <td>47.85</td>\n",
       "      <td>54.29</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.99</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>38.26</td>\n",
       "      <td>50.95</td>\n",
       "      <td>63.59</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.48</td>\n",
       "      <td>11.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>26.87</td>\n",
       "      <td>41.90</td>\n",
       "      <td>48.33</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50               13             15              0                    83.65   \n",
       "51                4             25              0                    64.23   \n",
       "52                2              2              0                     7.36   \n",
       "53                7              3              0                     9.00   \n",
       "54                2              8              0                    48.51   \n",
       "55                2              1              0                    57.22   \n",
       "56                3             12              0                    38.59   \n",
       "57                0              0              0                     7.93   \n",
       "58                1              7              0                    40.36   \n",
       "59                0              0              0                    30.36   \n",
       "60                1              3              0                    14.33   \n",
       "61                1              8              0                    74.32   \n",
       "62                2             60              0                    56.29   \n",
       "63                7             30              0                    28.04   \n",
       "64                3              8              0                    47.46   \n",
       "65                4              0              0                     6.03   \n",
       "66               15             17              0                    38.26   \n",
       "67                0              0              0                     9.48   \n",
       "68                2             10              0                    26.87   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                     69.14                     26.07           79.42   \n",
       "51                     57.55                     70.79           97.61   \n",
       "52                     10.01                     25.70            4.73   \n",
       "53                     66.92                     61.40           66.44   \n",
       "54                     55.93                     63.85           46.37   \n",
       "55                     37.96                     52.72           32.87   \n",
       "56                     31.92                     33.52           44.72   \n",
       "57                     12.74                     10.22           10.34   \n",
       "58                     72.15                     47.00           81.74   \n",
       "59                      7.50                      4.78            3.77   \n",
       "60                     21.72                     12.48           29.07   \n",
       "61                     66.79                     40.39           60.62   \n",
       "62                     70.34                     51.43           42.65   \n",
       "63                     36.26                     44.33            1.49   \n",
       "64                     47.85                     54.29           35.06   \n",
       "65                     13.21                      3.99           14.24   \n",
       "66                     50.95                     63.59           93.14   \n",
       "67                     11.70                      3.17            6.09   \n",
       "68                     41.90                     48.33           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2  meth1_similarites  \\\n",
       "50            9.45             95.91             41.50              256.4   \n",
       "51            8.36             96.46             11.05              165.4   \n",
       "52            8.62             99.99             32.26               80.7   \n",
       "53           10.38             97.21             16.85              564.1   \n",
       "54            8.59             83.60             30.36              374.8   \n",
       "55           10.75             18.59             33.70              130.0   \n",
       "56            9.49              7.46             28.30              138.8   \n",
       "57           10.07             99.87             46.52               21.1   \n",
       "58           11.49             99.90             34.50              223.8   \n",
       "59           13.04             91.10             36.71               50.7   \n",
       "60            8.22              0.16             35.38              120.0   \n",
       "61           10.50             99.88             19.83              437.9   \n",
       "62           10.45             99.30             42.80              344.5   \n",
       "63            9.78             99.97             29.27              142.0   \n",
       "64           10.08             97.33             30.89               21.2   \n",
       "65            8.91              1.03             20.16              174.0   \n",
       "66            9.39             99.98             31.05              176.2   \n",
       "67            8.37             99.84             29.93                8.8   \n",
       "68           10.33             99.54             27.09              150.3   \n",
       "\n",
       "    meth2_similarites  Overall  RF  \n",
       "50              301.4        1   1  \n",
       "51              389.4        1   1  \n",
       "52              215.1        4   3  \n",
       "53              248.6        1   1  \n",
       "54              339.8        1   1  \n",
       "55              159.8        2   2  \n",
       "56               74.0        2   3  \n",
       "57               54.1        4   4  \n",
       "58              170.8        2   1  \n",
       "59               68.7        2   4  \n",
       "60              228.2        4   3  \n",
       "61              301.2        2   1  \n",
       "62              485.7        1   1  \n",
       "63              289.0        2   3  \n",
       "64               35.8        3   1  \n",
       "65              179.9        3   4  \n",
       "66              258.7        1   1  \n",
       "67               28.4        4   4  \n",
       "68              114.6        3   2  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf = rf.predict(Xtrain[50:])\n",
    "res_rf = pd.concat([Xtrain[50:],ytrain[50:],pd.DataFrame(res_rf,columns = ['RF'],index = range(50,69))],axis=1)\n",
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 0, 0],\n",
       "       [2, 1, 2, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résultats corrects : 9/19 - 8/19 : 1 d'écart - 2/19 : 2 écart \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(res_rf.Overall,res_rf.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  8,  2,  9,  7,  0,  6,  3, 11,  5, 10,  4], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(rf, Xtrain, ytrain, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "tree_feature_importances = rf.feature_importances_\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(predicteurs))\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.array(predicteurs)[sorted_idx])\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Overall  RF  LDA\n",
       "50        1   1    2\n",
       "51        1   1    1\n",
       "52        4   3    4\n",
       "53        1   1    1\n",
       "54        1   1    1\n",
       "55        2   2    3\n",
       "56        2   3    3\n",
       "57        4   4    3\n",
       "58        2   1    1\n",
       "59        2   4    3\n",
       "60        4   3    3\n",
       "61        2   1    1\n",
       "62        1   1    2\n",
       "63        2   3    3\n",
       "64        3   1    3\n",
       "65        3   4    4\n",
       "66        1   1    2\n",
       "67        4   4    4\n",
       "68        3   2    3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Xtrain[:50],ytrain[:50])\n",
    "res_lda = lda.predict(Xtrain[50:])\n",
    "res_final = pd.concat([res_rf[['Overall','RF']],pd.DataFrame(res_lda,columns = ['LDA'],index = range(50,69))],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.76, 93.17,  0.07,  0.  ],\n",
       "       [94.81,  4.46,  0.72,  0.01],\n",
       "       [ 0.  ,  1.8 , 40.51, 57.69],\n",
       "       [99.95,  0.  ,  0.  ,  0.04],\n",
       "       [99.11,  0.25,  0.58,  0.06],\n",
       "       [ 4.16, 17.3 , 72.09,  6.45],\n",
       "       [ 5.13, 17.86, 72.58,  4.43],\n",
       "       [ 0.  ,  6.57, 66.63, 26.79],\n",
       "       [83.44, 15.84,  0.68,  0.04],\n",
       "       [ 0.  ,  4.03, 60.53, 35.45],\n",
       "       [ 0.12, 29.8 , 65.36,  4.73],\n",
       "       [99.94,  0.05,  0.01,  0.  ],\n",
       "       [ 0.  , 90.9 ,  9.1 ,  0.  ],\n",
       "       [ 0.  , 37.38, 62.32,  0.3 ],\n",
       "       [ 0.26, 35.8 , 45.62, 18.32],\n",
       "       [ 0.01,  3.81, 20.88, 75.3 ],\n",
       "       [ 6.97, 90.03,  2.92,  0.08],\n",
       "       [ 0.  ,  0.74,  9.01, 90.26],\n",
       "       [ 0.09, 12.34, 57.52, 30.05]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import around\n",
    "import numpy\n",
    "np.set_printoptions(suppress=True)  # supprime notation exp\n",
    "res_lda2 = around(lda.predict_proba(Xtrain[50:])*100, decimals=2)\n",
    "res_lda2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Remarquer que la classification ne tient pas compte du fait que c'est ordonné en classement 1-2-3-4 : ce qui est TRES important (ex : ligne 55% de 1 - 43% de 4) !! : il faudrait donc faire ressortir un score avec les probas plutot !!!_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42., 41., 17.,  0.],\n",
       "       [55., 33.,  6.,  6.],\n",
       "       [ 0., 16., 66., 18.],\n",
       "       [47., 37.,  8.,  8.],\n",
       "       [49., 41.,  6.,  4.],\n",
       "       [25., 46.,  9., 20.],\n",
       "       [ 7., 32., 34., 27.],\n",
       "       [ 0.,  7., 20., 73.],\n",
       "       [43., 28., 17., 12.],\n",
       "       [ 0., 11., 39., 50.],\n",
       "       [ 1., 16., 56., 27.],\n",
       "       [50., 32.,  8., 10.],\n",
       "       [49., 37., 10.,  4.],\n",
       "       [14., 38., 45.,  3.],\n",
       "       [28., 28., 18., 26.],\n",
       "       [ 0., 20., 34., 46.],\n",
       "       [45., 36., 15.,  4.],\n",
       "       [ 0.,  3., 17., 80.],\n",
       "       [31., 35., 14., 20.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf2 = around(rf.predict_proba(Xtrain[50:])*100, decimals=2)\n",
    "res_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau programme basé sur les scores probas : si plus de 50% mettre catégorie obtenue sinon, faire la somme 1-2 et 3/4 \n",
    "# et prendre le plus gros score puis regarder si ce sore > 65% alors à ce moment là prendre le plus gros de la catégorie \n",
    "# sinon prendre 2 ou 3\n",
    "def choix_classes(score_prob):\n",
    "    classe_finale = []\n",
    "    for i in range(len(score_prob)):\n",
    "        res = list(score_prob[i,:])\n",
    "        max_res = max(res)\n",
    "        if max_res > 50:\n",
    "            classe_finale.append(res.index(max_res)+1)\n",
    "        else:\n",
    "            som1 = res[0]+res[1]\n",
    "            som2 = res[2]+res[3]\n",
    "            if som1 > som2:\n",
    "                if som1 >= 65:\n",
    "                    choix = 1 if res[0]>res[1] else 2\n",
    "                else:\n",
    "                    choix = 2\n",
    "            else:\n",
    "                if som2 >= 65:\n",
    "                    choix = 4 if res[3]>res[2] else 3\n",
    "                else:\n",
    "                    choix = 3\n",
    "            classe_finale.append(choix)\n",
    "    return classe_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_rf = choix_classes(res_rf2)\n",
    "liste_lda = choix_classes(res_lda2)\n",
    "res_final = pd.concat([res_final,pd.DataFrame(liste_lda,columns = ['LDA_Prob'],index = range(50,69)),\n",
    "                       pd.DataFrame(liste_rf,columns = ['RF_Prob'],index = range(50,69))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(Xtrain[:50],ytrain[:50])\n",
    "res_knn = knn.predict(Xtrain[50:])\n",
    "liste_knn = choix_classes(around(knn.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['KNN'],index = range(50,69)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['KNN_Prob'],index = range(50,69))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain[:50],ytrain[:50])\n",
    "res_logreg = logreg.predict(Xtrain[50:])\n",
    "liste_logreg = choix_classes(around(logreg.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_logreg,columns = ['LOGR'],index = range(50,69)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['LOGR_Prob'],index = range(50,69))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(Xtrain[:50],ytrain[:50])\n",
    "res_ada = ada.predict(Xtrain[50:])\n",
    "liste_ada = choix_classes(around(ada.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['ADA'],index = range(50,69)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['ADA_Prob'],index = range(50,69))],axis=1)\n",
    "res_final = res_final [['Overall','RF','LDA','KNN','LOGR','ADA','RF_Prob','LDA_Prob','KNN_Prob','LOGR_Prob','ADA_Prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>ADA</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>KNN_Prob</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>ADA_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Overall  RF  LDA  KNN  LOGR  ADA  RF_Prob  LDA_Prob  KNN_Prob  LOGR_Prob  \\\n",
       "50        1   1    2    2     2    2        1         2         2          2   \n",
       "51        1   1    1    3     1    3        1         1         3          3   \n",
       "52        4   3    4    3     3    3        3         4         3          3   \n",
       "53        1   1    1    1     1    1        1         1         1          1   \n",
       "54        1   1    1    1     1    1        1         1         1          1   \n",
       "55        2   2    3    4     3    4        2         3         3          3   \n",
       "56        2   3    3    4     2    4        3         3         4          4   \n",
       "57        4   4    3    4     4    4        4         3         4          4   \n",
       "58        2   1    1    1     1    1        1         1         2          2   \n",
       "59        2   4    3    3     4    3        4         3         3          3   \n",
       "60        4   3    3    3     2    3        3         3         3          3   \n",
       "61        2   1    1    1     1    1        1         1         1          1   \n",
       "62        1   1    2    1     3    1        1         2         2          2   \n",
       "63        2   3    3    2     3    2        2         3         2          2   \n",
       "64        3   1    3    4     4    4        2         3         4          4   \n",
       "65        3   4    4    3     2    3        4         4         3          3   \n",
       "66        1   1    2    2     2    2        1         2         2          2   \n",
       "67        4   4    4    4     4    4        4         4         4          4   \n",
       "68        3   2    3    4     3    4        2         3         4          4   \n",
       "\n",
       "    ADA_Prob  \n",
       "50         2  \n",
       "51         3  \n",
       "52         3  \n",
       "53         1  \n",
       "54         1  \n",
       "55         3  \n",
       "56         4  \n",
       "57         4  \n",
       "58         2  \n",
       "59         3  \n",
       "60         3  \n",
       "61         1  \n",
       "62         2  \n",
       "63         2  \n",
       "64         4  \n",
       "65         3  \n",
       "66         2  \n",
       "67         4  \n",
       "68         4  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir ensuite à utiliser les resultats reçus pour obtenir un resultat final : mieux ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "francais = pd.read_csv('corpus_fr_notes_v2.csv',index_col=0)\n",
    "francais = francais[francais.meth1_similarites!='Error']\n",
    "french_classif = setup(data = francais[predicteurs + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.2064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.2978</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.3949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6703</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>-0.2341</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>0.2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9839</td>\n",
       "      <td>1.3960</td>\n",
       "      <td>1.1815</td>\n",
       "      <td>-7.7247</td>\n",
       "      <td>0.3025</td>\n",
       "      <td>0.3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5577</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.8109</td>\n",
       "      <td>-0.0275</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>0.3345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5264</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>-0.0959</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>-0.1815</td>\n",
       "      <td>0.2511</td>\n",
       "      <td>0.1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.1975</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>1.5131</td>\n",
       "      <td>-1.3848</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8941</td>\n",
       "      <td>1.1564</td>\n",
       "      <td>1.0753</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>0.6939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5581</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.7188</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7178</td>\n",
       "      <td>0.9211</td>\n",
       "      <td>0.9228</td>\n",
       "      <td>-0.7658</td>\n",
       "      <td>0.2591</td>\n",
       "      <td>0.3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>2.3861</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.1552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.6550  0.5902  0.7682  0.5082  0.2132  0.2064\n",
       "1     0.4899  0.2978  0.5457  0.5346  0.2197  0.3949\n",
       "2     0.6703  0.7899  0.8887 -0.2341  0.2319  0.2419\n",
       "3     0.9839  1.3960  1.1815 -7.7247  0.3025  0.3171\n",
       "4     0.5577  0.6576  0.8109 -0.0275  0.2795  0.3345\n",
       "5     0.5264  0.6137  0.7834 -0.0959  0.2464  0.1820\n",
       "6     0.6451  0.9452  0.9722 -0.1815  0.2511  0.1837\n",
       "7     1.1975  2.2894  1.5131 -1.3848  0.3654  0.5084\n",
       "8     0.8941  1.1564  1.0753  0.2291  0.2277  0.6939\n",
       "9     0.5581  0.4746  0.6889  0.7188  0.2535  0.4270\n",
       "Mean  0.7178  0.9211  0.9228 -0.7658  0.2591  0.3490\n",
       "SD    0.2198  0.5507  0.2636  2.3861  0.0439  0.1552"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.2471</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.1549</td>\n",
       "      <td>0.2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2484</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>-0.3447</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>0.5392</td>\n",
       "      <td>0.5458</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>0.2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6237</td>\n",
       "      <td>0.5694</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>0.1841</td>\n",
       "      <td>0.1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9939</td>\n",
       "      <td>1.3812</td>\n",
       "      <td>1.1752</td>\n",
       "      <td>-0.7265</td>\n",
       "      <td>0.3136</td>\n",
       "      <td>0.3422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7381</td>\n",
       "      <td>0.8188</td>\n",
       "      <td>0.9049</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.2953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.3799</td>\n",
       "      <td>0.6164</td>\n",
       "      <td>0.7467</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7577</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.3277</td>\n",
       "      <td>0.6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.5061</td>\n",
       "      <td>0.6658</td>\n",
       "      <td>0.3130</td>\n",
       "      <td>0.2049</td>\n",
       "      <td>0.2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.1429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.4671  0.2471  0.4971  0.7941  0.1549  0.2248\n",
       "1     0.4937  0.2465  0.4965  0.6149  0.1981  0.3883\n",
       "2     0.2484  0.0926  0.3043  0.8553  0.0938  0.1012\n",
       "3     0.3478  0.2151  0.4638 -0.3447  0.1186  0.1150\n",
       "4     0.4885  0.2907  0.5392  0.5458  0.2027  0.2968\n",
       "5     0.6237  0.5694  0.7546 -0.0167  0.1841  0.1823\n",
       "6     0.9939  1.3812  1.1752 -0.7265  0.3136  0.3422\n",
       "7     0.7381  0.8188  0.9049  0.1471  0.2325  0.2953\n",
       "8     0.5401  0.3799  0.6164  0.7467  0.2225  0.3897\n",
       "9     0.7577  0.8202  0.9056  0.5140  0.3277  0.6059\n",
       "Mean  0.5699  0.5061  0.6658  0.3130  0.2049  0.2942\n",
       "SD    0.2056  0.3766  0.2508  0.5048  0.0712  0.1429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.7093</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.2818</td>\n",
       "      <td>0.5293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3640</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.5503</td>\n",
       "      <td>0.5269</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>-2.0640</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>0.6935</td>\n",
       "      <td>0.2485</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.7798</td>\n",
       "      <td>-0.0859</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8280</td>\n",
       "      <td>1.7129</td>\n",
       "      <td>1.3088</td>\n",
       "      <td>-1.1412</td>\n",
       "      <td>0.3852</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9740</td>\n",
       "      <td>1.4281</td>\n",
       "      <td>1.1950</td>\n",
       "      <td>-0.4876</td>\n",
       "      <td>0.3115</td>\n",
       "      <td>0.4070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.3312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5450</td>\n",
       "      <td>0.4191</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.3879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5479</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.7246</td>\n",
       "      <td>-0.0209</td>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2152</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.0856</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.1940  0.0476  0.2181  0.9604  0.0647  0.0862\n",
       "1     0.5860  0.5031  0.7093  0.2138  0.2818  0.5293\n",
       "2     0.3640  0.3028  0.5503  0.5269  0.1345  0.1237\n",
       "3     0.6280  0.4902  0.7002 -2.0640  0.1945  0.2003\n",
       "4     0.5180  0.4810  0.6935  0.2485  0.2228  0.2213\n",
       "5     0.4600  0.6081  0.7798 -0.0859  0.2520  0.1512\n",
       "6     0.8280  1.7129  1.3088 -1.1412  0.3852  0.2490\n",
       "7     0.9740  1.4281  1.1950 -0.4876  0.3115  0.4070\n",
       "8     0.3825  0.1969  0.4437  0.8688  0.1879  0.3312\n",
       "9     0.5450  0.4191  0.6474  0.7516  0.2290  0.3879\n",
       "Mean  0.5479  0.6190  0.7246 -0.0209  0.2264  0.2687\n",
       "SD    0.2152  0.5045  0.3065  0.9182  0.0856  0.1344"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.3246</td>\n",
       "      <td>0.5697</td>\n",
       "      <td>0.7295</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6148</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>0.3824</td>\n",
       "      <td>0.2503</td>\n",
       "      <td>0.5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.4326</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3137</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>-0.2938</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.5416</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.2867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.5202</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1881</td>\n",
       "      <td>0.1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0074</td>\n",
       "      <td>1.4916</td>\n",
       "      <td>1.2213</td>\n",
       "      <td>-0.8644</td>\n",
       "      <td>0.3276</td>\n",
       "      <td>0.3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.8551</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.3045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.4808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.7239</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.3092</td>\n",
       "      <td>0.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.6012</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.7011</td>\n",
       "      <td>0.2659</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.3757</td>\n",
       "      <td>0.2292</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.1438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.5318  0.3246  0.5697  0.7295  0.1720  0.2503\n",
       "1     0.6148  0.3953  0.6287  0.3824  0.2503  0.5002\n",
       "2     0.3737  0.1871  0.4326  0.7076  0.1533  0.1611\n",
       "3     0.3137  0.2070  0.4550 -0.2938  0.1266  0.1044\n",
       "4     0.5123  0.2933  0.5416  0.5417  0.1989  0.2867\n",
       "5     0.6065  0.5202  0.7212  0.0711  0.1881  0.1882\n",
       "6     1.0074  1.4916  1.2213 -0.8644  0.3276  0.3455\n",
       "7     0.7550  0.8551  0.9247  0.1093  0.2462  0.3045\n",
       "8     0.6124  0.4426  0.6653  0.7049  0.2536  0.4808\n",
       "9     0.6846  0.7239  0.8508  0.5710  0.3092  0.5491\n",
       "Mean  0.6012  0.5441  0.7011  0.2659  0.2226  0.3171\n",
       "SD    0.1852  0.3757  0.2292  0.4939  0.0626  0.1438"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.3076</td>\n",
       "      <td>0.9211</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>-0.2880</td>\n",
       "      <td>0.3507</td>\n",
       "      <td>0.6957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4131</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>0.5203</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>-0.7990</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.5442</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.2349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>-0.5754</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.2477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.1075</td>\n",
       "      <td>1.9997</td>\n",
       "      <td>1.4141</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>0.4043</td>\n",
       "      <td>0.3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6779</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.2384</td>\n",
       "      <td>0.2756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>0.7629</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.4980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.4497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.6235</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.3205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.5191</td>\n",
       "      <td>0.2958</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>0.1746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.2604  0.0946  0.3076  0.9211  0.1057  0.1384\n",
       "1     0.7326  0.8243  0.9079 -0.2880  0.3507  0.6957\n",
       "2     0.4131  0.2707  0.5203  0.5771  0.1339  0.1472\n",
       "3     0.4184  0.2878  0.5365 -0.7990  0.1459  0.1353\n",
       "4     0.4472  0.2962  0.5442  0.5372  0.1776  0.2349\n",
       "5     0.7909  0.8822  0.9393 -0.5754  0.2605  0.2477\n",
       "6     1.1075  1.9997  1.4141 -1.4996  0.4043  0.3821\n",
       "7     0.6779  0.8769  0.9364  0.0865  0.2384  0.2756\n",
       "8     0.7480  0.5820  0.7629  0.6120  0.2586  0.4980\n",
       "9     0.6391  0.4902  0.7001  0.7095  0.2517  0.4497\n",
       "Mean  0.6235  0.6605  0.7569  0.0282  0.2327  0.3205\n",
       "SD    0.2328  0.5191  0.2958  0.7516  0.0904  0.1746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6904</td>\n",
       "      <td>0.7353</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>0.3872</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.3235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4713</td>\n",
       "      <td>2.7944</td>\n",
       "      <td>1.6717</td>\n",
       "      <td>-3.3663</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>1.3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8845</td>\n",
       "      <td>1.2034</td>\n",
       "      <td>1.0970</td>\n",
       "      <td>-0.8803</td>\n",
       "      <td>0.3381</td>\n",
       "      <td>0.3784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5168</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>1.6011</td>\n",
       "      <td>-15.0212</td>\n",
       "      <td>0.5232</td>\n",
       "      <td>0.4888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0728</td>\n",
       "      <td>1.8186</td>\n",
       "      <td>1.3485</td>\n",
       "      <td>-1.8415</td>\n",
       "      <td>0.3251</td>\n",
       "      <td>0.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1010</td>\n",
       "      <td>1.6080</td>\n",
       "      <td>1.2681</td>\n",
       "      <td>-1.8714</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.3867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.6215</td>\n",
       "      <td>5.0308</td>\n",
       "      <td>2.2429</td>\n",
       "      <td>-5.2885</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.6390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.1896</td>\n",
       "      <td>1.8656</td>\n",
       "      <td>1.3659</td>\n",
       "      <td>-0.9433</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2512</td>\n",
       "      <td>2.5196</td>\n",
       "      <td>1.5873</td>\n",
       "      <td>-0.6797</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>1.1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.4319</td>\n",
       "      <td>2.5876</td>\n",
       "      <td>1.6086</td>\n",
       "      <td>-0.5334</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.9660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1.2231</td>\n",
       "      <td>2.2727</td>\n",
       "      <td>1.4649</td>\n",
       "      <td>-3.0038</td>\n",
       "      <td>0.4208</td>\n",
       "      <td>0.6637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2807</td>\n",
       "      <td>1.1156</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>4.2914</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.3376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE       R2   RMSLE    MAPE\n",
       "0     0.6904  0.7353  0.8575   0.3872  0.2573  0.3235\n",
       "1     1.4713  2.7944  1.6717  -3.3663  0.4318  1.3330\n",
       "2     0.8845  1.2034  1.0970  -0.8803  0.3381  0.3784\n",
       "3     1.5168  2.5634  1.6011 -15.0212  0.5232  0.4888\n",
       "4     1.0728  1.8186  1.3485  -1.8415  0.3251  0.5300\n",
       "5     1.1010  1.6080  1.2681  -1.8714  0.3398  0.3867\n",
       "6     1.6215  5.0308  2.2429  -5.2885  0.5437  0.6390\n",
       "7     1.1896  1.8656  1.3659  -0.9433  0.4462  0.4475\n",
       "8     1.2512  2.5196  1.5873  -0.6797  0.5215  1.1437\n",
       "9     1.4319  2.5876  1.6086  -0.5334  0.4814  0.9660\n",
       "Mean  1.2231  2.2727  1.4649  -3.0038  0.4208  0.6637\n",
       "SD    0.2807  1.1156  0.3562   4.2914  0.0946  0.3376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = create_model('lr')\n",
    "rr = create_model('lasso')\n",
    "etr = create_model('et')\n",
    "svr = create_model('svm')\n",
    "adar = create_model('ada')\n",
    "mlpr = create_model('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression simple sur scikit learn\n",
    "essai_classif = francais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites','meth2_similarites']]\n",
    "lr = LinearRegression()\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>83.65</td>\n",
       "      <td>69.14</td>\n",
       "      <td>26.07</td>\n",
       "      <td>79.42</td>\n",
       "      <td>9.45</td>\n",
       "      <td>95.91</td>\n",
       "      <td>41.50</td>\n",
       "      <td>256.4</td>\n",
       "      <td>301.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.591923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>64.23</td>\n",
       "      <td>57.55</td>\n",
       "      <td>70.79</td>\n",
       "      <td>97.61</td>\n",
       "      <td>8.36</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11.05</td>\n",
       "      <td>165.4</td>\n",
       "      <td>389.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.165432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.01</td>\n",
       "      <td>25.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.62</td>\n",
       "      <td>99.99</td>\n",
       "      <td>32.26</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.646610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>66.92</td>\n",
       "      <td>61.40</td>\n",
       "      <td>66.44</td>\n",
       "      <td>10.38</td>\n",
       "      <td>97.21</td>\n",
       "      <td>16.85</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.067664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>48.51</td>\n",
       "      <td>55.93</td>\n",
       "      <td>63.85</td>\n",
       "      <td>46.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>83.60</td>\n",
       "      <td>30.36</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.736236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.22</td>\n",
       "      <td>37.96</td>\n",
       "      <td>52.72</td>\n",
       "      <td>32.87</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.315933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>38.59</td>\n",
       "      <td>31.92</td>\n",
       "      <td>33.52</td>\n",
       "      <td>44.72</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.46</td>\n",
       "      <td>28.30</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.236454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.93</td>\n",
       "      <td>12.74</td>\n",
       "      <td>10.22</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.07</td>\n",
       "      <td>99.87</td>\n",
       "      <td>46.52</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.424757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>40.36</td>\n",
       "      <td>72.15</td>\n",
       "      <td>47.00</td>\n",
       "      <td>81.74</td>\n",
       "      <td>11.49</td>\n",
       "      <td>99.90</td>\n",
       "      <td>34.50</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.316925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.78</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13.04</td>\n",
       "      <td>91.10</td>\n",
       "      <td>36.71</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.713748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>21.72</td>\n",
       "      <td>12.48</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.38</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.463118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>74.32</td>\n",
       "      <td>66.79</td>\n",
       "      <td>40.39</td>\n",
       "      <td>60.62</td>\n",
       "      <td>10.50</td>\n",
       "      <td>99.88</td>\n",
       "      <td>19.83</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.503630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>56.29</td>\n",
       "      <td>70.34</td>\n",
       "      <td>51.43</td>\n",
       "      <td>42.65</td>\n",
       "      <td>10.45</td>\n",
       "      <td>99.30</td>\n",
       "      <td>42.80</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.206912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>28.04</td>\n",
       "      <td>36.26</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>99.97</td>\n",
       "      <td>29.27</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.694124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>47.46</td>\n",
       "      <td>47.85</td>\n",
       "      <td>54.29</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.620129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.99</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.315097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>38.26</td>\n",
       "      <td>50.95</td>\n",
       "      <td>63.59</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.427666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.48</td>\n",
       "      <td>11.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.822111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>26.87</td>\n",
       "      <td>41.90</td>\n",
       "      <td>48.33</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.865212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50               13             15              0                    83.65   \n",
       "51                4             25              0                    64.23   \n",
       "52                2              2              0                     7.36   \n",
       "53                7              3              0                     9.00   \n",
       "54                2              8              0                    48.51   \n",
       "55                2              1              0                    57.22   \n",
       "56                3             12              0                    38.59   \n",
       "57                0              0              0                     7.93   \n",
       "58                1              7              0                    40.36   \n",
       "59                0              0              0                    30.36   \n",
       "60                1              3              0                    14.33   \n",
       "61                1              8              0                    74.32   \n",
       "62                2             60              0                    56.29   \n",
       "63                7             30              0                    28.04   \n",
       "64                3              8              0                    47.46   \n",
       "65                4              0              0                     6.03   \n",
       "66               15             17              0                    38.26   \n",
       "67                0              0              0                     9.48   \n",
       "68                2             10              0                    26.87   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                     69.14                     26.07           79.42   \n",
       "51                     57.55                     70.79           97.61   \n",
       "52                     10.01                     25.70            4.73   \n",
       "53                     66.92                     61.40           66.44   \n",
       "54                     55.93                     63.85           46.37   \n",
       "55                     37.96                     52.72           32.87   \n",
       "56                     31.92                     33.52           44.72   \n",
       "57                     12.74                     10.22           10.34   \n",
       "58                     72.15                     47.00           81.74   \n",
       "59                      7.50                      4.78            3.77   \n",
       "60                     21.72                     12.48           29.07   \n",
       "61                     66.79                     40.39           60.62   \n",
       "62                     70.34                     51.43           42.65   \n",
       "63                     36.26                     44.33            1.49   \n",
       "64                     47.85                     54.29           35.06   \n",
       "65                     13.21                      3.99           14.24   \n",
       "66                     50.95                     63.59           93.14   \n",
       "67                     11.70                      3.17            6.09   \n",
       "68                     41.90                     48.33           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2 meth1_similarites  \\\n",
       "50            9.45             95.91             41.50             256.4   \n",
       "51            8.36             96.46             11.05             165.4   \n",
       "52            8.62             99.99             32.26              80.7   \n",
       "53           10.38             97.21             16.85             564.1   \n",
       "54            8.59             83.60             30.36             374.8   \n",
       "55           10.75             18.59             33.70             130.0   \n",
       "56            9.49              7.46             28.30             138.8   \n",
       "57           10.07             99.87             46.52              21.1   \n",
       "58           11.49             99.90             34.50             223.8   \n",
       "59           13.04             91.10             36.71              50.7   \n",
       "60            8.22              0.16             35.38             120.0   \n",
       "61           10.50             99.88             19.83             437.9   \n",
       "62           10.45             99.30             42.80             344.5   \n",
       "63            9.78             99.97             29.27             142.0   \n",
       "64           10.08             97.33             30.89              21.2   \n",
       "65            8.91              1.03             20.16             174.0   \n",
       "66            9.39             99.98             31.05             176.2   \n",
       "67            8.37             99.84             29.93               8.8   \n",
       "68           10.33             99.54             27.09             150.3   \n",
       "\n",
       "   meth2_similarites  Overall        LR  \n",
       "50             301.4      1.0  0.591923  \n",
       "51             389.4      1.0  1.165432  \n",
       "52             215.1      4.0  3.646610  \n",
       "53             248.6      1.0  2.067664  \n",
       "54             339.8      1.0  1.736236  \n",
       "55             159.8      2.0  2.315933  \n",
       "56              74.0      2.0  2.236454  \n",
       "57              54.1      4.0  3.424757  \n",
       "58             170.8      2.0  1.316925  \n",
       "59              68.7      2.0  3.713748  \n",
       "60             228.2      4.0  2.463118  \n",
       "61             301.2      2.0  1.503630  \n",
       "62             485.7      1.0  0.206912  \n",
       "63             289.0      2.0  2.694124  \n",
       "64              35.8      3.0  2.620129  \n",
       "65             179.9      3.0  3.315097  \n",
       "66             258.7      1.0  1.427666  \n",
       "67              28.4      4.0  3.822111  \n",
       "68             114.6      3.0  2.865212  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(Xtrain[:50],ytrain[:50])\n",
    "res_lr = lr.predict(Xtrain[50:])\n",
    "res_lr = pd.concat([Xtrain[50:],ytrain[50:],pd.DataFrame(res_lr,columns = ['LR'],index = range(50,69))],axis=1)\n",
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,res_lr['LR']],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remarque : les résultats sont assez différents : voir à utiliser différents algos ? <br/>\n",
    "En classification : Logistic Regression - XG Boost ?? - Linear Discriminant Analysis qui était OK en essai - Bayésien ? ADA Boost ? SVM ? : 1 score de classif en utilisant proba <br/>\n",
    "puis un score de régression : la Régression PLS peut être intéressante car les notes doivent très corrélées entre elles - Lasso ou ridge ne servent à rien a priori - SVR - RDN ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>83.65</td>\n",
       "      <td>69.14</td>\n",
       "      <td>26.07</td>\n",
       "      <td>79.42</td>\n",
       "      <td>9.45</td>\n",
       "      <td>95.91</td>\n",
       "      <td>41.50</td>\n",
       "      <td>256.4</td>\n",
       "      <td>301.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.591923</td>\n",
       "      <td>1.030360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>64.23</td>\n",
       "      <td>57.55</td>\n",
       "      <td>70.79</td>\n",
       "      <td>97.61</td>\n",
       "      <td>8.36</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11.05</td>\n",
       "      <td>165.4</td>\n",
       "      <td>389.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.165432</td>\n",
       "      <td>1.382881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.01</td>\n",
       "      <td>25.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.62</td>\n",
       "      <td>99.99</td>\n",
       "      <td>32.26</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.646610</td>\n",
       "      <td>3.459383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>66.92</td>\n",
       "      <td>61.40</td>\n",
       "      <td>66.44</td>\n",
       "      <td>10.38</td>\n",
       "      <td>97.21</td>\n",
       "      <td>16.85</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.067664</td>\n",
       "      <td>1.721224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>48.51</td>\n",
       "      <td>55.93</td>\n",
       "      <td>63.85</td>\n",
       "      <td>46.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>83.60</td>\n",
       "      <td>30.36</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.736236</td>\n",
       "      <td>1.753070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.22</td>\n",
       "      <td>37.96</td>\n",
       "      <td>52.72</td>\n",
       "      <td>32.87</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.315933</td>\n",
       "      <td>2.308580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>38.59</td>\n",
       "      <td>31.92</td>\n",
       "      <td>33.52</td>\n",
       "      <td>44.72</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.46</td>\n",
       "      <td>28.30</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.236454</td>\n",
       "      <td>2.483379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.93</td>\n",
       "      <td>12.74</td>\n",
       "      <td>10.22</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.07</td>\n",
       "      <td>99.87</td>\n",
       "      <td>46.52</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.424757</td>\n",
       "      <td>3.614719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>40.36</td>\n",
       "      <td>72.15</td>\n",
       "      <td>47.00</td>\n",
       "      <td>81.74</td>\n",
       "      <td>11.49</td>\n",
       "      <td>99.90</td>\n",
       "      <td>34.50</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.316925</td>\n",
       "      <td>1.740797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.78</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13.04</td>\n",
       "      <td>91.10</td>\n",
       "      <td>36.71</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.713748</td>\n",
       "      <td>3.832773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>21.72</td>\n",
       "      <td>12.48</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.38</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.463118</td>\n",
       "      <td>2.654394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>74.32</td>\n",
       "      <td>66.79</td>\n",
       "      <td>40.39</td>\n",
       "      <td>60.62</td>\n",
       "      <td>10.50</td>\n",
       "      <td>99.88</td>\n",
       "      <td>19.83</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.503630</td>\n",
       "      <td>1.716132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>56.29</td>\n",
       "      <td>70.34</td>\n",
       "      <td>51.43</td>\n",
       "      <td>42.65</td>\n",
       "      <td>10.45</td>\n",
       "      <td>99.30</td>\n",
       "      <td>42.80</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.206912</td>\n",
       "      <td>1.637124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>28.04</td>\n",
       "      <td>36.26</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>99.97</td>\n",
       "      <td>29.27</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.694124</td>\n",
       "      <td>2.927832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>47.46</td>\n",
       "      <td>47.85</td>\n",
       "      <td>54.29</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.620129</td>\n",
       "      <td>2.700901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.99</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.315097</td>\n",
       "      <td>3.126964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>38.26</td>\n",
       "      <td>50.95</td>\n",
       "      <td>63.59</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.427666</td>\n",
       "      <td>1.360300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.48</td>\n",
       "      <td>11.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.822111</td>\n",
       "      <td>3.832011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>26.87</td>\n",
       "      <td>41.90</td>\n",
       "      <td>48.33</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.865212</td>\n",
       "      <td>2.902245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50               13             15              0                    83.65   \n",
       "51                4             25              0                    64.23   \n",
       "52                2              2              0                     7.36   \n",
       "53                7              3              0                     9.00   \n",
       "54                2              8              0                    48.51   \n",
       "55                2              1              0                    57.22   \n",
       "56                3             12              0                    38.59   \n",
       "57                0              0              0                     7.93   \n",
       "58                1              7              0                    40.36   \n",
       "59                0              0              0                    30.36   \n",
       "60                1              3              0                    14.33   \n",
       "61                1              8              0                    74.32   \n",
       "62                2             60              0                    56.29   \n",
       "63                7             30              0                    28.04   \n",
       "64                3              8              0                    47.46   \n",
       "65                4              0              0                     6.03   \n",
       "66               15             17              0                    38.26   \n",
       "67                0              0              0                     9.48   \n",
       "68                2             10              0                    26.87   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                     69.14                     26.07           79.42   \n",
       "51                     57.55                     70.79           97.61   \n",
       "52                     10.01                     25.70            4.73   \n",
       "53                     66.92                     61.40           66.44   \n",
       "54                     55.93                     63.85           46.37   \n",
       "55                     37.96                     52.72           32.87   \n",
       "56                     31.92                     33.52           44.72   \n",
       "57                     12.74                     10.22           10.34   \n",
       "58                     72.15                     47.00           81.74   \n",
       "59                      7.50                      4.78            3.77   \n",
       "60                     21.72                     12.48           29.07   \n",
       "61                     66.79                     40.39           60.62   \n",
       "62                     70.34                     51.43           42.65   \n",
       "63                     36.26                     44.33            1.49   \n",
       "64                     47.85                     54.29           35.06   \n",
       "65                     13.21                      3.99           14.24   \n",
       "66                     50.95                     63.59           93.14   \n",
       "67                     11.70                      3.17            6.09   \n",
       "68                     41.90                     48.33           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2 meth1_similarites  \\\n",
       "50            9.45             95.91             41.50             256.4   \n",
       "51            8.36             96.46             11.05             165.4   \n",
       "52            8.62             99.99             32.26              80.7   \n",
       "53           10.38             97.21             16.85             564.1   \n",
       "54            8.59             83.60             30.36             374.8   \n",
       "55           10.75             18.59             33.70             130.0   \n",
       "56            9.49              7.46             28.30             138.8   \n",
       "57           10.07             99.87             46.52              21.1   \n",
       "58           11.49             99.90             34.50             223.8   \n",
       "59           13.04             91.10             36.71              50.7   \n",
       "60            8.22              0.16             35.38             120.0   \n",
       "61           10.50             99.88             19.83             437.9   \n",
       "62           10.45             99.30             42.80             344.5   \n",
       "63            9.78             99.97             29.27             142.0   \n",
       "64           10.08             97.33             30.89              21.2   \n",
       "65            8.91              1.03             20.16             174.0   \n",
       "66            9.39             99.98             31.05             176.2   \n",
       "67            8.37             99.84             29.93               8.8   \n",
       "68           10.33             99.54             27.09             150.3   \n",
       "\n",
       "   meth2_similarites  Overall        LR       PLS  \n",
       "50             301.4      1.0  0.591923  1.030360  \n",
       "51             389.4      1.0  1.165432  1.382881  \n",
       "52             215.1      4.0  3.646610  3.459383  \n",
       "53             248.6      1.0  2.067664  1.721224  \n",
       "54             339.8      1.0  1.736236  1.753070  \n",
       "55             159.8      2.0  2.315933  2.308580  \n",
       "56              74.0      2.0  2.236454  2.483379  \n",
       "57              54.1      4.0  3.424757  3.614719  \n",
       "58             170.8      2.0  1.316925  1.740797  \n",
       "59              68.7      2.0  3.713748  3.832773  \n",
       "60             228.2      4.0  2.463118  2.654394  \n",
       "61             301.2      2.0  1.503630  1.716132  \n",
       "62             485.7      1.0  0.206912  1.637124  \n",
       "63             289.0      2.0  2.694124  2.927832  \n",
       "64              35.8      3.0  2.620129  2.700901  \n",
       "65             179.9      3.0  3.315097  3.126964  \n",
       "66             258.7      1.0  1.427666  1.360300  \n",
       "67              28.4      4.0  3.822111  3.832011  \n",
       "68             114.6      3.0  2.865212  2.902245  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls = PLSRegression()\n",
    "pls.fit(Xtrain[:50],ytrain[:50])\n",
    "res_pls = list(pls.predict(Xtrain[50:]).flatten())\n",
    "res_pls = pd.concat([res_lr,pd.DataFrame(res_pls,columns = ['PLS'],index = range(50,69))],axis=1)\n",
    "res_pls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les scores de la regression PLS sont assez proches de la régression linéaire !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>ADA</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>KNN_Prob</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>ADA_Prob</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.591923</td>\n",
       "      <td>1.030360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.165432</td>\n",
       "      <td>1.382881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.646610</td>\n",
       "      <td>3.459383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.067664</td>\n",
       "      <td>1.721224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.736236</td>\n",
       "      <td>1.753070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.315933</td>\n",
       "      <td>2.308580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.236454</td>\n",
       "      <td>2.483379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.424757</td>\n",
       "      <td>3.614719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.316925</td>\n",
       "      <td>1.740797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.713748</td>\n",
       "      <td>3.832773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.463118</td>\n",
       "      <td>2.654394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.503630</td>\n",
       "      <td>1.716132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.206912</td>\n",
       "      <td>1.637124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.694124</td>\n",
       "      <td>2.927832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.620129</td>\n",
       "      <td>2.700901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.315097</td>\n",
       "      <td>3.126964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.427666</td>\n",
       "      <td>1.360300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.822111</td>\n",
       "      <td>3.832011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.865212</td>\n",
       "      <td>2.902245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Overall  RF  LDA  KNN  LOGR  ADA  RF_Prob  LDA_Prob  KNN_Prob  LOGR_Prob  \\\n",
       "50        1   1    2    2     2    2        1         2         2          2   \n",
       "51        1   1    1    3     1    3        1         1         3          3   \n",
       "52        4   3    4    3     3    3        3         4         3          3   \n",
       "53        1   1    1    1     1    1        1         1         1          1   \n",
       "54        1   1    1    1     1    1        1         1         1          1   \n",
       "55        2   2    3    4     3    4        2         3         3          3   \n",
       "56        2   3    3    4     2    4        3         3         4          4   \n",
       "57        4   4    3    4     4    4        4         3         4          4   \n",
       "58        2   1    1    1     1    1        1         1         2          2   \n",
       "59        2   4    3    3     4    3        4         3         3          3   \n",
       "60        4   3    3    3     2    3        3         3         3          3   \n",
       "61        2   1    1    1     1    1        1         1         1          1   \n",
       "62        1   1    2    1     3    1        1         2         2          2   \n",
       "63        2   3    3    2     3    2        2         3         2          2   \n",
       "64        3   1    3    4     4    4        2         3         4          4   \n",
       "65        3   4    4    3     2    3        4         4         3          3   \n",
       "66        1   1    2    2     2    2        1         2         2          2   \n",
       "67        4   4    4    4     4    4        4         4         4          4   \n",
       "68        3   2    3    4     3    4        2         3         4          4   \n",
       "\n",
       "    ADA_Prob        LR       PLS  \n",
       "50         2  0.591923  1.030360  \n",
       "51         3  1.165432  1.382881  \n",
       "52         3  3.646610  3.459383  \n",
       "53         1  2.067664  1.721224  \n",
       "54         1  1.736236  1.753070  \n",
       "55         3  2.315933  2.308580  \n",
       "56         4  2.236454  2.483379  \n",
       "57         4  3.424757  3.614719  \n",
       "58         2  1.316925  1.740797  \n",
       "59         3  3.713748  3.832773  \n",
       "60         3  2.463118  2.654394  \n",
       "61         1  1.503630  1.716132  \n",
       "62         2  0.206912  1.637124  \n",
       "63         2  2.694124  2.927832  \n",
       "64         4  2.620129  2.700901  \n",
       "65         3  3.315097  3.126964  \n",
       "66         2  1.427666  1.360300  \n",
       "67         4  3.822111  3.832011  \n",
       "68         4  2.865212  2.902245  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final = pd.concat([res_final,res_pls['PLS']],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compléments d'information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuel = francais[['title_1', 'title_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2',\n",
    "    'nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "    'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "    'score_sentiment2', 'meth1_similarites', 'meth2_similarites','Overall']]\n",
    "visuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pair_id', 'pair_lang', 'source_url_1', 'publish_date_1',\n",
       "       'source_url_2', 'publish_date_2', 'title_1', 'text_1',\n",
       "       'meta_description_1', 'meta_keywords_1', 'title_2', 'text_2',\n",
       "       'meta_description_2', 'meta_keywords_2', 'Geography', 'Entities',\n",
       "       'Time', 'Narrative', 'Overall', 'Style', 'Tone', 'ligne'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_francais = data.loc[data.pair_lang == 'fr_fr',['source_url_1', 'publish_date_1','source_url_2', 'publish_date_2', \n",
    "       'meta_description_1', 'meta_keywords_1', 'meta_description_2', 'meta_keywords_2','Overall']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://votreargent.lexpress.fr</td>\n",
       "      <td>Wed Mar 25 20:11:35 2020</td>\n",
       "      <td>https://www.lexpress.fr</td>\n",
       "      <td>Wed Mar 25 07:00:00 2020</td>\n",
       "      <td>Le cap du million de ventes a été dépassé l'an...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Stocks réduits ou distribués au \"compte-goutte...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.coupdoeil.info</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>http://www.lechodelaval.ca</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://ici.radio-canada.ca</td>\n",
       "      <td></td>\n",
       "      <td>https://www.lapresse.ca</td>\n",
       "      <td>Wed Mar 25 05:00:00 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>Des Québécois coincés au Pérou qualifient de «...</td>\n",
       "      <td>['']</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://beninsite.net</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>http://www.togolais.info</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>En l'espace de quelques jours, deux piliers de...</td>\n",
       "      <td>[\"L'Afrique pleure Manu Dibango\", '', 'info', ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.lareleve.qc.ca</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>https://canadianwomen.org</td>\n",
       "      <td>Wed Mar 25 21:15:26 2020</td>\n",
       "      <td>La MRC a décidé de mettre de l’avant différent...</td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>https://www.bladi.net</td>\n",
       "      <td></td>\n",
       "      <td>https://www.bladi.net</td>\n",
       "      <td></td>\n",
       "      <td>Les forces de l’ordre effectuent des inspectio...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>http://ici.radio-canada.ca</td>\n",
       "      <td></td>\n",
       "      <td>https://www.journalexpress.ca</td>\n",
       "      <td>Wed May 27 00:00:00 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>http://fr.nhandan.com.vn</td>\n",
       "      <td></td>\n",
       "      <td>http://fr.nhandan.com.vn</td>\n",
       "      <td></td>\n",
       "      <td>Nhân Dân en ligne - Asiatoday, l'un des princi...</td>\n",
       "      <td>['Le journal Nhân Dân', 'politique', 'économie...</td>\n",
       "      <td>Nhân Dân en ligne - Le Premier ministre (PM) v...</td>\n",
       "      <td>['Le journal Nhân Dân', 'politique', 'économie...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>https://www.acadienouvelle.com</td>\n",
       "      <td>Thu Jun 11 00:00:00 2020</td>\n",
       "      <td>https://www.telecablesat.fr</td>\n",
       "      <td></td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>['Acadie']</td>\n",
       "      <td>Comment avez-vous vécu le confinement?Au début...</td>\n",
       "      <td>['']</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>https://benin24tv.com</td>\n",
       "      <td>Mon Mar  2 18:47:14 2020</td>\n",
       "      <td>https://www.seneplus.com</td>\n",
       "      <td>Sat Mar 28 14:02:20 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>Alors que le directeur de l’Organisation mondi...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source_url_1            publish_date_1  \\\n",
       "0   https://votreargent.lexpress.fr  Wed Mar 25 20:11:35 2020   \n",
       "1        https://www.coupdoeil.info  Wed Mar 25 00:00:00 2020   \n",
       "2        http://ici.radio-canada.ca                             \n",
       "3              http://beninsite.net  Wed Mar 25 00:00:00 2020   \n",
       "4        https://www.lareleve.qc.ca  Wed Mar 25 00:00:00 2020   \n",
       "..                              ...                       ...   \n",
       "67            https://www.bladi.net                             \n",
       "68       http://ici.radio-canada.ca                             \n",
       "69         http://fr.nhandan.com.vn                             \n",
       "70   https://www.acadienouvelle.com  Thu Jun 11 00:00:00 2020   \n",
       "71            https://benin24tv.com  Mon Mar  2 18:47:14 2020   \n",
       "\n",
       "                     source_url_2            publish_date_2  \\\n",
       "0         https://www.lexpress.fr  Wed Mar 25 07:00:00 2020   \n",
       "1      http://www.lechodelaval.ca                             \n",
       "2         https://www.lapresse.ca  Wed Mar 25 05:00:00 2020   \n",
       "3        http://www.togolais.info                             \n",
       "4       https://canadianwomen.org  Wed Mar 25 21:15:26 2020   \n",
       "..                            ...                       ...   \n",
       "67          https://www.bladi.net                             \n",
       "68  https://www.journalexpress.ca  Wed May 27 00:00:00 2020   \n",
       "69       http://fr.nhandan.com.vn                             \n",
       "70    https://www.telecablesat.fr                             \n",
       "71       https://www.seneplus.com  Sat Mar 28 14:02:20 2020   \n",
       "\n",
       "                                   meta_description_1  \\\n",
       "0   Le cap du million de ventes a été dépassé l'an...   \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4   La MRC a décidé de mettre de l’avant différent...   \n",
       "..                                                ...   \n",
       "67  Les forces de l’ordre effectuent des inspectio...   \n",
       "68                                                      \n",
       "69  Nhân Dân en ligne - Asiatoday, l'un des princi...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71                                                      \n",
       "\n",
       "                                      meta_keywords_1  \\\n",
       "0                                                ['']   \n",
       "1                                                ['']   \n",
       "2                                                ['']   \n",
       "3                                                ['']   \n",
       "4                                                ['']   \n",
       "..                                                ...   \n",
       "67                                               ['']   \n",
       "68                                               ['']   \n",
       "69  ['Le journal Nhân Dân', 'politique', 'économie...   \n",
       "70                                         ['Acadie']   \n",
       "71                                               ['']   \n",
       "\n",
       "                                   meta_description_2  \\\n",
       "0   Stocks réduits ou distribués au \"compte-goutte...   \n",
       "1                                                       \n",
       "2   Des Québécois coincés au Pérou qualifient de «...   \n",
       "3   En l'espace de quelques jours, deux piliers de...   \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "67  Suite aux violations du confinement dans les v...   \n",
       "68                                                      \n",
       "69  Nhân Dân en ligne - Le Premier ministre (PM) v...   \n",
       "70  Comment avez-vous vécu le confinement?Au début...   \n",
       "71  Alors que le directeur de l’Organisation mondi...   \n",
       "\n",
       "                                      meta_keywords_2  Overall  \n",
       "0                                                ['']      3.0  \n",
       "1                                                ['']      4.0  \n",
       "2                                                ['']      2.0  \n",
       "3   [\"L'Afrique pleure Manu Dibango\", '', 'info', ...      1.0  \n",
       "4                                                ['']      3.0  \n",
       "..                                                ...      ...  \n",
       "67                                               ['']      3.0  \n",
       "68                                               ['']      3.0  \n",
       "69  ['Le journal Nhân Dân', 'politique', 'économie...      1.0  \n",
       "70                                               ['']      4.0  \n",
       "71                                               ['']      3.0  \n",
       "\n",
       "[72 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_francais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

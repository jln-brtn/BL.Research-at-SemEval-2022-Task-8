{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de classification en Français \n",
    "\n",
    "    - Transformers : Summarization : 2 modèles --> 2 Résumés / Puis score de similarités de ces 2 résumés\n",
    "    Noter que l'on peut faire aussi la similarité des textes (autre note ?) et non du résumé\n",
    "    - Text classification sur une base de catégories \"Presse\" : sport - actaulités - économie - etc\n",
    "    - Sentiment analysis : voir si le ton du texte est de même type \n",
    "    - Les 2 derniers classifier seronts utilisés en produit scalaire : Par Catégorie : texte1: note1 - texte2 : note2\n",
    "    et donc sum(notes_par_catégorie) = sum(note1*note2) * 100 au bout (note sur 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pke\n",
    "import spacy\n",
    "import torch\n",
    "import stanza\n",
    "import spacy_stanza\n",
    "import warnings\n",
    "import string\n",
    "from gensim.models import KeyedVectors\n",
    "import enchant    # Pour correction orthographique de synonymes\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection des modèles NLP : ici FRANCAIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement pour l'utilisation de Spacy  - Français\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_spacy = {'fr':nlp_fr}   # 'en':nlp_en,'de':nlp_de,'es':nlp_es,'pl':nlp_pl  - POUR MEMOIRE\n",
    "langues = ['en','fr','es','de','pl','ar','tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle Word2Vec pour utilisation de synonymes\n",
    "model_gensim = KeyedVectors.load_word2vec_format(\"D:/Users/STG-SDU/Documents/NLP/Word2Vec.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords Français NLTK + Spacy \n",
    "stopWords = list(nlp_fr.Defaults.stop_words)\n",
    "stopwords_fr = list(stopwords.words('french'))  \n",
    "stopwords_fr = list(set(stopwords_fr + stopWords))\n",
    "stopwds_lg = {'fr':stopwords_fr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcteur orthographique pour validation des synonymes OPTIONNEL CAR NON NECESSAIRE\n",
    "d = enchant.Dict(\"fr\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection des modèles Transformers : Summary - Text Classification - Sentiment Analysis - Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèles Transformers de Résumé (NB : Ne pas oublier d'ajouter la truncation pour tous les modèles, peut être source d'erreur)\n",
    "\n",
    "summarizer1 = pipeline(\"summarization\", model=\"moussaKam/barthez-orangesum-title\", truncation = \"only_first\")\n",
    "summarizer2 = pipeline(\"summarization\", model=\"lincoln/mbart-mlsum-automatic-summarization\", truncation = \"only_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textes classification ou Zero shot classification (permet de chosiri nos propres thèmes)\n",
    "text_clf1 = pipeline(\"text-classification\", model = \"lincoln/flaubert-mlsum-topic-classification\", truncation = \"only_first\")   # 10 actégories, voir hugging face\n",
    "\n",
    "# NB : BUG : zero_shot_clf = pipeline(\"zero-shot-classification\", model=\"BaptisteDoyen/camembert-base-xlni\") # download ne marche pas, donc manuel\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(\"BaptisteDoyen/camembert-base-xnli\")\n",
    "zero_tokenizer = AutoTokenizer.from_pretrained(\"BaptisteDoyen/camembert-base-xnli\") \n",
    "text_clf2 = pipeline('zero-shot-classification', model=nli_model, tokenizer=zero_tokenizer,truncation = \"only_first\")\n",
    "# ce modèle est un zero shot classification : catégories possibles choisies par mes soins (dans la presse)\n",
    "candidate_labels = ['Sciences','Politique','Education','Actualités','Santé','Technologie','Société', 'Sport','Economie','Culture','International','Environnement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DemangeJeremy/4-sentiments-with-flaubert were not used when initializing FlaubertForSequenceClassification: ['transformer.position_ids']\n",
      "- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "sentiment1 = pipeline(\"text-classification\", model = 'moussaKam/barthez-sentiment-classification')\n",
    "\n",
    "# ATTENTION CE MODELE n°2 SE DEFINIT SUR 4 CLASSES : mixed, positif, negatif, objectif\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained('flaubert/flaubert_large_cased')\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(\"DemangeJeremy/4-sentiments-with-flaubert\")\n",
    "sentiment2 = pipeline('sentiment-analysis', model=loaded_model, tokenizer=loaded_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_similarite(premise,hypothesis):\n",
    "    # Compute a probability P(premise|hypothesis) : Score de similarités entre 2 titres - Par encodage\n",
    "    # attention pour les textes : tensor trop long, pb résolu en utilisant : truncation = \"only_first\"\n",
    "    x = zero_tokenizer.encode(premise, hypothesis,truncation = \"only_first\", return_tensors='pt')\n",
    "    \n",
    "    logits = nli_model(x)[0]\n",
    "    entail_contradiction_logits = logits[:,::2]\n",
    "    probs = entail_contradiction_logits.softmax(dim=1)\n",
    "    prob_label_is_true = probs[:,0]\n",
    "    return round(prob_label_is_true[0].tolist() * 100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection Data par langues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data_prep_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>pair_lang</th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>title_1</th>\n",
       "      <th>text_1</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>...</th>\n",
       "      <th>text_2</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Style</th>\n",
       "      <th>Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1484084337_1484110209</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>MARTINSBURG, W.Va. — A suspected drunken drive...</td>\n",
       "      <td>Police in West Virginia say a suspected drunke...</td>\n",
       "      <td>['Highway Fatal-DUI-West Virginia', 'Martinsbu...</td>\n",
       "      <td>...</td>\n",
       "      <td>PORT-AU-PRINCE, Haiti — Haitian President Jove...</td>\n",
       "      <td>Haitian President Jovenel Moïse has broken wit...</td>\n",
       "      <td>['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1484396422_1483924666</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.stlucianewsonline.com</td>\n",
       "      <td>Wed Jan  1 21:17:15 2020</td>\n",
       "      <td>https://www.thestar.com</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...</td>\n",
       "      <td>-</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>BERLIN - A fire at a zoo in western Germany in...</td>\n",
       "      <td>['smg2_world', 'smg_europe', 'smg2_news']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1484698254_1483758694</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.teaparty.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.timesofisrael.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>(Breitbart) – President Donald Trump welcomed ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>PALM BEACH, United States — US President Donal...</td>\n",
       "      <td>US president says response to rioting by pro-I...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1576314516_1576455088</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://gadgets.ndtv.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Uber has sold its online food-ordering busines...</td>\n",
       "      <td>Zomato on Tuesday announced it has acquired Ub...</td>\n",
       "      <td>['zomato uber eats business acquisition india ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rapid digitisation and growth in both online b...</td>\n",
       "      <td>The report by Google and Boston Consulting Gro...</td>\n",
       "      <td>['indian online food delivery market to hit us...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484036253_1483894099</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://news.yahoo.com</td>\n",
       "      <td>Wed Jan  1 08:57:59 2020</td>\n",
       "      <td>https://www.channelnewsasia.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>BENGALURU (Reuters) - India has approved its t...</td>\n",
       "      <td>India has approved its third lunar mission mon...</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>BANGALORE: India plans to make a fresh attempt...</td>\n",
       "      <td>India plans to make a fresh attempt to land an...</td>\n",
       "      <td>['India', 'space']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>1586195445_1598778991</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>BM, Aden'de 2 bini aşkın iç göçmenin selden za...</td>\n",
       "      <td>Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...</td>\n",
       "      <td>...</td>\n",
       "      <td>BM'den Yemen'de kadınların doğumda ölüm riski ...</td>\n",
       "      <td>BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...</td>\n",
       "      <td>['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>1590915424_1590940388</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.aksam.com.tr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Kovid-19'dan dolayı La Liga kulüplerinde hayat...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>Yeni tip koronavirüs (Kovid-19) salgınının eko...</td>\n",
       "      <td>['İspanya 1. Futbol Ligi', 'la liga', 'koronav...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>1526157103_1492737005</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>http://www.samanyoluhaber.com</td>\n",
       "      <td>Thu Feb 20 10:47:10 2020</td>\n",
       "      <td>https://www.fotomac.com.tr</td>\n",
       "      <td>Sun Jan 12 00:00:00 2020</td>\n",
       "      <td>Saray da çare olmadı: 'Borca boğulan dev kulüp...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...</td>\n",
       "      <td>SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...</td>\n",
       "      <td>['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...</td>\n",
       "      <td>...</td>\n",
       "      <td>TFF, resmi internet sitesinden Beşiktaş'ın fai...</td>\n",
       "      <td>Federasyon, Başkan Çebi’nin yaptığı açıklamala...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>1603274500_1618292937</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.haberler.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Ergene Belediyesi yol çalışmalarına aksatmadan...</td>\n",
       "      <td>Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...</td>\n",
       "      <td>['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...</td>\n",
       "      <td>...</td>\n",
       "      <td>Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...</td>\n",
       "      <td>Covid-19 salgınından vatandaşların korunması i...</td>\n",
       "      <td>['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>1597247537_1604202164</td>\n",
       "      <td>tr_tr</td>\n",
       "      <td>https://www.takvim.com.tr</td>\n",
       "      <td>Tue May  5 00:00:00 2020</td>\n",
       "      <td>https://www.yeniasir.com.tr</td>\n",
       "      <td>Tue May 12 00:00:00 2020</td>\n",
       "      <td>Grup Yorum üyeleri zorla başlatmıştı... İbrahi...</td>\n",
       "      <td>DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>...</td>\n",
       "      <td>Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4964 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pair_id pair_lang                       source_url_1  \\\n",
       "0     1484084337_1484110209     en_en     https://www.washingtonpost.com   \n",
       "1     1484396422_1483924666     en_en  https://www.stlucianewsonline.com   \n",
       "2     1484698254_1483758694     en_en           https://www.teaparty.org   \n",
       "3     1576314516_1576455088     en_en           https://gadgets.ndtv.com   \n",
       "4     1484036253_1483894099     en_en             https://news.yahoo.com   \n",
       "...                     ...       ...                                ...   \n",
       "4959  1586195445_1598778991     tr_tr            http://www.haberler.com   \n",
       "4960  1590915424_1590940388     tr_tr           https://www.haberler.com   \n",
       "4961  1526157103_1492737005     tr_tr      http://www.samanyoluhaber.com   \n",
       "4962  1603274500_1618292937     tr_tr           https://www.haberler.com   \n",
       "4963  1597247537_1604202164     tr_tr          https://www.takvim.com.tr   \n",
       "\n",
       "                publish_date_1                     source_url_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020   https://www.washingtonpost.com   \n",
       "1     Wed Jan  1 21:17:15 2020          https://www.thestar.com   \n",
       "2                          NaN    https://www.timesofisrael.com   \n",
       "3                          NaN         https://gadgets.ndtv.com   \n",
       "4     Wed Jan  1 08:57:59 2020  https://www.channelnewsasia.com   \n",
       "...                        ...                              ...   \n",
       "4959                       NaN         https://www.haberler.com   \n",
       "4960                       NaN         https://www.aksam.com.tr   \n",
       "4961  Thu Feb 20 10:47:10 2020       https://www.fotomac.com.tr   \n",
       "4962                       NaN         https://www.haberler.com   \n",
       "4963  Tue May  5 00:00:00 2020      https://www.yeniasir.com.tr   \n",
       "\n",
       "                publish_date_2  \\\n",
       "0     Wed Jan  1 00:00:00 2020   \n",
       "1     Wed Jan  1 00:00:00 2020   \n",
       "2                          NaN   \n",
       "3                          NaN   \n",
       "4                          NaN   \n",
       "...                        ...   \n",
       "4959                       NaN   \n",
       "4960                       NaN   \n",
       "4961  Sun Jan 12 00:00:00 2020   \n",
       "4962                       NaN   \n",
       "4963  Tue May 12 00:00:00 2020   \n",
       "\n",
       "                                                title_1  \\\n",
       "0     Virginia man arrested in fatal DUI crash in We...   \n",
       "1     Guyana: Three injured after car crashes into u...   \n",
       "2     Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3     Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4     India approves third moon mission, months afte...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  Saray da çare olmadı: 'Borca boğulan dev kulüp...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  Grup Yorum üyeleri zorla başlatmıştı... İbrahi...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     MARTINSBURG, W.Va. — A suspected drunken drive...   \n",
       "1     Share This On:\\n\\nPin 11 Shares\\n\\n(NEWS ROOM ...   \n",
       "2     (Breitbart) – President Donald Trump welcomed ...   \n",
       "3     Uber has sold its online food-ordering busines...   \n",
       "4     BENGALURU (Reuters) - India has approved its t...   \n",
       "...                                                 ...   \n",
       "4959  BM, Aden'de 2 bini aşkın iç göçmenin selden za...   \n",
       "4960  Kovid-19'dan dolayı La Liga kulüplerinde hayat...   \n",
       "4961  \\n\\n\\n\\n\\n\\n\\n\\nİflas noktasındaki kulüplerin ...   \n",
       "4962  Ergene Belediyesi yol çalışmalarına aksatmadan...   \n",
       "4963  DHKP-C Terör Örgütü üyeliğinden yargılanan ve ...   \n",
       "\n",
       "                                     meta_description_1  \\\n",
       "0     Police in West Virginia say a suspected drunke...   \n",
       "1                                                     -   \n",
       "2                                                   NaN   \n",
       "3     Zomato on Tuesday announced it has acquired Ub...   \n",
       "4     India has approved its third lunar mission mon...   \n",
       "...                                                 ...   \n",
       "4959  Birleşmiş Milletler (BM), 2 bini aşkın iç göçm...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  SARAY DA ÇARE OLMADI: 'BORCA BOĞULAN DEV KULÜP...   \n",
       "4962  Tekirdağ'ın Ergene Belediyesi, Covid-19 salgın...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_1  ...  \\\n",
       "0     ['Highway Fatal-DUI-West Virginia', 'Martinsbu...  ...   \n",
       "1                                                  ['']  ...   \n",
       "2                                                  ['']  ...   \n",
       "3     ['zomato uber eats business acquisition india ...  ...   \n",
       "4                                                  ['']  ...   \n",
       "...                                                 ...  ...   \n",
       "4959  ['Birleşmiş Milletler', 'Twitter', 'Yemen', 'G...  ...   \n",
       "4960  ['Real Madrid', 'İspanya', 'La Liga', 'Futbol'...  ...   \n",
       "4961  ['Saray', 'da', 'çare', 'olmadı:', \"'Borca\", '...  ...   \n",
       "4962  ['Rasim Yüksel', 'Koronavirüs', 'Tekirdağ', 'E...  ...   \n",
       "4963                                               ['']  ...   \n",
       "\n",
       "                                                 text_2  \\\n",
       "0     PORT-AU-PRINCE, Haiti — Haitian President Jove...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     PALM BEACH, United States — US President Donal...   \n",
       "3     Rapid digitisation and growth in both online b...   \n",
       "4     BANGALORE: India plans to make a fresh attempt...   \n",
       "...                                                 ...   \n",
       "4959  BM'den Yemen'de kadınların doğumda ölüm riski ...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  TFF, resmi internet sitesinden Beşiktaş'ın fai...   \n",
       "4962  Ergene'de Ahimehmet ve Yeşiltepe mahallelerind...   \n",
       "4963  Ceza Mahkemesi'nde DHKP-C terör örgütü üyeliği...   \n",
       "\n",
       "                                     meta_description_2  \\\n",
       "0     Haitian President Jovenel Moïse has broken wit...   \n",
       "1     BERLIN - A fire at a zoo in western Germany in...   \n",
       "2     US president says response to rioting by pro-I...   \n",
       "3     The report by Google and Boston Consulting Gro...   \n",
       "4     India plans to make a fresh attempt to land an...   \n",
       "...                                                 ...   \n",
       "4959  BİRLEŞMİŞ Birleşmiş Milletler (BM) dünyanın en...   \n",
       "4960  Yeni tip koronavirüs (Kovid-19) salgınının eko...   \n",
       "4961  Federasyon, Başkan Çebi’nin yaptığı açıklamala...   \n",
       "4962  Covid-19 salgınından vatandaşların korunması i...   \n",
       "4963                                                NaN   \n",
       "\n",
       "                                        meta_keywords_2 Geography  Entities  \\\n",
       "0     ['CB-Haiti-Political Turmoil', 'Jean', 'Haiti'...       4.0  4.000000   \n",
       "1             ['smg2_world', 'smg_europe', 'smg2_news']       4.0  4.000000   \n",
       "2                                                  ['']       1.0  2.000000   \n",
       "3     ['indian online food delivery market to hit us...       1.0  2.333333   \n",
       "4                                    ['India', 'space']       1.0  1.250000   \n",
       "...                                                 ...       ...       ...   \n",
       "4959  ['Birleşmiş Milletler', 'Yemen', 'Güncel', 'Ha...       1.0  2.000000   \n",
       "4960  ['İspanya 1. Futbol Ligi', 'la liga', 'koronav...       1.0  1.000000   \n",
       "4961                                               ['']       1.0  2.000000   \n",
       "4962     ['Koronavirüs', 'Yeşiltepe', 'Yaşam', 'Haber']       1.0  2.000000   \n",
       "4963                                               ['']       2.0  2.000000   \n",
       "\n",
       "          Time  Narrative   Overall     Style      Tone  \n",
       "0     1.000000   4.000000  4.000000  1.666667  2.000000  \n",
       "1     1.000000   4.000000  3.666667  1.666667  1.333333  \n",
       "2     1.000000   2.333333  2.333333  1.000000  1.333333  \n",
       "3     2.666667   1.666667  2.000000  1.666667  1.666667  \n",
       "4     1.000000   1.250000  1.250000  1.000000  1.000000  \n",
       "...        ...        ...       ...       ...       ...  \n",
       "4959  2.000000   4.000000  3.000000  1.000000  1.000000  \n",
       "4960  1.000000   1.000000  1.000000  1.000000  1.000000  \n",
       "4961  3.000000   4.000000  3.000000  1.000000  2.000000  \n",
       "4962  3.000000   3.000000  3.000000  1.000000  1.000000  \n",
       "4963  1.000000   2.000000  2.000000  3.000000  1.000000  \n",
       "\n",
       "[4964 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remémorer numéro de ligne - compléter les Nan\n",
    "data['ligne'] = data.index\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation des datasets, le dernier étant à traduire en plus\n",
    "francais = data.loc[data.pair_lang == 'fr_fr',['ligne','title_1','title_2','text_1','text_2','Geography', 'Entities',\n",
    "       'Time', 'Narrative', 'Overall', 'Style', 'Tone']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests divers et Fonctions nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus : le chanteur et chanteur camerounais Manu Dibango est décédé\n",
      "Coronavirus : l'Afrique pleure Manu Dibango victime du coronavirus\n"
     ]
    }
   ],
   "source": [
    "# Résumés\n",
    "print(summarizer1(francais.text_1[3])[0]['summary_text'])\n",
    "print(summarizer1(francais.text_2[3])[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atteint par le covid-19, l'artiste camerounais est mort mardi matin des suites de la maladie, à l'âge de 86 ans.\n",
      "En l'espace de quelques jours, deux piliers de la musique du continent sont morts des suites du coronavirus.\n"
     ]
    }
   ],
   "source": [
    "print(summarizer2(francais.text_1[3])[0]['summary_text'])\n",
    "print(summarizer2(francais.text_2[3])[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de calcul du score (produit scalaire) pour résultats de classifaction\n",
    "def fonction_produit_dotcom(liste_categor, dico_scores1,dico_scores2):\n",
    "    \"\"\"\"dico scores sont les résultats obtenus pour chaque catégorie des textes 1 et 2\"\"\"\n",
    "    result = 0.0\n",
    "    for cat in liste_categor:\n",
    "        result += round(dico_scores1[cat] * dico_scores2[cat],4)\n",
    "    return result * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type1\n",
    "def transform_text_clf1(liste_dico):\n",
    "    res = {}\n",
    "    for dic in liste_dico:\n",
    "        res[dic['label']] = dic['score']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type2\n",
    "def transform_text_clf2(liste_cat,liste_sc):\n",
    "    res = {}\n",
    "    for i in range(len(liste_cat)):\n",
    "        res[liste_cat[i]] = liste_sc[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Culture': 0.8504540324211121, 'Economie': 0.016547389328479767, 'Education': 0.001298199757002294, 'Environement': 0.004739914555102587, 'Justice': 0.005226531997323036, 'Opinion': 0.006533971522003412, 'Politique': 0.010109643451869488, 'Societe': 0.09446243196725845, 'Sport': 0.0021014309022575617, 'Technologie': 0.008526437915861607}\n",
      "{'Culture': 0.27542635798454285, 'Economie': 0.01746021956205368, 'Education': 0.014121603220701218, 'Environement': 0.13672736287117004, 'Justice': 0.00473390007391572, 'Opinion': 0.11063723266124725, 'Politique': 0.007973399013280869, 'Societe': 0.13605180382728577, 'Sport': 0.14063476026058197, 'Technologie': 0.1562332808971405}\n",
      "25.039999999999996\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "liste_categories = ['Culture', 'Politique', 'Economie','Education','Technologie','Justice','Sport', 'Environement', 'Societe', 'Opinion']\n",
    "scores1 = transform_text_clf1(text_clf1(francais.text_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(text_clf1(francais.text_2[3],return_all_scores=True)[0])\n",
    "print(scores1)\n",
    "print(scores2)\n",
    "print(fonction_produit_dotcom(liste_categories, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.45\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "classes = text_clf2(francais.text_1[3], candidate_labels)\n",
    "scores1 = transform_text_clf2(classes['labels'],classes['scores'])\n",
    "classes2 = text_clf2(francais.text_2[3], candidate_labels)\n",
    "scores2 = transform_text_clf2(classes2['labels'],classes2['scores'])\n",
    "print(fonction_produit_dotcom(candidate_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negative': 0.0010380345629528165, 'Positive': 0.9989619255065918}\n",
      "{'Negative': 0.0012133318232372403, 'Positive': 0.9987866282463074}\n",
      "99.77000000000001\n"
     ]
    }
   ],
   "source": [
    "# Tests sentiment analysis\n",
    "liste_labels = ['Negative','Positive']\n",
    "scores1 = transform_text_clf1(sentiment1(francais.text_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(sentiment1(francais.text_2[3],return_all_scores=True)[0])\n",
    "print(scores1)\n",
    "print(scores2)\n",
    "print(fonction_produit_dotcom(liste_labels, scores1,scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.889999999999997\n",
      "41.05\n"
     ]
    }
   ],
   "source": [
    "# ATTENTION CE MODELE SE DEFINIT SUR 4 CLASSES : mixed, positif, negatif, objectif\n",
    "liste_sentiments = ['MIXED','NEGATIVE','POSITIVE','OBJECTIVE']\n",
    "scores1 = transform_text_clf1(sentiment2(francais.title_1[3],return_all_scores=True)[0])\n",
    "scores2 = transform_text_clf1(sentiment2(francais.title_2[3],return_all_scores=True)[0])\n",
    "scores3 = transform_text_clf1(sentiment2(francais.text_1[3],return_all_scores=True)[0])\n",
    "scores4 = transform_text_clf1(sentiment2(francais.text_2[3],return_all_scores=True)[0])\n",
    "print(fonction_produit_dotcom(liste_sentiments, scores1,scores2))\n",
    "print(fonction_produit_dotcom(liste_sentiments, scores3,scores4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.1\n",
      "95.88\n",
      "0.24\n",
      "0.51\n"
     ]
    }
   ],
   "source": [
    "# TESTS SCORES DE SIMILARITES : Titres, Textes complets (attention Truncation ...)\n",
    "print(score_similarite(francais.title_1[3],francais.title_2[3]))\n",
    "print(score_similarite(francais.text_1[3],francais.text_2[3]))\n",
    "print(score_similarite(summarizer1(francais.text_1[0])[0]['summary_text'],summarizer1(francais.text_2[0])[0]['summary_text']))\n",
    "print(score_similarite(summarizer2(francais.text_1[0])[0]['summary_text'],summarizer2(francais.text_2[0])[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('décéder', 0.6537684202194214),\n",
       " ('décé', 0.5344727039337158),\n",
       " ('deces', 0.5302326679229736),\n",
       " ('survenir', 0.5168903470039368),\n",
       " ('accident', 0.5078858137130737),\n",
       " ('surmortalité', 0.4999918043613434),\n",
       " ('obsèque', 0.49124661087989807),\n",
       " ('invalidité', 0.4891868233680725),\n",
       " ('mortalité', 0.48478570580482483),\n",
       " ('défunt', 0.48272594809532166)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essais de synonymies à utiliser pour sorties PKE, termes prinicpaux\n",
    "syns = model_gensim.most_similar(\"décès\", topn=10)\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de summarization \n",
    "def summarization(texte):\n",
    "    return summarizer1(texte)[0]['summary_text'], summarizer2(texte)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_classifiers = {'text_clf1': 'score_classif1','text_clf2':'score_classif2','sentiment1':'score_sentiment1',\n",
    "                    'sentiment2': 'score_sentiment2'}\n",
    "dico_categories = {'text_clf1': liste_categories,'text_clf2':candidate_labels,'sentiment1':liste_labels,\n",
    "                    'sentiment2': liste_sentiments}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de classification et sentiment analysis\n",
    "def classification(texte,clf):\n",
    "    # assume nms des classifiers et methode de transformation\n",
    "    if clf == \"text_clf1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(text_clf1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"text_clf2\":                                 \n",
    "        try:\n",
    "            classes = text_clf2(texte,dico_categories['text_clf2'])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return transform_text_clf2(classes['labels'],classes['scores'])                          \n",
    "    elif clf == \"sentiment1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"sentiment2\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment2(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    else:\n",
    "        return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des mots de moins de 2 lettres non numériques\n",
    "def supp_moins_2_lettres_stopwords(phrase,stopwd):\n",
    "    temp = phrase.split(' ')\n",
    "    res = ''\n",
    "    for mot in temp:\n",
    "        if mot not in stopwd and (len(mot)>2 or (len(mot)>0 and mot[0] in ['0','1','2','3','4','5','6','7','8','9'])):\n",
    "            res += mot + ' '\n",
    "    return res[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des traits d'union(regroupe)/ des apostrophes / ponctuations\n",
    "def modif(texte,stopmots):\n",
    "    # modifications simples des textes : ponctuations, petits mots, stopwords (à faire pour entités et pke textes)\n",
    "    texte=re.sub('\\'',' ',texte)   # suppression apostrophe\n",
    "    texte=re.sub('-','',texte)    # suppression trait union\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation)) # suppression de toutes les ponctuations\n",
    "    texte=regex.sub(' ',texte)\n",
    "    texte = supp_moins_2_lettres_stopwords(texte,stopmots)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des synonymes (existants en orthographe) à la suite de l'analyse pke\n",
    "def ajout_synonymes(mot, correct_ortho = True):\n",
    "    # on ajoute les 10 premiers synonymes existants, on vérifie orthographe (optionnel)\n",
    "    syns = model_gensim.most_similar(mot,topn = 20)\n",
    "    if correct_ortho == True:\n",
    "        res = []\n",
    "        for m in syns:\n",
    "            if d.check(m[0]):   #  il y a le mot et son pourcentage d'importance\n",
    "                res.append(m)\n",
    "        syns = res\n",
    "    return syns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la bonne méthodologie à appliquer PKE ??? : Noms Ok - Verbes ? - Adjectifs ? - Noms propres ?\n",
    "Quelle quantité de mots prendre ?\n",
    "Ne pas noter les titres seuls ? : trop peu de mots !  Et du coup note peut être forte avec un seul mot !\n",
    "Supprimer en en-tête les stopwords, ponctuation, les apostrophes - AUTRES ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres de la méthode : A revoir ?\n",
    "methode1 = {\"NOUN\", \"PROPN\", \"ADJ\",\"VERB\"}\n",
    "methode2 = {\"NOUN\", \"PROPN\", \"ADJ\"}\n",
    "nb_mots = {'meth1': 30, 'meth2':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKE : Analyse des termes principaux dans les textes et titres \n",
    "# Problème \n",
    "def transformation_pke_results(res1,res2, correct_ortho = True):\n",
    "    \"\"\"\n",
    "    Transformation des resultats de PKE : Pb bigramme peuvent ne pas être ds les 2 textes mais 1 mot seulement\n",
    "    liste de clés et dictionnaires de valeurs, bigrammes jouera ainsi de maniere coefficientée \n",
    "    Exemple : fuite eau:0.05 --> 3 mots au final : fuite, eau, fuite eau : 0.05\n",
    "    De plus on ajoute les synonymes issus de gensim en les coefficiant et vérifiant que cela \"\"\"\n",
    "    \n",
    "    liste1 = []; liste2 = [] ; dico1 = {}; dico2 = {}\n",
    "    for elt in res1:\n",
    "        liste1.append(elt[0])\n",
    "        dico1[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:    # bigramme dans ce cas, ajout des 2 mots\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste1.append(mot)\n",
    "                dico1[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste1.append(syn[0])   # Ajout du mot \n",
    "                        dico1[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "                    \n",
    "    for elt in res2:\n",
    "        liste2.append(elt[0])\n",
    "        dico2[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste2.append(mot)\n",
    "                dico2[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste2.append(syn[0])   # Ajout du mot \n",
    "                        dico2[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "    \n",
    "    # similarites entre les 2 listes issus de pke avec poids\n",
    "    sim = 0\n",
    "    for elt in liste1:\n",
    "        if elt in liste2:\n",
    "            sim += (dico1[elt] + dico2[elt])/2\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entites_communes(nlp,text1,text2):\n",
    "    \"\"\"\"\n",
    "    Cette première fonction ne regarde que les entités communes : personnes, dates, groupe, localisations\n",
    "    Elle sera appliquée aux textes et aux titres et cumulé : si cumul en titre et texte : compte double !\"\"\"\n",
    "    \n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    nb_commun_ent = 0; liste_commun_ent = []\n",
    "    nb_commun_geo = 0; liste_commun_geo = []\n",
    "    nb_commun_dat = 0; liste_commun_dat = []\n",
    "    \n",
    "    if len(doc1.ents)>0 and len(doc2.ents)>0:\n",
    "        liste1 = []; dico1 = {}\n",
    "        for elt in doc1.ents:\n",
    "            if elt.label_ == 'PERSON' and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste1:\n",
    "                        liste1.append(mot)\n",
    "                        dico1[mot] = elt.label_\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste1:\n",
    "                    liste1.append(elt.text)\n",
    "                    dico1[elt.text] = elt.label_\n",
    "        liste2 = []\n",
    "        for elt in doc2.ents:\n",
    "            if elt.label_ == 'PERSON' and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste2:\n",
    "                        liste2.append(mot)\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste2:\n",
    "                    liste2.append(elt.text)\n",
    "        \n",
    "        # points communs des listes        \n",
    "        for elt in liste1:\n",
    "            if elt in liste2:\n",
    "                if dico1[elt] == 'LOC':\n",
    "                    nb_commun_geo += 1\n",
    "                    liste_commun_geo.append(elt)\n",
    "                elif dico1[elt] in ['DATE','TIME']:\n",
    "                    nb_commun_dat += 1\n",
    "                    liste_commun_dat.append(elt)\n",
    "                else:\n",
    "                    nb_commun_ent += 1\n",
    "                    liste_commun_ent.append(elt)\n",
    "                    \n",
    "    return nb_commun_ent, liste_commun_ent,nb_commun_geo, liste_commun_geo,nb_commun_dat, liste_commun_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Creation_features_comparaison(df,langue, test_position = [methode1,methode2]):\n",
    "    \"\"\"Création des notes pour classification ensuite\"\"\"\n",
    "    \n",
    "    resultats = pd.DataFrame(columns = ['summary1_text1','summary2_text1','summary1_text2','summary2_text2',\n",
    "            'nb_entites_idem','nb_lieux_idem', 'nb_dates_idem','entites_idem','lieux_idem','dates_idem',\n",
    "            'score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "            'score_sentiment1','score_sentiment2','meth1_similarites','meth2_similarites'])\n",
    "    \n",
    "    # initialisation de la langue stanza\n",
    "    stanza.download(langue)\n",
    "    nlp_stanza = spacy_stanza.load_pipeline(langue)\n",
    "    stopmts = stopwds_lg[langue]\n",
    "    if langue in dico_spacy.keys():\n",
    "        nlp_spacy = dico_spacy[langue]\n",
    "    else:\n",
    "        nlp_spacy = None\n",
    "        \n",
    "    for i in tqdm(range(len(df))):\n",
    "        dico_res = {}\n",
    "        \n",
    "        # Summary et comparatifs \n",
    "        dico_res['summary1_text1'],dico_res['summary2_text1'] = summarization(df.text_1[i])\n",
    "        dico_res['summary1_text2'],dico_res['summary2_text2'] = summarization(df.text_2[i])\n",
    "        dico_res['score_similarite_titres'] = score_similarite(df.title_1[i],df.title_2[i])\n",
    "        dico_res['score_similarite_resume1'] = score_similarite(dico_res['summary1_text1'],dico_res['summary1_text2'])\n",
    "        dico_res['score_similarite_resume2'] = score_similarite(dico_res['summary2_text1'],dico_res['summary2_text2'])\n",
    "        \n",
    "        # analyse de textes classification et de sentiments\n",
    "        texte1 = df.title_1[i] + ' ' + df.text_1[i]\n",
    "        texte2 = df.title_2[i] + ' ' + df.text_2[i]\n",
    "        if len(texte1)>0 and len(texte2)>0:\n",
    "            for classifier in dico_classifiers.keys():\n",
    "                scores1 = classification(texte1,classifier)\n",
    "                scores2 = classification(texte2,classifier)\n",
    "                if scores1 != 'error' and scores2 != 'error':\n",
    "                    dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                else:\n",
    "                    scores1 = classification(df.title_1[i],classifier)\n",
    "                    scores2 = classification(df.title_2[i],classifier)\n",
    "                    if scores1 != 'error' and scores2 != 'error':\n",
    "                        dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                    else:\n",
    "                        dico_res[dico_classifiers[classifier]] = None\n",
    "                \n",
    "        # pré traitement des textes pour entités et PKE\n",
    "        texte1 = modif(texte1, stopmts)\n",
    "        texte2 = modif(texte2, stopmts)\n",
    "        \n",
    "        # ENTITES COMMUNES : on tient compte des bigrammes Noms qui posent erreurs ex: Joe Biden et Biden \n",
    "        # Ici, on considère mieux le CUMUl titres et Textes avec une pondération double pour le titre \n",
    "        # Il faut aussi enlever les petits mots donc pré-traitement en texte\n",
    "        \n",
    "        nb_ent1,list_ent1,nb_geo1,list_geo1,nb_dat1,list_dat1 = entites_communes(nlp_stanza,df.title_1[i],df.title_2[i])\n",
    "        nb_ent2,list_ent2,nb_geo2,list_geo2,nb_dat2,list_dat2 = entites_communes(nlp_stanza,df.text_1[i],df.text_2[i])\n",
    "        if nlp_spacy != None:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = entites_communes(nlp_spacy,df.title_1[i],df.title_2[i])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = entites_communes(nlp_spacy,df.text_1[i],df.text_2[i])\n",
    "        else:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = (0,[],0,[],0,[])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = (0,[],0,[],0,[])\n",
    "        dico_res['nb_entites_idem'] = nb_ent1 * 2 + nb_ent2 + nb_ent3 * 2 + nb_ent4\n",
    "        dico_res['nb_lieux_idem'] = nb_geo1  * 2 + nb_geo2 + nb_geo3  * 2 + nb_geo4\n",
    "        dico_res['nb_dates_idem'] = nb_dat1 * 2 + nb_dat2 + nb_dat3 * 2 + nb_dat4\n",
    "        # fusion des listes en supprimant les doublons\n",
    "        dico_res['entites_idem'] = list(set(list_ent1+list_ent2+ list_ent3+list_ent4))\n",
    "        dico_res['lieux_idem'] = list(set(list_geo1+list_geo2+list_geo3+list_geo4))\n",
    "        dico_res['dates_idem'] = list(set(list_dat1+list_dat2+list_dat3+list_dat4))\n",
    "        \n",
    "        for j,meth in enumerate(test_position):\n",
    "            nom ='meth'+str(j+1)\n",
    "            nb_mots_meth = nb_mots[nom]\n",
    "            if len(texte1)>0 and len(texte2)>0:\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte1,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases3 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte2,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases4 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                dico_res[nom+'_similarites'] = round(100*transformation_pke_results(keyphrases3,keyphrases4),1)\n",
    "            else:\n",
    "                dico_res[nom+'_similarites'] = 'Error'\n",
    "        \n",
    "        resultats.loc[len(resultats)] = dico_res\n",
    "        \n",
    "    newdf = pd.concat([df,resultats],axis=1)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94830fa18ff04fc9840e0d33e268146c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 07:15:04 INFO: Downloading default packages for language: fr (French)...\n",
      "2021-12-19 07:15:07 INFO: File exists: C:\\Users\\stg-sdu\\stanza_resources\\fr\\default.zip.\n",
      "2021-12-19 07:15:15 INFO: Finished downloading models and saved to C:\\Users\\stg-sdu\\stanza_resources.\n",
      "2021-12-19 07:15:15 INFO: Loading these models for language: fr (French):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "| ner       | wikiner |\n",
      "=======================\n",
      "\n",
      "2021-12-19 07:15:15 INFO: Use device: cpu\n",
      "2021-12-19 07:15:15 INFO: Loading: tokenize\n",
      "2021-12-19 07:15:15 INFO: Loading: mwt\n",
      "2021-12-19 07:15:15 INFO: Loading: pos\n",
      "2021-12-19 07:15:15 INFO: Loading: lemma\n",
      "2021-12-19 07:15:16 INFO: Loading: depparse\n",
      "2021-12-19 07:15:16 INFO: Loading: ner\n",
      "2021-12-19 07:15:18 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152970371dee4f458897070fee9256ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 200, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 179. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 150. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 10, but you input_length is only 2. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 100, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 10, but you input_length is only 2. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 100, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 72. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 171. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 177. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 10, but you input_length is only 2. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 100, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 58. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 62. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 155. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 38. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 46. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 173. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 188. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 182. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 133. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 99. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your min_length is set to 10, but you input_length is only 2. You might consider decreasing min_length manually, e.g. summarizer('...', min_length=10)\n",
      "Your max_length is set to 100, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 172. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 159. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 28. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 34. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 173. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 168. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 187. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "# Attention probleme au 16e index non identifié ...\n",
    "similarites = Creation_features_comparaison(francais,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarites.to_csv('corpus_fr_notes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "francais = pd.read_csv('corpus_fr_notes.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention certains textes ne sont pas fournies et donc mis en \"Error\" : A supprimer donc\n",
    "# On pourrait éventuellement tester en ne prenant plus les meth similarités ds les predicteurs\n",
    "francais = francais[francais.meth1_similarites!='Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "francais = francais.round({'Geography':0, 'Entities':0,'Time':0, 'Narrative':0, 'Overall':0, 'Style':0, 'Tone':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "partiel = francais[['Geography', 'Entities','Time', 'Narrative', 'Overall', 'Style', 'Tone']].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "francais = pd.concat([francais[['ligne', 'title_1', 'title_2', 'text_1', 'text_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2']],\n",
    "        partiel,francais[['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "       'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "       'score_sentiment2', 'meth1_similarites', 'meth2_similarites']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>summary1_text1</th>\n",
       "      <th>summary2_text1</th>\n",
       "      <th>summary1_text2</th>\n",
       "      <th>summary2_text2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>...</th>\n",
       "      <th>dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2317</td>\n",
       "      <td>L'euphorie du marché résistera-t-elle au coron...</td>\n",
       "      <td>De nombreux médecins toujours sans masques, ma...</td>\n",
       "      <td>Le cap du million de ventes a été dépassé l'an...</td>\n",
       "      <td>Stocks réduits ou distribués au \"compte-goutte...</td>\n",
       "      <td>Immobilier : le cap du million de ventes dépas...</td>\n",
       "      <td>L'empressement des acheteurs à devenir proprié...</td>\n",
       "      <td>Coronavirus : les soignants manquent toujours ...</td>\n",
       "      <td>Les soignants français manquent toujours de ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>5.90</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.04</td>\n",
       "      <td>28.06</td>\n",
       "      <td>164.8</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2318</td>\n",
       "      <td>Clarenceville: Alexandre et Ilana Dupont n’iro...</td>\n",
       "      <td>COVID-19 : le fédéral donnera 2 000 $ par mois...</td>\n",
       "      <td>SPORTS – La majorité des activités sportives d...</td>\n",
       "      <td>Cette nuit, la Chambre des communes a adopté l...</td>\n",
       "      <td>Coronavirus : le Canada n'enverrait pas ses at...</td>\n",
       "      <td>La majorité des activités sportives de la plan...</td>\n",
       "      <td>Canada : 82 G d'aide d'urgence pour les Canadiens</td>\n",
       "      <td>Cette nuit, la Chambre des communes a adopté l...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.02</td>\n",
       "      <td>99.92</td>\n",
       "      <td>31.29</td>\n",
       "      <td>160.8</td>\n",
       "      <td>84.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2319</td>\n",
       "      <td>Deux retraités matanais sont coincés en Équateur</td>\n",
       "      <td>L'opération de rapatriement est un «fiasco», d...</td>\n",
       "      <td>Deux Matanais, Hélène Gagnon et Clarence Bouff...</td>\n",
       "      <td>Sarah Mahu est coincée au Pérou. Elle a réussi...</td>\n",
       "      <td>Coronavirus : des Canadiens coincés en Équateu...</td>\n",
       "      <td>Un couple de Québécois, coincés en Équateur, a...</td>\n",
       "      <td>Coronavirus : des Québécois coincés au Pérou q...</td>\n",
       "      <td>Un mois après la proclamation de l'état d'urge...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3.72</td>\n",
       "      <td>34.85</td>\n",
       "      <td>8.48</td>\n",
       "      <td>98.21</td>\n",
       "      <td>25.93</td>\n",
       "      <td>136.0</td>\n",
       "      <td>234.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2320</td>\n",
       "      <td>Coronavirus : le musicien et chanteur cameroun...</td>\n",
       "      <td>L'Afrique pleure Manu Dibango, victime du coro...</td>\n",
       "      <td>Atteint par le covid-19, l’artiste camerounais...</td>\n",
       "      <td>L'Afrique pleure Manu Dibango, victime du coro...</td>\n",
       "      <td>Coronavirus : le chanteur et chanteur cameroun...</td>\n",
       "      <td>Atteint par le covid-19, l'artiste camerounais...</td>\n",
       "      <td>Coronavirus : l'Afrique pleure Manu Dibango vi...</td>\n",
       "      <td>En l'espace de quelques jours, deux piliers de...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>69.10</td>\n",
       "      <td>54.08</td>\n",
       "      <td>73.07</td>\n",
       "      <td>35.05</td>\n",
       "      <td>9.03</td>\n",
       "      <td>99.62</td>\n",
       "      <td>30.55</td>\n",
       "      <td>148.4</td>\n",
       "      <td>134.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2321</td>\n",
       "      <td>La MRC de Marguerite-D’Youville prend les gran...</td>\n",
       "      <td>Le travail inquiétant des femmes dans la pandé...</td>\n",
       "      <td>C’est dans le cadre de la crise générée par la...</td>\n",
       "      <td>Pour la version anglais, cliquez ici. / For th...</td>\n",
       "      <td>Crise de la Covid-19 : la MRC de Marguerite-D’...</td>\n",
       "      <td>Dans le cadre de la crise générée par la COVID...</td>\n",
       "      <td>Coronavirus : les femmes sont nettement plus i...</td>\n",
       "      <td>Pour lutter contre la pauvreté et les inégalit...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.54</td>\n",
       "      <td>6.57</td>\n",
       "      <td>7.90</td>\n",
       "      <td>5.27</td>\n",
       "      <td>8.97</td>\n",
       "      <td>99.97</td>\n",
       "      <td>40.37</td>\n",
       "      <td>107.4</td>\n",
       "      <td>117.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4879</td>\n",
       "      <td>Maroc : la location aux touristes interdite</td>\n",
       "      <td>Maroc : la justice ouvre une enquête pour viol...</td>\n",
       "      <td>Les forces de l’ordre effectuent des inspectio...</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>Maroc : la police inspecte les appartements de...</td>\n",
       "      <td>Les forces de l'ordre effectuent des inspectio...</td>\n",
       "      <td>Confinement : le parquet de Tanger ouvre une e...</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.43</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4880</td>\n",
       "      <td>Loi sur la relance : l'opposition « à plus de ...</td>\n",
       "      <td>10Â 000 prÃ©posÃ©s aux bÃ©nÃ©ficiaires recherc...</td>\n",
       "      <td>Deux journées de commission parlementaire n'au...</td>\n",
       "      <td>CORONAVIRUS. QuÃ©bec veut lancer une opÃ©ratio...</td>\n",
       "      <td>Projet de loi 61 : l'opposition accuse le gouv...</td>\n",
       "      <td>Le projet de loi sur la relance de l'économie ...</td>\n",
       "      <td>Qubec : 10 000 prposs aux bnficiaires, annonce...</td>\n",
       "      <td>Le gouvernement souhaite que les militaires de...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4881</td>\n",
       "      <td>Média sud-coréen : “Avec le rôle de président ...</td>\n",
       "      <td>Le 36e Sommet de l’ASEAN couronné de succès</td>\n",
       "      <td>En 2020, le Vietnam assume un double rôle de p...</td>\n",
       "      <td>Le chef du gouvernement vietnamien, qui est ég...</td>\n",
       "      <td>Le Vietnam devient président de l'ASEAN et mem...</td>\n",
       "      <td>En 2020, le Vietnam devient un double rôle de ...</td>\n",
       "      <td>Le Vietnam salue le succès du Sommet de l'ASEA...</td>\n",
       "      <td>Le chef du gouvernement vietnamien, qui est ég...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.70</td>\n",
       "      <td>6.68</td>\n",
       "      <td>9.80</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4882</td>\n",
       "      <td>Adieu à Muriel Roy</td>\n",
       "      <td>«Les pouvoirs extraordinaire du corps humain»:...</td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>Comment avez-vous vécu le confinement?\\n\\nAu d...</td>\n",
       "      <td>Muriel Roy est décédée à l'âge de 100 ans</td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>Comment avez-vous vécu le confinement?</td>\n",
       "      <td>C'est à voir. Le 3 mars, on avait des pseudo-c...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8.12</td>\n",
       "      <td>27.36</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4883</td>\n",
       "      <td>Congo : des experts africains formés à Brazzav...</td>\n",
       "      <td>«EN AFRIQUE, L’EVOLUTION DE LA PANDEMIE EST TR...</td>\n",
       "      <td>Congo : des experts africains formés à Brazzav...</td>\n",
       "      <td>Alors que le directeur de l’Organisation mondi...</td>\n",
       "      <td>Coronavirus : des experts africains formés à B...</td>\n",
       "      <td>Des professionnels de santé de 24 pays d'Afriq...</td>\n",
       "      <td>Coronavirus : l'Afrique «très préoccupante» av...</td>\n",
       "      <td>La directrice Afrique de l'Organisation mondia...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.08</td>\n",
       "      <td>15.51</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ligne                                            title_1  \\\n",
       "0    2317  L'euphorie du marché résistera-t-elle au coron...   \n",
       "1    2318  Clarenceville: Alexandre et Ilana Dupont n’iro...   \n",
       "2    2319   Deux retraités matanais sont coincés en Équateur   \n",
       "3    2320  Coronavirus : le musicien et chanteur cameroun...   \n",
       "4    2321  La MRC de Marguerite-D’Youville prend les gran...   \n",
       "..    ...                                                ...   \n",
       "67   4879        Maroc : la location aux touristes interdite   \n",
       "68   4880  Loi sur la relance : l'opposition « à plus de ...   \n",
       "69   4881  Média sud-coréen : “Avec le rôle de président ...   \n",
       "70   4882                                 Adieu à Muriel Roy   \n",
       "71   4883  Congo : des experts africains formés à Brazzav...   \n",
       "\n",
       "                                              title_2  \\\n",
       "0   De nombreux médecins toujours sans masques, ma...   \n",
       "1   COVID-19 : le fédéral donnera 2 000 $ par mois...   \n",
       "2   L'opération de rapatriement est un «fiasco», d...   \n",
       "3   L'Afrique pleure Manu Dibango, victime du coro...   \n",
       "4   Le travail inquiétant des femmes dans la pandé...   \n",
       "..                                                ...   \n",
       "67  Maroc : la justice ouvre une enquête pour viol...   \n",
       "68  10Â 000 prÃ©posÃ©s aux bÃ©nÃ©ficiaires recherc...   \n",
       "69        Le 36e Sommet de l’ASEAN couronné de succès   \n",
       "70  «Les pouvoirs extraordinaire du corps humain»:...   \n",
       "71  «EN AFRIQUE, L’EVOLUTION DE LA PANDEMIE EST TR...   \n",
       "\n",
       "                                               text_1  \\\n",
       "0   Le cap du million de ventes a été dépassé l'an...   \n",
       "1   SPORTS – La majorité des activités sportives d...   \n",
       "2   Deux Matanais, Hélène Gagnon et Clarence Bouff...   \n",
       "3   Atteint par le covid-19, l’artiste camerounais...   \n",
       "4   C’est dans le cadre de la crise générée par la...   \n",
       "..                                                ...   \n",
       "67  Les forces de l’ordre effectuent des inspectio...   \n",
       "68  Deux journées de commission parlementaire n'au...   \n",
       "69  En 2020, le Vietnam assume un double rôle de p...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71  Congo : des experts africains formés à Brazzav...   \n",
       "\n",
       "                                               text_2  \\\n",
       "0   Stocks réduits ou distribués au \"compte-goutte...   \n",
       "1   Cette nuit, la Chambre des communes a adopté l...   \n",
       "2   Sarah Mahu est coincée au Pérou. Elle a réussi...   \n",
       "3   L'Afrique pleure Manu Dibango, victime du coro...   \n",
       "4   Pour la version anglais, cliquez ici. / For th...   \n",
       "..                                                ...   \n",
       "67  Suite aux violations du confinement dans les v...   \n",
       "68  CORONAVIRUS. QuÃ©bec veut lancer une opÃ©ratio...   \n",
       "69  Le chef du gouvernement vietnamien, qui est ég...   \n",
       "70  Comment avez-vous vécu le confinement?\\n\\nAu d...   \n",
       "71  Alors que le directeur de l’Organisation mondi...   \n",
       "\n",
       "                                       summary1_text1  \\\n",
       "0   Immobilier : le cap du million de ventes dépas...   \n",
       "1   Coronavirus : le Canada n'enverrait pas ses at...   \n",
       "2   Coronavirus : des Canadiens coincés en Équateu...   \n",
       "3   Coronavirus : le chanteur et chanteur cameroun...   \n",
       "4   Crise de la Covid-19 : la MRC de Marguerite-D’...   \n",
       "..                                                ...   \n",
       "67  Maroc : la police inspecte les appartements de...   \n",
       "68  Projet de loi 61 : l'opposition accuse le gouv...   \n",
       "69  Le Vietnam devient président de l'ASEAN et mem...   \n",
       "70          Muriel Roy est décédée à l'âge de 100 ans   \n",
       "71  Coronavirus : des experts africains formés à B...   \n",
       "\n",
       "                                       summary2_text1  \\\n",
       "0   L'empressement des acheteurs à devenir proprié...   \n",
       "1   La majorité des activités sportives de la plan...   \n",
       "2   Un couple de Québécois, coincés en Équateur, a...   \n",
       "3   Atteint par le covid-19, l'artiste camerounais...   \n",
       "4   Dans le cadre de la crise générée par la COVID...   \n",
       "..                                                ...   \n",
       "67  Les forces de l'ordre effectuent des inspectio...   \n",
       "68  Le projet de loi sur la relance de l'économie ...   \n",
       "69  En 2020, le Vietnam devient un double rôle de ...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71  Des professionnels de santé de 24 pays d'Afriq...   \n",
       "\n",
       "                                       summary1_text2  \\\n",
       "0   Coronavirus : les soignants manquent toujours ...   \n",
       "1   Canada : 82 G d'aide d'urgence pour les Canadiens   \n",
       "2   Coronavirus : des Québécois coincés au Pérou q...   \n",
       "3   Coronavirus : l'Afrique pleure Manu Dibango vi...   \n",
       "4   Coronavirus : les femmes sont nettement plus i...   \n",
       "..                                                ...   \n",
       "67  Confinement : le parquet de Tanger ouvre une e...   \n",
       "68  Qubec : 10 000 prposs aux bnficiaires, annonce...   \n",
       "69  Le Vietnam salue le succès du Sommet de l'ASEA...   \n",
       "70             Comment avez-vous vécu le confinement?   \n",
       "71  Coronavirus : l'Afrique «très préoccupante» av...   \n",
       "\n",
       "                                       summary2_text2  Geography  ...  \\\n",
       "0   Les soignants français manquent toujours de ma...          1  ...   \n",
       "1   Cette nuit, la Chambre des communes a adopté l...          3  ...   \n",
       "2   Un mois après la proclamation de l'état d'urge...          3  ...   \n",
       "3   En l'espace de quelques jours, deux piliers de...          1  ...   \n",
       "4   Pour lutter contre la pauvreté et les inégalit...          3  ...   \n",
       "..                                                ...        ...  ...   \n",
       "67  Suite aux violations du confinement dans les v...          2  ...   \n",
       "68  Le gouvernement souhaite que les militaires de...          1  ...   \n",
       "69  Le chef du gouvernement vietnamien, qui est ég...          1  ...   \n",
       "70  C'est à voir. Le 3 mars, on avait des pseudo-c...          4  ...   \n",
       "71  La directrice Afrique de l'Organisation mondia...          3  ...   \n",
       "\n",
       "    dates_idem  score_similarite_titres  score_similarite_resume1  \\\n",
       "0           []                     3.26                      0.24   \n",
       "1           []                     0.56                      0.35   \n",
       "2           []                     5.87                      0.17   \n",
       "3           []                    69.10                     54.08   \n",
       "4           []                     0.54                      6.57   \n",
       "..         ...                      ...                       ...   \n",
       "67          []                     2.53                      2.35   \n",
       "68          []                     2.03                      0.61   \n",
       "69          []                     5.70                      6.68   \n",
       "70          []                     0.25                      8.12   \n",
       "71          []                     2.38                      2.08   \n",
       "\n",
       "    score_similarite_resume2  score_classif1  score_classif2  \\\n",
       "0                       0.51            5.90            8.42   \n",
       "1                       0.69            0.10            9.02   \n",
       "2                       3.72           34.85            8.48   \n",
       "3                      73.07           35.05            9.03   \n",
       "4                       7.90            5.27            8.97   \n",
       "..                       ...             ...             ...   \n",
       "67                      1.43           35.06           10.08   \n",
       "68                      0.21           14.24            8.91   \n",
       "69                      9.80           93.14            9.39   \n",
       "70                     27.36            6.09            8.37   \n",
       "71                     15.51           26.10           10.33   \n",
       "\n",
       "    score_sentiment1  score_sentiment2  meth1_similarites meth2_similarites  \n",
       "0               0.04             28.06              164.8             249.0  \n",
       "1              99.92             31.29              160.8              84.6  \n",
       "2              98.21             25.93              136.0             234.2  \n",
       "3              99.62             30.55              148.4             134.8  \n",
       "4              99.97             40.37              107.4             117.8  \n",
       "..               ...               ...                ...               ...  \n",
       "67             97.33             30.89               21.2              35.8  \n",
       "68              1.03             20.16              174.0             179.9  \n",
       "69             99.98             31.05              176.2             258.7  \n",
       "70             99.84             29.93                8.8              28.4  \n",
       "71             99.54             27.09              150.3             114.6  \n",
       "\n",
       "[69 rows x 30 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "francais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteurs = ['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1',\n",
    "    'score_similarite_resume2', 'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites',\n",
    "    'meth2_similarites']\n",
    "# 2e test sans les predicteurs entites et méthodes similarités\n",
    "# predicteurs1 = ['score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "#            'score_sentiment1','score_sentiment2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "french_classif = setup(data = francais[predicteurs + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>0.2387</td>\n",
       "      <td>0.2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.1953</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.3063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.5000  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "1       0.6000  0.8500  0.6250  0.7000  0.6000  0.4737  0.5000\n",
       "2       0.0000  0.4000  0.0000  0.0000  0.0000 -0.3158 -0.3780\n",
       "3       0.2000  0.4833  0.2500  0.0500  0.0800 -0.0526 -0.0833\n",
       "4       0.6000  0.7500  0.5000  0.4667  0.5000  0.4444  0.5443\n",
       "5       0.4000  0.7667  0.5000  0.4000  0.4000  0.2105  0.2222\n",
       "6       0.4000  0.5833  0.5000  0.4000  0.4000  0.2105  0.2222\n",
       "7       0.4000  0.7667  0.3750  0.4000  0.4000  0.1667  0.1768\n",
       "8       0.5000  0.7500  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "9       0.7500  1.0000  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "Mean    0.4250  0.6850  0.4500  0.3542  0.3660  0.2387  0.2759\n",
       "SD      0.2016  0.1774  0.1953  0.2125  0.1977  0.2625  0.3063"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>0.2713</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.1658</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.2078</td>\n",
       "      <td>0.2362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.2000  0.6333  0.2500  0.0500  0.0800  0.0000  0.0000\n",
       "1       0.4000  0.8500  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "2       0.0000  0.0500  0.0000  0.0000  0.0000 -0.3158 -0.3780\n",
       "3       0.2000  0.4833  0.2500  0.0667  0.1000 -0.0526 -0.0630\n",
       "4       0.4000  0.5000  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "5       0.6000  0.7667  0.6250  0.6000  0.6000  0.4444  0.4444\n",
       "6       0.4000  0.5417  0.5000  0.4000  0.4000  0.2105  0.2222\n",
       "7       0.4000  0.7167  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "8       0.2500  0.8333  0.2500  0.0625  0.1000  0.0000  0.0000\n",
       "9       0.5000  0.9167  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "Mean    0.3350  0.6292  0.3500  0.2829  0.2713  0.1251  0.1390\n",
       "SD      0.1644  0.2410  0.1658  0.2112  0.1802  0.2078  0.2362"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6167</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3889</td>\n",
       "      <td>-0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3889</td>\n",
       "      <td>-0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>-0.0089</td>\n",
       "      <td>0.0144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.1682</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.3304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.6167  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "1       0.4000  0.9000  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "2       0.0000  0.3333  0.0000  0.0000  0.0000 -0.3158 -0.3780\n",
       "3       0.0000  0.4333  0.0000  0.0000  0.0000 -0.3889 -0.4125\n",
       "4       0.6000  0.8000  0.5000  0.4667  0.5000  0.4444  0.5443\n",
       "5       0.2000  0.6333  0.2500  0.2000  0.2000 -0.1111 -0.1179\n",
       "6       0.0000  0.3500  0.0000  0.0000  0.0000 -0.3889 -0.4125\n",
       "7       0.4000  0.7000  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "8       0.2500  0.5833  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "9       0.2500  0.7500  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "Mean    0.2500  0.6100  0.2500  0.2017  0.1963 -0.0089  0.0144\n",
       "SD      0.1949  0.1802  0.1854  0.1905  0.1682  0.2761  0.3304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5517</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.2585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.4833   0.250  0.2667  0.3200  0.1176  0.1260\n",
       "1       0.4000  0.5833   0.375  0.4500  0.3467  0.2105  0.3333\n",
       "2       0.4000  0.5000   0.250  0.1600  0.2286  0.0000  0.0000\n",
       "3       0.4000  0.4667   0.250  0.2000  0.2667  0.0625  0.0833\n",
       "4       0.6000  0.7500   0.500  0.4667  0.5000  0.4444  0.5443\n",
       "5       0.4000  0.6000   0.500  0.2667  0.3000  0.2105  0.2520\n",
       "6       0.2000  0.3833   0.125  0.4000  0.2667 -0.0526 -0.0630\n",
       "7       0.2000  0.5000   0.250  0.0500  0.0800 -0.0526 -0.0833\n",
       "8       0.7500  0.8333   0.750  0.6250  0.6667  0.6667  0.7303\n",
       "9       0.2500  0.4167   0.250  0.1250  0.1667  0.0000  0.0000\n",
       "Mean    0.4000  0.5517   0.350  0.3010  0.3142  0.1607  0.1923\n",
       "SD      0.1628  0.1363   0.175  0.1705  0.1576  0.2226  0.2585"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>-0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2713</td>\n",
       "      <td>0.2337</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>0.3471</td>\n",
       "      <td>0.3866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.2000  0.6833  0.2500  0.0667  0.1000 -0.0526 -0.0630\n",
       "1       0.8000  1.0000  0.8750  0.9000  0.8000  0.7368  0.7778\n",
       "2       0.0000  0.3667  0.0000  0.0000  0.0000 -0.3158 -0.3536\n",
       "3       0.2000  0.4833  0.2500  0.0667  0.1000 -0.1111 -0.1361\n",
       "4       0.0000  0.5500  0.0000  0.0000  0.0000 -0.2500 -0.2946\n",
       "5       0.8000  0.9500  0.7500  0.6667  0.7200  0.7059  0.7559\n",
       "6       0.4000  0.5333  0.5000  0.3000  0.3333  0.2105  0.2222\n",
       "7       0.4000  0.8500  0.3750  0.5000  0.4000  0.2105  0.2357\n",
       "8       0.5000  1.0000  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "9       0.5000  1.0000  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "Mean    0.3800  0.7417  0.4000  0.3083  0.3162  0.1801  0.2024\n",
       "SD      0.2713  0.2337  0.2727  0.2874  0.2649  0.3471  0.3866"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3889</td>\n",
       "      <td>-0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8083</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.6267</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>0.3635</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2631</td>\n",
       "      <td>0.2074</td>\n",
       "      <td>0.2853</td>\n",
       "      <td>0.3019</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.3691</td>\n",
       "      <td>0.4058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.6000  0.8167  0.6250  0.6667  0.5667  0.4737  0.5669\n",
       "1       0.2000  0.7000  0.2500  0.1000  0.1333 -0.0526 -0.0556\n",
       "2       0.2000  0.3000  0.1250  0.1333  0.1600 -0.1765 -0.2041\n",
       "3       0.2000  0.4667  0.1250  0.2000  0.2000 -0.1111 -0.1111\n",
       "4       0.6000  0.8000  0.6250  0.7000  0.6000  0.4737  0.5000\n",
       "5       0.0000  0.2500  0.0000  0.0000  0.0000 -0.3889 -0.4125\n",
       "6       0.8000  0.8083  0.8750  0.9000  0.8000  0.7368  0.7778\n",
       "7       0.2000  0.5833  0.2500  0.1000  0.1333  0.0000  0.0000\n",
       "8       0.5000  0.7083  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "9       0.7500  0.8333  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "Mean    0.4050  0.6267  0.4125  0.3758  0.3635  0.1955  0.2263\n",
       "SD      0.2631  0.2074  0.2853  0.3019  0.2619  0.3691  0.4058"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3889</td>\n",
       "      <td>-0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.6483</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.2968</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.2118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1817</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.1656</td>\n",
       "      <td>0.2579</td>\n",
       "      <td>0.2852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.5000   0.500  0.2667  0.3000  0.2500  0.3150\n",
       "1       0.4000  0.5833   0.500  0.3000  0.3333  0.2500  0.2946\n",
       "2       0.0000  0.3500   0.000  0.0000  0.0000 -0.3889 -0.4125\n",
       "3       0.2000  0.5167   0.250  0.1000  0.1333  0.0000  0.0000\n",
       "4       0.4000  0.8500   0.375  0.4667  0.3667  0.2105  0.2520\n",
       "5       0.4000  0.5833   0.250  0.1600  0.2286  0.0000  0.0000\n",
       "6       0.4000  0.6333   0.500  0.3000  0.3333  0.2500  0.2946\n",
       "7       0.4000  0.8000   0.375  0.5000  0.4000  0.2105  0.2357\n",
       "8       0.5000  1.0000   0.500  0.2500  0.3333  0.3333  0.4082\n",
       "9       0.7500  0.6667   0.750  0.6250  0.6667  0.6667  0.7303\n",
       "Mean    0.3850  0.6483   0.400  0.2968  0.3095  0.1782  0.2118\n",
       "SD      0.1817  0.1802   0.192  0.1807  0.1656  0.2579  0.2852"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3889</td>\n",
       "      <td>-0.4763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>-0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.2338</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.3139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.0000  0.0  0.0000  0.0000  0.0000 -0.3889 -0.4763\n",
       "1       0.6000  0.0  0.5000  0.4000  0.4667  0.3750  0.5000\n",
       "2       0.2000  0.0  0.2500  0.0667  0.1000  0.0000  0.0000\n",
       "3       0.4000  0.0  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "4       0.0000  0.0  0.0000  0.0000  0.0000 -0.2500 -0.3402\n",
       "5       0.4000  0.0  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "6       0.4000  0.0  0.3750  0.5000  0.4000  0.2105  0.2357\n",
       "7       0.4000  0.0  0.3750  0.5000  0.4000  0.2105  0.2357\n",
       "8       0.5000  0.0  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "9       0.2500  0.0  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "Mean    0.3150  0.0  0.3250  0.2217  0.2338  0.0990  0.1320\n",
       "SD      0.1898  0.0  0.1871  0.1824  0.1614  0.2410  0.3139"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.4706</td>\n",
       "      <td>-0.5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.1853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1936</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.2664</td>\n",
       "      <td>0.3368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.6000  0.2333  0.5000  0.4000  0.4667  0.3750  0.5000\n",
       "1       0.4000  0.1833  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "2       0.4000  0.7000  0.2500  0.1600  0.2286  0.0000  0.0000\n",
       "3       0.0000  0.2000  0.0000  0.0000  0.0000 -0.4706 -0.5443\n",
       "4       0.6000  0.1000  0.7500  0.4667  0.5000  0.5000  0.6299\n",
       "5       0.2000  0.3667  0.2500  0.0500  0.0800 -0.0526 -0.0833\n",
       "6       0.4000  0.7333  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "7       0.2000  0.3333  0.2500  0.0500  0.0800  0.0000  0.0000\n",
       "8       0.5000  0.2500  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "9       0.5000  0.5000  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "Mean    0.3800  0.3600  0.3750  0.2327  0.2705  0.1352  0.1853\n",
       "SD      0.1833  0.2069  0.1936  0.1521  0.1619  0.2664  0.3368"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5583</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>-0.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4917</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.5717</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.1505</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.5750  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "1       0.2000  0.5583  0.2500  0.0500  0.0800  0.0000  0.0000\n",
       "2       0.0000  0.2500  0.0000  0.0000  0.0000 -0.2500 -0.3150\n",
       "3       0.2000  0.4583  0.2500  0.2000  0.2000 -0.0526 -0.0556\n",
       "4       0.2000  0.2750  0.2500  0.0500  0.0800  0.0000  0.0000\n",
       "5       0.4000  0.7500  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "6       0.2000  0.4917  0.2500  0.2000  0.2000 -0.0526 -0.0630\n",
       "7       0.4000  0.7750  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "8       0.2500  0.8750  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "9       0.5000  0.7083  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "Mean    0.2750  0.5717  0.3125  0.1517  0.1832  0.0645  0.0936\n",
       "SD      0.1401  0.1987  0.1505  0.0926  0.1034  0.1704  0.2272"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>0.2817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.7167  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "1       0.2000  0.7167  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "2       0.2000  0.5000  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "3       0.2000  0.3500  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "4       0.4000  0.8833  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "5       0.4000  0.3833  0.2500  0.1600  0.2286  0.0000  0.0000\n",
       "6       0.4000  0.5000  0.2500  0.1600  0.2286  0.0000  0.0000\n",
       "7       0.2000  0.3833  0.1250  0.1333  0.1600 -0.1765 -0.2041\n",
       "8       0.0000  0.4167  0.0000  0.0000  0.0000 -0.3333 -0.4714\n",
       "9       0.5000  0.7500  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "Mean    0.2900  0.5600  0.2875  0.1407  0.1752  0.0324  0.0629\n",
       "SD      0.1446  0.1800  0.1586  0.1058  0.1157  0.1918  0.2817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = create_model('lr')\n",
    "rf = create_model('rf')\n",
    "xgb = create_model('xgboost')\n",
    "ada = create_model('ada')\n",
    "lda = create_model('lda')  # linear discriminant\n",
    "knn = create_model('knn')\n",
    "mlp = create_model('mlp')\n",
    "svm = create_model('svm')\n",
    "rbfsvm = create_model('rbfsvm')\n",
    "nb = create_model('nb')\n",
    "gpc = create_model('gpc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicteurs : Les plus satisfaisants : ADA - LDA - KNN - LR : pluto moins bien en accuracy .... <br/>\n",
    "predicteurs 1 : Les plus satisfaisants : LR - LDA - RF - XGB - NB : environ 40% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai_classif = francais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites','meth2_similarites']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography                     int32\n",
       "Entities                      int32\n",
       "Time                          int32\n",
       "Narrative                     int32\n",
       "Overall                       int32\n",
       "Style                         int32\n",
       "Tone                          int32\n",
       "nb_entites_idem               int64\n",
       "nb_lieux_idem                 int64\n",
       "nb_dates_idem                 int64\n",
       "score_similarite_titres     float64\n",
       "score_similarite_resume1    float64\n",
       "score_similarite_resume2    float64\n",
       "score_classif1              float64\n",
       "score_classif2              float64\n",
       "score_sentiment1            float64\n",
       "score_sentiment2            float64\n",
       "meth1_similarites           float64\n",
       "meth2_similarites           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si on veut utiliser faire un classemen,t supprimer ligne error puis changer les types pour meth1 meth2\n",
    "essai_classif = essai_classif[essai_classif.meth1_similarites != 'Error']\n",
    "essai_classif['meth1_similarites'] = essai_classif['meth1_similarites'].astype('float')\n",
    "essai_classif['meth2_similarites'] = essai_classif['meth2_similarites'].astype('float')\n",
    "essai_classif.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6167</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.4235</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>0.3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1536</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>0.1658</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.1558</td>\n",
       "      <td>0.2288</td>\n",
       "      <td>0.2562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.8000  0.5000  0.2000  0.2667  0.2105  0.2357\n",
       "1       0.4000  0.8500  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "2       0.2000  0.6167  0.1250  0.1333  0.1600 -0.1765 -0.1890\n",
       "3       0.4000  0.8167  0.3750  0.3000  0.3333  0.1667  0.1768\n",
       "4       0.4000  0.5500  0.3750  0.4000  0.4000  0.1667  0.1667\n",
       "5       0.6000  1.0000  0.6250  0.6667  0.5667  0.4737  0.5669\n",
       "6       0.6000  1.0000  0.6250  0.6000  0.5333  0.4737  0.5303\n",
       "7       0.8000  1.0000  0.7500  0.7000  0.7333  0.7222  0.7660\n",
       "8       0.5000  0.6667  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "9       0.5000  0.0000  0.5000  0.5000  0.5000  0.2000  0.2000\n",
       "Mean    0.4800  0.7300  0.4750  0.4300  0.4235  0.2781  0.3177\n",
       "SD      0.1536  0.2877  0.1658  0.1822  0.1558  0.2288  0.2562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xtrain = essai_classif[predicteurs + ['Overall']]\n",
    "french_classif = setup(data = Xtrain,  target = 'Overall', html=False, silent=True, verbose=False)\n",
    "rf = create_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.3111</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy     AUC  Recall   Prec.      F1  Kappa  \\\n",
       "0  Random Forest Classifier    0.2381  0.5699  0.3083  0.3111  0.2492   0.04   \n",
       "\n",
       "      MCC  \n",
       "0  0.0458  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9876/2267293530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ne marche pas ????\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pycaret\\classification.py\u001b[0m in \u001b[0;36mpredict_model\u001b[1;34m(estimator, data, probability_threshold, encoded_labels, round, verbose)\u001b[0m\n\u001b[0;32m   1894\u001b[0m     \"\"\"\n\u001b[0;32m   1895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1896\u001b[1;33m     return pycaret.internal.tabular.predict_model(\n\u001b[0m\u001b[0;32m   1897\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pycaret\\internal\\tabular.py\u001b[0m in \u001b[0;36mpredict_model\u001b[1;34m(estimator, data, probability_threshold, encoded_labels, round, verbose, ml_usecase, display)\u001b[0m\n\u001b[0;32m   8373\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8374\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8375\u001b[1;33m             \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8377\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "predictions = predict_model(rf)  # ne marche pas ????\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.2092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.1965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.2000  0.5333  0.1250  0.2000  0.2000 -0.1111 -0.1179\n",
       "1       0.6000  0.9000  0.5000  0.4667  0.5000  0.4444  0.5443\n",
       "2       0.4000  0.6833  0.3750  0.3000  0.3333  0.1667  0.1768\n",
       "3       0.4000  0.5000  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "4       0.2000  0.5500  0.1250  0.2000  0.2000 -0.1111 -0.1179\n",
       "5       0.4000  0.7333  0.3750  0.5000  0.4000  0.2105  0.2357\n",
       "6       0.4000  0.8500  0.3750  0.5000  0.4000  0.2105  0.2222\n",
       "7       0.4000  0.8500  0.2500  0.4000  0.4000  0.1667  0.1768\n",
       "8       0.5000  0.8333  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "9       0.5000  0.0000  0.5000  0.3750  0.4167  0.2000  0.2236\n",
       "Mean    0.4000  0.6433  0.3625  0.3358  0.3417  0.1760  0.2092\n",
       "SD      0.1183  0.2554  0.1420  0.1228  0.0964  0.1644  0.1965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda = create_model('lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random Forest simple sur scikit learn\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xtrain[:50],ytrain[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>99.54</td>\n",
       "      <td>9.49</td>\n",
       "      <td>14.58</td>\n",
       "      <td>79.42</td>\n",
       "      <td>9.45</td>\n",
       "      <td>95.91</td>\n",
       "      <td>41.50</td>\n",
       "      <td>256.4</td>\n",
       "      <td>301.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>81.60</td>\n",
       "      <td>36.71</td>\n",
       "      <td>24.86</td>\n",
       "      <td>97.61</td>\n",
       "      <td>8.36</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11.05</td>\n",
       "      <td>165.4</td>\n",
       "      <td>389.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.62</td>\n",
       "      <td>99.99</td>\n",
       "      <td>32.26</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>81.61</td>\n",
       "      <td>11.23</td>\n",
       "      <td>66.44</td>\n",
       "      <td>10.38</td>\n",
       "      <td>97.21</td>\n",
       "      <td>16.85</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>46.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>83.60</td>\n",
       "      <td>30.36</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>8.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>32.87</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.40</td>\n",
       "      <td>44.72</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.46</td>\n",
       "      <td>28.30</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.33</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.07</td>\n",
       "      <td>99.87</td>\n",
       "      <td>46.52</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>10.72</td>\n",
       "      <td>2.12</td>\n",
       "      <td>81.74</td>\n",
       "      <td>11.49</td>\n",
       "      <td>99.90</td>\n",
       "      <td>34.50</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13.04</td>\n",
       "      <td>91.10</td>\n",
       "      <td>36.71</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.38</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24.83</td>\n",
       "      <td>12.14</td>\n",
       "      <td>22.22</td>\n",
       "      <td>60.62</td>\n",
       "      <td>10.50</td>\n",
       "      <td>99.88</td>\n",
       "      <td>19.83</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>42.65</td>\n",
       "      <td>10.45</td>\n",
       "      <td>99.30</td>\n",
       "      <td>42.80</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>99.97</td>\n",
       "      <td>29.27</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.43</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>6.68</td>\n",
       "      <td>9.80</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8.12</td>\n",
       "      <td>27.36</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.08</td>\n",
       "      <td>15.51</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50                6              8              0                    99.54   \n",
       "51                0             13              0                    81.60   \n",
       "52                0              0              0                     0.56   \n",
       "53                4              0              0                     0.12   \n",
       "54                1              3              0                     0.52   \n",
       "55                1              0              0                     0.33   \n",
       "56                0              3              0                     0.75   \n",
       "57                0              0              0                     7.73   \n",
       "58                0              4              0                     5.24   \n",
       "59                0              0              0                     0.23   \n",
       "60                1              2              0                     2.44   \n",
       "61                1              3              0                    24.83   \n",
       "62                0             22              0                     0.48   \n",
       "63                0             10              0                     0.36   \n",
       "64                1              4              0                     2.53   \n",
       "65                2              0              0                     2.03   \n",
       "66                2              4              0                     5.70   \n",
       "67                0              0              0                     0.25   \n",
       "68                0              4              0                     2.38   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                      9.49                     14.58           79.42   \n",
       "51                     36.71                     24.86           97.61   \n",
       "52                      0.70                      0.73            4.73   \n",
       "53                     81.61                     11.23           66.44   \n",
       "54                      1.27                      0.58           46.37   \n",
       "55                      8.41                      0.59           32.87   \n",
       "56                      0.11                      1.40           44.72   \n",
       "57                      2.12                      4.33           10.34   \n",
       "58                     10.72                      2.12           81.74   \n",
       "59                      0.74                      0.27            3.77   \n",
       "60                      0.08                      0.12           29.07   \n",
       "61                     12.14                     22.22           60.62   \n",
       "62                      0.09                      0.35           42.65   \n",
       "63                      7.38                      0.76            1.49   \n",
       "64                      2.35                      1.43           35.06   \n",
       "65                      0.61                      0.21           14.24   \n",
       "66                      6.68                      9.80           93.14   \n",
       "67                      8.12                     27.36            6.09   \n",
       "68                      2.08                     15.51           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2  meth1_similarites  \\\n",
       "50            9.45             95.91             41.50              256.4   \n",
       "51            8.36             96.46             11.05              165.4   \n",
       "52            8.62             99.99             32.26               80.7   \n",
       "53           10.38             97.21             16.85              564.1   \n",
       "54            8.59             83.60             30.36              374.8   \n",
       "55           10.75             18.59             33.70              130.0   \n",
       "56            9.49              7.46             28.30              138.8   \n",
       "57           10.07             99.87             46.52               21.1   \n",
       "58           11.49             99.90             34.50              223.8   \n",
       "59           13.04             91.10             36.71               50.7   \n",
       "60            8.22              0.16             35.38              120.0   \n",
       "61           10.50             99.88             19.83              437.9   \n",
       "62           10.45             99.30             42.80              344.5   \n",
       "63            9.78             99.97             29.27              142.0   \n",
       "64           10.08             97.33             30.89               21.2   \n",
       "65            8.91              1.03             20.16              174.0   \n",
       "66            9.39             99.98             31.05              176.2   \n",
       "67            8.37             99.84             29.93                8.8   \n",
       "68           10.33             99.54             27.09              150.3   \n",
       "\n",
       "    meth2_similarites  Overall  RF  \n",
       "50              301.4        1   1  \n",
       "51              389.4        1   1  \n",
       "52              215.1        4   3  \n",
       "53              248.6        1   4  \n",
       "54              339.8        1   2  \n",
       "55              159.8        2   2  \n",
       "56               74.0        2   4  \n",
       "57               54.1        4   4  \n",
       "58              170.8        2   1  \n",
       "59               68.7        2   4  \n",
       "60              228.2        4   2  \n",
       "61              301.2        2   1  \n",
       "62              485.7        1   2  \n",
       "63              289.0        2   3  \n",
       "64               35.8        3   4  \n",
       "65              179.9        3   3  \n",
       "66              258.7        1   2  \n",
       "67               28.4        4   4  \n",
       "68              114.6        3   3  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf = rf.predict(Xtrain[50:])\n",
    "res_rf = pd.concat([Xtrain[50:],ytrain[50:],pd.DataFrame(res_rf,columns = ['RF'],index = range(50,69))],axis=1)\n",
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 0, 1],\n",
       "       [2, 1, 1, 2],\n",
       "       [0, 0, 2, 1],\n",
       "       [0, 1, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résultats corrects : 7/19 - 8/19 : 1 d'écart - 3/19 : 2 écart - 1 : 3 catégories écart \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(res_rf.Overall,res_rf.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  9,  4,  2,  3,  7, 10,  5,  1,  8,  6, 11], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(rf, Xtrain, ytrain, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "tree_feature_importances = rf.feature_importances_\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(predicteurs))\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.array(predicteurs)[sorted_idx])\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Overall  RF  LDA\n",
       "50        1   1    2\n",
       "51        1   1    1\n",
       "52        4   3    3\n",
       "53        1   4    1\n",
       "54        1   2    3\n",
       "55        2   2    3\n",
       "56        2   4    3\n",
       "57        4   4    3\n",
       "58        2   1    1\n",
       "59        2   4    3\n",
       "60        4   2    2\n",
       "61        2   1    1\n",
       "62        1   2    2\n",
       "63        2   3    3\n",
       "64        3   4    4\n",
       "65        3   3    4\n",
       "66        1   2    2\n",
       "67        4   4    4\n",
       "68        3   3    3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Xtrain[:50],ytrain[:50])\n",
    "res_lda = lda.predict(Xtrain[50:])\n",
    "res_final = pd.concat([res_rf[['Overall','RF']],pd.DataFrame(res_lda,columns = ['LDA'],index = range(50,69))],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.96,  91.76,   1.28,   0.01],\n",
       "       [100.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [  0.  ,  29.61,  35.34,  35.05],\n",
       "       [ 57.3 ,   0.25,   0.26,  42.19],\n",
       "       [ 14.64,  40.2 ,  41.63,   3.53],\n",
       "       [  0.  ,  38.36,  51.99,   9.65],\n",
       "       [  0.34,  16.88,  71.01,  11.77],\n",
       "       [  0.  ,  41.09,  43.95,  14.96],\n",
       "       [ 35.43,  28.85,  34.27,   1.45],\n",
       "       [  0.  ,  19.77,  46.84,  33.39],\n",
       "       [  0.  ,  50.83,  46.97,   2.2 ],\n",
       "       [ 99.26,   0.16,   0.47,   0.1 ],\n",
       "       [  0.05,  54.95,  44.99,   0.  ],\n",
       "       [  0.  ,  33.09,  59.88,   7.04],\n",
       "       [  0.  ,  20.58,  30.76,  48.66],\n",
       "       [  0.  ,  12.57,  27.79,  59.63],\n",
       "       [ 19.62,  57.28,  21.57,   1.52],\n",
       "       [  0.  ,   1.66,   9.86,  88.48],\n",
       "       [  0.01,   9.7 ,  49.91,  40.39]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import around\n",
    "import numpy\n",
    "np.set_printoptions(suppress=True)  # supprime notation exp\n",
    "res_lda2 = around(lda.predict_proba(Xtrain[50:])*100, decimals=2)\n",
    "res_lda2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Remarquer que la classification ne tient pas compte du fait que c'est ordonné en classement 1-2-3-4 : ce qui est TRES important (ex : ligne 55% de 1 - 43% de 4) !! : il faudrait donc faire ressortir un score avec les probas plutot !!!_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41., 27., 30.,  2.],\n",
       "       [48., 15., 23., 14.],\n",
       "       [ 3., 31., 40., 26.],\n",
       "       [31., 23.,  8., 38.],\n",
       "       [31., 42., 16., 11.],\n",
       "       [ 6., 63., 11., 20.],\n",
       "       [ 4., 28., 33., 35.],\n",
       "       [ 1.,  7., 45., 47.],\n",
       "       [36., 24., 35.,  5.],\n",
       "       [ 0., 14., 30., 56.],\n",
       "       [ 4., 43., 41., 12.],\n",
       "       [62., 10., 17., 11.],\n",
       "       [26., 32., 26., 16.],\n",
       "       [ 4., 36., 52.,  8.],\n",
       "       [ 7., 24., 26., 43.],\n",
       "       [ 5., 32., 38., 25.],\n",
       "       [33., 40., 24.,  3.],\n",
       "       [ 0., 11., 20., 69.],\n",
       "       [13., 27., 35., 25.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf2 = around(rf.predict_proba(Xtrain[50:])*100, decimals=2)\n",
    "res_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau programme basé sur les scores probas : si plus de 50% mettre catégorie obtenue sinon, faire la somme 1-2 et 3/4 \n",
    "# et prendre le plus gros score puis regarder si ce sore > 65% alors à ce moment là prendre le plus gros de la catégorie \n",
    "# sinon prendre 2 ou 3\n",
    "def choix_classes(score_prob):\n",
    "    classe_finale = []\n",
    "    for i in range(len(score_prob)):\n",
    "        res = list(score_prob[i,:])\n",
    "        max_res = max(res)\n",
    "        if max_res > 50:\n",
    "            classe_finale.append(res.index(max_res)+1)\n",
    "        else:\n",
    "            som1 = res[0]+res[1]\n",
    "            som2 = res[2]+res[3]\n",
    "            if som1 > som2:\n",
    "                if som1 >= 65:\n",
    "                    choix = 1 if res[0]>res[1] else 2\n",
    "                else:\n",
    "                    choix = 2\n",
    "            else:\n",
    "                if som2 >= 65:\n",
    "                    choix = 4 if res[3]>res[2] else 3\n",
    "                else:\n",
    "                    choix = 3\n",
    "            classe_finale.append(choix)\n",
    "    return classe_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_rf = choix_classes(res_rf2)\n",
    "liste_lda = choix_classes(res_lda2)\n",
    "res_final = pd.concat([res_final,pd.DataFrame(liste_lda,columns = ['LDA_Prob'],index = range(50,69)),\n",
    "                       pd.DataFrame(liste_rf,columns = ['RF_Prob'],index = range(50,69))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(Xtrain[:50],ytrain[:50])\n",
    "res_knn = knn.predict(Xtrain[50:])\n",
    "liste_knn = choix_classes(around(knn.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['KNN'],index = range(50,69)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['KNN_Prob'],index = range(50,69))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain[:50],ytrain[:50])\n",
    "res_logreg = logreg.predict(Xtrain[50:])\n",
    "liste_logreg = choix_classes(around(logreg.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_logreg,columns = ['LOGR'],index = range(50,69)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['LOGR_Prob'],index = range(50,69))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(Xtrain[:50],ytrain[:50])\n",
    "res_ada = ada.predict(Xtrain[50:])\n",
    "liste_ada = choix_classes(around(ada.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['ADA'],index = range(50,69)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['ADA_Prob'],index = range(50,69))],axis=1)\n",
    "res_final = res_final [['Overall','RF','LDA','KNN','LOGR','ADA','RF_Prob','LDA_Prob','KNN_Prob','LOGR_Prob','ADA_Prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>ADA</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>KNN_Prob</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>ADA_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Overall  RF  LDA  KNN  LOGR  ADA  RF_Prob  LDA_Prob  KNN_Prob  LOGR_Prob  \\\n",
       "50        1   1    2    2     1    2        1         2         2          2   \n",
       "51        1   1    1    3     1    3        2         1         3          3   \n",
       "52        4   3    3    2     2    2        3         3         3          3   \n",
       "53        1   4    1    1     1    1        2         1         1          1   \n",
       "54        1   2    3    1     2    1        2         2         2          2   \n",
       "55        2   2    3    2     2    2        2         3         3          3   \n",
       "56        2   4    3    4     3    4        4         3         4          4   \n",
       "57        4   4    3    4     3    4        4         3         4          4   \n",
       "58        2   1    1    2     2    2        2         2         2          2   \n",
       "59        2   4    3    3     4    3        4         3         3          3   \n",
       "60        4   2    2    3     2    3        3         2         3          3   \n",
       "61        2   1    1    1     1    1        1         1         1          1   \n",
       "62        1   2    2    1     2    1        2         2         2          2   \n",
       "63        2   3    3    2     2    2        3         3         2          2   \n",
       "64        3   4    4    4     4    4        4         4         4          4   \n",
       "65        3   3    4    3     3    3        3         4         3          3   \n",
       "66        1   2    2    2     2    2        2         2         2          2   \n",
       "67        4   4    4    4     4    4        4         4         4          4   \n",
       "68        3   3    3    4     4    4        3         3         4          4   \n",
       "\n",
       "    ADA_Prob  \n",
       "50         2  \n",
       "51         3  \n",
       "52         3  \n",
       "53         1  \n",
       "54         2  \n",
       "55         3  \n",
       "56         4  \n",
       "57         4  \n",
       "58         2  \n",
       "59         3  \n",
       "60         3  \n",
       "61         1  \n",
       "62         2  \n",
       "63         2  \n",
       "64         4  \n",
       "65         3  \n",
       "66         2  \n",
       "67         4  \n",
       "68         4  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir ensuite à utiliser les resultats reçus pour obtenir un resultat final : mieux ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "francais = pd.read_csv('corpus_fr_notes.csv',index_col=0)\n",
    "francais = francais[francais.meth1_similarites!='Error']\n",
    "french_classif = setup(data = francais[predicteurs + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.9496</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>-2.9566</td>\n",
       "      <td>0.2968</td>\n",
       "      <td>0.2380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6085</td>\n",
       "      <td>0.4427</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>0.2094</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>0.3617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.7961</td>\n",
       "      <td>0.2078</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>0.4529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5847</td>\n",
       "      <td>0.5855</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.2096</td>\n",
       "      <td>0.2599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8956</td>\n",
       "      <td>1.0115</td>\n",
       "      <td>1.0057</td>\n",
       "      <td>-0.8063</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>0.2599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1116</td>\n",
       "      <td>1.3586</td>\n",
       "      <td>1.1656</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.3817</td>\n",
       "      <td>0.7350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7928</td>\n",
       "      <td>1.0261</td>\n",
       "      <td>1.0130</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0283</td>\n",
       "      <td>1.4605</td>\n",
       "      <td>1.2085</td>\n",
       "      <td>-1.6081</td>\n",
       "      <td>0.3836</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8877</td>\n",
       "      <td>1.6309</td>\n",
       "      <td>1.2771</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.4169</td>\n",
       "      <td>0.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8531</td>\n",
       "      <td>1.3986</td>\n",
       "      <td>1.1826</td>\n",
       "      <td>-1.0344</td>\n",
       "      <td>0.4347</td>\n",
       "      <td>0.3814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.8273</td>\n",
       "      <td>1.0498</td>\n",
       "      <td>1.0054</td>\n",
       "      <td>-0.5179</td>\n",
       "      <td>0.3201</td>\n",
       "      <td>0.4483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.3863</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>1.0322</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.1974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.7741  0.9496  0.9745 -2.9566  0.2968  0.2380\n",
       "1     0.6085  0.4427  0.6654  0.2094  0.2201  0.3617\n",
       "2     0.7360  0.6338  0.7961  0.2078  0.3253  0.4529\n",
       "3     0.5847  0.5855  0.7652  0.2681  0.2096  0.2599\n",
       "4     0.8956  1.0115  1.0057 -0.8063  0.2527  0.2599\n",
       "5     1.1116  1.3586  1.1656  0.2616  0.3817  0.7350\n",
       "6     0.7928  1.0261  1.0130  0.2455  0.2791  0.3279\n",
       "7     1.0283  1.4605  1.2085 -1.6081  0.3836  0.6925\n",
       "8     0.8877  1.6309  1.2771  0.0336  0.4169  0.7739\n",
       "9     0.8531  1.3986  1.1826 -1.0344  0.4347  0.3814\n",
       "Mean  0.8273  1.0498  1.0054 -0.5179  0.3201  0.4483\n",
       "SD    0.1579  0.3863  0.1976  1.0322  0.0770  0.1974"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>-1.7326</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>0.1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7289</td>\n",
       "      <td>0.7609</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>0.2996</td>\n",
       "      <td>0.5035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>0.1536</td>\n",
       "      <td>0.2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8249</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>-0.0230</td>\n",
       "      <td>0.2374</td>\n",
       "      <td>0.3254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.8187</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>-0.4619</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.1773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9655</td>\n",
       "      <td>1.0765</td>\n",
       "      <td>1.0375</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.5435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9742</td>\n",
       "      <td>1.1829</td>\n",
       "      <td>1.0876</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.4879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7142</td>\n",
       "      <td>0.7068</td>\n",
       "      <td>0.8407</td>\n",
       "      <td>-0.2622</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.4690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8893</td>\n",
       "      <td>1.1285</td>\n",
       "      <td>1.0623</td>\n",
       "      <td>0.3313</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.6802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.7010</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>-0.0196</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7427</td>\n",
       "      <td>0.8063</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>-0.1248</td>\n",
       "      <td>0.2676</td>\n",
       "      <td>0.3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1763</td>\n",
       "      <td>0.2676</td>\n",
       "      <td>0.1689</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.1614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.6809  0.6558  0.8098 -1.7326  0.2126  0.1969\n",
       "1     0.7289  0.7609  0.8723 -0.3587  0.2996  0.5035\n",
       "2     0.3455  0.2134  0.4620  0.7332  0.1536  0.2214\n",
       "3     0.8249  0.8184  0.9047 -0.0230  0.2374  0.3254\n",
       "4     0.6574  0.8187  0.9048 -0.4619  0.2139  0.1773\n",
       "5     0.9655  1.0765  1.0375  0.4150  0.3170  0.5435\n",
       "6     0.9742  1.1829  1.0876  0.1302  0.3175  0.4879\n",
       "7     0.7142  0.7068  0.8407 -0.2622  0.2900  0.4690\n",
       "8     0.8893  1.1285  1.0623  0.3313  0.3636  0.6802\n",
       "9     0.6460  0.7010  0.8372 -0.0196  0.2709  0.2948\n",
       "Mean  0.7427  0.8063  0.8819 -0.1248  0.2676  0.3900\n",
       "SD    0.1763  0.2676  0.1689  0.6399  0.0596  0.1614"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4760</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>-1.0712</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8040</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.9147</td>\n",
       "      <td>-0.4941</td>\n",
       "      <td>0.3004</td>\n",
       "      <td>0.5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.8574</td>\n",
       "      <td>0.9260</td>\n",
       "      <td>-0.0718</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.3382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1320</td>\n",
       "      <td>2.0218</td>\n",
       "      <td>1.4219</td>\n",
       "      <td>-2.6104</td>\n",
       "      <td>0.3794</td>\n",
       "      <td>0.3243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.7062</td>\n",
       "      <td>0.8404</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>0.2612</td>\n",
       "      <td>0.4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2060</td>\n",
       "      <td>2.1693</td>\n",
       "      <td>1.4729</td>\n",
       "      <td>-0.5951</td>\n",
       "      <td>0.4377</td>\n",
       "      <td>0.5395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9440</td>\n",
       "      <td>1.3534</td>\n",
       "      <td>1.1634</td>\n",
       "      <td>-1.4169</td>\n",
       "      <td>0.3728</td>\n",
       "      <td>0.6107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.4635</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.4133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7575</td>\n",
       "      <td>0.8009</td>\n",
       "      <td>0.8949</td>\n",
       "      <td>-0.1649</td>\n",
       "      <td>0.2921</td>\n",
       "      <td>0.3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7917</td>\n",
       "      <td>1.0009</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>-0.4461</td>\n",
       "      <td>0.2893</td>\n",
       "      <td>0.3935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.6113</td>\n",
       "      <td>0.2916</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.1351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.4760  0.4971  0.7050 -1.0712  0.1949  0.1413\n",
       "1     0.8040  0.8367  0.9147 -0.4941  0.3004  0.5150\n",
       "2     0.4120  0.3027  0.5502  0.6216  0.1645  0.2320\n",
       "3     0.8500  0.8574  0.9260 -0.0718  0.2450  0.3382\n",
       "4     1.1320  2.0218  1.4219 -2.6104  0.3794  0.3243\n",
       "5     0.7480  0.7062  0.8404  0.6162  0.2612  0.4300\n",
       "6     1.2060  2.1693  1.4729 -0.5951  0.4377  0.5395\n",
       "7     0.9440  1.3534  1.1634 -1.4169  0.3728  0.6107\n",
       "8     0.5875  0.4635  0.6808  0.7253  0.2452  0.4133\n",
       "9     0.7575  0.8009  0.8949 -0.1649  0.2921  0.3904\n",
       "Mean  0.7917  1.0009  0.9570 -0.4461  0.2893  0.3935\n",
       "SD    0.2455  0.6113  0.2916  0.9951  0.0815  0.1351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>0.8661</td>\n",
       "      <td>-2.1253</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>0.1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>0.7598</td>\n",
       "      <td>-0.0309</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3292</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>0.7859</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>0.1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8556</td>\n",
       "      <td>0.7837</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.3221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6266</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>-0.5600</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8541</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.4646</td>\n",
       "      <td>0.2777</td>\n",
       "      <td>0.4042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8499</td>\n",
       "      <td>1.0026</td>\n",
       "      <td>1.0013</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>0.3727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.7283</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>-0.3005</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>0.4298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8045</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.9504</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.5912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6055</td>\n",
       "      <td>0.6138</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.2855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.8441</td>\n",
       "      <td>-0.0911</td>\n",
       "      <td>0.2513</td>\n",
       "      <td>0.3381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1594</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>0.1255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.6943  0.7501  0.8661 -2.1253  0.2310  0.1991\n",
       "1     0.5486  0.5773  0.7598 -0.0309  0.2722  0.4172\n",
       "2     0.3292  0.1713  0.4139  0.7859  0.1332  0.1992\n",
       "3     0.8556  0.7837  0.8852  0.0204  0.2298  0.3221\n",
       "4     0.6266  0.8736  0.9347 -0.5600  0.2217  0.1603\n",
       "5     0.8541  0.9852  0.9926  0.4646  0.2777  0.4042\n",
       "6     0.8499  1.0026  1.0013  0.2628  0.2769  0.3727\n",
       "7     0.6788  0.7283  0.8534 -0.3005  0.2930  0.4298\n",
       "8     0.8045  0.9033  0.9504  0.4647  0.3268  0.5912\n",
       "9     0.6055  0.6138  0.7835  0.1072  0.2508  0.2855\n",
       "Mean  0.6847  0.7389  0.8441 -0.0911  0.2513  0.3381\n",
       "SD    0.1594  0.2327  0.1626  0.7726  0.0499  0.1255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.6158</td>\n",
       "      <td>-0.5799</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9898</td>\n",
       "      <td>1.0885</td>\n",
       "      <td>1.0433</td>\n",
       "      <td>-0.9437</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>0.6002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4042</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.5196</td>\n",
       "      <td>0.6626</td>\n",
       "      <td>0.1691</td>\n",
       "      <td>0.2642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>-0.0732</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9886</td>\n",
       "      <td>1.5795</td>\n",
       "      <td>1.2568</td>\n",
       "      <td>-1.8206</td>\n",
       "      <td>0.3266</td>\n",
       "      <td>0.2868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.9323</td>\n",
       "      <td>0.5276</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>0.5533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.3422</td>\n",
       "      <td>2.4099</td>\n",
       "      <td>1.5524</td>\n",
       "      <td>-0.7720</td>\n",
       "      <td>0.4590</td>\n",
       "      <td>0.7089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7856</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>-0.7143</td>\n",
       "      <td>0.3332</td>\n",
       "      <td>0.4553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6508</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.8078</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.4450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5706</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.3273</td>\n",
       "      <td>0.2014</td>\n",
       "      <td>0.2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.9314</td>\n",
       "      <td>-0.2773</td>\n",
       "      <td>0.2803</td>\n",
       "      <td>0.4063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.6063</td>\n",
       "      <td>0.2922</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.1686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.4833  0.3792  0.6158 -0.5799  0.1576  0.1389\n",
       "1     0.9898  1.0885  1.0433 -0.9437  0.3304  0.6002\n",
       "2     0.4042  0.2700  0.5196  0.6626  0.1691  0.2642\n",
       "3     0.9145  0.8585  0.9266 -0.0732  0.2424  0.3453\n",
       "4     0.9886  1.5795  1.2568 -1.8206  0.3266  0.2868\n",
       "5     0.8578  0.8692  0.9323  0.5276  0.3095  0.5533\n",
       "6     1.3422  2.4099  1.5524 -0.7720  0.4590  0.7089\n",
       "7     0.7856  0.9600  0.9798 -0.7143  0.3332  0.4553\n",
       "8     0.6508  0.6525  0.8078  0.6133  0.2743  0.4450\n",
       "9     0.5706  0.4625  0.6801  0.3273  0.2014  0.2651\n",
       "Mean  0.7987  0.9530  0.9314 -0.2773  0.2803  0.4063\n",
       "SD    0.2672  0.6063  0.2922  0.7800  0.0868  0.1686"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.2032</td>\n",
       "      <td>8.0222</td>\n",
       "      <td>2.8323</td>\n",
       "      <td>-32.4257</td>\n",
       "      <td>0.4694</td>\n",
       "      <td>0.6833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5357</td>\n",
       "      <td>10.2582</td>\n",
       "      <td>3.2028</td>\n",
       "      <td>-17.3181</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>1.7978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6617</td>\n",
       "      <td>9.8158</td>\n",
       "      <td>3.1330</td>\n",
       "      <td>-11.2698</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>1.7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1170</td>\n",
       "      <td>5.7157</td>\n",
       "      <td>2.3907</td>\n",
       "      <td>-6.1446</td>\n",
       "      <td>0.6683</td>\n",
       "      <td>0.7954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0644</td>\n",
       "      <td>6.9507</td>\n",
       "      <td>2.6364</td>\n",
       "      <td>-11.4120</td>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.7838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.6205</td>\n",
       "      <td>4.8418</td>\n",
       "      <td>2.2004</td>\n",
       "      <td>-1.6314</td>\n",
       "      <td>0.6047</td>\n",
       "      <td>1.3561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0986</td>\n",
       "      <td>22.0949</td>\n",
       "      <td>4.7005</td>\n",
       "      <td>-15.2462</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>2.3708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1007</td>\n",
       "      <td>4.9239</td>\n",
       "      <td>2.2190</td>\n",
       "      <td>-7.7927</td>\n",
       "      <td>0.5886</td>\n",
       "      <td>1.2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.3286</td>\n",
       "      <td>51.7128</td>\n",
       "      <td>7.1912</td>\n",
       "      <td>-29.6446</td>\n",
       "      <td>1.2716</td>\n",
       "      <td>5.1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.1139</td>\n",
       "      <td>14.7283</td>\n",
       "      <td>3.8377</td>\n",
       "      <td>-20.4229</td>\n",
       "      <td>0.8278</td>\n",
       "      <td>2.2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>2.6844</td>\n",
       "      <td>13.9064</td>\n",
       "      <td>3.4344</td>\n",
       "      <td>-15.3308</td>\n",
       "      <td>0.7295</td>\n",
       "      <td>1.8134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.9890</td>\n",
       "      <td>13.5648</td>\n",
       "      <td>1.4530</td>\n",
       "      <td>9.4220</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>1.2328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE      MSE    RMSE       R2   RMSLE    MAPE\n",
       "0     2.2032   8.0222  2.8323 -32.4257  0.4694  0.6833\n",
       "1     2.5357  10.2582  3.2028 -17.3181  0.7458  1.7978\n",
       "2     2.6617   9.8158  3.1330 -11.2698  0.7183  1.7039\n",
       "3     2.1170   5.7157  2.3907  -6.1446  0.6683  0.7954\n",
       "4     2.0644   6.9507  2.6364 -11.4120  0.5057  0.7838\n",
       "5     1.6205   4.8418  2.2004  -1.6314  0.6047  1.3561\n",
       "6     3.0986  22.0949  4.7005 -15.2462  0.8951  2.3708\n",
       "7     2.1007   4.9239  2.2190  -7.7927  0.5886  1.2917\n",
       "8     5.3286  51.7128  7.1912 -29.6446  1.2716  5.1045\n",
       "9     3.1139  14.7283  3.8377 -20.4229  0.8278  2.2467\n",
       "Mean  2.6844  13.9064  3.4344 -15.3308  0.7295  1.8134\n",
       "SD    0.9890  13.5648  1.4530   9.4220  0.2210  1.2328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = create_model('lr')\n",
    "rr = create_model('lasso')\n",
    "etr = create_model('et')\n",
    "svr = create_model('svm')\n",
    "adar = create_model('ada')\n",
    "mlpr = create_model('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression simple sur scikit learn\n",
    "essai_classif = francais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites','meth2_similarites']]\n",
    "lr = LinearRegression()\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>99.54</td>\n",
       "      <td>9.49</td>\n",
       "      <td>14.58</td>\n",
       "      <td>79.42</td>\n",
       "      <td>9.45</td>\n",
       "      <td>95.91</td>\n",
       "      <td>41.50</td>\n",
       "      <td>256.4</td>\n",
       "      <td>301.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.599858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>81.60</td>\n",
       "      <td>36.71</td>\n",
       "      <td>24.86</td>\n",
       "      <td>97.61</td>\n",
       "      <td>8.36</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11.05</td>\n",
       "      <td>165.4</td>\n",
       "      <td>389.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.62</td>\n",
       "      <td>99.99</td>\n",
       "      <td>32.26</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.222043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>81.61</td>\n",
       "      <td>11.23</td>\n",
       "      <td>66.44</td>\n",
       "      <td>10.38</td>\n",
       "      <td>97.21</td>\n",
       "      <td>16.85</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.897480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>46.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>83.60</td>\n",
       "      <td>30.36</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.929214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>8.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>32.87</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.748877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.40</td>\n",
       "      <td>44.72</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.46</td>\n",
       "      <td>28.30</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.529084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.33</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.07</td>\n",
       "      <td>99.87</td>\n",
       "      <td>46.52</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.034551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>10.72</td>\n",
       "      <td>2.12</td>\n",
       "      <td>81.74</td>\n",
       "      <td>11.49</td>\n",
       "      <td>99.90</td>\n",
       "      <td>34.50</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.758119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13.04</td>\n",
       "      <td>91.10</td>\n",
       "      <td>36.71</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.645473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.38</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.324108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24.83</td>\n",
       "      <td>12.14</td>\n",
       "      <td>22.22</td>\n",
       "      <td>60.62</td>\n",
       "      <td>10.50</td>\n",
       "      <td>99.88</td>\n",
       "      <td>19.83</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.863311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>42.65</td>\n",
       "      <td>10.45</td>\n",
       "      <td>99.30</td>\n",
       "      <td>42.80</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>99.97</td>\n",
       "      <td>29.27</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.43</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.283364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.345327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>6.68</td>\n",
       "      <td>9.80</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.682769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8.12</td>\n",
       "      <td>27.36</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.700288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.08</td>\n",
       "      <td>15.51</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.077994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50                6              8              0                    99.54   \n",
       "51                0             13              0                    81.60   \n",
       "52                0              0              0                     0.56   \n",
       "53                4              0              0                     0.12   \n",
       "54                1              3              0                     0.52   \n",
       "55                1              0              0                     0.33   \n",
       "56                0              3              0                     0.75   \n",
       "57                0              0              0                     7.73   \n",
       "58                0              4              0                     5.24   \n",
       "59                0              0              0                     0.23   \n",
       "60                1              2              0                     2.44   \n",
       "61                1              3              0                    24.83   \n",
       "62                0             22              0                     0.48   \n",
       "63                0             10              0                     0.36   \n",
       "64                1              4              0                     2.53   \n",
       "65                2              0              0                     2.03   \n",
       "66                2              4              0                     5.70   \n",
       "67                0              0              0                     0.25   \n",
       "68                0              4              0                     2.38   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                      9.49                     14.58           79.42   \n",
       "51                     36.71                     24.86           97.61   \n",
       "52                      0.70                      0.73            4.73   \n",
       "53                     81.61                     11.23           66.44   \n",
       "54                      1.27                      0.58           46.37   \n",
       "55                      8.41                      0.59           32.87   \n",
       "56                      0.11                      1.40           44.72   \n",
       "57                      2.12                      4.33           10.34   \n",
       "58                     10.72                      2.12           81.74   \n",
       "59                      0.74                      0.27            3.77   \n",
       "60                      0.08                      0.12           29.07   \n",
       "61                     12.14                     22.22           60.62   \n",
       "62                      0.09                      0.35           42.65   \n",
       "63                      7.38                      0.76            1.49   \n",
       "64                      2.35                      1.43           35.06   \n",
       "65                      0.61                      0.21           14.24   \n",
       "66                      6.68                      9.80           93.14   \n",
       "67                      8.12                     27.36            6.09   \n",
       "68                      2.08                     15.51           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2 meth1_similarites  \\\n",
       "50            9.45             95.91             41.50             256.4   \n",
       "51            8.36             96.46             11.05             165.4   \n",
       "52            8.62             99.99             32.26              80.7   \n",
       "53           10.38             97.21             16.85             564.1   \n",
       "54            8.59             83.60             30.36             374.8   \n",
       "55           10.75             18.59             33.70             130.0   \n",
       "56            9.49              7.46             28.30             138.8   \n",
       "57           10.07             99.87             46.52              21.1   \n",
       "58           11.49             99.90             34.50             223.8   \n",
       "59           13.04             91.10             36.71              50.7   \n",
       "60            8.22              0.16             35.38             120.0   \n",
       "61           10.50             99.88             19.83             437.9   \n",
       "62           10.45             99.30             42.80             344.5   \n",
       "63            9.78             99.97             29.27             142.0   \n",
       "64           10.08             97.33             30.89              21.2   \n",
       "65            8.91              1.03             20.16             174.0   \n",
       "66            9.39             99.98             31.05             176.2   \n",
       "67            8.37             99.84             29.93               8.8   \n",
       "68           10.33             99.54             27.09             150.3   \n",
       "\n",
       "   meth2_similarites  Overall        LR  \n",
       "50             301.4      1.0  0.599858  \n",
       "51             389.4      1.0  0.578922  \n",
       "52             215.1      4.0  3.222043  \n",
       "53             248.6      1.0  2.897480  \n",
       "54             339.8      1.0  1.929214  \n",
       "55             159.8      2.0  2.748877  \n",
       "56              74.0      2.0  2.529084  \n",
       "57              54.1      4.0  3.034551  \n",
       "58             170.8      2.0  1.758119  \n",
       "59              68.7      2.0  3.645473  \n",
       "60             228.2      4.0  2.324108  \n",
       "61             301.2      2.0  1.863311  \n",
       "62             485.7      1.0  0.899217  \n",
       "63             289.0      2.0  3.008400  \n",
       "64              35.8      3.0  3.283364  \n",
       "65             179.9      3.0  3.345327  \n",
       "66             258.7      1.0  1.682769  \n",
       "67              28.4      4.0  3.700288  \n",
       "68             114.6      3.0  3.077994  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(Xtrain[:50],ytrain[:50])\n",
    "res_lr = lr.predict(Xtrain[50:])\n",
    "res_lr = pd.concat([Xtrain[50:],ytrain[50:],pd.DataFrame(res_lr,columns = ['LR'],index = range(50,69))],axis=1)\n",
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,res_lr['LR']],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remarque : les résultats sont assez différents : voir à utiliser différents algos ? <br/>\n",
    "En classification : Logistic Regression - XG Boost ?? - Linear Discriminant Analysis qui était OK en essai - Bayésien ? ADA Boost ? SVM ? : 1 score de classif en utilisant proba <br/>\n",
    "puis un score de régression : la Régression PLS peut être intéressante car les notes doivent très corrélées entre elles - Lasso ou ridge ne servent à rien a priori - SVR - RDN ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>99.54</td>\n",
       "      <td>9.49</td>\n",
       "      <td>14.58</td>\n",
       "      <td>79.42</td>\n",
       "      <td>9.45</td>\n",
       "      <td>95.91</td>\n",
       "      <td>41.50</td>\n",
       "      <td>256.4</td>\n",
       "      <td>301.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.599858</td>\n",
       "      <td>0.762088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>81.60</td>\n",
       "      <td>36.71</td>\n",
       "      <td>24.86</td>\n",
       "      <td>97.61</td>\n",
       "      <td>8.36</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11.05</td>\n",
       "      <td>165.4</td>\n",
       "      <td>389.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578922</td>\n",
       "      <td>0.670705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.62</td>\n",
       "      <td>99.99</td>\n",
       "      <td>32.26</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.222043</td>\n",
       "      <td>3.041758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>81.61</td>\n",
       "      <td>11.23</td>\n",
       "      <td>66.44</td>\n",
       "      <td>10.38</td>\n",
       "      <td>97.21</td>\n",
       "      <td>16.85</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.897480</td>\n",
       "      <td>2.537666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>46.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>83.60</td>\n",
       "      <td>30.36</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.929214</td>\n",
       "      <td>1.842386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>8.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>32.87</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.748877</td>\n",
       "      <td>2.877619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.40</td>\n",
       "      <td>44.72</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.46</td>\n",
       "      <td>28.30</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.529084</td>\n",
       "      <td>2.728216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.33</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.07</td>\n",
       "      <td>99.87</td>\n",
       "      <td>46.52</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.034551</td>\n",
       "      <td>3.115408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>10.72</td>\n",
       "      <td>2.12</td>\n",
       "      <td>81.74</td>\n",
       "      <td>11.49</td>\n",
       "      <td>99.90</td>\n",
       "      <td>34.50</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.758119</td>\n",
       "      <td>2.026156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13.04</td>\n",
       "      <td>91.10</td>\n",
       "      <td>36.71</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.645473</td>\n",
       "      <td>3.820556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.38</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.324108</td>\n",
       "      <td>2.334202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24.83</td>\n",
       "      <td>12.14</td>\n",
       "      <td>22.22</td>\n",
       "      <td>60.62</td>\n",
       "      <td>10.50</td>\n",
       "      <td>99.88</td>\n",
       "      <td>19.83</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.863311</td>\n",
       "      <td>1.944828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>42.65</td>\n",
       "      <td>10.45</td>\n",
       "      <td>99.30</td>\n",
       "      <td>42.80</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899217</td>\n",
       "      <td>0.948367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>99.97</td>\n",
       "      <td>29.27</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.008400</td>\n",
       "      <td>2.832326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.43</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.283364</td>\n",
       "      <td>3.297847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.345327</td>\n",
       "      <td>3.244682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>6.68</td>\n",
       "      <td>9.80</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.682769</td>\n",
       "      <td>1.718097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8.12</td>\n",
       "      <td>27.36</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.700288</td>\n",
       "      <td>3.565186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.08</td>\n",
       "      <td>15.51</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.077994</td>\n",
       "      <td>3.113272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50                6              8              0                    99.54   \n",
       "51                0             13              0                    81.60   \n",
       "52                0              0              0                     0.56   \n",
       "53                4              0              0                     0.12   \n",
       "54                1              3              0                     0.52   \n",
       "55                1              0              0                     0.33   \n",
       "56                0              3              0                     0.75   \n",
       "57                0              0              0                     7.73   \n",
       "58                0              4              0                     5.24   \n",
       "59                0              0              0                     0.23   \n",
       "60                1              2              0                     2.44   \n",
       "61                1              3              0                    24.83   \n",
       "62                0             22              0                     0.48   \n",
       "63                0             10              0                     0.36   \n",
       "64                1              4              0                     2.53   \n",
       "65                2              0              0                     2.03   \n",
       "66                2              4              0                     5.70   \n",
       "67                0              0              0                     0.25   \n",
       "68                0              4              0                     2.38   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                      9.49                     14.58           79.42   \n",
       "51                     36.71                     24.86           97.61   \n",
       "52                      0.70                      0.73            4.73   \n",
       "53                     81.61                     11.23           66.44   \n",
       "54                      1.27                      0.58           46.37   \n",
       "55                      8.41                      0.59           32.87   \n",
       "56                      0.11                      1.40           44.72   \n",
       "57                      2.12                      4.33           10.34   \n",
       "58                     10.72                      2.12           81.74   \n",
       "59                      0.74                      0.27            3.77   \n",
       "60                      0.08                      0.12           29.07   \n",
       "61                     12.14                     22.22           60.62   \n",
       "62                      0.09                      0.35           42.65   \n",
       "63                      7.38                      0.76            1.49   \n",
       "64                      2.35                      1.43           35.06   \n",
       "65                      0.61                      0.21           14.24   \n",
       "66                      6.68                      9.80           93.14   \n",
       "67                      8.12                     27.36            6.09   \n",
       "68                      2.08                     15.51           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2 meth1_similarites  \\\n",
       "50            9.45             95.91             41.50             256.4   \n",
       "51            8.36             96.46             11.05             165.4   \n",
       "52            8.62             99.99             32.26              80.7   \n",
       "53           10.38             97.21             16.85             564.1   \n",
       "54            8.59             83.60             30.36             374.8   \n",
       "55           10.75             18.59             33.70             130.0   \n",
       "56            9.49              7.46             28.30             138.8   \n",
       "57           10.07             99.87             46.52              21.1   \n",
       "58           11.49             99.90             34.50             223.8   \n",
       "59           13.04             91.10             36.71              50.7   \n",
       "60            8.22              0.16             35.38             120.0   \n",
       "61           10.50             99.88             19.83             437.9   \n",
       "62           10.45             99.30             42.80             344.5   \n",
       "63            9.78             99.97             29.27             142.0   \n",
       "64           10.08             97.33             30.89              21.2   \n",
       "65            8.91              1.03             20.16             174.0   \n",
       "66            9.39             99.98             31.05             176.2   \n",
       "67            8.37             99.84             29.93               8.8   \n",
       "68           10.33             99.54             27.09             150.3   \n",
       "\n",
       "   meth2_similarites  Overall        LR       PLS  \n",
       "50             301.4      1.0  0.599858  0.762088  \n",
       "51             389.4      1.0  0.578922  0.670705  \n",
       "52             215.1      4.0  3.222043  3.041758  \n",
       "53             248.6      1.0  2.897480  2.537666  \n",
       "54             339.8      1.0  1.929214  1.842386  \n",
       "55             159.8      2.0  2.748877  2.877619  \n",
       "56              74.0      2.0  2.529084  2.728216  \n",
       "57              54.1      4.0  3.034551  3.115408  \n",
       "58             170.8      2.0  1.758119  2.026156  \n",
       "59              68.7      2.0  3.645473  3.820556  \n",
       "60             228.2      4.0  2.324108  2.334202  \n",
       "61             301.2      2.0  1.863311  1.944828  \n",
       "62             485.7      1.0  0.899217  0.948367  \n",
       "63             289.0      2.0  3.008400  2.832326  \n",
       "64              35.8      3.0  3.283364  3.297847  \n",
       "65             179.9      3.0  3.345327  3.244682  \n",
       "66             258.7      1.0  1.682769  1.718097  \n",
       "67              28.4      4.0  3.700288  3.565186  \n",
       "68             114.6      3.0  3.077994  3.113272  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls = PLSRegression()\n",
    "pls.fit(Xtrain[:50],ytrain[:50])\n",
    "res_pls = list(pls.predict(Xtrain[50:]).flatten())\n",
    "res_pls = pd.concat([res_lr,pd.DataFrame(res_pls,columns = ['PLS'],index = range(50,69))],axis=1)\n",
    "res_pls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les scores de la regression PLS sont assez proches de la régression linéaire !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>ADA</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>KNN_Prob</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>ADA_Prob</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.599858</td>\n",
       "      <td>0.762088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.578922</td>\n",
       "      <td>0.670705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.222043</td>\n",
       "      <td>3.041758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.897480</td>\n",
       "      <td>2.537666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.929214</td>\n",
       "      <td>1.842386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.748877</td>\n",
       "      <td>2.877619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.529084</td>\n",
       "      <td>2.728216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.034551</td>\n",
       "      <td>3.115408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.758119</td>\n",
       "      <td>2.026156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.645473</td>\n",
       "      <td>3.820556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.324108</td>\n",
       "      <td>2.334202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.863311</td>\n",
       "      <td>1.944828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.899217</td>\n",
       "      <td>0.948367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.008400</td>\n",
       "      <td>2.832326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.283364</td>\n",
       "      <td>3.297847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.345327</td>\n",
       "      <td>3.244682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.682769</td>\n",
       "      <td>1.718097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.700288</td>\n",
       "      <td>3.565186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.077994</td>\n",
       "      <td>3.113272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Overall  RF  LDA  KNN  LOGR  ADA  RF_Prob  LDA_Prob  KNN_Prob  LOGR_Prob  \\\n",
       "50        1   1    2    2     1    2        1         2         2          2   \n",
       "51        1   1    1    3     1    3        2         1         3          3   \n",
       "52        4   3    3    2     2    2        3         3         3          3   \n",
       "53        1   4    1    1     1    1        2         1         1          1   \n",
       "54        1   2    3    1     2    1        2         2         2          2   \n",
       "55        2   2    3    2     2    2        2         3         3          3   \n",
       "56        2   4    3    4     3    4        4         3         4          4   \n",
       "57        4   4    3    4     3    4        4         3         4          4   \n",
       "58        2   1    1    2     2    2        2         2         2          2   \n",
       "59        2   4    3    3     4    3        4         3         3          3   \n",
       "60        4   2    2    3     2    3        3         2         3          3   \n",
       "61        2   1    1    1     1    1        1         1         1          1   \n",
       "62        1   2    2    1     2    1        2         2         2          2   \n",
       "63        2   3    3    2     2    2        3         3         2          2   \n",
       "64        3   4    4    4     4    4        4         4         4          4   \n",
       "65        3   3    4    3     3    3        3         4         3          3   \n",
       "66        1   2    2    2     2    2        2         2         2          2   \n",
       "67        4   4    4    4     4    4        4         4         4          4   \n",
       "68        3   3    3    4     4    4        3         3         4          4   \n",
       "\n",
       "    ADA_Prob        LR       PLS  \n",
       "50         2  0.599858  0.762088  \n",
       "51         3  0.578922  0.670705  \n",
       "52         3  3.222043  3.041758  \n",
       "53         1  2.897480  2.537666  \n",
       "54         2  1.929214  1.842386  \n",
       "55         3  2.748877  2.877619  \n",
       "56         4  2.529084  2.728216  \n",
       "57         4  3.034551  3.115408  \n",
       "58         2  1.758119  2.026156  \n",
       "59         3  3.645473  3.820556  \n",
       "60         3  2.324108  2.334202  \n",
       "61         1  1.863311  1.944828  \n",
       "62         2  0.899217  0.948367  \n",
       "63         2  3.008400  2.832326  \n",
       "64         4  3.283364  3.297847  \n",
       "65         3  3.345327  3.244682  \n",
       "66         2  1.682769  1.718097  \n",
       "67         4  3.700288  3.565186  \n",
       "68         4  3.077994  3.113272  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final = pd.concat([res_final,res_pls['PLS']],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compléments d'information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuel = francais[['title_1', 'title_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2',\n",
    "    'nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "    'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "    'score_sentiment2', 'meth1_similarites', 'meth2_similarites','Overall']]\n",
    "visuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pair_id', 'pair_lang', 'source_url_1', 'publish_date_1',\n",
       "       'source_url_2', 'publish_date_2', 'title_1', 'text_1',\n",
       "       'meta_description_1', 'meta_keywords_1', 'title_2', 'text_2',\n",
       "       'meta_description_2', 'meta_keywords_2', 'Geography', 'Entities',\n",
       "       'Time', 'Narrative', 'Overall', 'Style', 'Tone', 'ligne'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_francais = data.loc[data.pair_lang == 'fr_fr',['source_url_1', 'publish_date_1','source_url_2', 'publish_date_2', \n",
    "       'meta_description_1', 'meta_keywords_1', 'meta_description_2', 'meta_keywords_2','Overall']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://votreargent.lexpress.fr</td>\n",
       "      <td>Wed Mar 25 20:11:35 2020</td>\n",
       "      <td>https://www.lexpress.fr</td>\n",
       "      <td>Wed Mar 25 07:00:00 2020</td>\n",
       "      <td>Le cap du million de ventes a été dépassé l'an...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Stocks réduits ou distribués au \"compte-goutte...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.coupdoeil.info</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>http://www.lechodelaval.ca</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://ici.radio-canada.ca</td>\n",
       "      <td></td>\n",
       "      <td>https://www.lapresse.ca</td>\n",
       "      <td>Wed Mar 25 05:00:00 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>Des Québécois coincés au Pérou qualifient de «...</td>\n",
       "      <td>['']</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://beninsite.net</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>http://www.togolais.info</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>En l'espace de quelques jours, deux piliers de...</td>\n",
       "      <td>[\"L'Afrique pleure Manu Dibango\", '', 'info', ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.lareleve.qc.ca</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>https://canadianwomen.org</td>\n",
       "      <td>Wed Mar 25 21:15:26 2020</td>\n",
       "      <td>La MRC a décidé de mettre de l’avant différent...</td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>https://www.bladi.net</td>\n",
       "      <td></td>\n",
       "      <td>https://www.bladi.net</td>\n",
       "      <td></td>\n",
       "      <td>Les forces de l’ordre effectuent des inspectio...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>http://ici.radio-canada.ca</td>\n",
       "      <td></td>\n",
       "      <td>https://www.journalexpress.ca</td>\n",
       "      <td>Wed May 27 00:00:00 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>http://fr.nhandan.com.vn</td>\n",
       "      <td></td>\n",
       "      <td>http://fr.nhandan.com.vn</td>\n",
       "      <td></td>\n",
       "      <td>Nhân Dân en ligne - Asiatoday, l'un des princi...</td>\n",
       "      <td>['Le journal Nhân Dân', 'politique', 'économie...</td>\n",
       "      <td>Nhân Dân en ligne - Le Premier ministre (PM) v...</td>\n",
       "      <td>['Le journal Nhân Dân', 'politique', 'économie...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>https://www.acadienouvelle.com</td>\n",
       "      <td>Thu Jun 11 00:00:00 2020</td>\n",
       "      <td>https://www.telecablesat.fr</td>\n",
       "      <td></td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>['Acadie']</td>\n",
       "      <td>Comment avez-vous vécu le confinement?Au début...</td>\n",
       "      <td>['']</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>https://benin24tv.com</td>\n",
       "      <td>Mon Mar  2 18:47:14 2020</td>\n",
       "      <td>https://www.seneplus.com</td>\n",
       "      <td>Sat Mar 28 14:02:20 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>Alors que le directeur de l’Organisation mondi...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source_url_1            publish_date_1  \\\n",
       "0   https://votreargent.lexpress.fr  Wed Mar 25 20:11:35 2020   \n",
       "1        https://www.coupdoeil.info  Wed Mar 25 00:00:00 2020   \n",
       "2        http://ici.radio-canada.ca                             \n",
       "3              http://beninsite.net  Wed Mar 25 00:00:00 2020   \n",
       "4        https://www.lareleve.qc.ca  Wed Mar 25 00:00:00 2020   \n",
       "..                              ...                       ...   \n",
       "67            https://www.bladi.net                             \n",
       "68       http://ici.radio-canada.ca                             \n",
       "69         http://fr.nhandan.com.vn                             \n",
       "70   https://www.acadienouvelle.com  Thu Jun 11 00:00:00 2020   \n",
       "71            https://benin24tv.com  Mon Mar  2 18:47:14 2020   \n",
       "\n",
       "                     source_url_2            publish_date_2  \\\n",
       "0         https://www.lexpress.fr  Wed Mar 25 07:00:00 2020   \n",
       "1      http://www.lechodelaval.ca                             \n",
       "2         https://www.lapresse.ca  Wed Mar 25 05:00:00 2020   \n",
       "3        http://www.togolais.info                             \n",
       "4       https://canadianwomen.org  Wed Mar 25 21:15:26 2020   \n",
       "..                            ...                       ...   \n",
       "67          https://www.bladi.net                             \n",
       "68  https://www.journalexpress.ca  Wed May 27 00:00:00 2020   \n",
       "69       http://fr.nhandan.com.vn                             \n",
       "70    https://www.telecablesat.fr                             \n",
       "71       https://www.seneplus.com  Sat Mar 28 14:02:20 2020   \n",
       "\n",
       "                                   meta_description_1  \\\n",
       "0   Le cap du million de ventes a été dépassé l'an...   \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4   La MRC a décidé de mettre de l’avant différent...   \n",
       "..                                                ...   \n",
       "67  Les forces de l’ordre effectuent des inspectio...   \n",
       "68                                                      \n",
       "69  Nhân Dân en ligne - Asiatoday, l'un des princi...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71                                                      \n",
       "\n",
       "                                      meta_keywords_1  \\\n",
       "0                                                ['']   \n",
       "1                                                ['']   \n",
       "2                                                ['']   \n",
       "3                                                ['']   \n",
       "4                                                ['']   \n",
       "..                                                ...   \n",
       "67                                               ['']   \n",
       "68                                               ['']   \n",
       "69  ['Le journal Nhân Dân', 'politique', 'économie...   \n",
       "70                                         ['Acadie']   \n",
       "71                                               ['']   \n",
       "\n",
       "                                   meta_description_2  \\\n",
       "0   Stocks réduits ou distribués au \"compte-goutte...   \n",
       "1                                                       \n",
       "2   Des Québécois coincés au Pérou qualifient de «...   \n",
       "3   En l'espace de quelques jours, deux piliers de...   \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "67  Suite aux violations du confinement dans les v...   \n",
       "68                                                      \n",
       "69  Nhân Dân en ligne - Le Premier ministre (PM) v...   \n",
       "70  Comment avez-vous vécu le confinement?Au début...   \n",
       "71  Alors que le directeur de l’Organisation mondi...   \n",
       "\n",
       "                                      meta_keywords_2  Overall  \n",
       "0                                                ['']      3.0  \n",
       "1                                                ['']      4.0  \n",
       "2                                                ['']      2.0  \n",
       "3   [\"L'Afrique pleure Manu Dibango\", '', 'info', ...      1.0  \n",
       "4                                                ['']      3.0  \n",
       "..                                                ...      ...  \n",
       "67                                               ['']      3.0  \n",
       "68                                               ['']      3.0  \n",
       "69  ['Le journal Nhân Dân', 'politique', 'économie...      1.0  \n",
       "70                                               ['']      4.0  \n",
       "71                                               ['']      3.0  \n",
       "\n",
       "[72 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_francais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

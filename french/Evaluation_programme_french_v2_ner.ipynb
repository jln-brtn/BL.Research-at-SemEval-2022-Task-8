{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de classification en Français V2\n",
    "\n",
    "    - Transformers : Summarization : 2 modèles --> 2 Résumés / Puis score de similarités de ces 2 résumés\n",
    "    Noter que l'on peut faire aussi la similarité des textes (autre note ?) et non du résumé\n",
    "    - Text classification sur une base de catégories \"Presse\" : sport - actaulités - économie - etc\n",
    "    - Sentiment analysis : voir si le ton du texte est de même type \n",
    "    - Les 2 derniers classifier seronts utilisés en produit scalaire : Par Catégorie : texte1: note1 - texte2 : note2\n",
    "    et donc sum(notes_par_catégorie) = sum(note1*note2) * 100 au bout (note sur 100)\n",
    "    \n",
    "    ici plus de passage par Stanza : 1 fois avec NER Spacy et une fois avec NER Camembert\n",
    "    Score de similarité par Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'click._bashcomplete'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19804/1245235029.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpke\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pke\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpke\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_structures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCandidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDocument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpke\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinimalCoreNLPReader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRawTextReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpke\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLoadFile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m from pke.utils import (load_document_frequency_file, compute_document_frequency,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pke\\readers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mElementTree\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0metree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpke\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_structures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcli\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minfo\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mglossary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexplain\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\cli\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwasabi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetup_cli\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# These are the actual functions, NOT the wrapped CLI commands. The CLI commands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\cli\\_util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msrsly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtyper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mclick\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNoSuchOption\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplit_arg_string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\typer\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTyper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mTyper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCallbackParam\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mCallbackParam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\typer\\main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcompletion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_completion_inspect_parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTyperArgument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTyperCommand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m from .models import (\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\typer\\completion.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bashcomplete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParamMeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'click._bashcomplete'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pke\n",
    "import spacy\n",
    "import torch\n",
    "import warnings\n",
    "import string\n",
    "from gensim.models import KeyedVectors\n",
    "import enchant    # Pour correction orthographique de synonymes\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection des modèles NLP : ici FRANCAIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement pour l'utilisation de Spacy  - Français\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_spacy = {'fr':nlp_fr}   # 'en':nlp_en,'de':nlp_de,'es':nlp_es,'pl':nlp_pl  - POUR MEMOIRE\n",
    "langues = ['en','fr','es','de','pl','ar','tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle Word2Vec pour utilisation de synonymes\n",
    "model_gensim = KeyedVectors.load_word2vec_format(\"D:/Users/STG-SDU/Documents/NLP/Word2Vec.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords Français NLTK + Spacy \n",
    "stopWords = list(nlp_fr.Defaults.stop_words)\n",
    "stopwords_fr = list(stopwords.words('french'))  \n",
    "stopwords_fr = list(set(stopwords_fr + stopWords))\n",
    "stopwds_lg = {'fr':stopwords_fr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcteur orthographique pour validation des synonymes OPTIONNEL CAR NON NECESSAIRE\n",
    "d = enchant.Dict(\"fr\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection des modèles Transformers : Summary - Text Classification - Sentiment Analysis - Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèles Transformers de Résumé (NB : Ne pas oublier d'ajouter la truncation pour tous les modèles, peut être source d'erreur)\n",
    "summarizer1 = pipeline(\"summarization\", model=\"moussaKam/barthez-orangesum-title\", truncation = \"only_first\")\n",
    "summarizer2 = pipeline(\"summarization\", model=\"lincoln/mbart-mlsum-automatic-summarization\", truncation = \"only_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textes classification ou Zero shot classification (permet de chosiri nos propres thèmes)\n",
    "text_clf1 = pipeline(\"text-classification\", model = \"lincoln/flaubert-mlsum-topic-classification\", truncation = \"only_first\")   # 10 actégories, voir hugging face\n",
    "# NB : BUG : zero_shot_clf = pipeline(\"zero-shot-classification\", model=\"BaptisteDoyen/camembert-base-xlni\") # download ne marche pas, donc manuel\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(\"BaptisteDoyen/camembert-base-xnli\")\n",
    "zero_tokenizer = AutoTokenizer.from_pretrained(\"BaptisteDoyen/camembert-base-xnli\") \n",
    "text_clf2 = pipeline('zero-shot-classification', model=nli_model, tokenizer=zero_tokenizer,truncation = \"only_first\")\n",
    "# ce modèle est un zero shot classification : catégories possibles choisies par mes soins (dans la presse)\n",
    "candidate_labels = ['Sciences','Politique','Education','Actualités','Santé','Technologie','Société', 'Sport','Economie','Culture','International','Environnement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DemangeJeremy/4-sentiments-with-flaubert were not used when initializing FlaubertForSequenceClassification: ['transformer.position_ids']\n",
      "- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "sentiment1 = pipeline(\"text-classification\", model = 'moussaKam/barthez-sentiment-classification')\n",
    "\n",
    "# ATTENTION CE MODELE n°2 SE DEFINIT SUR 4 CLASSES : mixed, positif, negatif, objectif\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained('flaubert/flaubert_large_cased')\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(\"DemangeJeremy/4-sentiments-with-flaubert\")\n",
    "sentiment2 = pipeline('sentiment-analysis', model=loaded_model, tokenizer=loaded_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise ici sentence similarity et sentence transformers\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "encoder = SentenceTransformer(\"Sahajtomar/french_semantic\")\n",
    "def score_similarite(sentence1,sentence2):\n",
    "    # attention, pour que torch fonctionne en dimension sentence1 (et 2) est une liste simple\n",
    "    embed1 = encoder.encode(sentence1, convert_to_tensor=True)\n",
    "    embed2 = encoder.encode(sentence2, convert_to_tensor=True)\n",
    "    return round(float(util.pytorch_cos_sim(embed1,embed2))*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER camembert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "ner = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection Data par langues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('eval_data_prep_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>pair_lang</th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>title_1</th>\n",
       "      <th>text_1</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_2</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>ligne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1484189203_1484121193</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://wsvn.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wsvn.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police: 2 men stole tools from Lowe’s in Davie</td>\n",
       "      <td>DAVIE, FLA. (WSVN) - Police need help catching...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>No-swim advisory lifted for Deerfield Beach Pier</td>\n",
       "      <td>DEERFIELD BEACH, FLA. (WSVN) - A no-swim advis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1484011097_1484011106</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.zdnet.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://securityboulevard.com</td>\n",
       "      <td>Fri Oct 25 11:10:18 2019</td>\n",
       "      <td>Open database leaked 179GB in customer, US gov...</td>\n",
       "      <td>Govt officials confirm Trump can block US comp...</td>\n",
       "      <td>The US Department of Homeland Security has bec...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Best Western’s Massive Data Leak: 179GB Amazon...</td>\n",
       "      <td>The latest huge unsecured cloud storage find i...</td>\n",
       "      <td>The latest huge unsecured cloud storage find i...</td>\n",
       "      <td>['']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1484039488_1484261803</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.presstelegram.com</td>\n",
       "      <td>Tue Dec 31 00:00:00 2019</td>\n",
       "      <td>https://boingboing.net</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Ducks are own worst enemies in sloppy loss in ...</td>\n",
       "      <td>Ducks defenseman Erik Gudbranson, left, knocks...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Woody Guthrie's 1943 New Year's Resolutions ar...</td>\n",
       "      <td>Woody Guthrie's 1943 New Year's Resolutions ar...</td>\n",
       "      <td>I'd seen this before, but I was reminded of it...</td>\n",
       "      <td>['']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1484332324_1484796748</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.financialexpress.com</td>\n",
       "      <td>Thu Jan  2 08:28:22 2020</td>\n",
       "      <td>https://www.news18.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Another Bengal vs Centre tussle? Govt rejects ...</td>\n",
       "      <td>The West Bengal government’s proposal was reje...</td>\n",
       "      <td>The West Bengal government's proposal was reje...</td>\n",
       "      <td>['republic day', 'west bengal tableau', 'benga...</td>\n",
       "      <td>'Congress Rejected 7 Times': BJP's Reminder as...</td>\n",
       "      <td>Mumbai: The NCP and Shiv Sena on Thursday targ...</td>\n",
       "      <td>BJP ally and Union minister Ramdas Athawale sa...</td>\n",
       "      <td>['BJP', 'congress', 'Mamata Banerjee', 'NCP', ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484012256_1484419682</td>\n",
       "      <td>en_en</td>\n",
       "      <td>https://www.birminghammail.co.uk</td>\n",
       "      <td>Wed Jan  1 15:03:04 2020</td>\n",
       "      <td>http://m.fightbacknews.org</td>\n",
       "      <td>Wed Jan  1 00:00:00 2020</td>\n",
       "      <td>Bars and clubs you loved and lost this decade ...</td>\n",
       "      <td>The video will start in 8 Cancel\\n\\nSign up to...</td>\n",
       "      <td>Nightclubs and bars that have closed in the pa...</td>\n",
       "      <td>['Birmingham City Centre', 'Digbeth', 'Things ...</td>\n",
       "      <td>Top 20 films of the 2010s</td>\n",
       "      <td>Jacksonville, FL - I'm not sure how we'll look...</td>\n",
       "      <td>Jacksonville, FL - I'm not sure how we'll look...</td>\n",
       "      <td>['organizing', 'activism', 'socialism', \"Peopl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>1553907621_1553488848</td>\n",
       "      <td>es_it</td>\n",
       "      <td>https://www.diariolibre.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.basketuniverso.it</td>\n",
       "      <td>Thu Mar 19 23:45:49 2020</td>\n",
       "      <td>Denver Nuggets reporta que “un miembro de la o...</td>\n",
       "      <td>Los Denver Nuggets de la NBA reportaron este j...</td>\n",
       "      <td>Los Denver Nuggets de la NBA reportaron este j...</td>\n",
       "      <td>['NBA']</td>\n",
       "      <td>Coronavirus, un caso anche fra i Denver Nuggets</td>\n",
       "      <td>Nato ad Alatri (Fr) nel ’93 e qui diplomato al...</td>\n",
       "      <td>Un altro caso di Coronavirus nella NBA, stavol...</td>\n",
       "      <td>['']</td>\n",
       "      <td>4948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>1646957948_1643667075</td>\n",
       "      <td>es_it</td>\n",
       "      <td>https://diario16.com</td>\n",
       "      <td>Sun Jun 28 04:20:00 2020</td>\n",
       "      <td>https://www.laregione.ch</td>\n",
       "      <td>Wed Jun 24 16:41:00 2020</td>\n",
       "      <td>Vivir en España es más barato que en la media ...</td>\n",
       "      <td>El estudio realizado por Eurostat muestra que ...</td>\n",
       "      <td>El estudio realizado por Eurostat muestra que ...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Coronavirus, in Europa 140mila morti in più in...</td>\n",
       "      <td>Nei mesi di marzo e aprile 2020, dalla decima ...</td>\n",
       "      <td>Il picco di morti aggiuntivi rispetto alla med...</td>\n",
       "      <td>['']</td>\n",
       "      <td>4949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>1504063453_1502866628</td>\n",
       "      <td>es_it</td>\n",
       "      <td>https://elaragueno.com.ve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.greenme.it</td>\n",
       "      <td>Thu Jan 23 12:46:02 2020</td>\n",
       "      <td>Activan sistema de vigilancia epidemiológica e...</td>\n",
       "      <td>Foto: Archivo Foto: Archivo\\n\\nEl sistema de v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Coronavirus in Cina: consumo di serpenti e zup...</td>\n",
       "      <td>La diffusione del mortale Coronavirus potrebbe...</td>\n",
       "      <td>L'infezione da coronavirus potrebbe aver avuto...</td>\n",
       "      <td>['cina', 'coronavirus', 'pipistrelli', 'serpen...</td>\n",
       "      <td>4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>1647862428_1647712939</td>\n",
       "      <td>es_it</td>\n",
       "      <td>http://www.am.com.mx</td>\n",
       "      <td>Mon Jun 29 00:00:00 2020</td>\n",
       "      <td>https://it.sputniknews.com</td>\n",
       "      <td>Mon Jun 29 13:46:00 2020</td>\n",
       "      <td>Emite Irán orden de arresto contra Tump por as...</td>\n",
       "      <td>CDMX.- Anunció Irán este lunes que ha emitido ...</td>\n",
       "      <td>Ha emitido Irán una orden de arresto, que ha s...</td>\n",
       "      <td>['DONALD TRUMP', 'ESTADOS UNIDOS', 'IRÁN']</td>\n",
       "      <td>Iran emette mandato di arresto per Trump per l...</td>\n",
       "      <td>Il procuratore di Teheran Ali Alqasi Mehr in u...</td>\n",
       "      <td>Il procuratore di Teheran, Ali Alqasi Mehr, ha...</td>\n",
       "      <td>['mondo', 'qasem soleimani', \"le tensioni tra ...</td>\n",
       "      <td>4951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>1636570015_1637492652</td>\n",
       "      <td>es_it</td>\n",
       "      <td>https://elnuevodiario.com.do</td>\n",
       "      <td>Tue Jun 16 18:49:57 2020</td>\n",
       "      <td>https://it.notizie.yahoo.com</td>\n",
       "      <td>Wed Jun 17 16:44:25 2020</td>\n",
       "      <td>Biden, con más de 10 puntos que Trump en estad...</td>\n",
       "      <td>Comparte esta noticia\\n\\nEL NUEVO DIARIO,MIAMI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Sondaggio Usa 2020: Biden in vantaggio nei 6 S...</td>\n",
       "      <td>New York, 17 giu. (askanews) - L'ex vicepresid...</td>\n",
       "      <td>Per la prima volta, Trump  in ritardo in tutti...</td>\n",
       "      <td>['']</td>\n",
       "      <td>4952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4953 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pair_id pair_lang                      source_url_1  \\\n",
       "0     1484189203_1484121193     en_en                  https://wsvn.com   \n",
       "1     1484011097_1484011106     en_en             https://www.zdnet.com   \n",
       "2     1484039488_1484261803     en_en     https://www.presstelegram.com   \n",
       "3     1484332324_1484796748     en_en  https://www.financialexpress.com   \n",
       "4     1484012256_1484419682     en_en  https://www.birminghammail.co.uk   \n",
       "...                     ...       ...                               ...   \n",
       "4948  1553907621_1553488848     es_it       https://www.diariolibre.com   \n",
       "4949  1646957948_1643667075     es_it              https://diario16.com   \n",
       "4950  1504063453_1502866628     es_it         https://elaragueno.com.ve   \n",
       "4951  1647862428_1647712939     es_it              http://www.am.com.mx   \n",
       "4952  1636570015_1637492652     es_it      https://elnuevodiario.com.do   \n",
       "\n",
       "                publish_date_1                   source_url_2  \\\n",
       "0                          NaN               https://wsvn.com   \n",
       "1                          NaN  https://securityboulevard.com   \n",
       "2     Tue Dec 31 00:00:00 2019         https://boingboing.net   \n",
       "3     Thu Jan  2 08:28:22 2020         https://www.news18.com   \n",
       "4     Wed Jan  1 15:03:04 2020     http://m.fightbacknews.org   \n",
       "...                        ...                            ...   \n",
       "4948                       NaN  https://www.basketuniverso.it   \n",
       "4949  Sun Jun 28 04:20:00 2020       https://www.laregione.ch   \n",
       "4950                       NaN         https://www.greenme.it   \n",
       "4951  Mon Jun 29 00:00:00 2020     https://it.sputniknews.com   \n",
       "4952  Tue Jun 16 18:49:57 2020   https://it.notizie.yahoo.com   \n",
       "\n",
       "                publish_date_2  \\\n",
       "0                          NaN   \n",
       "1     Fri Oct 25 11:10:18 2019   \n",
       "2     Wed Jan  1 00:00:00 2020   \n",
       "3                          NaN   \n",
       "4     Wed Jan  1 00:00:00 2020   \n",
       "...                        ...   \n",
       "4948  Thu Mar 19 23:45:49 2020   \n",
       "4949  Wed Jun 24 16:41:00 2020   \n",
       "4950  Thu Jan 23 12:46:02 2020   \n",
       "4951  Mon Jun 29 13:46:00 2020   \n",
       "4952  Wed Jun 17 16:44:25 2020   \n",
       "\n",
       "                                                title_1  \\\n",
       "0        Police: 2 men stole tools from Lowe’s in Davie   \n",
       "1     Open database leaked 179GB in customer, US gov...   \n",
       "2     Ducks are own worst enemies in sloppy loss in ...   \n",
       "3     Another Bengal vs Centre tussle? Govt rejects ...   \n",
       "4     Bars and clubs you loved and lost this decade ...   \n",
       "...                                                 ...   \n",
       "4948  Denver Nuggets reporta que “un miembro de la o...   \n",
       "4949  Vivir en España es más barato que en la media ...   \n",
       "4950  Activan sistema de vigilancia epidemiológica e...   \n",
       "4951  Emite Irán orden de arresto contra Tump por as...   \n",
       "4952  Biden, con más de 10 puntos que Trump en estad...   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     DAVIE, FLA. (WSVN) - Police need help catching...   \n",
       "1     Govt officials confirm Trump can block US comp...   \n",
       "2     Ducks defenseman Erik Gudbranson, left, knocks...   \n",
       "3     The West Bengal government’s proposal was reje...   \n",
       "4     The video will start in 8 Cancel\\n\\nSign up to...   \n",
       "...                                                 ...   \n",
       "4948  Los Denver Nuggets de la NBA reportaron este j...   \n",
       "4949  El estudio realizado por Eurostat muestra que ...   \n",
       "4950  Foto: Archivo Foto: Archivo\\n\\nEl sistema de v...   \n",
       "4951  CDMX.- Anunció Irán este lunes que ha emitido ...   \n",
       "4952  Comparte esta noticia\\n\\nEL NUEVO DIARIO,MIAMI...   \n",
       "\n",
       "                                     meta_description_1  \\\n",
       "0                                                   NaN   \n",
       "1     The US Department of Homeland Security has bec...   \n",
       "2                                                   NaN   \n",
       "3     The West Bengal government's proposal was reje...   \n",
       "4     Nightclubs and bars that have closed in the pa...   \n",
       "...                                                 ...   \n",
       "4948  Los Denver Nuggets de la NBA reportaron este j...   \n",
       "4949  El estudio realizado por Eurostat muestra que ...   \n",
       "4950                                                NaN   \n",
       "4951  Ha emitido Irán una orden de arresto, que ha s...   \n",
       "4952                                                NaN   \n",
       "\n",
       "                                        meta_keywords_1  \\\n",
       "0                                                  ['']   \n",
       "1                                                  ['']   \n",
       "2                                                  ['']   \n",
       "3     ['republic day', 'west bengal tableau', 'benga...   \n",
       "4     ['Birmingham City Centre', 'Digbeth', 'Things ...   \n",
       "...                                                 ...   \n",
       "4948                                            ['NBA']   \n",
       "4949                                               ['']   \n",
       "4950                                               ['']   \n",
       "4951         ['DONALD TRUMP', 'ESTADOS UNIDOS', 'IRÁN']   \n",
       "4952                                               ['']   \n",
       "\n",
       "                                                title_2  \\\n",
       "0      No-swim advisory lifted for Deerfield Beach Pier   \n",
       "1     Best Western’s Massive Data Leak: 179GB Amazon...   \n",
       "2     Woody Guthrie's 1943 New Year's Resolutions ar...   \n",
       "3     'Congress Rejected 7 Times': BJP's Reminder as...   \n",
       "4                             Top 20 films of the 2010s   \n",
       "...                                                 ...   \n",
       "4948    Coronavirus, un caso anche fra i Denver Nuggets   \n",
       "4949  Coronavirus, in Europa 140mila morti in più in...   \n",
       "4950  Coronavirus in Cina: consumo di serpenti e zup...   \n",
       "4951  Iran emette mandato di arresto per Trump per l...   \n",
       "4952  Sondaggio Usa 2020: Biden in vantaggio nei 6 S...   \n",
       "\n",
       "                                                 text_2  \\\n",
       "0     DEERFIELD BEACH, FLA. (WSVN) - A no-swim advis...   \n",
       "1     The latest huge unsecured cloud storage find i...   \n",
       "2     Woody Guthrie's 1943 New Year's Resolutions ar...   \n",
       "3     Mumbai: The NCP and Shiv Sena on Thursday targ...   \n",
       "4     Jacksonville, FL - I'm not sure how we'll look...   \n",
       "...                                                 ...   \n",
       "4948  Nato ad Alatri (Fr) nel ’93 e qui diplomato al...   \n",
       "4949  Nei mesi di marzo e aprile 2020, dalla decima ...   \n",
       "4950  La diffusione del mortale Coronavirus potrebbe...   \n",
       "4951  Il procuratore di Teheran Ali Alqasi Mehr in u...   \n",
       "4952  New York, 17 giu. (askanews) - L'ex vicepresid...   \n",
       "\n",
       "                                     meta_description_2  \\\n",
       "0                                                   NaN   \n",
       "1     The latest huge unsecured cloud storage find i...   \n",
       "2     I'd seen this before, but I was reminded of it...   \n",
       "3     BJP ally and Union minister Ramdas Athawale sa...   \n",
       "4     Jacksonville, FL - I'm not sure how we'll look...   \n",
       "...                                                 ...   \n",
       "4948  Un altro caso di Coronavirus nella NBA, stavol...   \n",
       "4949  Il picco di morti aggiuntivi rispetto alla med...   \n",
       "4950  L'infezione da coronavirus potrebbe aver avuto...   \n",
       "4951  Il procuratore di Teheran, Ali Alqasi Mehr, ha...   \n",
       "4952  Per la prima volta, Trump  in ritardo in tutti...   \n",
       "\n",
       "                                        meta_keywords_2  ligne  \n",
       "0                                                  ['']      0  \n",
       "1                                                  ['']      1  \n",
       "2                                                  ['']      2  \n",
       "3     ['BJP', 'congress', 'Mamata Banerjee', 'NCP', ...      3  \n",
       "4     ['organizing', 'activism', 'socialism', \"Peopl...      4  \n",
       "...                                                 ...    ...  \n",
       "4948                                               ['']   4948  \n",
       "4949                                               ['']   4949  \n",
       "4950  ['cina', 'coronavirus', 'pipistrelli', 'serpen...   4950  \n",
       "4951  ['mondo', 'qasem soleimani', \"le tensioni tra ...   4951  \n",
       "4952                                               ['']   4952  \n",
       "\n",
       "[4953 rows x 15 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remémorer numéro de ligne - compléter les Nan\n",
    "data['ligne'] = data.index\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation des datasets, le dernier étant à traduire en plus\n",
    "francais = data.loc[data.pair_lang == 'fr_fr',['ligne','title_1','title_2','text_1','text_2']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2613</td>\n",
       "      <td>Kédougou : Sa mère se suicide, il se tire une ...</td>\n",
       "      <td>Kédougou : Une fille de 4 ans chute mortelleme...</td>\n",
       "      <td>Kédougou : Sa mère se suicide, il se tire une ...</td>\n",
       "      <td>Kédougou : Une fille de 4 ans chute mortelleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2614</td>\n",
       "      <td>Etats-Unis : Uber licencie 3 700 employés en t...</td>\n",
       "      <td>Uber vire 3.500 employés par visioconférence e...</td>\n",
       "      <td>Lors d'une visio-conférence sur Zoom, service ...</td>\n",
       "      <td>Les employés concernés ont appris la nouvelle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2615</td>\n",
       "      <td>AFRIQUE - SUD-SOUDAN: EMBARGO DE L’ONU SUR LES...</td>\n",
       "      <td>Soudan du Sud: le président Kiir dévoile le no...</td>\n",
       "      <td>Le Conseil de sécurité de l’ONU a prolongé ven...</td>\n",
       "      <td>Le président sud-soudanais Salva Kiir a dévoil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2616</td>\n",
       "      <td>Allemagne : le ministère de l'Intérieur interd...</td>\n",
       "      <td>En Allemagne, les autorités ont déjoué un proj...</td>\n",
       "      <td>L'Allemagne a interdit un groupuscule d'extrêm...</td>\n",
       "      <td>Un drame semblable à la tuerie de Christchurch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2617</td>\n",
       "      <td>Coronavirus : le nombre de patients en réanima...</td>\n",
       "      <td>Bison Futé prévoit un week-end de l'Ascension ...</td>\n",
       "      <td>Retrouvez ici l'intégralité de notre live #COR...</td>\n",
       "      <td>Pour le week-end de l'Ascension, Bison Futé pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2618</td>\n",
       "      <td>Givenchy a trouvé son nouveau directeur artist...</td>\n",
       "      <td>Breaking News : Givenchy Nomme Matthew William...</td>\n",
       "      <td>Le 10 avril dernier, en plein confinement, la ...</td>\n",
       "      <td>MODE - Le fondateur de la marque 1017-Alyx-9SM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2619</td>\n",
       "      <td>Dozulé : Sophie Gaugain a dévoilé son équipe d...</td>\n",
       "      <td>Sophie Gaugain réélue pour un troisième mandat...</td>\n",
       "      <td>Mardi 4 février 2020, à l'occasion de sa premi...</td>\n",
       "      <td>« C’est dans des circonstances toutes particul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2620</td>\n",
       "      <td>Frédéric Veaux, l’expérience à la tête de la p...</td>\n",
       "      <td>Frédéric Veaux, nouveau directeur général de l...</td>\n",
       "      <td>Portrait L’ancien préfet de la Mayenne a offic...</td>\n",
       "      <td>L’homme est un habitué des missions difficiles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2621</td>\n",
       "      <td>Des images de foule à un check-point de Bethlé...</td>\n",
       "      <td>La Jordanie dit avoir déjoué des attaques cont...</td>\n",
       "      <td>Malgré les assurances du ministère de la Défen...</td>\n",
       "      <td>Cinq Jordaniens sont jugés dans leur pays pour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2622</td>\n",
       "      <td>Coronavirus : l'Iran, pays où l'épidémie a fai...</td>\n",
       "      <td>Coronavirus : l'Iran annonce 129 nouveaux décè...</td>\n",
       "      <td>Alors que l'épidémie de coronavirus accélère h...</td>\n",
       "      <td>Le ministère de la Santé iranien a annoncé dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2623</td>\n",
       "      <td>Pourquoi c'est important Municipales : coup d’...</td>\n",
       "      <td>Résultats du second tour des municipales : spe...</td>\n",
       "      <td>Trois mois jour pour jour après le premier tou...</td>\n",
       "      <td>« Ce qui a gagné ce soir, me semble-t-il, c'es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ligne                                            title_1  \\\n",
       "100   2613  Kédougou : Sa mère se suicide, il se tire une ...   \n",
       "101   2614  Etats-Unis : Uber licencie 3 700 employés en t...   \n",
       "102   2615  AFRIQUE - SUD-SOUDAN: EMBARGO DE L’ONU SUR LES...   \n",
       "103   2616  Allemagne : le ministère de l'Intérieur interd...   \n",
       "104   2617  Coronavirus : le nombre de patients en réanima...   \n",
       "105   2618  Givenchy a trouvé son nouveau directeur artist...   \n",
       "106   2619  Dozulé : Sophie Gaugain a dévoilé son équipe d...   \n",
       "107   2620  Frédéric Veaux, l’expérience à la tête de la p...   \n",
       "108   2621  Des images de foule à un check-point de Bethlé...   \n",
       "109   2622  Coronavirus : l'Iran, pays où l'épidémie a fai...   \n",
       "110   2623  Pourquoi c'est important Municipales : coup d’...   \n",
       "\n",
       "                                               title_2  \\\n",
       "100  Kédougou : Une fille de 4 ans chute mortelleme...   \n",
       "101  Uber vire 3.500 employés par visioconférence e...   \n",
       "102  Soudan du Sud: le président Kiir dévoile le no...   \n",
       "103  En Allemagne, les autorités ont déjoué un proj...   \n",
       "104  Bison Futé prévoit un week-end de l'Ascension ...   \n",
       "105  Breaking News : Givenchy Nomme Matthew William...   \n",
       "106  Sophie Gaugain réélue pour un troisième mandat...   \n",
       "107  Frédéric Veaux, nouveau directeur général de l...   \n",
       "108  La Jordanie dit avoir déjoué des attaques cont...   \n",
       "109  Coronavirus : l'Iran annonce 129 nouveaux décè...   \n",
       "110  Résultats du second tour des municipales : spe...   \n",
       "\n",
       "                                                text_1  \\\n",
       "100  Kédougou : Sa mère se suicide, il se tire une ...   \n",
       "101  Lors d'une visio-conférence sur Zoom, service ...   \n",
       "102  Le Conseil de sécurité de l’ONU a prolongé ven...   \n",
       "103  L'Allemagne a interdit un groupuscule d'extrêm...   \n",
       "104  Retrouvez ici l'intégralité de notre live #COR...   \n",
       "105  Le 10 avril dernier, en plein confinement, la ...   \n",
       "106  Mardi 4 février 2020, à l'occasion de sa premi...   \n",
       "107  Portrait L’ancien préfet de la Mayenne a offic...   \n",
       "108  Malgré les assurances du ministère de la Défen...   \n",
       "109  Alors que l'épidémie de coronavirus accélère h...   \n",
       "110  Trois mois jour pour jour après le premier tou...   \n",
       "\n",
       "                                                text_2  \n",
       "100  Kédougou : Une fille de 4 ans chute mortelleme...  \n",
       "101  Les employés concernés ont appris la nouvelle ...  \n",
       "102  Le président sud-soudanais Salva Kiir a dévoil...  \n",
       "103  Un drame semblable à la tuerie de Christchurch...  \n",
       "104  Pour le week-end de l'Ascension, Bison Futé pr...  \n",
       "105  MODE - Le fondateur de la marque 1017-Alyx-9SM...  \n",
       "106  « C’est dans des circonstances toutes particul...  \n",
       "107  L’homme est un habitué des missions difficiles...  \n",
       "108  Cinq Jordaniens sont jugés dans leur pays pour...  \n",
       "109  Le ministère de la Santé iranien a annoncé dim...  \n",
       "110  « Ce qui a gagné ce soir, me semble-t-il, c'es...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corrections\n",
    "francais.iloc[100:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/stg-sdu/Notebooks/NLP/SemEval-2022/Data/'\n",
    "eval_data_location = path + \"semeval-2022_task8_eval_data_202201.csv\"\n",
    "data_eval_location = pd.read_csv(eval_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_indexes = []\n",
    "liste_lignes= []\n",
    "for i in range(len(francais)):\n",
    "    b = False\n",
    "    if len(francais.title_1[i]) == 0:\n",
    "        print('index ',i,' titre 1 : ligne ',francais.ligne[i],data_eval_location.ia_link1[francais.ligne[i]])\n",
    "        b=True\n",
    "    if len(francais.text_1[i]) == 0:\n",
    "        print('index ',i,' texte 1 : ligne ',francais.ligne[i],data_eval_location.ia_link1[francais.ligne[i]])  \n",
    "        liste_indexes.append(i);liste_lignes.append(i)\n",
    "        b=True\n",
    "    if len(francais.title_2[i]) == 0:\n",
    "        print('index ',i,' titre 2 : ligne ',francais.ligne[i],data_eval_location.ia_link2[francais.ligne[i]])\n",
    "        b=True\n",
    "    if len(francais.text_2[i]) == 0:\n",
    "        print('index ',i,' texte 2 : ligne ',francais.ligne[i],data_eval_location.ia_link2[francais.ligne[i]])\n",
    "        b = True\n",
    "    if b == True:\n",
    "        liste_indexes.append(i);liste_lignes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('eval_data_prep_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout partie polonaise/french\n",
    "fr_pl = pd.read_csv('pol_french_traduit.csv')\n",
    "francais = pd.concat([francais,fr_pl],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>507</td>\n",
       "      <td>Est-il vraiment dangereux de réveiller un somn...</td>\n",
       "      <td>Municipales : les procurations faites pour le ...</td>\n",
       "      <td>On dit souvent que réveiller un somnambule est...</td>\n",
       "      <td>A cause de la crise sanitaire, le second tour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2514</td>\n",
       "      <td>[Coronavirus] Macron annonce un plan massif po...</td>\n",
       "      <td>Coronavirus - Macron annonce un plan massif d'...</td>\n",
       "      <td>Après sa visite de l'hôpital militaire de camp...</td>\n",
       "      <td>Le président Macron était sur le terrain ce me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2515</td>\n",
       "      <td>Apprentissage des valeurs du respect : BIC Mar...</td>\n",
       "      <td>BIC Maroc sensibilise les enfants à la valeur ...</td>\n",
       "      <td>«Au-delà de mettre en avant la valeur du respe...</td>\n",
       "      <td>Dans le cadre de ses initiatives éducatives, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2516</td>\n",
       "      <td>Municipales à Bobigny : la revanche des commun...</td>\n",
       "      <td>Municipales 2020. Avec l’élection d’Abdel Sadi...</td>\n",
       "      <td>Bobigny, dimanche soir. Abdel Sadi a été premi...</td>\n",
       "      <td>C’était une des pertes majeures du Parti commu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2517</td>\n",
       "      <td>Database of Press Releases related to Africa –...</td>\n",
       "      <td>Database of Press Releases related to Africa –...</td>\n",
       "      <td>Aperçu de la situation et besoins humanitaires...</td>\n",
       "      <td>Après deux mois consécutifs de travail sur le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4092</td>\n",
       "      <td>Deux membres du clan Kennedy portés disparus</td>\n",
       "      <td>Un autre cas de la \"malédiction Kennedy\". Le c...</td>\n",
       "      <td>Deux membres de la famille Kennedy, dont une p...</td>\n",
       "      <td>Le corps de Maeve McKean, la petite-fille de R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4093</td>\n",
       "      <td>César 2020: Florence Foresti, une maîtresse de...</td>\n",
       "      <td>Le monde des célébrités s'effondre. La controv...</td>\n",
       "      <td>« Je suis très heureuse d’être là. Enfin \"très...</td>\n",
       "      <td>Les Césars, le plus important prix du cinéma e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>4094</td>\n",
       "      <td>Coronavirus - Afrique : Une checklist pour les...</td>\n",
       "      <td>Messe traditionnelle dans le monde en 2019</td>\n",
       "      <td>Human Rights Watch surveille activement les di...</td>\n",
       "      <td>Comme l'année dernière, nous publions un bilan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4095</td>\n",
       "      <td>Coronavirus: les vétérinaires prêts à seconder...</td>\n",
       "      <td>Coronavirus. Un \"crash test\" pour l'Union euro...</td>\n",
       "      <td>Une seule santé : les vétérinaires de France o...</td>\n",
       "      <td>Bruxelles a dû taper du poing sur la table et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>4096</td>\n",
       "      <td>Ain Bloqué au Maroc dans son camping-car, un c...</td>\n",
       "      <td>\"Ce qui est bon pour le tourisme est souvent b...</td>\n",
       "      <td>Les appels se multiplient depuis plusieurs sem...</td>\n",
       "      <td>×\\n\\nAucune partie ainsi que l'ensemble des tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ligne                                            title_1  \\\n",
       "0      507  Est-il vraiment dangereux de réveiller un somn...   \n",
       "1     2514  [Coronavirus] Macron annonce un plan massif po...   \n",
       "2     2515  Apprentissage des valeurs du respect : BIC Mar...   \n",
       "3     2516  Municipales à Bobigny : la revanche des commun...   \n",
       "4     2517  Database of Press Releases related to Africa –...   \n",
       "..     ...                                                ...   \n",
       "117   4092       Deux membres du clan Kennedy portés disparus   \n",
       "118   4093  César 2020: Florence Foresti, une maîtresse de...   \n",
       "119   4094  Coronavirus - Afrique : Une checklist pour les...   \n",
       "120   4095  Coronavirus: les vétérinaires prêts à seconder...   \n",
       "121   4096  Ain Bloqué au Maroc dans son camping-car, un c...   \n",
       "\n",
       "                                               title_2  \\\n",
       "0    Municipales : les procurations faites pour le ...   \n",
       "1    Coronavirus - Macron annonce un plan massif d'...   \n",
       "2    BIC Maroc sensibilise les enfants à la valeur ...   \n",
       "3    Municipales 2020. Avec l’élection d’Abdel Sadi...   \n",
       "4    Database of Press Releases related to Africa –...   \n",
       "..                                                 ...   \n",
       "117  Un autre cas de la \"malédiction Kennedy\". Le c...   \n",
       "118  Le monde des célébrités s'effondre. La controv...   \n",
       "119         Messe traditionnelle dans le monde en 2019   \n",
       "120  Coronavirus. Un \"crash test\" pour l'Union euro...   \n",
       "121  \"Ce qui est bon pour le tourisme est souvent b...   \n",
       "\n",
       "                                                text_1  \\\n",
       "0    On dit souvent que réveiller un somnambule est...   \n",
       "1    Après sa visite de l'hôpital militaire de camp...   \n",
       "2    «Au-delà de mettre en avant la valeur du respe...   \n",
       "3    Bobigny, dimanche soir. Abdel Sadi a été premi...   \n",
       "4    Aperçu de la situation et besoins humanitaires...   \n",
       "..                                                 ...   \n",
       "117  Deux membres de la famille Kennedy, dont une p...   \n",
       "118  « Je suis très heureuse d’être là. Enfin \"très...   \n",
       "119  Human Rights Watch surveille activement les di...   \n",
       "120  Une seule santé : les vétérinaires de France o...   \n",
       "121  Les appels se multiplient depuis plusieurs sem...   \n",
       "\n",
       "                                                text_2  \n",
       "0    A cause de la crise sanitaire, le second tour ...  \n",
       "1    Le président Macron était sur le terrain ce me...  \n",
       "2    Dans le cadre de ses initiatives éducatives, B...  \n",
       "3    C’était une des pertes majeures du Parti commu...  \n",
       "4    Après deux mois consécutifs de travail sur le ...  \n",
       "..                                                 ...  \n",
       "117  Le corps de Maeve McKean, la petite-fille de R...  \n",
       "118  Les Césars, le plus important prix du cinéma e...  \n",
       "119  Comme l'année dernière, nous publions un bilan...  \n",
       "120  Bruxelles a dû taper du poing sur la table et ...  \n",
       "121  ×\\n\\nAucune partie ainsi que l'ensemble des tr...  \n",
       "\n",
       "[122 rows x 5 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "francais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de calcul du score (produit scalaire) pour résultats de classifaction\n",
    "def fonction_produit_dotcom(liste_categor, dico_scores1,dico_scores2):\n",
    "    \"\"\"\"dico scores sont les résultats obtenus pour chaque catégorie des textes 1 et 2\"\"\"\n",
    "    result = 0.0\n",
    "    for cat in liste_categor:\n",
    "        result += round(dico_scores1[cat] * dico_scores2[cat],4)\n",
    "    return result * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type1\n",
    "def transform_text_clf1(liste_dico):\n",
    "    res = {}\n",
    "    for dic in liste_dico:\n",
    "        res[dic['label']] = dic['score']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des résultats du transformer type2\n",
    "def transform_text_clf2(liste_cat,liste_sc):\n",
    "    res = {}\n",
    "    for i in range(len(liste_cat)):\n",
    "        res[liste_cat[i]] = liste_sc[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "liste_categories = ['Culture', 'Politique', 'Economie','Education','Technologie','Justice','Sport', 'Environement', 'Societe', 'Opinion']\n",
    "liste_labels = ['Negative','Positive']\n",
    "liste_sentiments = ['MIXED','NEGATIVE','POSITIVE','OBJECTIVE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de summarization \n",
    "def summarization(texte):\n",
    "    return summarizer1(texte)[0]['summary_text'], summarizer2(texte)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_classifiers = {'text_clf1': 'score_classif1','text_clf2':'score_classif2','sentiment1':'score_sentiment1',\n",
    "                    'sentiment2': 'score_sentiment2'}\n",
    "dico_categories = {'text_clf1': liste_categories,'text_clf2':candidate_labels,'sentiment1':liste_labels,\n",
    "                    'sentiment2': liste_sentiments}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de classification et sentiment analysis\n",
    "def classification(texte,clf):\n",
    "    # assume nms des classifiers et methode de transformation\n",
    "    if clf == \"text_clf1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(text_clf1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"text_clf2\":                                 \n",
    "        try:\n",
    "            classes = text_clf2(texte,dico_categories['text_clf2'])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return transform_text_clf2(classes['labels'],classes['scores'])                          \n",
    "    elif clf == \"sentiment1\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment1(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    elif clf == \"sentiment2\":\n",
    "        try:\n",
    "            scores = transform_text_clf1(sentiment2(texte,return_all_scores=True)[0])\n",
    "        except:\n",
    "            return 'error'\n",
    "        else:\n",
    "            return scores\n",
    "    else:\n",
    "        return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des mots de moins de 2 lettres non numériques\n",
    "def supp_moins_2_lettres_stopwords(phrase,stopwd):\n",
    "    temp = phrase.split(' ')\n",
    "    res = ''\n",
    "    for mot in temp:\n",
    "        if mot not in stopwd and (len(mot)>2 or (len(mot)>0 and mot[0] in ['0','1','2','3','4','5','6','7','8','9'])):\n",
    "            res += mot + ' '\n",
    "    return res[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement NLP pour PKE : suppression des traits d'union(regroupe)/ des apostrophes / ponctuations\n",
    "def modif(texte,stopmots):\n",
    "    # modifications simples des textes : ponctuations, petits mots, stopwords (à faire pour entités et pke textes)\n",
    "    texte=re.sub('\\'',' ',texte)   # suppression apostrophe\n",
    "    texte=re.sub('-','',texte)    # suppression trait union\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation)) # suppression de toutes les ponctuations\n",
    "    texte=regex.sub(' ',texte)\n",
    "    texte = supp_moins_2_lettres_stopwords(texte,stopmots)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des synonymes (existants en orthographe) à la suite de l'analyse pke\n",
    "def ajout_synonymes(mot, correct_ortho = True):\n",
    "    # on ajoute les 10 premiers synonymes existants, on vérifie orthographe (optionnel)\n",
    "    syns = model_gensim.most_similar(mot,topn = 20)\n",
    "    if correct_ortho == True:\n",
    "        res = []\n",
    "        for m in syns:\n",
    "            if d.check(m[0]):   #  il y a le mot et son pourcentage d'importance\n",
    "                res.append(m)\n",
    "        syns = res\n",
    "    return syns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres de la méthode : A revoir ?\n",
    "methode1 = {\"NOUN\", \"PROPN\", \"ADJ\",\"VERB\"}\n",
    "methode2 = {\"NOUN\", \"PROPN\", \"ADJ\"}\n",
    "nb_mots = {'meth1': 30, 'meth2':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKE : Analyse des termes principaux dans les textes et titres \n",
    "# Problème \n",
    "def transformation_pke_results(res1,res2, correct_ortho = True):\n",
    "    \"\"\"\n",
    "    Transformation des resultats de PKE : Pb bigramme peuvent ne pas être ds les 2 textes mais 1 mot seulement\n",
    "    liste de clés et dictionnaires de valeurs, bigrammes jouera ainsi de maniere coefficientée \n",
    "    Exemple : fuite eau:0.05 --> 3 mots au final : fuite, eau, fuite eau : 0.05\n",
    "    De plus on ajoute les synonymes issus de gensim en les coefficiant et vérifiant que cela \"\"\"\n",
    "    \n",
    "    liste1 = []; liste2 = [] ; dico1 = {}; dico2 = {}\n",
    "    for elt in res1:\n",
    "        liste1.append(elt[0])\n",
    "        dico1[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:    # bigramme dans ce cas, ajout des 2 mots\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste1.append(mot)\n",
    "                dico1[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste1.append(syn[0])   # Ajout du mot \n",
    "                        dico1[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "                    \n",
    "    for elt in res2:\n",
    "        liste2.append(elt[0])\n",
    "        dico2[elt[0]] = round(elt[1],3)\n",
    "        if ' ' in elt[0]:\n",
    "            liste = elt[0].split(' ')\n",
    "            for mot in liste:\n",
    "                liste2.append(mot)\n",
    "                dico2[mot] = round(elt[1],3)\n",
    "                try:\n",
    "                    synonyms = ajout_synonymes(mot,correct_ortho = correct_ortho)\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for syn in synonyms:\n",
    "                        liste2.append(syn[0])   # Ajout du mot \n",
    "                        dico2[syn[0]] = round(elt[1] * syn[1], 3)  # poids considéré\n",
    "    \n",
    "    # similarites entre les 2 listes issus de pke avec poids\n",
    "    sim = 0\n",
    "    for elt in liste1:\n",
    "        if elt in liste2:\n",
    "            sim += (dico1[elt] + dico2[elt])/2\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entites_communes(nlp,text1,text2):\n",
    "    \"\"\"\"\n",
    "    Cette première fonction ne regarde que les entités communes : personnes, dates, groupe, localisations\n",
    "    Elle sera appliquée aux textes et aux titres et cumulé : si cumul en titre et texte : compte double !\"\"\"\n",
    "    \n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    nb_commun_ent = 0; liste_commun_ent = []\n",
    "    nb_commun_geo = 0; liste_commun_geo = []\n",
    "    nb_commun_dat = 0; liste_commun_dat = []\n",
    "    \n",
    "    if len(doc1.ents)>0 and len(doc2.ents)>0:\n",
    "        liste1 = []; dico1 = {}\n",
    "        for elt in doc1.ents:\n",
    "            if elt.label_ in ['PERSON','PER'] and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste1:\n",
    "                        liste1.append(mot)\n",
    "                        dico1[mot] = elt.label_\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste1:\n",
    "                    liste1.append(elt.text)\n",
    "                    dico1[elt.text] = elt.label_\n",
    "        liste2 = []\n",
    "        for elt in doc2.ents:\n",
    "            if elt.label_ in ['PERSON','PER'] and ' ' in elt.text:\n",
    "                mots = elt.text.split(' ')\n",
    "                for mot in mots:\n",
    "                    if mot not in liste2:\n",
    "                        liste2.append(mot)\n",
    "            elif elt.label_ in ['LOC','ORG','GPE','DATE','TIME']:\n",
    "                if elt.text not in liste2:\n",
    "                    liste2.append(elt.text)\n",
    "        \n",
    "        # points communs des listes        \n",
    "        for elt in liste1:\n",
    "            if elt in liste2:\n",
    "                if dico1[elt] == 'LOC':\n",
    "                    nb_commun_geo += 1\n",
    "                    liste_commun_geo.append(elt)\n",
    "                elif dico1[elt] in ['DATE','TIME']:\n",
    "                    nb_commun_dat += 1\n",
    "                    liste_commun_dat.append(elt)\n",
    "                else:\n",
    "                    nb_commun_ent += 1\n",
    "                    liste_commun_ent.append(elt)\n",
    "                    \n",
    "    return nb_commun_ent, liste_commun_ent,nb_commun_geo, liste_commun_geo,nb_commun_dat, liste_commun_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entites_communes_ner(nlp,text1,text2):\n",
    "    \"\"\"\"\n",
    "    Cette première fonction ne regarde que les entités communes : personnes, dates, groupe, localisations\n",
    "    Elle sera appliquée aux textes et aux titres et cumulé : si cumul en titre et texte : compte double !\"\"\"\n",
    "    \n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    nb_commun_ent = 0; liste_commun_ent = []\n",
    "    nb_commun_geo = 0; liste_commun_geo = []\n",
    "    nb_commun_dat = 0; liste_commun_dat = []\n",
    "    if len(doc1)>0 and len(doc2)>0:\n",
    "        liste1 = []; dico1 = {}\n",
    "        for elt in doc1:\n",
    "            if '-' in elt['entity_group'] and elt['entity_group'].split('-')[1] in ['PERSON','PER','LOC','ORG','GPE','NORP','DATE','TIME']:\n",
    "                liste1.append(elt['word'])\n",
    "                dico1[elt['word']] = elt['entity_group'].split('-')[1]\n",
    "            elif elt['entity_group'] in ['PERSON','PER','LOC','ORG','GPE','NORP','DATE','TIME']:\n",
    "                liste1.append(elt['word'])\n",
    "                dico1[elt['word']] = elt['entity_group']  \n",
    "        liste2 = []\n",
    "        for elt in doc2:\n",
    "            if '-' in elt['entity_group'] and elt['entity_group'].split('-')[1] in ['PERSON','PER','LOC','ORG','GPE','NORP','DATE','TIME']:\n",
    "                liste2.append(elt['word'])\n",
    "            elif elt['entity_group'] in ['LOC','ORG','GPE','NORP','DATE','TIME']:\n",
    "                liste2.append(elt['word'])\n",
    "        \n",
    "        # points communs des listes    \n",
    "        for elt in liste1:\n",
    "            if elt in liste2:\n",
    "                if dico1[elt] == 'LOC':\n",
    "                    nb_commun_geo += 1\n",
    "                    liste_commun_geo.append(elt)\n",
    "                elif dico1[elt] in ['DATE','TIME']:\n",
    "                    nb_commun_dat += 1\n",
    "                    liste_commun_dat.append(elt)\n",
    "                else:\n",
    "                    nb_commun_ent += 1\n",
    "                    liste_commun_ent.append(elt)\n",
    "                    \n",
    "    return nb_commun_ent, liste_commun_ent,nb_commun_geo, liste_commun_geo,nb_commun_dat, liste_commun_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Creation_features_comparaison(df,langue, test_position = [methode1,methode2]):\n",
    "    \"\"\"Création des notes pour classification ensuite\"\"\"\n",
    "    \n",
    "    resultats = pd.DataFrame(columns = ['summary1_text1','summary2_text1','summary1_text2','summary2_text2',\n",
    "            'nb_entites_idem','nb_lieux_idem', 'nb_dates_idem','entites_idem','lieux_idem','dates_idem',\n",
    "            'score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "            'score_sentiment1','score_sentiment2','meth1_similarites','meth2_similarites'])\n",
    "    \n",
    "    # initialisation\n",
    "    stopmts = stopwds_lg[langue]\n",
    "    if langue in dico_spacy.keys():\n",
    "        nlp_spacy = dico_spacy[langue]\n",
    "    else:\n",
    "        nlp_spacy = None\n",
    "        \n",
    "    for i in tqdm(range(len(df))):\n",
    "        dico_res = {}\n",
    "        \n",
    "        # Summary et comparatifs \n",
    "        dico_res['summary1_text1'],dico_res['summary2_text1'] = summarization(df.text_1[i])\n",
    "        dico_res['summary1_text2'],dico_res['summary2_text2'] = summarization(df.text_2[i])\n",
    "        dico_res['score_similarite_titres'] = score_similarite(df.title_1[i],df.title_2[i])\n",
    "        dico_res['score_similarite_resume1'] = score_similarite(dico_res['summary1_text1'],dico_res['summary1_text2'])\n",
    "        dico_res['score_similarite_resume2'] = score_similarite(dico_res['summary2_text1'],dico_res['summary2_text2'])\n",
    "        \n",
    "        # analyse de textes classification et de sentiments\n",
    "        texte1 = df.title_1[i] + ' ' + df.text_1[i]\n",
    "        texte2 = df.title_2[i] + ' ' + df.text_2[i]\n",
    "        if len(texte1)>0 and len(texte2)>0:\n",
    "            for classifier in dico_classifiers.keys():\n",
    "                scores1 = classification(texte1,classifier)\n",
    "                scores2 = classification(texte2,classifier)\n",
    "                if scores1 != 'error' and scores2 != 'error':\n",
    "                    dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                else:\n",
    "                    scores1 = classification(df.title_1[i],classifier)\n",
    "                    scores2 = classification(df.title_2[i],classifier)\n",
    "                    if scores1 != 'error' and scores2 != 'error':\n",
    "                        dico_res[dico_classifiers[classifier]] = fonction_produit_dotcom(dico_categories[classifier], scores1,scores2)\n",
    "                    else:\n",
    "                        dico_res[dico_classifiers[classifier]] = None\n",
    "                \n",
    "        # pré traitement des textes pour entités et PKE\n",
    "        texte1 = modif(texte1, stopmts)\n",
    "        texte2 = modif(texte2, stopmts)\n",
    "        \n",
    "        # ENTITES COMMUNES : on tient compte des bigrammes Noms qui posent erreurs ex: Joe Biden et Biden \n",
    "        # Ici, on considère mieux le CUMUl titres et Textes avec une pondération double pour le titre \n",
    "        # Il faut aussi enlever les petits mots donc pré-traitement en texte\n",
    "        \n",
    "        nb_ent1,list_ent1,nb_geo1,list_geo1,nb_dat1,list_dat1 = entites_communes_ner(ner,df.title_1[i],df.title_2[i])\n",
    "        nb_ent2,list_ent2,nb_geo2,list_geo2,nb_dat2,list_dat2 = entites_communes_ner(ner,df.text_1[i],df.text_2[i])\n",
    "        if nlp_spacy != None:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = entites_communes(nlp_spacy,df.title_1[i],df.title_2[i])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = entites_communes(nlp_spacy,df.text_1[i],df.text_2[i])\n",
    "        else:\n",
    "            nb_ent3,list_ent3,nb_geo3,list_geo3,nb_dat3,list_dat3 = (0,[],0,[],0,[])\n",
    "            nb_ent4,list_ent4,nb_geo4,list_geo4,nb_dat4,list_dat4 = (0,[],0,[],0,[])\n",
    "        dico_res['nb_entites_idem'] = nb_ent1 * 2 + nb_ent2 + nb_ent3 * 2 + nb_ent4\n",
    "        dico_res['nb_lieux_idem'] = nb_geo1  * 2 + nb_geo2 + nb_geo3  * 2 + nb_geo4\n",
    "        dico_res['nb_dates_idem'] = nb_dat1 * 2 + nb_dat2 + nb_dat3 * 2 + nb_dat4\n",
    "        # fusion des listes en supprimant les doublons\n",
    "        dico_res['entites_idem'] = list(set(list_ent1+list_ent2+ list_ent3+list_ent4))\n",
    "        dico_res['lieux_idem'] = list(set(list_geo1+list_geo2+list_geo3+list_geo4))\n",
    "        dico_res['dates_idem'] = list(set(list_dat1+list_dat2+list_dat3+list_dat4))\n",
    "        \n",
    "        for j,meth in enumerate(test_position):\n",
    "            nom ='meth'+str(j+1)\n",
    "            nb_mots_meth = nb_mots[nom]\n",
    "            if len(texte1)>0 and len(texte2)>0:\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte1,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases3 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                extractor = pke.unsupervised.TopicRank()\n",
    "                extractor.load_document(input=texte2,language=langue,normalization=\"stemming\")\n",
    "                extractor.candidate_selection(pos=meth)\n",
    "                extractor.candidate_weighting()\n",
    "                keyphrases4 = extractor.get_n_best(n=nb_mots_meth)\n",
    "                dico_res[nom+'_similarites'] = round(100*transformation_pke_results(keyphrases3,keyphrases4),1)\n",
    "            else:\n",
    "                dico_res[nom+'_similarites'] = 'Error'\n",
    "        \n",
    "        resultats.loc[len(resultats)] = dico_res\n",
    "        \n",
    "    newdf = pd.concat([df,resultats],axis=1)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f32439c8ab4f3495401efb2bc46788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 100, but you input_length is only 24. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 30. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 164. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 157. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 191. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 197. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 169. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 20. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 147. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 150. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 163. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 140. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 23. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 29. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 20. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 23. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 23. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 24. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 193. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 150. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 141. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 62. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 71. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 59. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 72. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 97. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 100, but you input_length is only 84. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 102. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 148. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "# Attention probleme au 16e index non identifié ...\n",
    "similarites = Creation_features_comparaison(francais,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarites.to_csv('eval_fr_notes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\stg-sdu\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "francais = pd.read_csv('corpus_fr_notes_v2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligne</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3462</td>\n",
       "      <td>Agriculteurs et chasseurs, victimes de la prol...</td>\n",
       "      <td>Ce qu'il faut savoir pour déterminer si une re...</td>\n",
       "      <td>Aidées par le réchauffement climatique et le c...</td>\n",
       "      <td>Sites de prépublications, revues prestigieuses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3463</td>\n",
       "      <td>Maroc : combien gagnent les walis et gouverneu...</td>\n",
       "      <td>Maroc : voici le mode d’emploi du deuxième moi...</td>\n",
       "      <td>En plus de leurs salaires nets, calculés sur l...</td>\n",
       "      <td>Après la première étape de l’état d’urgence, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3464</td>\n",
       "      <td>Décès des petites Lila et Adélaïde : l’auteur ...</td>\n",
       "      <td>Drame de Festieux : Vincent Montré remis en li...</td>\n",
       "      <td>Le 3 avril 2018, Lila, 3 ans et demi, et Adéla...</td>\n",
       "      <td>Le chef d'entreprise de 48 ans (à droite) aura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3465</td>\n",
       "      <td>Coronavirus : Brussels Airlines va sabrer dans...</td>\n",
       "      <td>Brussels Airlines supprime 8 destinations jusq...</td>\n",
       "      <td>Brussels Airlines ne rependra pas ses vols, ap...</td>\n",
       "      <td>En raison de la pandémie de coronavirus, le se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3466</td>\n",
       "      <td>Virus de la tomate : contamination confirmée d...</td>\n",
       "      <td>Ce qu'il faut savoir sur le virus qui inquiète...</td>\n",
       "      <td>Le ministère de l'Agriculture a confirmé lundi...</td>\n",
       "      <td>Depuis une dizaine de jours, un virus extrêmem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3467</td>\n",
       "      <td>Le mirage de l'union nationale</td>\n",
       "      <td>Coronavirus: ces magasins et services qui ont ...</td>\n",
       "      <td>Crédit Image : GONZALO FUENTES / POOL / AFP | ...</td>\n",
       "      <td>Dans l'attente de l'allocution du Président de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3468</td>\n",
       "      <td>Sécurité routière 3 239 morts sur les routes e...</td>\n",
       "      <td>Sécurité routière: le gouvernement vante les 8...</td>\n",
       "      <td>Le nombre de morts sur les routes de France mé...</td>\n",
       "      <td>Le nombre de morts sur les routes a atteint en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4869</td>\n",
       "      <td>Justice Pédophilie : un pilote de ligne frança...</td>\n",
       "      <td>Pédopornographie : cinq ans de prison pour le ...</td>\n",
       "      <td>Un pilote de ligne français de 50 ans, soupçon...</td>\n",
       "      <td>Le pilote de ligne, jugé pour avoir commandé d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4870</td>\n",
       "      <td>Institut Pasteur de Dakar : Les tests de diagn...</td>\n",
       "      <td>Sénégal: Plusieurs cas de contaminations et 01...</td>\n",
       "      <td>On en sait un peu sur le coût des tests de dia...</td>\n",
       "      <td>Après les hôpitaux, le nouveau coronavirus s'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4871</td>\n",
       "      <td>Val-d’Oise. Pontoise : « Non, le chantier du f...</td>\n",
       "      <td>Val-d’Oise. Sécurité de l’hôpital de Pontoise ...</td>\n",
       "      <td>À Pontoise (Val-d’Oise), depuis la parution de...</td>\n",
       "      <td>Le 21 décembre 2017, la commission de sécurité...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4872</td>\n",
       "      <td>Les Français sont-ils sales? Seuls 3 Français ...</td>\n",
       "      <td>Municipales : vers une abstention record ?</td>\n",
       "      <td>\"On leur a dit bonjour donc on stresse\": des j...</td>\n",
       "      <td>l'essentiel Un sondage Ifop pour le site Direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4873</td>\n",
       "      <td>Un lieu de confinement sécurisé pour SDF malad...</td>\n",
       "      <td>Nancy : dispositif de prise en charge des SDF</td>\n",
       "      <td>Des mesures exceptionnelles\\n\\nEn Meurthe-et-M...</td>\n",
       "      <td>Le Gouvernement a prolongé de deux mois le dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4874</td>\n",
       "      <td>Le GNA annonce la reprise de deux villes dans ...</td>\n",
       "      <td>L’armée de Haftar annonce s’éloigner de Tripol...</td>\n",
       "      <td>Pour améliorer le fonctionnement de notre site...</td>\n",
       "      <td>Les forces du maréchal Haftar sont sur le poin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4875</td>\n",
       "      <td>Vol de données d’enseignants : Québec se dit «...</td>\n",
       "      <td>Le retour en classes se fera le 11 mai</td>\n",
       "      <td>Lors d’une mêlée de presse lundi, Éric Caire (...</td>\n",
       "      <td>Le retour en classes et des services de garde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4876</td>\n",
       "      <td>Coronavirus Algérie : La barre des 6000 cas co...</td>\n",
       "      <td>Coronavirus Algérie : Le bilan s’approche de l...</td>\n",
       "      <td>Le bilan quotidien des nouveaux cas de Covid-1...</td>\n",
       "      <td>Le bilan du Covid-19 a encore augmenter en Alg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4877</td>\n",
       "      <td>Covid-19 : Guérisons en hausse et pas de décès...</td>\n",
       "      <td>Covid-19 en Tunisie : Contaminations et décès ...</td>\n",
       "      <td>Le ministère de la Santé a annoncé, ce vendred...</td>\n",
       "      <td>Le ministère de la Santé a annoncé, ce mercred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4878</td>\n",
       "      <td>«La France est l’un des principaux partenaires...</td>\n",
       "      <td>Poutine souhaite un «respect mutuel» comme bas...</td>\n",
       "      <td>Recevant les lettres de créance de plusieurs a...</td>\n",
       "      <td>La Russie est «ouverte à une coopération avec ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4879</td>\n",
       "      <td>Maroc : la location aux touristes interdite</td>\n",
       "      <td>Maroc : la justice ouvre une enquête pour viol...</td>\n",
       "      <td>Les forces de l’ordre effectuent des inspectio...</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4880</td>\n",
       "      <td>Loi sur la relance : l'opposition « à plus de ...</td>\n",
       "      <td>10Â 000 prÃ©posÃ©s aux bÃ©nÃ©ficiaires recherc...</td>\n",
       "      <td>Deux journées de commission parlementaire n'au...</td>\n",
       "      <td>CORONAVIRUS. QuÃ©bec veut lancer une opÃ©ratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4881</td>\n",
       "      <td>Média sud-coréen : “Avec le rôle de président ...</td>\n",
       "      <td>Le 36e Sommet de l’ASEAN couronné de succès</td>\n",
       "      <td>En 2020, le Vietnam assume un double rôle de p...</td>\n",
       "      <td>Le chef du gouvernement vietnamien, qui est ég...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4882</td>\n",
       "      <td>Adieu à Muriel Roy</td>\n",
       "      <td>«Les pouvoirs extraordinaire du corps humain»:...</td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>Comment avez-vous vécu le confinement?\\n\\nAu d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4883</td>\n",
       "      <td>Congo : des experts africains formés à Brazzav...</td>\n",
       "      <td>«EN AFRIQUE, L’EVOLUTION DE LA PANDEMIE EST TR...</td>\n",
       "      <td>Congo : des experts africains formés à Brazzav...</td>\n",
       "      <td>Alors que le directeur de l’Organisation mondi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ligne                                            title_1  \\\n",
       "50   3462  Agriculteurs et chasseurs, victimes de la prol...   \n",
       "51   3463  Maroc : combien gagnent les walis et gouverneu...   \n",
       "52   3464  Décès des petites Lila et Adélaïde : l’auteur ...   \n",
       "53   3465  Coronavirus : Brussels Airlines va sabrer dans...   \n",
       "54   3466  Virus de la tomate : contamination confirmée d...   \n",
       "55   3467                     Le mirage de l'union nationale   \n",
       "56   3468  Sécurité routière 3 239 morts sur les routes e...   \n",
       "57   4869  Justice Pédophilie : un pilote de ligne frança...   \n",
       "58   4870  Institut Pasteur de Dakar : Les tests de diagn...   \n",
       "59   4871  Val-d’Oise. Pontoise : « Non, le chantier du f...   \n",
       "60   4872  Les Français sont-ils sales? Seuls 3 Français ...   \n",
       "61   4873  Un lieu de confinement sécurisé pour SDF malad...   \n",
       "62   4874  Le GNA annonce la reprise de deux villes dans ...   \n",
       "63   4875  Vol de données d’enseignants : Québec se dit «...   \n",
       "64   4876  Coronavirus Algérie : La barre des 6000 cas co...   \n",
       "65   4877  Covid-19 : Guérisons en hausse et pas de décès...   \n",
       "66   4878  «La France est l’un des principaux partenaires...   \n",
       "67   4879        Maroc : la location aux touristes interdite   \n",
       "68   4880  Loi sur la relance : l'opposition « à plus de ...   \n",
       "69   4881  Média sud-coréen : “Avec le rôle de président ...   \n",
       "70   4882                                 Adieu à Muriel Roy   \n",
       "71   4883  Congo : des experts africains formés à Brazzav...   \n",
       "\n",
       "                                              title_2  \\\n",
       "50  Ce qu'il faut savoir pour déterminer si une re...   \n",
       "51  Maroc : voici le mode d’emploi du deuxième moi...   \n",
       "52  Drame de Festieux : Vincent Montré remis en li...   \n",
       "53  Brussels Airlines supprime 8 destinations jusq...   \n",
       "54  Ce qu'il faut savoir sur le virus qui inquiète...   \n",
       "55  Coronavirus: ces magasins et services qui ont ...   \n",
       "56  Sécurité routière: le gouvernement vante les 8...   \n",
       "57  Pédopornographie : cinq ans de prison pour le ...   \n",
       "58  Sénégal: Plusieurs cas de contaminations et 01...   \n",
       "59  Val-d’Oise. Sécurité de l’hôpital de Pontoise ...   \n",
       "60         Municipales : vers une abstention record ?   \n",
       "61      Nancy : dispositif de prise en charge des SDF   \n",
       "62  L’armée de Haftar annonce s’éloigner de Tripol...   \n",
       "63             Le retour en classes se fera le 11 mai   \n",
       "64  Coronavirus Algérie : Le bilan s’approche de l...   \n",
       "65  Covid-19 en Tunisie : Contaminations et décès ...   \n",
       "66  Poutine souhaite un «respect mutuel» comme bas...   \n",
       "67  Maroc : la justice ouvre une enquête pour viol...   \n",
       "68  10Â 000 prÃ©posÃ©s aux bÃ©nÃ©ficiaires recherc...   \n",
       "69        Le 36e Sommet de l’ASEAN couronné de succès   \n",
       "70  «Les pouvoirs extraordinaire du corps humain»:...   \n",
       "71  «EN AFRIQUE, L’EVOLUTION DE LA PANDEMIE EST TR...   \n",
       "\n",
       "                                               text_1  \\\n",
       "50  Aidées par le réchauffement climatique et le c...   \n",
       "51  En plus de leurs salaires nets, calculés sur l...   \n",
       "52  Le 3 avril 2018, Lila, 3 ans et demi, et Adéla...   \n",
       "53  Brussels Airlines ne rependra pas ses vols, ap...   \n",
       "54  Le ministère de l'Agriculture a confirmé lundi...   \n",
       "55  Crédit Image : GONZALO FUENTES / POOL / AFP | ...   \n",
       "56  Le nombre de morts sur les routes de France mé...   \n",
       "57  Un pilote de ligne français de 50 ans, soupçon...   \n",
       "58  On en sait un peu sur le coût des tests de dia...   \n",
       "59  À Pontoise (Val-d’Oise), depuis la parution de...   \n",
       "60  \"On leur a dit bonjour donc on stresse\": des j...   \n",
       "61  Des mesures exceptionnelles\\n\\nEn Meurthe-et-M...   \n",
       "62  Pour améliorer le fonctionnement de notre site...   \n",
       "63  Lors d’une mêlée de presse lundi, Éric Caire (...   \n",
       "64  Le bilan quotidien des nouveaux cas de Covid-1...   \n",
       "65  Le ministère de la Santé a annoncé, ce vendred...   \n",
       "66  Recevant les lettres de créance de plusieurs a...   \n",
       "67  Les forces de l’ordre effectuent des inspectio...   \n",
       "68  Deux journées de commission parlementaire n'au...   \n",
       "69  En 2020, le Vietnam assume un double rôle de p...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71  Congo : des experts africains formés à Brazzav...   \n",
       "\n",
       "                                               text_2  \n",
       "50  Sites de prépublications, revues prestigieuses...  \n",
       "51  Après la première étape de l’état d’urgence, l...  \n",
       "52  Le chef d'entreprise de 48 ans (à droite) aura...  \n",
       "53  En raison de la pandémie de coronavirus, le se...  \n",
       "54  Depuis une dizaine de jours, un virus extrêmem...  \n",
       "55  Dans l'attente de l'allocution du Président de...  \n",
       "56  Le nombre de morts sur les routes a atteint en...  \n",
       "57  Le pilote de ligne, jugé pour avoir commandé d...  \n",
       "58  Après les hôpitaux, le nouveau coronavirus s'e...  \n",
       "59  Le 21 décembre 2017, la commission de sécurité...  \n",
       "60  l'essentiel Un sondage Ifop pour le site Direc...  \n",
       "61  Le Gouvernement a prolongé de deux mois le dis...  \n",
       "62  Les forces du maréchal Haftar sont sur le poin...  \n",
       "63  Le retour en classes et des services de garde ...  \n",
       "64  Le bilan du Covid-19 a encore augmenter en Alg...  \n",
       "65  Le ministère de la Santé a annoncé, ce mercred...  \n",
       "66  La Russie est «ouverte à une coopération avec ...  \n",
       "67  Suite aux violations du confinement dans les v...  \n",
       "68  CORONAVIRUS. QuÃ©bec veut lancer une opÃ©ratio...  \n",
       "69  Le chef du gouvernement vietnamien, qui est ég...  \n",
       "70  Comment avez-vous vécu le confinement?\\n\\nAu d...  \n",
       "71  Alors que le directeur de l’Organisation mondi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "francais.loc[50:,['ligne', 'title_1', 'title_2', 'text_1', 'text_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention certains textes ne sont pas fournies et donc mis en \"Error\" : A supprimer donc\n",
    "# On pourrait éventuellement tester en ne prenant plus les meth similarités ds les predicteurs\n",
    "francais = francais[francais.meth1_similarites!='Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ligne', 'title_1', 'title_2', 'text_1', 'text_2', 'Geography',\n",
       "       'Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone',\n",
       "       'summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2',\n",
       "       'nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem',\n",
       "       'lieux_idem', 'dates_idem', 'score_similarite_titres',\n",
       "       'score_similarite_resume1', 'score_similarite_resume2',\n",
       "       'score_classif1', 'score_classif2', 'score_sentiment1',\n",
       "       'score_sentiment2', 'meth1_similarites', 'meth2_similarites'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "francais.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "francais=francais.loc[:,['ligne', 'title_1', 'title_2', 'text_1', 'text_2','Overall',\n",
    "       'summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2',\n",
    "       'nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem',\n",
    "       'lieux_idem', 'dates_idem', 'score_similarite_titres',\n",
    "       'score_similarite_resume1', 'score_similarite_resume2',\n",
    "       'score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "       'score_sentiment2', 'meth1_similarites', 'meth2_similarites']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "francais['Overall2'] = francais.Overall\n",
    "francais = francais.round({'Geography':0, 'Entities':0,'Time':0, 'Narrative':0, 'Overall':0, 'Style':0, 'Tone':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "partiel = francais[['Overall']].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "francais = pd.concat([francais[['ligne', 'title_1', 'title_2', 'text_1', 'text_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2']],\n",
    "        partiel,francais[['Overall2','nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "       'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "       'score_sentiment2', 'meth1_similarites', 'meth2_similarites']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    19\n",
       "3    18\n",
       "2    18\n",
       "1    14\n",
       "Name: Overall, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#équilibré\n",
    "francais.Overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "francais.to_csv('dataset_french.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteurs = ['nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1',\n",
    "    'score_similarite_resume2', 'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites',\n",
    "    'meth2_similarites']\n",
    "# 2e test sans les predicteurs entites et méthodes similarités\n",
    "# predicteurs1 = ['score_similarite_titres','score_similarite_resume1','score_similarite_resume2','score_classif1','score_classif2',\n",
    "#            'score_sentiment1','score_sentiment2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "french_classif = setup(data = francais[predicteurs + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.6033</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>0.3890</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.3314</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>0.2261</td>\n",
       "      <td>0.2631</td>\n",
       "      <td>0.2792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.7500  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "1       0.4000  0.0000  0.2500  0.2667  0.3200  0.1667  0.2004\n",
       "2       0.8000  0.0000  0.6667  0.6667  0.7200  0.6667  0.7217\n",
       "3       0.2000  0.7500  0.2500  0.2000  0.2000  0.0000  0.0000\n",
       "4       0.4000  0.8167  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "5       0.2000  0.4833  0.2500  0.1000  0.1333 -0.0526 -0.0589\n",
       "6       0.6000  0.9000  0.6250  0.7000  0.6000  0.4737  0.5000\n",
       "7       0.8000  1.0000  0.8750  0.9000  0.8000  0.7368  0.7778\n",
       "8       0.5000  0.7500  0.5000  0.3750  0.4167  0.3333  0.3651\n",
       "9       0.2500  0.5833  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "Mean    0.4550  0.6033  0.4542  0.3767  0.3890  0.2741  0.3050\n",
       "SD      0.2103  0.3314  0.2070  0.2649  0.2261  0.2631  0.2792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.4075</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.2728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1844</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.2411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.8333  0.3750  0.3000  0.3333  0.1667  0.1768\n",
       "1       0.8000  0.0000  0.8333  0.9000  0.8000  0.7059  0.7500\n",
       "2       0.6000  0.0000  0.5000  0.6000  0.6000  0.3750  0.3750\n",
       "3       0.6000  0.7833  0.6250  0.7000  0.6000  0.4737  0.5000\n",
       "4       0.6000  0.7833  0.6250  0.7000  0.6000  0.4737  0.5000\n",
       "5       0.2000  0.7417  0.2500  0.1000  0.1333  0.0000  0.0000\n",
       "6       0.4000  0.8167  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "7       0.4000  0.8167  0.5000  0.3000  0.3333  0.2105  0.2222\n",
       "8       0.2500  0.6250  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "9       0.2500  0.7500  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "Mean    0.4500  0.6150  0.4583  0.4075  0.3992  0.2572  0.2728\n",
       "SD      0.1844  0.3125  0.1854  0.2781  0.2236  0.2293  0.2411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.2646</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.3120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.7667  0.5000  0.2000  0.2667  0.2500  0.2946\n",
       "1       0.6000  0.0000  0.6667  0.8667  0.6333  0.4444  0.5345\n",
       "2       0.0000  0.0000  0.0000  0.0000  0.0000 -0.3158 -0.5303\n",
       "3       0.4000  0.6333  0.5000  0.2667  0.3000  0.2500  0.3150\n",
       "4       0.4000  0.6000  0.3750  0.6000  0.4667  0.2105  0.2222\n",
       "5       0.2000  0.7167  0.2500  0.1000  0.1333 -0.0526 -0.0589\n",
       "6       0.4000  0.7500  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "7       0.4000  0.6833  0.5000  0.3000  0.3333  0.2105  0.2222\n",
       "8       0.0000  0.5000  0.0000  0.0000  0.0000 -0.3333 -0.3651\n",
       "9       0.2500  0.5000  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "Mean    0.3050  0.5150  0.3417  0.2925  0.2667  0.0874  0.0886\n",
       "SD      0.1823  0.2720  0.2082  0.2646  0.1897  0.2434  0.3120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1588</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.7083  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "1       0.4000  0.0000  0.5000  0.4500  0.3467  0.2105  0.3536\n",
       "2       0.2000  0.0000  0.1667  0.1333  0.1600 -0.1765 -0.2165\n",
       "3       0.6000  0.8250  0.7500  0.4000  0.4667  0.5000  0.5893\n",
       "4       0.2000  0.8500  0.2500  0.0500  0.0800 -0.0526 -0.0833\n",
       "5       0.2000  0.6750  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "6       0.4000  0.5333  0.2500  0.2000  0.2667  0.0625  0.0833\n",
       "7       0.4000  0.8250  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "8       0.0000  0.5000  0.0000  0.0000  0.0000 -0.3333 -0.4082\n",
       "9       0.2500  0.5833  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "Mean    0.3050  0.5500  0.3167  0.1890  0.2112  0.0544  0.0726\n",
       "SD      0.1588  0.2985  0.1920  0.1471  0.1397  0.2166  0.2702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.5083</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.3653</td>\n",
       "      <td>0.2337</td>\n",
       "      <td>0.3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.3092</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.2336</td>\n",
       "      <td>0.2633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.4667  0.3750  0.4500  0.3467  0.2105  0.3333\n",
       "1       0.4000  0.0000  0.5000  0.4500  0.3467  0.2105  0.3536\n",
       "2       0.6000  0.0000  0.6667  0.8667  0.6333  0.4444  0.5345\n",
       "3       0.4000  0.8833  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "4       0.4000  0.4167  0.2500  0.2667  0.3200  0.1176  0.1260\n",
       "5       0.4000  0.6333  0.5000  0.2000  0.2667  0.2105  0.2357\n",
       "6       0.2000  0.7167  0.1250  0.1333  0.1600 -0.1765 -0.1890\n",
       "7       0.8000  0.8833  0.8750  0.9000  0.8000  0.7368  0.7778\n",
       "8       0.5000  0.7500  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "9       0.2500  0.3333  0.2500  0.0833  0.1250  0.0000  0.0000\n",
       "Mean    0.4350  0.5083  0.4542  0.3933  0.3653  0.2337  0.3060\n",
       "SD      0.1613  0.3092  0.2070  0.2699  0.1951  0.2336  0.2633"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.4883</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.2965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0         0.20  0.5333  0.1250  0.2000  0.2000 -0.1111 -0.1179\n",
       "1         0.80  0.0000  0.8333  0.9000  0.8000  0.7059  0.7500\n",
       "2         0.80  0.0000  0.8333  0.9000  0.8000  0.7059  0.7500\n",
       "3         0.60  0.8417  0.6250  0.6667  0.5667  0.4737  0.5669\n",
       "4         0.40  0.7750  0.3750  0.5000  0.4000  0.2105  0.2222\n",
       "5         0.40  0.8333  0.5000  0.2000  0.2667  0.2500  0.2946\n",
       "6         0.40  0.7583  0.5000  0.2667  0.3000  0.2105  0.2520\n",
       "7         0.60  0.7333  0.6250  0.5000  0.5333  0.4444  0.4714\n",
       "8         0.25  0.5417  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "9         0.75  0.6667  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "Mean      0.52  0.5683  0.5417  0.4883  0.4700  0.3557  0.3920\n",
       "SD        0.21  0.3014  0.2275  0.2715  0.2258  0.2760  0.2965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.5208</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.3649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.2294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.7000  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "1       0.8000  0.0000  0.8333  0.9000  0.8000  0.7059  0.7500\n",
       "2       0.4000  0.0000  0.5000  0.2667  0.3000  0.1667  0.2165\n",
       "3       0.6000  0.7500  0.5000  0.6000  0.6000  0.4444  0.4444\n",
       "4       0.8000  0.8500  0.7500  0.7000  0.7333  0.7222  0.7660\n",
       "5       0.4000  0.7167  0.5000  0.3000  0.3333  0.2500  0.2946\n",
       "6       0.4000  0.4833  0.5000  0.2667  0.3000  0.2105  0.2520\n",
       "7       0.4000  0.6000  0.3750  0.3000  0.3333  0.1667  0.1768\n",
       "8       0.2500  0.5833  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "9       0.5000  0.5833  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "Mean    0.4950  0.5267  0.5208  0.3875  0.4133  0.3250  0.3649\n",
       "SD      0.1739  0.2809  0.1573  0.2422  0.2061  0.2230  0.2294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.2593</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.2412</td>\n",
       "      <td>0.2758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.4000  0.0  0.5000  0.2667  0.3000  0.2500  0.3150\n",
       "1       0.6000  0.0  0.6667  0.7000  0.6000  0.4118  0.4375\n",
       "2       0.2000  0.0  0.1250  0.1333  0.1600 -0.0526 -0.0722\n",
       "3       0.4000  0.0  0.3750  0.2667  0.3000  0.1667  0.2041\n",
       "4       0.2000  0.0  0.2500  0.0667  0.1000  0.0000  0.0000\n",
       "5       0.4000  0.0  0.5000  0.2667  0.3000  0.2500  0.3150\n",
       "6       0.2000  0.0  0.2500  0.2000  0.2000 -0.1111 -0.1179\n",
       "7       0.6000  0.0  0.7500  0.4000  0.4667  0.5000  0.5893\n",
       "8       0.0000  0.0  0.0000  0.0000  0.0000 -0.3333 -0.3651\n",
       "9       0.2500  0.0  0.2500  0.1250  0.1667  0.0000  0.0000\n",
       "Mean    0.3250  0.0  0.3667  0.2425  0.2593  0.1081  0.1306\n",
       "SD      0.1806  0.0  0.2250  0.1879  0.1669  0.2412  0.2758"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.3708</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>0.2289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.2000  0.5167  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "1       0.4000  0.0000  0.5000  0.4500  0.3467  0.2105  0.3536\n",
       "2       0.2000  0.0000  0.3333  0.0400  0.0667  0.0000  0.0000\n",
       "3       0.2000  0.1500  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "4       0.2000  0.3167  0.2500  0.0500  0.0800 -0.0526 -0.0833\n",
       "5       0.2000  0.3167  0.2500  0.0400  0.0667  0.0000  0.0000\n",
       "6       0.4000  0.3667  0.5000  0.2500  0.2800  0.2500  0.4167\n",
       "7       0.6000  0.1333  0.6250  0.6000  0.5333  0.4737  0.5303\n",
       "8       0.5000  0.2500  0.5000  0.3333  0.3750  0.3333  0.4714\n",
       "9       0.2500  0.5000  0.2500  0.0625  0.1000  0.0000  0.0000\n",
       "Mean    0.3150  0.2550  0.3708  0.1906  0.1982  0.1215  0.1689\n",
       "SD      0.1415  0.1745  0.1375  0.1964  0.1628  0.1725  0.2289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>-0.1765</td>\n",
       "      <td>-0.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>-0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.420</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.204</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.3245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0        0.200  0.7167  0.1250  0.1333  0.1600 -0.1765 -0.1890\n",
       "1        0.600  0.0000  0.3750  0.8000  0.6667  0.4737  0.5625\n",
       "2        0.600  0.0000  0.3750  0.6000  0.6000  0.4118  0.4375\n",
       "3        0.600  0.8333  0.6250  0.6000  0.5333  0.4737  0.5303\n",
       "4        0.400  0.5250  0.5000  0.3000  0.3333  0.2500  0.2946\n",
       "5        0.600  0.6667  0.7500  0.4667  0.5000  0.5000  0.6299\n",
       "6        0.200  0.5167  0.2500  0.0667  0.1000  0.0000  0.0000\n",
       "7        0.000  0.3000  0.0000  0.0000  0.0000 -0.3158 -0.3780\n",
       "8        0.500  0.8333  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "9        0.500  0.5833  0.5000  0.2500  0.3333  0.3333  0.4082\n",
       "Mean     0.420  0.4975  0.4000  0.3467  0.3560  0.2284  0.2704\n",
       "SD       0.204  0.2906  0.2151  0.2476  0.2099  0.2761  0.3245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1  Kappa  MCC\n",
       "0       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "1       0.4000  0.0  0.3333  0.1600  0.2286    0.0  0.0\n",
       "2       0.4000  0.0  0.3333  0.1600  0.2286    0.0  0.0\n",
       "3       0.4000  0.5  0.2500  0.1600  0.2286    0.0  0.0\n",
       "4       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "5       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "6       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "7       0.2000  0.5  0.2500  0.0400  0.0667    0.0  0.0\n",
       "8       0.2500  0.5  0.2500  0.0625  0.1000    0.0  0.0\n",
       "9       0.2500  0.5  0.2500  0.0625  0.1000    0.0  0.0\n",
       "Mean    0.2700  0.4  0.2667  0.0805  0.1219    0.0  0.0\n",
       "SD      0.0872  0.2  0.0333  0.0527  0.0710    0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = create_model('lr')\n",
    "rf = create_model('rf')\n",
    "xgb = create_model('xgboost')\n",
    "ada = create_model('ada')\n",
    "lda = create_model('lda')  # linear discriminant\n",
    "knn = create_model('knn')\n",
    "mlp = create_model('mlp')\n",
    "svm = create_model('svm')\n",
    "rbfsvm = create_model('rbfsvm')\n",
    "nb = create_model('nb')\n",
    "gpc = create_model('gpc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicteurs : Les plus satisfaisants : ADA - LDA - KNN - LR : pluto moins bien en accuracy .... <br/>\n",
    "predicteurs 1 : Les plus satisfaisants : LR - LDA - RF - XGB - NB : environ 40% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai_classif = francais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites','meth2_similarites']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography                     int32\n",
       "Entities                      int32\n",
       "Time                          int32\n",
       "Narrative                     int32\n",
       "Overall                       int32\n",
       "Style                         int32\n",
       "Tone                          int32\n",
       "nb_entites_idem               int64\n",
       "nb_lieux_idem                 int64\n",
       "nb_dates_idem                 int64\n",
       "score_similarite_titres     float64\n",
       "score_similarite_resume1    float64\n",
       "score_similarite_resume2    float64\n",
       "score_classif1              float64\n",
       "score_classif2              float64\n",
       "score_sentiment1            float64\n",
       "score_sentiment2            float64\n",
       "meth1_similarites           float64\n",
       "meth2_similarites           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si on veut utiliser faire un classemen,t supprimer ligne error puis changer les types pour meth1 meth2\n",
    "essai_classif = essai_classif[essai_classif.meth1_similarites != 'Error']\n",
    "essai_classif['meth1_similarites'] = essai_classif['meth1_similarites'].astype('float')\n",
    "essai_classif['meth2_similarites'] = essai_classif['meth2_similarites'].astype('float')\n",
    "essai_classif.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.4763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.1361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.4860</td>\n",
       "      <td>0.3563</td>\n",
       "      <td>0.3945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1153</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>0.2799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.8000  0.9000  0.7500  0.6667  0.7200  0.7059  0.7559\n",
       "1       0.2000  0.6833  0.1250  0.2000  0.2000 -0.1111 -0.1111\n",
       "2       0.4000  0.8500  0.3750  0.4667  0.3667  0.2105  0.2520\n",
       "3       0.6000  0.6833  0.5000  0.3667  0.4533  0.4118  0.4763\n",
       "4       0.4000  0.6333  0.3750  0.6000  0.4667  0.2105  0.2222\n",
       "5       0.4000  0.7500  0.2500  0.2667  0.3200  0.1176  0.1361\n",
       "6       0.6000  0.8500  0.6250  0.6000  0.5333  0.4737  0.5303\n",
       "7       0.4000  0.7167  0.3750  0.6000  0.4667  0.2105  0.2222\n",
       "8       0.7500  0.9167  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "9       0.7500  1.0000  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "Mean    0.5300  0.7983  0.4875  0.5017  0.4860  0.3563  0.3945\n",
       "SD      0.1887  0.1153  0.2125  0.1589  0.1574  0.2590  0.2799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xtrain = essai_classif[predicteurs + ['Overall']]\n",
    "french_classif = setup(data = Xtrain,  target = 'Overall', html=False, silent=True, verbose=False)\n",
    "rf = create_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict_model(rf)  # ne marche pas ????\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.4763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6583</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>-0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5917</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.3950</td>\n",
       "      <td>0.5792</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>0.2145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.2774</td>\n",
       "      <td>0.3002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.6000  0.8000  0.5000  0.5000  0.5333  0.4444  0.4714\n",
       "1       0.6000  0.5833  0.5000  0.3667  0.4533  0.4118  0.4763\n",
       "2       0.4000  0.6583  0.3750  0.5000  0.4000  0.2105  0.2222\n",
       "3       0.2000  0.5500  0.1250  0.4000  0.2667 -0.0526 -0.0630\n",
       "4       0.4000  0.6250  0.3750  0.5000  0.4000  0.2105  0.2357\n",
       "5       0.2000  0.6000  0.1250  0.2000  0.2000 -0.1111 -0.1111\n",
       "6       0.4000  0.5500  0.3750  0.4000  0.4000  0.1667  0.1768\n",
       "7       0.4000  0.5917  0.5000  0.1667  0.2333  0.2500  0.3402\n",
       "8       0.7500  0.6667  0.7500  0.6250  0.6667  0.6667  0.7303\n",
       "9       0.0000  0.1667  0.0000  0.0000  0.0000 -0.3333 -0.3333\n",
       "Mean    0.3950  0.5792  0.3625  0.3658  0.3553  0.1864  0.2145\n",
       "SD      0.2103  0.1540  0.2125  0.1801  0.1781  0.2774  0.3002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda = create_model('lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random Forest simple sur scikit learn\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xtrain[:50],ytrain[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>83.65</td>\n",
       "      <td>69.14</td>\n",
       "      <td>26.07</td>\n",
       "      <td>79.42</td>\n",
       "      <td>9.45</td>\n",
       "      <td>95.91</td>\n",
       "      <td>41.50</td>\n",
       "      <td>256.4</td>\n",
       "      <td>301.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>64.23</td>\n",
       "      <td>57.55</td>\n",
       "      <td>70.79</td>\n",
       "      <td>97.61</td>\n",
       "      <td>8.36</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11.05</td>\n",
       "      <td>165.4</td>\n",
       "      <td>389.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.01</td>\n",
       "      <td>25.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.62</td>\n",
       "      <td>99.99</td>\n",
       "      <td>32.26</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>66.92</td>\n",
       "      <td>61.40</td>\n",
       "      <td>66.44</td>\n",
       "      <td>10.38</td>\n",
       "      <td>97.21</td>\n",
       "      <td>16.85</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>48.51</td>\n",
       "      <td>55.93</td>\n",
       "      <td>63.85</td>\n",
       "      <td>46.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>83.60</td>\n",
       "      <td>30.36</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.22</td>\n",
       "      <td>37.96</td>\n",
       "      <td>52.72</td>\n",
       "      <td>32.87</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>38.59</td>\n",
       "      <td>31.92</td>\n",
       "      <td>33.52</td>\n",
       "      <td>44.72</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.46</td>\n",
       "      <td>28.30</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.93</td>\n",
       "      <td>12.74</td>\n",
       "      <td>10.22</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.07</td>\n",
       "      <td>99.87</td>\n",
       "      <td>46.52</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>40.36</td>\n",
       "      <td>72.15</td>\n",
       "      <td>47.00</td>\n",
       "      <td>81.74</td>\n",
       "      <td>11.49</td>\n",
       "      <td>99.90</td>\n",
       "      <td>34.50</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.78</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13.04</td>\n",
       "      <td>91.10</td>\n",
       "      <td>36.71</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>21.72</td>\n",
       "      <td>12.48</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.38</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>74.32</td>\n",
       "      <td>66.79</td>\n",
       "      <td>40.39</td>\n",
       "      <td>60.62</td>\n",
       "      <td>10.50</td>\n",
       "      <td>99.88</td>\n",
       "      <td>19.83</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>56.29</td>\n",
       "      <td>70.34</td>\n",
       "      <td>51.43</td>\n",
       "      <td>42.65</td>\n",
       "      <td>10.45</td>\n",
       "      <td>99.30</td>\n",
       "      <td>42.80</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>28.04</td>\n",
       "      <td>36.26</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>99.97</td>\n",
       "      <td>29.27</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>47.46</td>\n",
       "      <td>47.85</td>\n",
       "      <td>54.29</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.99</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>38.26</td>\n",
       "      <td>50.95</td>\n",
       "      <td>63.59</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.48</td>\n",
       "      <td>11.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>26.87</td>\n",
       "      <td>41.90</td>\n",
       "      <td>48.33</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50               13             15              0                    83.65   \n",
       "51                4             25              0                    64.23   \n",
       "52                2              2              0                     7.36   \n",
       "53                7              3              0                     9.00   \n",
       "54                2              8              0                    48.51   \n",
       "55                2              1              0                    57.22   \n",
       "56                3             12              0                    38.59   \n",
       "57                0              0              0                     7.93   \n",
       "58                1              7              0                    40.36   \n",
       "59                0              0              0                    30.36   \n",
       "60                1              3              0                    14.33   \n",
       "61                1              8              0                    74.32   \n",
       "62                2             60              0                    56.29   \n",
       "63                7             30              0                    28.04   \n",
       "64                3              8              0                    47.46   \n",
       "65                4              0              0                     6.03   \n",
       "66               15             17              0                    38.26   \n",
       "67                0              0              0                     9.48   \n",
       "68                2             10              0                    26.87   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                     69.14                     26.07           79.42   \n",
       "51                     57.55                     70.79           97.61   \n",
       "52                     10.01                     25.70            4.73   \n",
       "53                     66.92                     61.40           66.44   \n",
       "54                     55.93                     63.85           46.37   \n",
       "55                     37.96                     52.72           32.87   \n",
       "56                     31.92                     33.52           44.72   \n",
       "57                     12.74                     10.22           10.34   \n",
       "58                     72.15                     47.00           81.74   \n",
       "59                      7.50                      4.78            3.77   \n",
       "60                     21.72                     12.48           29.07   \n",
       "61                     66.79                     40.39           60.62   \n",
       "62                     70.34                     51.43           42.65   \n",
       "63                     36.26                     44.33            1.49   \n",
       "64                     47.85                     54.29           35.06   \n",
       "65                     13.21                      3.99           14.24   \n",
       "66                     50.95                     63.59           93.14   \n",
       "67                     11.70                      3.17            6.09   \n",
       "68                     41.90                     48.33           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2  meth1_similarites  \\\n",
       "50            9.45             95.91             41.50              256.4   \n",
       "51            8.36             96.46             11.05              165.4   \n",
       "52            8.62             99.99             32.26               80.7   \n",
       "53           10.38             97.21             16.85              564.1   \n",
       "54            8.59             83.60             30.36              374.8   \n",
       "55           10.75             18.59             33.70              130.0   \n",
       "56            9.49              7.46             28.30              138.8   \n",
       "57           10.07             99.87             46.52               21.1   \n",
       "58           11.49             99.90             34.50              223.8   \n",
       "59           13.04             91.10             36.71               50.7   \n",
       "60            8.22              0.16             35.38              120.0   \n",
       "61           10.50             99.88             19.83              437.9   \n",
       "62           10.45             99.30             42.80              344.5   \n",
       "63            9.78             99.97             29.27              142.0   \n",
       "64           10.08             97.33             30.89               21.2   \n",
       "65            8.91              1.03             20.16              174.0   \n",
       "66            9.39             99.98             31.05              176.2   \n",
       "67            8.37             99.84             29.93                8.8   \n",
       "68           10.33             99.54             27.09              150.3   \n",
       "\n",
       "    meth2_similarites  Overall  RF  \n",
       "50              301.4        1   1  \n",
       "51              389.4        1   1  \n",
       "52              215.1        4   3  \n",
       "53              248.6        1   1  \n",
       "54              339.8        1   1  \n",
       "55              159.8        2   2  \n",
       "56               74.0        2   3  \n",
       "57               54.1        4   4  \n",
       "58              170.8        2   1  \n",
       "59               68.7        2   4  \n",
       "60              228.2        4   3  \n",
       "61              301.2        2   1  \n",
       "62              485.7        1   1  \n",
       "63              289.0        2   3  \n",
       "64               35.8        3   1  \n",
       "65              179.9        3   4  \n",
       "66              258.7        1   1  \n",
       "67               28.4        4   4  \n",
       "68              114.6        3   2  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf = rf.predict(Xtrain[50:])\n",
    "res_rf = pd.concat([Xtrain[50:],ytrain[50:],pd.DataFrame(res_rf,columns = ['RF'],index = range(50,69))],axis=1)\n",
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 0, 0],\n",
       "       [2, 1, 2, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résultats corrects : 9/19 - 8/19 : 1 d'écart - 2/19 : 2 écart \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(res_rf.Overall,res_rf.RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  8,  2,  9,  7,  0,  6,  3, 11,  5, 10,  4], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(rf, Xtrain, ytrain, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "tree_feature_importances = rf.feature_importances_\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(predicteurs))\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.array(predicteurs)[sorted_idx])\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Overall  RF  LDA\n",
       "50        1   1    2\n",
       "51        1   1    1\n",
       "52        4   3    4\n",
       "53        1   1    1\n",
       "54        1   1    1\n",
       "55        2   2    3\n",
       "56        2   3    3\n",
       "57        4   4    3\n",
       "58        2   1    1\n",
       "59        2   4    3\n",
       "60        4   3    3\n",
       "61        2   1    1\n",
       "62        1   1    2\n",
       "63        2   3    3\n",
       "64        3   1    3\n",
       "65        3   4    4\n",
       "66        1   1    2\n",
       "67        4   4    4\n",
       "68        3   2    3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Xtrain[:50],ytrain[:50])\n",
    "res_lda = lda.predict(Xtrain[50:])\n",
    "res_final = pd.concat([res_rf[['Overall','RF']],pd.DataFrame(res_lda,columns = ['LDA'],index = range(50,69))],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.76, 93.17,  0.07,  0.  ],\n",
       "       [94.81,  4.46,  0.72,  0.01],\n",
       "       [ 0.  ,  1.8 , 40.51, 57.69],\n",
       "       [99.95,  0.  ,  0.  ,  0.04],\n",
       "       [99.11,  0.25,  0.58,  0.06],\n",
       "       [ 4.16, 17.3 , 72.09,  6.45],\n",
       "       [ 5.13, 17.86, 72.58,  4.43],\n",
       "       [ 0.  ,  6.57, 66.63, 26.79],\n",
       "       [83.44, 15.84,  0.68,  0.04],\n",
       "       [ 0.  ,  4.03, 60.53, 35.45],\n",
       "       [ 0.12, 29.8 , 65.36,  4.73],\n",
       "       [99.94,  0.05,  0.01,  0.  ],\n",
       "       [ 0.  , 90.9 ,  9.1 ,  0.  ],\n",
       "       [ 0.  , 37.38, 62.32,  0.3 ],\n",
       "       [ 0.26, 35.8 , 45.62, 18.32],\n",
       "       [ 0.01,  3.81, 20.88, 75.3 ],\n",
       "       [ 6.97, 90.03,  2.92,  0.08],\n",
       "       [ 0.  ,  0.74,  9.01, 90.26],\n",
       "       [ 0.09, 12.34, 57.52, 30.05]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import around\n",
    "import numpy\n",
    "np.set_printoptions(suppress=True)  # supprime notation exp\n",
    "res_lda2 = around(lda.predict_proba(Xtrain[50:])*100, decimals=2)\n",
    "res_lda2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Remarquer que la classification ne tient pas compte du fait que c'est ordonné en classement 1-2-3-4 : ce qui est TRES important (ex : ligne 55% de 1 - 43% de 4) !! : il faudrait donc faire ressortir un score avec les probas plutot !!!_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42., 41., 17.,  0.],\n",
       "       [55., 33.,  6.,  6.],\n",
       "       [ 0., 16., 66., 18.],\n",
       "       [47., 37.,  8.,  8.],\n",
       "       [49., 41.,  6.,  4.],\n",
       "       [25., 46.,  9., 20.],\n",
       "       [ 7., 32., 34., 27.],\n",
       "       [ 0.,  7., 20., 73.],\n",
       "       [43., 28., 17., 12.],\n",
       "       [ 0., 11., 39., 50.],\n",
       "       [ 1., 16., 56., 27.],\n",
       "       [50., 32.,  8., 10.],\n",
       "       [49., 37., 10.,  4.],\n",
       "       [14., 38., 45.,  3.],\n",
       "       [28., 28., 18., 26.],\n",
       "       [ 0., 20., 34., 46.],\n",
       "       [45., 36., 15.,  4.],\n",
       "       [ 0.,  3., 17., 80.],\n",
       "       [31., 35., 14., 20.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf2 = around(rf.predict_proba(Xtrain[50:])*100, decimals=2)\n",
    "res_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau programme basé sur les scores probas : si plus de 50% mettre catégorie obtenue sinon, faire la somme 1-2 et 3/4 \n",
    "# et prendre le plus gros score puis regarder si ce sore > 65% alors à ce moment là prendre le plus gros de la catégorie \n",
    "# sinon prendre 2 ou 3\n",
    "def choix_classes(score_prob):\n",
    "    classe_finale = []\n",
    "    for i in range(len(score_prob)):\n",
    "        res = list(score_prob[i,:])\n",
    "        max_res = max(res)\n",
    "        if max_res > 50:\n",
    "            classe_finale.append(res.index(max_res)+1)\n",
    "        else:\n",
    "            som1 = res[0]+res[1]\n",
    "            som2 = res[2]+res[3]\n",
    "            if som1 > som2:\n",
    "                if som1 >= 65:\n",
    "                    choix = 1 if res[0]>res[1] else 2\n",
    "                else:\n",
    "                    choix = 2\n",
    "            else:\n",
    "                if som2 >= 65:\n",
    "                    choix = 4 if res[3]>res[2] else 3\n",
    "                else:\n",
    "                    choix = 3\n",
    "            classe_finale.append(choix)\n",
    "    return classe_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_rf = choix_classes(res_rf2)\n",
    "liste_lda = choix_classes(res_lda2)\n",
    "res_final = pd.concat([res_final,pd.DataFrame(liste_lda,columns = ['LDA_Prob'],index = range(50,69)),\n",
    "                       pd.DataFrame(liste_rf,columns = ['RF_Prob'],index = range(50,69))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(Xtrain[:50],ytrain[:50])\n",
    "res_knn = knn.predict(Xtrain[50:])\n",
    "liste_knn = choix_classes(around(knn.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['KNN'],index = range(50,69)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['KNN_Prob'],index = range(50,69))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain[:50],ytrain[:50])\n",
    "res_logreg = logreg.predict(Xtrain[50:])\n",
    "liste_logreg = choix_classes(around(logreg.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_logreg,columns = ['LOGR'],index = range(50,69)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['LOGR_Prob'],index = range(50,69))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(Xtrain[:50],ytrain[:50])\n",
    "res_ada = ada.predict(Xtrain[50:])\n",
    "liste_ada = choix_classes(around(ada.predict_proba(Xtrain[50:])*100, decimals=2))\n",
    "res_final = pd.concat([res_final,pd.DataFrame(res_knn,columns = ['ADA'],index = range(50,69)),\n",
    "                      pd.DataFrame(liste_knn,columns = ['ADA_Prob'],index = range(50,69))],axis=1)\n",
    "res_final = res_final [['Overall','RF','LDA','KNN','LOGR','ADA','RF_Prob','LDA_Prob','KNN_Prob','LOGR_Prob','ADA_Prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>ADA</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>KNN_Prob</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>ADA_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Overall  RF  LDA  KNN  LOGR  ADA  RF_Prob  LDA_Prob  KNN_Prob  LOGR_Prob  \\\n",
       "50        1   1    2    2     2    2        1         2         2          2   \n",
       "51        1   1    1    3     1    3        1         1         3          3   \n",
       "52        4   3    4    3     3    3        3         4         3          3   \n",
       "53        1   1    1    1     1    1        1         1         1          1   \n",
       "54        1   1    1    1     1    1        1         1         1          1   \n",
       "55        2   2    3    4     3    4        2         3         3          3   \n",
       "56        2   3    3    4     2    4        3         3         4          4   \n",
       "57        4   4    3    4     4    4        4         3         4          4   \n",
       "58        2   1    1    1     1    1        1         1         2          2   \n",
       "59        2   4    3    3     4    3        4         3         3          3   \n",
       "60        4   3    3    3     2    3        3         3         3          3   \n",
       "61        2   1    1    1     1    1        1         1         1          1   \n",
       "62        1   1    2    1     3    1        1         2         2          2   \n",
       "63        2   3    3    2     3    2        2         3         2          2   \n",
       "64        3   1    3    4     4    4        2         3         4          4   \n",
       "65        3   4    4    3     2    3        4         4         3          3   \n",
       "66        1   1    2    2     2    2        1         2         2          2   \n",
       "67        4   4    4    4     4    4        4         4         4          4   \n",
       "68        3   2    3    4     3    4        2         3         4          4   \n",
       "\n",
       "    ADA_Prob  \n",
       "50         2  \n",
       "51         3  \n",
       "52         3  \n",
       "53         1  \n",
       "54         1  \n",
       "55         3  \n",
       "56         4  \n",
       "57         4  \n",
       "58         2  \n",
       "59         3  \n",
       "60         3  \n",
       "61         1  \n",
       "62         2  \n",
       "63         2  \n",
       "64         4  \n",
       "65         3  \n",
       "66         2  \n",
       "67         4  \n",
       "68         4  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir ensuite à utiliser les resultats reçus pour obtenir un resultat final : mieux ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION Sklearn Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "francais = pd.read_csv('corpus_fr_notes_v2.csv',index_col=0)\n",
    "francais = francais[francais.meth1_similarites!='Error']\n",
    "french_classif = setup(data = francais[predicteurs + ['Overall']],  target = 'Overall', html=False, silent=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.2064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.2978</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.3949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6703</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>-0.2341</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>0.2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9839</td>\n",
       "      <td>1.3960</td>\n",
       "      <td>1.1815</td>\n",
       "      <td>-7.7247</td>\n",
       "      <td>0.3025</td>\n",
       "      <td>0.3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5577</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.8109</td>\n",
       "      <td>-0.0275</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>0.3345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5264</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>-0.0959</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>-0.1815</td>\n",
       "      <td>0.2511</td>\n",
       "      <td>0.1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.1975</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>1.5131</td>\n",
       "      <td>-1.3848</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8941</td>\n",
       "      <td>1.1564</td>\n",
       "      <td>1.0753</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>0.6939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5581</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.7188</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7178</td>\n",
       "      <td>0.9211</td>\n",
       "      <td>0.9228</td>\n",
       "      <td>-0.7658</td>\n",
       "      <td>0.2591</td>\n",
       "      <td>0.3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>2.3861</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.1552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.6550  0.5902  0.7682  0.5082  0.2132  0.2064\n",
       "1     0.4899  0.2978  0.5457  0.5346  0.2197  0.3949\n",
       "2     0.6703  0.7899  0.8887 -0.2341  0.2319  0.2419\n",
       "3     0.9839  1.3960  1.1815 -7.7247  0.3025  0.3171\n",
       "4     0.5577  0.6576  0.8109 -0.0275  0.2795  0.3345\n",
       "5     0.5264  0.6137  0.7834 -0.0959  0.2464  0.1820\n",
       "6     0.6451  0.9452  0.9722 -0.1815  0.2511  0.1837\n",
       "7     1.1975  2.2894  1.5131 -1.3848  0.3654  0.5084\n",
       "8     0.8941  1.1564  1.0753  0.2291  0.2277  0.6939\n",
       "9     0.5581  0.4746  0.6889  0.7188  0.2535  0.4270\n",
       "Mean  0.7178  0.9211  0.9228 -0.7658  0.2591  0.3490\n",
       "SD    0.2198  0.5507  0.2636  2.3861  0.0439  0.1552"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.2471</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.1549</td>\n",
       "      <td>0.2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2484</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>-0.3447</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>0.5392</td>\n",
       "      <td>0.5458</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>0.2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6237</td>\n",
       "      <td>0.5694</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>0.1841</td>\n",
       "      <td>0.1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9939</td>\n",
       "      <td>1.3812</td>\n",
       "      <td>1.1752</td>\n",
       "      <td>-0.7265</td>\n",
       "      <td>0.3136</td>\n",
       "      <td>0.3422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7381</td>\n",
       "      <td>0.8188</td>\n",
       "      <td>0.9049</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.2953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.3799</td>\n",
       "      <td>0.6164</td>\n",
       "      <td>0.7467</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7577</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.3277</td>\n",
       "      <td>0.6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.5061</td>\n",
       "      <td>0.6658</td>\n",
       "      <td>0.3130</td>\n",
       "      <td>0.2049</td>\n",
       "      <td>0.2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.1429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.4671  0.2471  0.4971  0.7941  0.1549  0.2248\n",
       "1     0.4937  0.2465  0.4965  0.6149  0.1981  0.3883\n",
       "2     0.2484  0.0926  0.3043  0.8553  0.0938  0.1012\n",
       "3     0.3478  0.2151  0.4638 -0.3447  0.1186  0.1150\n",
       "4     0.4885  0.2907  0.5392  0.5458  0.2027  0.2968\n",
       "5     0.6237  0.5694  0.7546 -0.0167  0.1841  0.1823\n",
       "6     0.9939  1.3812  1.1752 -0.7265  0.3136  0.3422\n",
       "7     0.7381  0.8188  0.9049  0.1471  0.2325  0.2953\n",
       "8     0.5401  0.3799  0.6164  0.7467  0.2225  0.3897\n",
       "9     0.7577  0.8202  0.9056  0.5140  0.3277  0.6059\n",
       "Mean  0.5699  0.5061  0.6658  0.3130  0.2049  0.2942\n",
       "SD    0.2056  0.3766  0.2508  0.5048  0.0712  0.1429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.7093</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.2818</td>\n",
       "      <td>0.5293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3640</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.5503</td>\n",
       "      <td>0.5269</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>-2.0640</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>0.6935</td>\n",
       "      <td>0.2485</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.7798</td>\n",
       "      <td>-0.0859</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8280</td>\n",
       "      <td>1.7129</td>\n",
       "      <td>1.3088</td>\n",
       "      <td>-1.1412</td>\n",
       "      <td>0.3852</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9740</td>\n",
       "      <td>1.4281</td>\n",
       "      <td>1.1950</td>\n",
       "      <td>-0.4876</td>\n",
       "      <td>0.3115</td>\n",
       "      <td>0.4070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.3312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5450</td>\n",
       "      <td>0.4191</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.3879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.5479</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.7246</td>\n",
       "      <td>-0.0209</td>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2152</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.0856</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.1940  0.0476  0.2181  0.9604  0.0647  0.0862\n",
       "1     0.5860  0.5031  0.7093  0.2138  0.2818  0.5293\n",
       "2     0.3640  0.3028  0.5503  0.5269  0.1345  0.1237\n",
       "3     0.6280  0.4902  0.7002 -2.0640  0.1945  0.2003\n",
       "4     0.5180  0.4810  0.6935  0.2485  0.2228  0.2213\n",
       "5     0.4600  0.6081  0.7798 -0.0859  0.2520  0.1512\n",
       "6     0.8280  1.7129  1.3088 -1.1412  0.3852  0.2490\n",
       "7     0.9740  1.4281  1.1950 -0.4876  0.3115  0.4070\n",
       "8     0.3825  0.1969  0.4437  0.8688  0.1879  0.3312\n",
       "9     0.5450  0.4191  0.6474  0.7516  0.2290  0.3879\n",
       "Mean  0.5479  0.6190  0.7246 -0.0209  0.2264  0.2687\n",
       "SD    0.2152  0.5045  0.3065  0.9182  0.0856  0.1344"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.3246</td>\n",
       "      <td>0.5697</td>\n",
       "      <td>0.7295</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6148</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>0.3824</td>\n",
       "      <td>0.2503</td>\n",
       "      <td>0.5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.4326</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3137</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>-0.2938</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.5416</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.2867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.5202</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1881</td>\n",
       "      <td>0.1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0074</td>\n",
       "      <td>1.4916</td>\n",
       "      <td>1.2213</td>\n",
       "      <td>-0.8644</td>\n",
       "      <td>0.3276</td>\n",
       "      <td>0.3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.8551</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.3045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.4808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.7239</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.3092</td>\n",
       "      <td>0.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.6012</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.7011</td>\n",
       "      <td>0.2659</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.3757</td>\n",
       "      <td>0.2292</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.1438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.5318  0.3246  0.5697  0.7295  0.1720  0.2503\n",
       "1     0.6148  0.3953  0.6287  0.3824  0.2503  0.5002\n",
       "2     0.3737  0.1871  0.4326  0.7076  0.1533  0.1611\n",
       "3     0.3137  0.2070  0.4550 -0.2938  0.1266  0.1044\n",
       "4     0.5123  0.2933  0.5416  0.5417  0.1989  0.2867\n",
       "5     0.6065  0.5202  0.7212  0.0711  0.1881  0.1882\n",
       "6     1.0074  1.4916  1.2213 -0.8644  0.3276  0.3455\n",
       "7     0.7550  0.8551  0.9247  0.1093  0.2462  0.3045\n",
       "8     0.6124  0.4426  0.6653  0.7049  0.2536  0.4808\n",
       "9     0.6846  0.7239  0.8508  0.5710  0.3092  0.5491\n",
       "Mean  0.6012  0.5441  0.7011  0.2659  0.2226  0.3171\n",
       "SD    0.1852  0.3757  0.2292  0.4939  0.0626  0.1438"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.3076</td>\n",
       "      <td>0.9211</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>-0.2880</td>\n",
       "      <td>0.3507</td>\n",
       "      <td>0.6957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4131</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>0.5203</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>-0.7990</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.5442</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.2349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>-0.5754</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.2477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.1075</td>\n",
       "      <td>1.9997</td>\n",
       "      <td>1.4141</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>0.4043</td>\n",
       "      <td>0.3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6779</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.2384</td>\n",
       "      <td>0.2756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>0.7629</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.4980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.4497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.6235</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.3205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.5191</td>\n",
       "      <td>0.2958</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>0.1746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE      R2   RMSLE    MAPE\n",
       "0     0.2604  0.0946  0.3076  0.9211  0.1057  0.1384\n",
       "1     0.7326  0.8243  0.9079 -0.2880  0.3507  0.6957\n",
       "2     0.4131  0.2707  0.5203  0.5771  0.1339  0.1472\n",
       "3     0.4184  0.2878  0.5365 -0.7990  0.1459  0.1353\n",
       "4     0.4472  0.2962  0.5442  0.5372  0.1776  0.2349\n",
       "5     0.7909  0.8822  0.9393 -0.5754  0.2605  0.2477\n",
       "6     1.1075  1.9997  1.4141 -1.4996  0.4043  0.3821\n",
       "7     0.6779  0.8769  0.9364  0.0865  0.2384  0.2756\n",
       "8     0.7480  0.5820  0.7629  0.6120  0.2586  0.4980\n",
       "9     0.6391  0.4902  0.7001  0.7095  0.2517  0.4497\n",
       "Mean  0.6235  0.6605  0.7569  0.0282  0.2327  0.3205\n",
       "SD    0.2328  0.5191  0.2958  0.7516  0.0904  0.1746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6904</td>\n",
       "      <td>0.7353</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>0.3872</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.3235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4713</td>\n",
       "      <td>2.7944</td>\n",
       "      <td>1.6717</td>\n",
       "      <td>-3.3663</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>1.3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8845</td>\n",
       "      <td>1.2034</td>\n",
       "      <td>1.0970</td>\n",
       "      <td>-0.8803</td>\n",
       "      <td>0.3381</td>\n",
       "      <td>0.3784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5168</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>1.6011</td>\n",
       "      <td>-15.0212</td>\n",
       "      <td>0.5232</td>\n",
       "      <td>0.4888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0728</td>\n",
       "      <td>1.8186</td>\n",
       "      <td>1.3485</td>\n",
       "      <td>-1.8415</td>\n",
       "      <td>0.3251</td>\n",
       "      <td>0.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1010</td>\n",
       "      <td>1.6080</td>\n",
       "      <td>1.2681</td>\n",
       "      <td>-1.8714</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.3867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.6215</td>\n",
       "      <td>5.0308</td>\n",
       "      <td>2.2429</td>\n",
       "      <td>-5.2885</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.6390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.1896</td>\n",
       "      <td>1.8656</td>\n",
       "      <td>1.3659</td>\n",
       "      <td>-0.9433</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2512</td>\n",
       "      <td>2.5196</td>\n",
       "      <td>1.5873</td>\n",
       "      <td>-0.6797</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>1.1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.4319</td>\n",
       "      <td>2.5876</td>\n",
       "      <td>1.6086</td>\n",
       "      <td>-0.5334</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.9660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1.2231</td>\n",
       "      <td>2.2727</td>\n",
       "      <td>1.4649</td>\n",
       "      <td>-3.0038</td>\n",
       "      <td>0.4208</td>\n",
       "      <td>0.6637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.2807</td>\n",
       "      <td>1.1156</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>4.2914</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.3376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE     MSE    RMSE       R2   RMSLE    MAPE\n",
       "0     0.6904  0.7353  0.8575   0.3872  0.2573  0.3235\n",
       "1     1.4713  2.7944  1.6717  -3.3663  0.4318  1.3330\n",
       "2     0.8845  1.2034  1.0970  -0.8803  0.3381  0.3784\n",
       "3     1.5168  2.5634  1.6011 -15.0212  0.5232  0.4888\n",
       "4     1.0728  1.8186  1.3485  -1.8415  0.3251  0.5300\n",
       "5     1.1010  1.6080  1.2681  -1.8714  0.3398  0.3867\n",
       "6     1.6215  5.0308  2.2429  -5.2885  0.5437  0.6390\n",
       "7     1.1896  1.8656  1.3659  -0.9433  0.4462  0.4475\n",
       "8     1.2512  2.5196  1.5873  -0.6797  0.5215  1.1437\n",
       "9     1.4319  2.5876  1.6086  -0.5334  0.4814  0.9660\n",
       "Mean  1.2231  2.2727  1.4649  -3.0038  0.4208  0.6637\n",
       "SD    0.2807  1.1156  0.3562   4.2914  0.0946  0.3376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = create_model('lr')\n",
    "rr = create_model('lasso')\n",
    "etr = create_model('et')\n",
    "svr = create_model('svm')\n",
    "adar = create_model('ada')\n",
    "mlpr = create_model('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression simple sur scikit learn\n",
    "essai_classif = francais[['Geography','Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone','nb_entites_idem', \n",
    "    'nb_lieux_idem', 'nb_dates_idem', 'score_similarite_titres', 'score_similarite_resume1','score_similarite_resume2', \n",
    "    'score_classif1', 'score_classif2','score_sentiment1', 'score_sentiment2', 'meth1_similarites','meth2_similarites']]\n",
    "lr = LinearRegression()\n",
    "Xtrain = essai_classif[predicteurs].reset_index(drop=True)\n",
    "ytrain = essai_classif['Overall'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>83.65</td>\n",
       "      <td>69.14</td>\n",
       "      <td>26.07</td>\n",
       "      <td>79.42</td>\n",
       "      <td>9.45</td>\n",
       "      <td>95.91</td>\n",
       "      <td>41.50</td>\n",
       "      <td>256.4</td>\n",
       "      <td>301.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.591923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>64.23</td>\n",
       "      <td>57.55</td>\n",
       "      <td>70.79</td>\n",
       "      <td>97.61</td>\n",
       "      <td>8.36</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11.05</td>\n",
       "      <td>165.4</td>\n",
       "      <td>389.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.165432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.01</td>\n",
       "      <td>25.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.62</td>\n",
       "      <td>99.99</td>\n",
       "      <td>32.26</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.646610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>66.92</td>\n",
       "      <td>61.40</td>\n",
       "      <td>66.44</td>\n",
       "      <td>10.38</td>\n",
       "      <td>97.21</td>\n",
       "      <td>16.85</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.067664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>48.51</td>\n",
       "      <td>55.93</td>\n",
       "      <td>63.85</td>\n",
       "      <td>46.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>83.60</td>\n",
       "      <td>30.36</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.736236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.22</td>\n",
       "      <td>37.96</td>\n",
       "      <td>52.72</td>\n",
       "      <td>32.87</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.315933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>38.59</td>\n",
       "      <td>31.92</td>\n",
       "      <td>33.52</td>\n",
       "      <td>44.72</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.46</td>\n",
       "      <td>28.30</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.236454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.93</td>\n",
       "      <td>12.74</td>\n",
       "      <td>10.22</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.07</td>\n",
       "      <td>99.87</td>\n",
       "      <td>46.52</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.424757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>40.36</td>\n",
       "      <td>72.15</td>\n",
       "      <td>47.00</td>\n",
       "      <td>81.74</td>\n",
       "      <td>11.49</td>\n",
       "      <td>99.90</td>\n",
       "      <td>34.50</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.316925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.78</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13.04</td>\n",
       "      <td>91.10</td>\n",
       "      <td>36.71</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.713748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>21.72</td>\n",
       "      <td>12.48</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.38</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.463118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>74.32</td>\n",
       "      <td>66.79</td>\n",
       "      <td>40.39</td>\n",
       "      <td>60.62</td>\n",
       "      <td>10.50</td>\n",
       "      <td>99.88</td>\n",
       "      <td>19.83</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.503630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>56.29</td>\n",
       "      <td>70.34</td>\n",
       "      <td>51.43</td>\n",
       "      <td>42.65</td>\n",
       "      <td>10.45</td>\n",
       "      <td>99.30</td>\n",
       "      <td>42.80</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.206912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>28.04</td>\n",
       "      <td>36.26</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>99.97</td>\n",
       "      <td>29.27</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.694124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>47.46</td>\n",
       "      <td>47.85</td>\n",
       "      <td>54.29</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.620129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.99</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.315097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>38.26</td>\n",
       "      <td>50.95</td>\n",
       "      <td>63.59</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.427666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.48</td>\n",
       "      <td>11.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.822111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>26.87</td>\n",
       "      <td>41.90</td>\n",
       "      <td>48.33</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.865212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50               13             15              0                    83.65   \n",
       "51                4             25              0                    64.23   \n",
       "52                2              2              0                     7.36   \n",
       "53                7              3              0                     9.00   \n",
       "54                2              8              0                    48.51   \n",
       "55                2              1              0                    57.22   \n",
       "56                3             12              0                    38.59   \n",
       "57                0              0              0                     7.93   \n",
       "58                1              7              0                    40.36   \n",
       "59                0              0              0                    30.36   \n",
       "60                1              3              0                    14.33   \n",
       "61                1              8              0                    74.32   \n",
       "62                2             60              0                    56.29   \n",
       "63                7             30              0                    28.04   \n",
       "64                3              8              0                    47.46   \n",
       "65                4              0              0                     6.03   \n",
       "66               15             17              0                    38.26   \n",
       "67                0              0              0                     9.48   \n",
       "68                2             10              0                    26.87   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                     69.14                     26.07           79.42   \n",
       "51                     57.55                     70.79           97.61   \n",
       "52                     10.01                     25.70            4.73   \n",
       "53                     66.92                     61.40           66.44   \n",
       "54                     55.93                     63.85           46.37   \n",
       "55                     37.96                     52.72           32.87   \n",
       "56                     31.92                     33.52           44.72   \n",
       "57                     12.74                     10.22           10.34   \n",
       "58                     72.15                     47.00           81.74   \n",
       "59                      7.50                      4.78            3.77   \n",
       "60                     21.72                     12.48           29.07   \n",
       "61                     66.79                     40.39           60.62   \n",
       "62                     70.34                     51.43           42.65   \n",
       "63                     36.26                     44.33            1.49   \n",
       "64                     47.85                     54.29           35.06   \n",
       "65                     13.21                      3.99           14.24   \n",
       "66                     50.95                     63.59           93.14   \n",
       "67                     11.70                      3.17            6.09   \n",
       "68                     41.90                     48.33           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2 meth1_similarites  \\\n",
       "50            9.45             95.91             41.50             256.4   \n",
       "51            8.36             96.46             11.05             165.4   \n",
       "52            8.62             99.99             32.26              80.7   \n",
       "53           10.38             97.21             16.85             564.1   \n",
       "54            8.59             83.60             30.36             374.8   \n",
       "55           10.75             18.59             33.70             130.0   \n",
       "56            9.49              7.46             28.30             138.8   \n",
       "57           10.07             99.87             46.52              21.1   \n",
       "58           11.49             99.90             34.50             223.8   \n",
       "59           13.04             91.10             36.71              50.7   \n",
       "60            8.22              0.16             35.38             120.0   \n",
       "61           10.50             99.88             19.83             437.9   \n",
       "62           10.45             99.30             42.80             344.5   \n",
       "63            9.78             99.97             29.27             142.0   \n",
       "64           10.08             97.33             30.89              21.2   \n",
       "65            8.91              1.03             20.16             174.0   \n",
       "66            9.39             99.98             31.05             176.2   \n",
       "67            8.37             99.84             29.93               8.8   \n",
       "68           10.33             99.54             27.09             150.3   \n",
       "\n",
       "   meth2_similarites  Overall        LR  \n",
       "50             301.4      1.0  0.591923  \n",
       "51             389.4      1.0  1.165432  \n",
       "52             215.1      4.0  3.646610  \n",
       "53             248.6      1.0  2.067664  \n",
       "54             339.8      1.0  1.736236  \n",
       "55             159.8      2.0  2.315933  \n",
       "56              74.0      2.0  2.236454  \n",
       "57              54.1      4.0  3.424757  \n",
       "58             170.8      2.0  1.316925  \n",
       "59              68.7      2.0  3.713748  \n",
       "60             228.2      4.0  2.463118  \n",
       "61             301.2      2.0  1.503630  \n",
       "62             485.7      1.0  0.206912  \n",
       "63             289.0      2.0  2.694124  \n",
       "64              35.8      3.0  2.620129  \n",
       "65             179.9      3.0  3.315097  \n",
       "66             258.7      1.0  1.427666  \n",
       "67              28.4      4.0  3.822111  \n",
       "68             114.6      3.0  2.865212  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(Xtrain[:50],ytrain[:50])\n",
    "res_lr = lr.predict(Xtrain[50:])\n",
    "res_lr = pd.concat([Xtrain[50:],ytrain[50:],pd.DataFrame(res_lr,columns = ['LR'],index = range(50,69))],axis=1)\n",
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final = pd.concat([res_final,res_lr['LR']],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remarque : les résultats sont assez différents : voir à utiliser différents algos ? <br/>\n",
    "En classification : Logistic Regression - XG Boost ?? - Linear Discriminant Analysis qui était OK en essai - Bayésien ? ADA Boost ? SVM ? : 1 score de classif en utilisant proba <br/>\n",
    "puis un score de régression : la Régression PLS peut être intéressante car les notes doivent très corrélées entre elles - Lasso ou ridge ne servent à rien a priori - SVR - RDN ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_entites_idem</th>\n",
       "      <th>nb_lieux_idem</th>\n",
       "      <th>nb_dates_idem</th>\n",
       "      <th>score_similarite_titres</th>\n",
       "      <th>score_similarite_resume1</th>\n",
       "      <th>score_similarite_resume2</th>\n",
       "      <th>score_classif1</th>\n",
       "      <th>score_classif2</th>\n",
       "      <th>score_sentiment1</th>\n",
       "      <th>score_sentiment2</th>\n",
       "      <th>meth1_similarites</th>\n",
       "      <th>meth2_similarites</th>\n",
       "      <th>Overall</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>83.65</td>\n",
       "      <td>69.14</td>\n",
       "      <td>26.07</td>\n",
       "      <td>79.42</td>\n",
       "      <td>9.45</td>\n",
       "      <td>95.91</td>\n",
       "      <td>41.50</td>\n",
       "      <td>256.4</td>\n",
       "      <td>301.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.591923</td>\n",
       "      <td>1.030360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>64.23</td>\n",
       "      <td>57.55</td>\n",
       "      <td>70.79</td>\n",
       "      <td>97.61</td>\n",
       "      <td>8.36</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11.05</td>\n",
       "      <td>165.4</td>\n",
       "      <td>389.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.165432</td>\n",
       "      <td>1.382881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.01</td>\n",
       "      <td>25.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.62</td>\n",
       "      <td>99.99</td>\n",
       "      <td>32.26</td>\n",
       "      <td>80.7</td>\n",
       "      <td>215.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.646610</td>\n",
       "      <td>3.459383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>66.92</td>\n",
       "      <td>61.40</td>\n",
       "      <td>66.44</td>\n",
       "      <td>10.38</td>\n",
       "      <td>97.21</td>\n",
       "      <td>16.85</td>\n",
       "      <td>564.1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.067664</td>\n",
       "      <td>1.721224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>48.51</td>\n",
       "      <td>55.93</td>\n",
       "      <td>63.85</td>\n",
       "      <td>46.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>83.60</td>\n",
       "      <td>30.36</td>\n",
       "      <td>374.8</td>\n",
       "      <td>339.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.736236</td>\n",
       "      <td>1.753070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.22</td>\n",
       "      <td>37.96</td>\n",
       "      <td>52.72</td>\n",
       "      <td>32.87</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>159.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.315933</td>\n",
       "      <td>2.308580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>38.59</td>\n",
       "      <td>31.92</td>\n",
       "      <td>33.52</td>\n",
       "      <td>44.72</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.46</td>\n",
       "      <td>28.30</td>\n",
       "      <td>138.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.236454</td>\n",
       "      <td>2.483379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.93</td>\n",
       "      <td>12.74</td>\n",
       "      <td>10.22</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.07</td>\n",
       "      <td>99.87</td>\n",
       "      <td>46.52</td>\n",
       "      <td>21.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.424757</td>\n",
       "      <td>3.614719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>40.36</td>\n",
       "      <td>72.15</td>\n",
       "      <td>47.00</td>\n",
       "      <td>81.74</td>\n",
       "      <td>11.49</td>\n",
       "      <td>99.90</td>\n",
       "      <td>34.50</td>\n",
       "      <td>223.8</td>\n",
       "      <td>170.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.316925</td>\n",
       "      <td>1.740797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.78</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13.04</td>\n",
       "      <td>91.10</td>\n",
       "      <td>36.71</td>\n",
       "      <td>50.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.713748</td>\n",
       "      <td>3.832773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>21.72</td>\n",
       "      <td>12.48</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.38</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.463118</td>\n",
       "      <td>2.654394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>74.32</td>\n",
       "      <td>66.79</td>\n",
       "      <td>40.39</td>\n",
       "      <td>60.62</td>\n",
       "      <td>10.50</td>\n",
       "      <td>99.88</td>\n",
       "      <td>19.83</td>\n",
       "      <td>437.9</td>\n",
       "      <td>301.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.503630</td>\n",
       "      <td>1.716132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>56.29</td>\n",
       "      <td>70.34</td>\n",
       "      <td>51.43</td>\n",
       "      <td>42.65</td>\n",
       "      <td>10.45</td>\n",
       "      <td>99.30</td>\n",
       "      <td>42.80</td>\n",
       "      <td>344.5</td>\n",
       "      <td>485.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.206912</td>\n",
       "      <td>1.637124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>28.04</td>\n",
       "      <td>36.26</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>99.97</td>\n",
       "      <td>29.27</td>\n",
       "      <td>142.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.694124</td>\n",
       "      <td>2.927832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>47.46</td>\n",
       "      <td>47.85</td>\n",
       "      <td>54.29</td>\n",
       "      <td>35.06</td>\n",
       "      <td>10.08</td>\n",
       "      <td>97.33</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.620129</td>\n",
       "      <td>2.700901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.99</td>\n",
       "      <td>14.24</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>20.16</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.315097</td>\n",
       "      <td>3.126964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>38.26</td>\n",
       "      <td>50.95</td>\n",
       "      <td>63.59</td>\n",
       "      <td>93.14</td>\n",
       "      <td>9.39</td>\n",
       "      <td>99.98</td>\n",
       "      <td>31.05</td>\n",
       "      <td>176.2</td>\n",
       "      <td>258.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.427666</td>\n",
       "      <td>1.360300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.48</td>\n",
       "      <td>11.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.37</td>\n",
       "      <td>99.84</td>\n",
       "      <td>29.93</td>\n",
       "      <td>8.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.822111</td>\n",
       "      <td>3.832011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>26.87</td>\n",
       "      <td>41.90</td>\n",
       "      <td>48.33</td>\n",
       "      <td>26.10</td>\n",
       "      <td>10.33</td>\n",
       "      <td>99.54</td>\n",
       "      <td>27.09</td>\n",
       "      <td>150.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.865212</td>\n",
       "      <td>2.902245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_entites_idem  nb_lieux_idem  nb_dates_idem  score_similarite_titres  \\\n",
       "50               13             15              0                    83.65   \n",
       "51                4             25              0                    64.23   \n",
       "52                2              2              0                     7.36   \n",
       "53                7              3              0                     9.00   \n",
       "54                2              8              0                    48.51   \n",
       "55                2              1              0                    57.22   \n",
       "56                3             12              0                    38.59   \n",
       "57                0              0              0                     7.93   \n",
       "58                1              7              0                    40.36   \n",
       "59                0              0              0                    30.36   \n",
       "60                1              3              0                    14.33   \n",
       "61                1              8              0                    74.32   \n",
       "62                2             60              0                    56.29   \n",
       "63                7             30              0                    28.04   \n",
       "64                3              8              0                    47.46   \n",
       "65                4              0              0                     6.03   \n",
       "66               15             17              0                    38.26   \n",
       "67                0              0              0                     9.48   \n",
       "68                2             10              0                    26.87   \n",
       "\n",
       "    score_similarite_resume1  score_similarite_resume2  score_classif1  \\\n",
       "50                     69.14                     26.07           79.42   \n",
       "51                     57.55                     70.79           97.61   \n",
       "52                     10.01                     25.70            4.73   \n",
       "53                     66.92                     61.40           66.44   \n",
       "54                     55.93                     63.85           46.37   \n",
       "55                     37.96                     52.72           32.87   \n",
       "56                     31.92                     33.52           44.72   \n",
       "57                     12.74                     10.22           10.34   \n",
       "58                     72.15                     47.00           81.74   \n",
       "59                      7.50                      4.78            3.77   \n",
       "60                     21.72                     12.48           29.07   \n",
       "61                     66.79                     40.39           60.62   \n",
       "62                     70.34                     51.43           42.65   \n",
       "63                     36.26                     44.33            1.49   \n",
       "64                     47.85                     54.29           35.06   \n",
       "65                     13.21                      3.99           14.24   \n",
       "66                     50.95                     63.59           93.14   \n",
       "67                     11.70                      3.17            6.09   \n",
       "68                     41.90                     48.33           26.10   \n",
       "\n",
       "    score_classif2  score_sentiment1  score_sentiment2 meth1_similarites  \\\n",
       "50            9.45             95.91             41.50             256.4   \n",
       "51            8.36             96.46             11.05             165.4   \n",
       "52            8.62             99.99             32.26              80.7   \n",
       "53           10.38             97.21             16.85             564.1   \n",
       "54            8.59             83.60             30.36             374.8   \n",
       "55           10.75             18.59             33.70             130.0   \n",
       "56            9.49              7.46             28.30             138.8   \n",
       "57           10.07             99.87             46.52              21.1   \n",
       "58           11.49             99.90             34.50             223.8   \n",
       "59           13.04             91.10             36.71              50.7   \n",
       "60            8.22              0.16             35.38             120.0   \n",
       "61           10.50             99.88             19.83             437.9   \n",
       "62           10.45             99.30             42.80             344.5   \n",
       "63            9.78             99.97             29.27             142.0   \n",
       "64           10.08             97.33             30.89              21.2   \n",
       "65            8.91              1.03             20.16             174.0   \n",
       "66            9.39             99.98             31.05             176.2   \n",
       "67            8.37             99.84             29.93               8.8   \n",
       "68           10.33             99.54             27.09             150.3   \n",
       "\n",
       "   meth2_similarites  Overall        LR       PLS  \n",
       "50             301.4      1.0  0.591923  1.030360  \n",
       "51             389.4      1.0  1.165432  1.382881  \n",
       "52             215.1      4.0  3.646610  3.459383  \n",
       "53             248.6      1.0  2.067664  1.721224  \n",
       "54             339.8      1.0  1.736236  1.753070  \n",
       "55             159.8      2.0  2.315933  2.308580  \n",
       "56              74.0      2.0  2.236454  2.483379  \n",
       "57              54.1      4.0  3.424757  3.614719  \n",
       "58             170.8      2.0  1.316925  1.740797  \n",
       "59              68.7      2.0  3.713748  3.832773  \n",
       "60             228.2      4.0  2.463118  2.654394  \n",
       "61             301.2      2.0  1.503630  1.716132  \n",
       "62             485.7      1.0  0.206912  1.637124  \n",
       "63             289.0      2.0  2.694124  2.927832  \n",
       "64              35.8      3.0  2.620129  2.700901  \n",
       "65             179.9      3.0  3.315097  3.126964  \n",
       "66             258.7      1.0  1.427666  1.360300  \n",
       "67              28.4      4.0  3.822111  3.832011  \n",
       "68             114.6      3.0  2.865212  2.902245  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls = PLSRegression()\n",
    "pls.fit(Xtrain[:50],ytrain[:50])\n",
    "res_pls = list(pls.predict(Xtrain[50:]).flatten())\n",
    "res_pls = pd.concat([res_lr,pd.DataFrame(res_pls,columns = ['PLS'],index = range(50,69))],axis=1)\n",
    "res_pls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les scores de la regression PLS sont assez proches de la régression linéaire !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>RF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LOGR</th>\n",
       "      <th>ADA</th>\n",
       "      <th>RF_Prob</th>\n",
       "      <th>LDA_Prob</th>\n",
       "      <th>KNN_Prob</th>\n",
       "      <th>LOGR_Prob</th>\n",
       "      <th>ADA_Prob</th>\n",
       "      <th>LR</th>\n",
       "      <th>PLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.591923</td>\n",
       "      <td>1.030360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.165432</td>\n",
       "      <td>1.382881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.646610</td>\n",
       "      <td>3.459383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.067664</td>\n",
       "      <td>1.721224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.736236</td>\n",
       "      <td>1.753070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.315933</td>\n",
       "      <td>2.308580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.236454</td>\n",
       "      <td>2.483379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.424757</td>\n",
       "      <td>3.614719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.316925</td>\n",
       "      <td>1.740797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.713748</td>\n",
       "      <td>3.832773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.463118</td>\n",
       "      <td>2.654394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.503630</td>\n",
       "      <td>1.716132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.206912</td>\n",
       "      <td>1.637124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.694124</td>\n",
       "      <td>2.927832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.620129</td>\n",
       "      <td>2.700901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.315097</td>\n",
       "      <td>3.126964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.427666</td>\n",
       "      <td>1.360300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.822111</td>\n",
       "      <td>3.832011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.865212</td>\n",
       "      <td>2.902245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Overall  RF  LDA  KNN  LOGR  ADA  RF_Prob  LDA_Prob  KNN_Prob  LOGR_Prob  \\\n",
       "50        1   1    2    2     2    2        1         2         2          2   \n",
       "51        1   1    1    3     1    3        1         1         3          3   \n",
       "52        4   3    4    3     3    3        3         4         3          3   \n",
       "53        1   1    1    1     1    1        1         1         1          1   \n",
       "54        1   1    1    1     1    1        1         1         1          1   \n",
       "55        2   2    3    4     3    4        2         3         3          3   \n",
       "56        2   3    3    4     2    4        3         3         4          4   \n",
       "57        4   4    3    4     4    4        4         3         4          4   \n",
       "58        2   1    1    1     1    1        1         1         2          2   \n",
       "59        2   4    3    3     4    3        4         3         3          3   \n",
       "60        4   3    3    3     2    3        3         3         3          3   \n",
       "61        2   1    1    1     1    1        1         1         1          1   \n",
       "62        1   1    2    1     3    1        1         2         2          2   \n",
       "63        2   3    3    2     3    2        2         3         2          2   \n",
       "64        3   1    3    4     4    4        2         3         4          4   \n",
       "65        3   4    4    3     2    3        4         4         3          3   \n",
       "66        1   1    2    2     2    2        1         2         2          2   \n",
       "67        4   4    4    4     4    4        4         4         4          4   \n",
       "68        3   2    3    4     3    4        2         3         4          4   \n",
       "\n",
       "    ADA_Prob        LR       PLS  \n",
       "50         2  0.591923  1.030360  \n",
       "51         3  1.165432  1.382881  \n",
       "52         3  3.646610  3.459383  \n",
       "53         1  2.067664  1.721224  \n",
       "54         1  1.736236  1.753070  \n",
       "55         3  2.315933  2.308580  \n",
       "56         4  2.236454  2.483379  \n",
       "57         4  3.424757  3.614719  \n",
       "58         2  1.316925  1.740797  \n",
       "59         3  3.713748  3.832773  \n",
       "60         3  2.463118  2.654394  \n",
       "61         1  1.503630  1.716132  \n",
       "62         2  0.206912  1.637124  \n",
       "63         2  2.694124  2.927832  \n",
       "64         4  2.620129  2.700901  \n",
       "65         3  3.315097  3.126964  \n",
       "66         2  1.427666  1.360300  \n",
       "67         4  3.822111  3.832011  \n",
       "68         4  2.865212  2.902245  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final = pd.concat([res_final,res_pls['PLS']],axis=1)\n",
    "res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compléments d'information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuel = francais[['title_1', 'title_2','summary1_text1', 'summary2_text1', 'summary1_text2', 'summary2_text2',\n",
    "    'nb_entites_idem', 'nb_lieux_idem', 'nb_dates_idem', 'entites_idem','dates_idem', 'score_similarite_titres',\n",
    "    'score_similarite_resume1', 'score_similarite_resume2','score_classif1', 'score_classif2', 'score_sentiment1',\n",
    "    'score_sentiment2', 'meth1_similarites', 'meth2_similarites','Overall']]\n",
    "visuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pair_id', 'pair_lang', 'source_url_1', 'publish_date_1',\n",
       "       'source_url_2', 'publish_date_2', 'title_1', 'text_1',\n",
       "       'meta_description_1', 'meta_keywords_1', 'title_2', 'text_2',\n",
       "       'meta_description_2', 'meta_keywords_2', 'Geography', 'Entities',\n",
       "       'Time', 'Narrative', 'Overall', 'Style', 'Tone', 'ligne'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_francais = data.loc[data.pair_lang == 'fr_fr',['source_url_1', 'publish_date_1','source_url_2', 'publish_date_2', \n",
    "       'meta_description_1', 'meta_keywords_1', 'meta_description_2', 'meta_keywords_2','Overall']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_url_1</th>\n",
       "      <th>publish_date_1</th>\n",
       "      <th>source_url_2</th>\n",
       "      <th>publish_date_2</th>\n",
       "      <th>meta_description_1</th>\n",
       "      <th>meta_keywords_1</th>\n",
       "      <th>meta_description_2</th>\n",
       "      <th>meta_keywords_2</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://votreargent.lexpress.fr</td>\n",
       "      <td>Wed Mar 25 20:11:35 2020</td>\n",
       "      <td>https://www.lexpress.fr</td>\n",
       "      <td>Wed Mar 25 07:00:00 2020</td>\n",
       "      <td>Le cap du million de ventes a été dépassé l'an...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Stocks réduits ou distribués au \"compte-goutte...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.coupdoeil.info</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>http://www.lechodelaval.ca</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://ici.radio-canada.ca</td>\n",
       "      <td></td>\n",
       "      <td>https://www.lapresse.ca</td>\n",
       "      <td>Wed Mar 25 05:00:00 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>Des Québécois coincés au Pérou qualifient de «...</td>\n",
       "      <td>['']</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://beninsite.net</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>http://www.togolais.info</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>En l'espace de quelques jours, deux piliers de...</td>\n",
       "      <td>[\"L'Afrique pleure Manu Dibango\", '', 'info', ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.lareleve.qc.ca</td>\n",
       "      <td>Wed Mar 25 00:00:00 2020</td>\n",
       "      <td>https://canadianwomen.org</td>\n",
       "      <td>Wed Mar 25 21:15:26 2020</td>\n",
       "      <td>La MRC a décidé de mettre de l’avant différent...</td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>https://www.bladi.net</td>\n",
       "      <td></td>\n",
       "      <td>https://www.bladi.net</td>\n",
       "      <td></td>\n",
       "      <td>Les forces de l’ordre effectuent des inspectio...</td>\n",
       "      <td>['']</td>\n",
       "      <td>Suite aux violations du confinement dans les v...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>http://ici.radio-canada.ca</td>\n",
       "      <td></td>\n",
       "      <td>https://www.journalexpress.ca</td>\n",
       "      <td>Wed May 27 00:00:00 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>http://fr.nhandan.com.vn</td>\n",
       "      <td></td>\n",
       "      <td>http://fr.nhandan.com.vn</td>\n",
       "      <td></td>\n",
       "      <td>Nhân Dân en ligne - Asiatoday, l'un des princi...</td>\n",
       "      <td>['Le journal Nhân Dân', 'politique', 'économie...</td>\n",
       "      <td>Nhân Dân en ligne - Le Premier ministre (PM) v...</td>\n",
       "      <td>['Le journal Nhân Dân', 'politique', 'économie...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>https://www.acadienouvelle.com</td>\n",
       "      <td>Thu Jun 11 00:00:00 2020</td>\n",
       "      <td>https://www.telecablesat.fr</td>\n",
       "      <td></td>\n",
       "      <td>Muriel Roy nous a quittés dans sa 100e année. ...</td>\n",
       "      <td>['Acadie']</td>\n",
       "      <td>Comment avez-vous vécu le confinement?Au début...</td>\n",
       "      <td>['']</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>https://benin24tv.com</td>\n",
       "      <td>Mon Mar  2 18:47:14 2020</td>\n",
       "      <td>https://www.seneplus.com</td>\n",
       "      <td>Sat Mar 28 14:02:20 2020</td>\n",
       "      <td></td>\n",
       "      <td>['']</td>\n",
       "      <td>Alors que le directeur de l’Organisation mondi...</td>\n",
       "      <td>['']</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source_url_1            publish_date_1  \\\n",
       "0   https://votreargent.lexpress.fr  Wed Mar 25 20:11:35 2020   \n",
       "1        https://www.coupdoeil.info  Wed Mar 25 00:00:00 2020   \n",
       "2        http://ici.radio-canada.ca                             \n",
       "3              http://beninsite.net  Wed Mar 25 00:00:00 2020   \n",
       "4        https://www.lareleve.qc.ca  Wed Mar 25 00:00:00 2020   \n",
       "..                              ...                       ...   \n",
       "67            https://www.bladi.net                             \n",
       "68       http://ici.radio-canada.ca                             \n",
       "69         http://fr.nhandan.com.vn                             \n",
       "70   https://www.acadienouvelle.com  Thu Jun 11 00:00:00 2020   \n",
       "71            https://benin24tv.com  Mon Mar  2 18:47:14 2020   \n",
       "\n",
       "                     source_url_2            publish_date_2  \\\n",
       "0         https://www.lexpress.fr  Wed Mar 25 07:00:00 2020   \n",
       "1      http://www.lechodelaval.ca                             \n",
       "2         https://www.lapresse.ca  Wed Mar 25 05:00:00 2020   \n",
       "3        http://www.togolais.info                             \n",
       "4       https://canadianwomen.org  Wed Mar 25 21:15:26 2020   \n",
       "..                            ...                       ...   \n",
       "67          https://www.bladi.net                             \n",
       "68  https://www.journalexpress.ca  Wed May 27 00:00:00 2020   \n",
       "69       http://fr.nhandan.com.vn                             \n",
       "70    https://www.telecablesat.fr                             \n",
       "71       https://www.seneplus.com  Sat Mar 28 14:02:20 2020   \n",
       "\n",
       "                                   meta_description_1  \\\n",
       "0   Le cap du million de ventes a été dépassé l'an...   \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4   La MRC a décidé de mettre de l’avant différent...   \n",
       "..                                                ...   \n",
       "67  Les forces de l’ordre effectuent des inspectio...   \n",
       "68                                                      \n",
       "69  Nhân Dân en ligne - Asiatoday, l'un des princi...   \n",
       "70  Muriel Roy nous a quittés dans sa 100e année. ...   \n",
       "71                                                      \n",
       "\n",
       "                                      meta_keywords_1  \\\n",
       "0                                                ['']   \n",
       "1                                                ['']   \n",
       "2                                                ['']   \n",
       "3                                                ['']   \n",
       "4                                                ['']   \n",
       "..                                                ...   \n",
       "67                                               ['']   \n",
       "68                                               ['']   \n",
       "69  ['Le journal Nhân Dân', 'politique', 'économie...   \n",
       "70                                         ['Acadie']   \n",
       "71                                               ['']   \n",
       "\n",
       "                                   meta_description_2  \\\n",
       "0   Stocks réduits ou distribués au \"compte-goutte...   \n",
       "1                                                       \n",
       "2   Des Québécois coincés au Pérou qualifient de «...   \n",
       "3   En l'espace de quelques jours, deux piliers de...   \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "67  Suite aux violations du confinement dans les v...   \n",
       "68                                                      \n",
       "69  Nhân Dân en ligne - Le Premier ministre (PM) v...   \n",
       "70  Comment avez-vous vécu le confinement?Au début...   \n",
       "71  Alors que le directeur de l’Organisation mondi...   \n",
       "\n",
       "                                      meta_keywords_2  Overall  \n",
       "0                                                ['']      3.0  \n",
       "1                                                ['']      4.0  \n",
       "2                                                ['']      2.0  \n",
       "3   [\"L'Afrique pleure Manu Dibango\", '', 'info', ...      1.0  \n",
       "4                                                ['']      3.0  \n",
       "..                                                ...      ...  \n",
       "67                                               ['']      3.0  \n",
       "68                                               ['']      3.0  \n",
       "69  ['Le journal Nhân Dân', 'politique', 'économie...      1.0  \n",
       "70                                               ['']      4.0  \n",
       "71                                               ['']      3.0  \n",
       "\n",
       "[72 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_francais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
